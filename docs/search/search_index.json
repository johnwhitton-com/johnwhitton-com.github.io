{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"template/","text":"Please use this template as a guide when creating pages for Docs. All pages use Markdown (cheat sheet here ) so be sure to use .md as the extension when creating the page file. Click here for an example of what a fully-fledged page looks like. [Template Begin] title: [Page Title] - Docs [Leave a blank line] description: [Meta description (155 characters recommended) [Leave a blank line] Page Heading [H1] Summary [H2] A summary of what the page is about. Features [H2] Main features. Sub-feature 1 [H3] Content for sub-feature 1. Sub-feature 2 [H3] Content for sub-feature 2. Resources [H2] Relevant resources like website, github link, blog posts etc go here [Template End]","title":"Template"},{"location":"template/#please-use-this-template-as-a-guide-when-creating-pages-for-docs-all-pages-use-markdown-cheat-sheet-here-so-be-sure-to-use-md-as-the-extension-when-creating-the-page-file","text":"","title":"Please use this template as a guide when creating pages for Docs. All pages use Markdown (cheat sheet here) so be sure to use .md as the extension when creating the page file."},{"location":"template/#click-here-for-an-example-of-what-a-fully-fledged-page-looks-like","text":"","title":"Click here for an example of what a fully-fledged page looks like."},{"location":"template/#template-begin","text":"title: [Page Title] - Docs [Leave a blank line] description: [Meta description (155 characters recommended) [Leave a blank line]","title":"[Template Begin]"},{"location":"template/#page-heading-h1","text":"","title":"Page Heading [H1]"},{"location":"template/#summary-h2","text":"A summary of what the page is about.","title":"Summary [H2]"},{"location":"template/#features-h2","text":"Main features.","title":"Features [H2]"},{"location":"template/#sub-feature-1-h3","text":"Content for sub-feature 1.","title":"Sub-feature 1 [H3]"},{"location":"template/#sub-feature-2-h3","text":"Content for sub-feature 2.","title":"Sub-feature 2 [H3]"},{"location":"template/#resources-h2","text":"Relevant resources like website, github link, blog posts etc go here","title":"Resources [H2]"},{"location":"template/#template-end","text":"","title":"[Template End]"},{"location":"api/orientation/","text":"Orientation This provides API documentation and tools for integrating with a blockchain.","title":"Orientation"},{"location":"api/orientation/#orientation","text":"This provides API documentation and tools for integrating with a blockchain.","title":"Orientation"},{"location":"basics/orientation/","text":"What is this Playground for? John created this site to capture the knowledge and share tools around blockchain ecoystems. The site is meant for not just DApp and Smart Contract developers but the larger blockchain ecosystem developer community including core protocol developers, tooling (API, SDK, IDE, etc) developers and centralized applications that integrate with blockchains such as exchanges, oracles and fintech applications. The initial library will focus heavily on the Harmony Protocol one of theleaders in high performant, sharded, proof of stake layer 1 protocols. Blockchain basics for non developers The purpose of this page is to give an overview of a blockchain ecosystem and how developers may contribute to it. For an overview of the basics from a non-developer viewpoint we recommend reading one of the following Harmony Introduction Ethereum Basics Near Protocol Basics For further information please see the links to other blockchain protocol documentataion in the resources section","title":"What is this Playground for?"},{"location":"basics/orientation/#what-is-this-playground-for","text":"John created this site to capture the knowledge and share tools around blockchain ecoystems. The site is meant for not just DApp and Smart Contract developers but the larger blockchain ecosystem developer community including core protocol developers, tooling (API, SDK, IDE, etc) developers and centralized applications that integrate with blockchains such as exchanges, oracles and fintech applications. The initial library will focus heavily on the Harmony Protocol one of theleaders in high performant, sharded, proof of stake layer 1 protocols.","title":"What is this Playground for?"},{"location":"basics/orientation/#blockchain-basics-for-non-developers","text":"The purpose of this page is to give an overview of a blockchain ecosystem and how developers may contribute to it. For an overview of the basics from a non-developer viewpoint we recommend reading one of the following Harmony Introduction Ethereum Basics Near Protocol Basics For further information please see the links to other blockchain protocol documentataion in the resources section","title":"Blockchain basics for non developers"},{"location":"basics/sample/","text":"Sample Blockchain Ecosystem Layer 1 blockchain protocols need to evolve a complete ecosystem in order to drive adoption and be sucessful. Two years ago John was designing a layer 1 protocol which leveraged the quality work done by the Ethereum Enterprise Alliance . The following is a draft blockchain landscape called project-x which built upon that foundation, it may be somewhat outdated as 2 years is a very long time in the blockchain space. We show it here for reference as, although the technologies have evolved, it still provides a good overview of what a blockchain ecosystem requires to be succesful.","title":"Sample Blockchain Ecosystem"},{"location":"basics/sample/#sample-blockchain-ecosystem","text":"Layer 1 blockchain protocols need to evolve a complete ecosystem in order to drive adoption and be sucessful. Two years ago John was designing a layer 1 protocol which leveraged the quality work done by the Ethereum Enterprise Alliance . The following is a draft blockchain landscape called project-x which built upon that foundation, it may be somewhat outdated as 2 years is a very long time in the blockchain space. We show it here for reference as, although the technologies have evolved, it still provides a good overview of what a blockchain ecosystem requires to be succesful.","title":"Sample Blockchain Ecosystem"},{"location":"contribute/breakdown/","text":"Ecosystem Breakdown for Developers Following are the key components and repositories for the Harmony Ecosystem covered in this guide. Protocol Developers Harmony Protocol : Harmony Core Protocol Consensus : Harmony Sharded Proof of Work with BLS key signing, VDR and VDF. LIBP2P Networking : Harmony Networking layer for transaction and block processing. Open Staking : Harmony Open Staking design. Execution EVM : Harmony virutal machine (EVM compatible). Harmony Roadmp Validator Resharding Shard Agnositic Privacy Primitives Zero Knowledge Proofs Network Operations Continuous Deployment Network Deployment experiment-deploy : Repository for conducting benchmark experiments harmony-ops : Harmony Ops Master Repository. Continuous Integration Continuous Deployment (CICD) Pipeline Harmony Test Framework - Harmony TF is a Test Framework for testing various types of test cases and transactions on Harmony's blockchain. Harmony Stress - Stress testing tools for Harmony. Monitoring and Analytics Monitoring Tools watchdog : Monitors Harmony network checking software versions, consensus, block creation and triggers alerts for issues. monitor : Project for https://monitor.hmny.io Analytics harmony-log-analysis : Harmony Log Analysis and Visualization pyhmy : A Python library for interacting and working with the harmony blockchain. Validator Tools harmony-tui : Text based user interface for Harmony node auto-node : Run a harmony node with 1 command! go-sdk : Go-SDK & CLI tool to interact with the Harmony Blockchain Documentation harmony-ops : Harmony Foundational Node Success Guide Explorers and Dashboards staking-dashboard : Harmony Staking Dashboard harmony-dashboard : Harmony Explorer Front End https://explorer.harmony.one TOOLING Development Environment Testnets Hosted API Endpoints Harmony GraphQL Profiling Suite Client Interfaces API backend.go : Harmony API definitions Harmony Open API Specification Generated Clients Protobuf client Postman documentation Client Interfaces SDKS go-sdk : Go-SDK & CLI tool to interact with the Harmony Blockchain go-lib : While go-sdk is an actual program/CLI this library is solely designed to be used/referenced by other tools and applications. sdk : Javascript SDK of Harmony protocol. harmonyj : Harmony Java SDK Web Based Tools Web Based IDE Remix Plugin Chain ide \" Web based IDE developed by White Matrix. TryCrypto DappStarter : DappStarter is a full stack development environment for blockchains. video Local IDE Harmony Deploy Harmony Ganache Harmony Truffle Integration Smart Contract Knowledgebase Smart Contract Standards openzepplin-contract : Harmony leverges open zepplins EVM compatible smart contract standards. Smart Contract Examples HRC : HRC token standards dapp-examples : harmony-sdk examples Smart Contract Protocols Deployed on Harmony DApp Developer Tools docs-developer : Developer Documentation DeFi Primitives Stable Coins busd-contract : Harmony Protocol Deployment of Binance USD (BUSD) Liquidity Pools Wrapped ONE Privacy rings-dapp : This is an Harmony transaction mixer that ultilizes parts of CryptoNote to enable zero-knowledge transactions. Ported from Heiswap from Ethureum. Integration Primitives Oracles KYC fiat on ramps InterChain native-bridge : Native ONE token bridge with BEP2/ERC20 ONE Wallets Cold Wallets *Trust wallet * wallet-core : Trust Wallet Core is a cross-platform library that implements low-level cryptographic wallet functionality for all supported blockchains * blockatlas : Block Atlas by Trust Wallet - Forked for Harmony Use Ledger ledger-app-one : Ledger hardware wallet support for Harmony ONE. ledger-jarmony-js : Web2USB/Javascript driver for Harmony on Ledger Nano S Hot Wallets Harmony Chrome Extension Mathwallet HRC20 Support Developer GAS DApp Developer Tools docs-developer : Developer Documentation DApp Development Tutorial dapp-examples : harmony-sdk examples Applications Exchanges CrossFi Applications MarketPlaces nft-store : NFT store sample dapp with client and server Gaming android-puzzle : Harmony Puzzle Game - Mobile version.","title":"Developer Breakdown"},{"location":"contribute/breakdown/#ecosystem-breakdown-for-developers","text":"Following are the key components and repositories for the Harmony Ecosystem covered in this guide.","title":"Ecosystem Breakdown for Developers"},{"location":"contribute/breakdown/#protocol-developers","text":"Harmony Protocol : Harmony Core Protocol Consensus : Harmony Sharded Proof of Work with BLS key signing, VDR and VDF. LIBP2P Networking : Harmony Networking layer for transaction and block processing. Open Staking : Harmony Open Staking design. Execution EVM : Harmony virutal machine (EVM compatible). Harmony Roadmp Validator Resharding Shard Agnositic Privacy Primitives Zero Knowledge Proofs","title":"Protocol Developers"},{"location":"contribute/breakdown/#network-operations","text":"Continuous Deployment Network Deployment experiment-deploy : Repository for conducting benchmark experiments harmony-ops : Harmony Ops Master Repository. Continuous Integration Continuous Deployment (CICD) Pipeline Harmony Test Framework - Harmony TF is a Test Framework for testing various types of test cases and transactions on Harmony's blockchain. Harmony Stress - Stress testing tools for Harmony. Monitoring and Analytics Monitoring Tools watchdog : Monitors Harmony network checking software versions, consensus, block creation and triggers alerts for issues. monitor : Project for https://monitor.hmny.io Analytics harmony-log-analysis : Harmony Log Analysis and Visualization pyhmy : A Python library for interacting and working with the harmony blockchain. Validator Tools harmony-tui : Text based user interface for Harmony node auto-node : Run a harmony node with 1 command! go-sdk : Go-SDK & CLI tool to interact with the Harmony Blockchain Documentation harmony-ops : Harmony Foundational Node Success Guide Explorers and Dashboards staking-dashboard : Harmony Staking Dashboard harmony-dashboard : Harmony Explorer Front End https://explorer.harmony.one","title":"Network Operations"},{"location":"contribute/breakdown/#tooling","text":"Development Environment Testnets Hosted API Endpoints Harmony GraphQL Profiling Suite Client Interfaces API backend.go : Harmony API definitions Harmony Open API Specification Generated Clients Protobuf client Postman documentation Client Interfaces SDKS go-sdk : Go-SDK & CLI tool to interact with the Harmony Blockchain go-lib : While go-sdk is an actual program/CLI this library is solely designed to be used/referenced by other tools and applications. sdk : Javascript SDK of Harmony protocol. harmonyj : Harmony Java SDK Web Based Tools Web Based IDE Remix Plugin Chain ide \" Web based IDE developed by White Matrix. TryCrypto DappStarter : DappStarter is a full stack development environment for blockchains. video Local IDE Harmony Deploy Harmony Ganache Harmony Truffle Integration Smart Contract Knowledgebase Smart Contract Standards openzepplin-contract : Harmony leverges open zepplins EVM compatible smart contract standards. Smart Contract Examples HRC : HRC token standards dapp-examples : harmony-sdk examples Smart Contract Protocols Deployed on Harmony DApp Developer Tools docs-developer : Developer Documentation DeFi Primitives Stable Coins busd-contract : Harmony Protocol Deployment of Binance USD (BUSD) Liquidity Pools Wrapped ONE Privacy rings-dapp : This is an Harmony transaction mixer that ultilizes parts of CryptoNote to enable zero-knowledge transactions. Ported from Heiswap from Ethureum. Integration Primitives Oracles KYC fiat on ramps InterChain native-bridge : Native ONE token bridge with BEP2/ERC20 ONE Wallets Cold Wallets *Trust wallet * wallet-core : Trust Wallet Core is a cross-platform library that implements low-level cryptographic wallet functionality for all supported blockchains * blockatlas : Block Atlas by Trust Wallet - Forked for Harmony Use Ledger ledger-app-one : Ledger hardware wallet support for Harmony ONE. ledger-jarmony-js : Web2USB/Javascript driver for Harmony on Ledger Nano S Hot Wallets Harmony Chrome Extension Mathwallet HRC20 Support Developer GAS DApp Developer Tools docs-developer : Developer Documentation DApp Development Tutorial dapp-examples : harmony-sdk examples","title":"TOOLING"},{"location":"contribute/breakdown/#applications","text":"Exchanges CrossFi Applications MarketPlaces nft-store : NFT store sample dapp with client and server Gaming android-puzzle : Harmony Puzzle Game - Mobile version.","title":"Applications"},{"location":"contribute/grants/","text":"Grant Proposals Please review the latest Harmony Grant Process as it has the most up to date information We activates our community through our grant program to grow our protocol and ecosystem. Applicants can apply for grants to build core protocol features, developer tooling, and critical applications including wallets and financial applications. Ecosystem and Protocol Incentives We plan to actively use our ecosystem and protocol monthly unlocking tokens, see https://harmony.one/unlock . Every month, our model unlocks 62 million ecosystem tokens to boost growth in our applications and users plus 92 million protocol tokens to boost growth in our developers and tooling. Areas of Focus We will provide grants to decentralized finance (DeFi) projects with 1,000+ users and to wallets with 10,000+ users that are fully integrated with our mainnet. Also, we will give grants to blockchain hackers to build BTC/ETH bridges and Truffle tooling and fintech developers to create identity and currency gateways that are fully integrated with our mainnet and SDK. Contributing Review the Layer One Improvement Process See the active Grants here . Collaborate with us on discord or get started today by submitting a proposal to grants@harmony.one. Submit your suggestion using the Layer One improvement template . Grant Working Process Moving forwards for ecosytem grants the following process is suggested Grant proposals are documented as a ticket in the Grant repository Once approved a page is added to the wiki for the grant component This page trackes the grant process Upon complettion the page is updated to include a user guide The information is also added to the ecoystem guide","title":"Grants"},{"location":"contribute/grants/#grant-proposals","text":"Please review the latest Harmony Grant Process as it has the most up to date information We activates our community through our grant program to grow our protocol and ecosystem. Applicants can apply for grants to build core protocol features, developer tooling, and critical applications including wallets and financial applications.","title":"Grant Proposals"},{"location":"contribute/grants/#ecosystem-and-protocol-incentives","text":"We plan to actively use our ecosystem and protocol monthly unlocking tokens, see https://harmony.one/unlock . Every month, our model unlocks 62 million ecosystem tokens to boost growth in our applications and users plus 92 million protocol tokens to boost growth in our developers and tooling.","title":"Ecosystem and Protocol Incentives"},{"location":"contribute/grants/#areas-of-focus","text":"We will provide grants to decentralized finance (DeFi) projects with 1,000+ users and to wallets with 10,000+ users that are fully integrated with our mainnet. Also, we will give grants to blockchain hackers to build BTC/ETH bridges and Truffle tooling and fintech developers to create identity and currency gateways that are fully integrated with our mainnet and SDK.","title":"Areas of Focus"},{"location":"contribute/grants/#contributing","text":"Review the Layer One Improvement Process See the active Grants here . Collaborate with us on discord or get started today by submitting a proposal to grants@harmony.one. Submit your suggestion using the Layer One improvement template .","title":"Contributing"},{"location":"contribute/grants/#grant-working-process","text":"Moving forwards for ecosytem grants the following process is suggested Grant proposals are documented as a ticket in the Grant repository Once approved a page is added to the wiki for the grant component This page trackes the grant process Upon complettion the page is updated to include a user guide The information is also added to the ecoystem guide","title":"Grant Working Process"},{"location":"contribute/harmony/","text":"Harmony Ecosystem Harmony has built not only a peformant scalable layer 1 blockchain, but also a robust ecosystem. The diagram below gives an overview of the components comprising the ecosystem. Harmony is actively working on enhancing the ecosysttem using Harmony Ecosystem Grants. The ecosystem diagram below gives an overview of the current state of the Harmony ecoystem, contribution is grouped into 4 categories. Harmony Core: these components have been built by the harmony core team Harmony Contributors: these components have already been built by individual contributors Harmony Partners: these components have already been built by partners and are typically stand alone applications such as exchanges, wallets and marketplaces Ecosystem Grants: harmony is providing a comprehensive grant process for contributors to build out these components (please see Grants ) Harmony Ecosystem Diagram The below diagram can be clicked upon to bring up an interactive image linking to all the component documentation.","title":"Overview"},{"location":"contribute/harmony/#harmony-ecosystem","text":"Harmony has built not only a peformant scalable layer 1 blockchain, but also a robust ecosystem. The diagram below gives an overview of the components comprising the ecosystem. Harmony is actively working on enhancing the ecosysttem using Harmony Ecosystem Grants. The ecosystem diagram below gives an overview of the current state of the Harmony ecoystem, contribution is grouped into 4 categories. Harmony Core: these components have been built by the harmony core team Harmony Contributors: these components have already been built by individual contributors Harmony Partners: these components have already been built by partners and are typically stand alone applications such as exchanges, wallets and marketplaces Ecosystem Grants: harmony is providing a comprehensive grant process for contributors to build out these components (please see Grants )","title":"Harmony Ecosystem"},{"location":"contribute/harmony/#harmony-ecosystem-diagram","text":"The below diagram can be clicked upon to bring up an interactive image linking to all the component documentation.","title":"Harmony Ecosystem Diagram"},{"location":"contribute/orientation/","text":"Orientation This section discusses grants and how to contribute to the codebase.","title":"Orientation"},{"location":"contribute/orientation/#orientation","text":"This section discusses grants and how to contribute to the codebase.","title":"Orientation"},{"location":"contribute/apps/blockexplorer/","text":"Component Name Overview Functional overview of what this component does Status - Built, Q2, Roadmap, Tenative Business Driver Ecosystem Grant - Eligible, Priority, Amount Deliverable Technical Specification Reference Material Level of Effort Developer or Partner Identified Harmony Owner Developer Guide","title":"Block Explorer"},{"location":"contribute/apps/blockexplorer/#component-name","text":"","title":"Component Name"},{"location":"contribute/apps/blockexplorer/#overview","text":"Functional overview of what this component does","title":"Overview"},{"location":"contribute/apps/blockexplorer/#status-built-q2-roadmap-tenative","text":"","title":"Status - Built, Q2, Roadmap, Tenative"},{"location":"contribute/apps/blockexplorer/#business-driver","text":"","title":"Business Driver"},{"location":"contribute/apps/blockexplorer/#ecosystem-grant-eligible-priority-amount","text":"","title":"Ecosystem Grant - Eligible, Priority, Amount"},{"location":"contribute/apps/blockexplorer/#deliverable","text":"","title":"Deliverable"},{"location":"contribute/apps/blockexplorer/#technical-specification","text":"","title":"Technical Specification"},{"location":"contribute/apps/blockexplorer/#reference-material","text":"","title":"Reference Material"},{"location":"contribute/apps/blockexplorer/#level-of-effort","text":"","title":"Level of Effort"},{"location":"contribute/apps/blockexplorer/#developer-or-partner-identified","text":"","title":"Developer or Partner Identified"},{"location":"contribute/apps/blockexplorer/#harmony-owner","text":"","title":"Harmony Owner"},{"location":"contribute/apps/blockexplorer/#developer-guide","text":"","title":"Developer Guide"},{"location":"contribute/apps/exchanges/","text":"Component Name Overview Functional overview of what this component does Status - Built, Q2, Roadmap, Tenative Business Driver Ecosystem Grant - Eligible, Priority, Amount Deliverable Technical Specification Reference Material Level of Effort Developer or Partner Identified Harmony Owner Developer Guide","title":"Exchanges"},{"location":"contribute/apps/exchanges/#component-name","text":"","title":"Component Name"},{"location":"contribute/apps/exchanges/#overview","text":"Functional overview of what this component does","title":"Overview"},{"location":"contribute/apps/exchanges/#status-built-q2-roadmap-tenative","text":"","title":"Status - Built, Q2, Roadmap, Tenative"},{"location":"contribute/apps/exchanges/#business-driver","text":"","title":"Business Driver"},{"location":"contribute/apps/exchanges/#ecosystem-grant-eligible-priority-amount","text":"","title":"Ecosystem Grant - Eligible, Priority, Amount"},{"location":"contribute/apps/exchanges/#deliverable","text":"","title":"Deliverable"},{"location":"contribute/apps/exchanges/#technical-specification","text":"","title":"Technical Specification"},{"location":"contribute/apps/exchanges/#reference-material","text":"","title":"Reference Material"},{"location":"contribute/apps/exchanges/#level-of-effort","text":"","title":"Level of Effort"},{"location":"contribute/apps/exchanges/#developer-or-partner-identified","text":"","title":"Developer or Partner Identified"},{"location":"contribute/apps/exchanges/#harmony-owner","text":"","title":"Harmony Owner"},{"location":"contribute/apps/exchanges/#developer-guide","text":"","title":"Developer Guide"},{"location":"contribute/apps/identity/","text":"Component Name Overview Functional overview of what this component does Status - Built, Q2, Roadmap, Tenative Business Driver Ecosystem Grant - Eligible, Priority, Amount Deliverable Technical Specification Reference Material Level of Effort Developer or Partner Identified Harmony Owner Developer Guide","title":"Identity"},{"location":"contribute/apps/identity/#component-name","text":"","title":"Component Name"},{"location":"contribute/apps/identity/#overview","text":"Functional overview of what this component does","title":"Overview"},{"location":"contribute/apps/identity/#status-built-q2-roadmap-tenative","text":"","title":"Status - Built, Q2, Roadmap, Tenative"},{"location":"contribute/apps/identity/#business-driver","text":"","title":"Business Driver"},{"location":"contribute/apps/identity/#ecosystem-grant-eligible-priority-amount","text":"","title":"Ecosystem Grant - Eligible, Priority, Amount"},{"location":"contribute/apps/identity/#deliverable","text":"","title":"Deliverable"},{"location":"contribute/apps/identity/#technical-specification","text":"","title":"Technical Specification"},{"location":"contribute/apps/identity/#reference-material","text":"","title":"Reference Material"},{"location":"contribute/apps/identity/#level-of-effort","text":"","title":"Level of Effort"},{"location":"contribute/apps/identity/#developer-or-partner-identified","text":"","title":"Developer or Partner Identified"},{"location":"contribute/apps/identity/#harmony-owner","text":"","title":"Harmony Owner"},{"location":"contribute/apps/identity/#developer-guide","text":"","title":"Developer Guide"},{"location":"contribute/apps/industryverticals/","text":"Component Name Overview Functional overview of what this component does Status - Built, Q2, Roadmap, Tenative Business Driver Ecosystem Grant - Eligible, Priority, Amount Deliverable Technical Specification Reference Material Level of Effort Developer or Partner Identified Harmony Owner Developer Guide","title":"Industry Verticals"},{"location":"contribute/apps/industryverticals/#component-name","text":"","title":"Component Name"},{"location":"contribute/apps/industryverticals/#overview","text":"Functional overview of what this component does","title":"Overview"},{"location":"contribute/apps/industryverticals/#status-built-q2-roadmap-tenative","text":"","title":"Status - Built, Q2, Roadmap, Tenative"},{"location":"contribute/apps/industryverticals/#business-driver","text":"","title":"Business Driver"},{"location":"contribute/apps/industryverticals/#ecosystem-grant-eligible-priority-amount","text":"","title":"Ecosystem Grant - Eligible, Priority, Amount"},{"location":"contribute/apps/industryverticals/#deliverable","text":"","title":"Deliverable"},{"location":"contribute/apps/industryverticals/#technical-specification","text":"","title":"Technical Specification"},{"location":"contribute/apps/industryverticals/#reference-material","text":"","title":"Reference Material"},{"location":"contribute/apps/industryverticals/#level-of-effort","text":"","title":"Level of Effort"},{"location":"contribute/apps/industryverticals/#developer-or-partner-identified","text":"","title":"Developer or Partner Identified"},{"location":"contribute/apps/industryverticals/#harmony-owner","text":"","title":"Harmony Owner"},{"location":"contribute/apps/industryverticals/#developer-guide","text":"","title":"Developer Guide"},{"location":"contribute/apps/lending/","text":"Component Name Overview Functional overview of what this component does Status - Built, Q2, Roadmap, Tenative Business Driver Ecosystem Grant - Eligible, Priority, Amount Deliverable Technical Specification Reference Material Level of Effort Developer or Partner Identified Harmony Owner Developer Guide","title":"Lending"},{"location":"contribute/apps/lending/#component-name","text":"","title":"Component Name"},{"location":"contribute/apps/lending/#overview","text":"Functional overview of what this component does","title":"Overview"},{"location":"contribute/apps/lending/#status-built-q2-roadmap-tenative","text":"","title":"Status - Built, Q2, Roadmap, Tenative"},{"location":"contribute/apps/lending/#business-driver","text":"","title":"Business Driver"},{"location":"contribute/apps/lending/#ecosystem-grant-eligible-priority-amount","text":"","title":"Ecosystem Grant - Eligible, Priority, Amount"},{"location":"contribute/apps/lending/#deliverable","text":"","title":"Deliverable"},{"location":"contribute/apps/lending/#technical-specification","text":"","title":"Technical Specification"},{"location":"contribute/apps/lending/#reference-material","text":"","title":"Reference Material"},{"location":"contribute/apps/lending/#level-of-effort","text":"","title":"Level of Effort"},{"location":"contribute/apps/lending/#developer-or-partner-identified","text":"","title":"Developer or Partner Identified"},{"location":"contribute/apps/lending/#harmony-owner","text":"","title":"Harmony Owner"},{"location":"contribute/apps/lending/#developer-guide","text":"","title":"Developer Guide"},{"location":"contribute/apps/marketplace/","text":"Component Name Overview Functional overview of what this component does Status - Built, Q2, Roadmap, Tenative Business Driver Ecosystem Grant - Eligible, Priority, Amount Deliverable Technical Specification Reference Material Level of Effort Developer or Partner Identified Harmony Owner Developer Guide","title":"Market Places"},{"location":"contribute/apps/marketplace/#component-name","text":"","title":"Component Name"},{"location":"contribute/apps/marketplace/#overview","text":"Functional overview of what this component does","title":"Overview"},{"location":"contribute/apps/marketplace/#status-built-q2-roadmap-tenative","text":"","title":"Status - Built, Q2, Roadmap, Tenative"},{"location":"contribute/apps/marketplace/#business-driver","text":"","title":"Business Driver"},{"location":"contribute/apps/marketplace/#ecosystem-grant-eligible-priority-amount","text":"","title":"Ecosystem Grant - Eligible, Priority, Amount"},{"location":"contribute/apps/marketplace/#deliverable","text":"","title":"Deliverable"},{"location":"contribute/apps/marketplace/#technical-specification","text":"","title":"Technical Specification"},{"location":"contribute/apps/marketplace/#reference-material","text":"","title":"Reference Material"},{"location":"contribute/apps/marketplace/#level-of-effort","text":"","title":"Level of Effort"},{"location":"contribute/apps/marketplace/#developer-or-partner-identified","text":"","title":"Developer or Partner Identified"},{"location":"contribute/apps/marketplace/#harmony-owner","text":"","title":"Harmony Owner"},{"location":"contribute/apps/marketplace/#developer-guide","text":"","title":"Developer Guide"},{"location":"contribute/apps/overview/","text":"Application Overview","title":"Overview"},{"location":"contribute/apps/overview/#application-overview","text":"","title":"Application Overview"},{"location":"contribute/apps/payments/","text":"Component Name Overview Functional overview of what this component does Status - Built, Q2, Roadmap, Tenative Business Driver Ecosystem Grant - Eligible, Priority, Amount Deliverable Technical Specification Reference Material Level of Effort Developer or Partner Identified Harmony Owner Developer Guide","title":"Payments"},{"location":"contribute/apps/payments/#component-name","text":"","title":"Component Name"},{"location":"contribute/apps/payments/#overview","text":"Functional overview of what this component does","title":"Overview"},{"location":"contribute/apps/payments/#status-built-q2-roadmap-tenative","text":"","title":"Status - Built, Q2, Roadmap, Tenative"},{"location":"contribute/apps/payments/#business-driver","text":"","title":"Business Driver"},{"location":"contribute/apps/payments/#ecosystem-grant-eligible-priority-amount","text":"","title":"Ecosystem Grant - Eligible, Priority, Amount"},{"location":"contribute/apps/payments/#deliverable","text":"","title":"Deliverable"},{"location":"contribute/apps/payments/#technical-specification","text":"","title":"Technical Specification"},{"location":"contribute/apps/payments/#reference-material","text":"","title":"Reference Material"},{"location":"contribute/apps/payments/#level-of-effort","text":"","title":"Level of Effort"},{"location":"contribute/apps/payments/#developer-or-partner-identified","text":"","title":"Developer or Partner Identified"},{"location":"contribute/apps/payments/#harmony-owner","text":"","title":"Harmony Owner"},{"location":"contribute/apps/payments/#developer-guide","text":"","title":"Developer Guide"},{"location":"contribute/apps/stakingdashboard/","text":"Component Name Overview Functional overview of what this component does Status - Built, Q2, Roadmap, Tenative Business Driver Ecosystem Grant - Eligible, Priority, Amount Deliverable Technical Specification Reference Material Level of Effort Developer or Partner Identified Harmony Owner Developer Guide","title":"Staking Dashboard"},{"location":"contribute/apps/stakingdashboard/#component-name","text":"","title":"Component Name"},{"location":"contribute/apps/stakingdashboard/#overview","text":"Functional overview of what this component does","title":"Overview"},{"location":"contribute/apps/stakingdashboard/#status-built-q2-roadmap-tenative","text":"","title":"Status - Built, Q2, Roadmap, Tenative"},{"location":"contribute/apps/stakingdashboard/#business-driver","text":"","title":"Business Driver"},{"location":"contribute/apps/stakingdashboard/#ecosystem-grant-eligible-priority-amount","text":"","title":"Ecosystem Grant - Eligible, Priority, Amount"},{"location":"contribute/apps/stakingdashboard/#deliverable","text":"","title":"Deliverable"},{"location":"contribute/apps/stakingdashboard/#technical-specification","text":"","title":"Technical Specification"},{"location":"contribute/apps/stakingdashboard/#reference-material","text":"","title":"Reference Material"},{"location":"contribute/apps/stakingdashboard/#level-of-effort","text":"","title":"Level of Effort"},{"location":"contribute/apps/stakingdashboard/#developer-or-partner-identified","text":"","title":"Developer or Partner Identified"},{"location":"contribute/apps/stakingdashboard/#harmony-owner","text":"","title":"Harmony Owner"},{"location":"contribute/apps/stakingdashboard/#developer-guide","text":"","title":"Developer Guide"},{"location":"contribute/core/consensus/","text":"Core Protocol - Consensus Overview Consensus package includes the Harmony BFT consensus protocol code, which uses BLS-based multi-signature to cosign the new block. The details are in Harmony's new consensus protocol design . Status - Launched Mainnet ONE Business Driver - Fastest Most Secure Layer 1 Blockchain Protocol Ecosystem Grant - N/A Delieverable Block Time - less than 5 seconds Validators - geeater than 250 per shard Shards - 4 Technical Specification Introduction to Harmony BFT with BLS signatures Harmony BFT consensus protocol consist of normal mode and view changing mode which is same as the PBFT(practical byzantine fault tolerance) protocol. The difference is we use the BLS aggregated signature to reduce O(N^2) communications to O(N), which is more efficient and scalable to traditional PBFT. For brevity, we will still call the whole process as PBFT. Normal mode To reach the consensus of the next block, there are 3 phases: announce(i.e. pre-prepare in PBFT), prepare and commit. Announce(leader): The leader broadcasts ANNOUNCE message along with candidate of the next block. Prepare(validator): The validator will validate the block sent by leader and send PREPARE message; if the block is invalid, the validator will propose view change. If the prepare timeout, the validator will also propose view change. Prepared(leader): The leader will collect 2f+1 PREPARE message including itself and broadcast PREPARED message with the aggregated signature Commit(validator): The validator will check the validity of aggregated signature (# of signatures >= 2f+1) and send COMMIT message; if the commit timeout, the validator will also propose view change. Committed(leader): The leader will collect 2f+1 COMMIT message including itself and broadcast COMMITTED message with the aggregated signature Finalize(leader and validators): Both the leader and validators will finalize the block into blockchain together with 2f+1 aggregated signatures. View changing mode ViewChange(validator): whenever a validator receives invalid block/signature from the leader, it should send VIEWCHANGE message with view v+1 together with its own prepared message(>=2f+1 aggregated prepare signatures) from previous views. NewView(new leader): when the new leader (uniquely determined) collect enough (2f+1) view change messages, it broadcasts the NEWVIEW message with aggregated VIEWCHANGE signatures. During the view changing process, if the new leader not send NEWVIEW message on time, the validator will propose ViewChange for the next view v+2 and so on... State Machine The whole process of PBFT can be described as a state machine. We don't separate the roles of leader and validators, instead we use PBFTState structure to describe the role and phase of a given node who is joining the consensus process. When a node receives a new message from its peer, its state will be updated. i.e. pbft_state --(upon receive new PBFTMessage)--> new_pbft_state. Thus the most nature and clear way is to describe the whole process as state machine. // PBFTState holds the state of a node in PBFT process type PBFTState struct { IsLeader bool phase PBFTPhase // Announce, Prepare(d), Commit(ted) ... } // PBFTLog stores the data in PBFT process, it will be used in different phases in order to determine whether a new PBFTMessage is valid or not. type PBFTLog struct { blocks []*types.Block messages []*PBFTMessage } // entry point and main loop; // in each loop, the node will receive PBFT message from peers with timeout, // then update its state accordingly. handleMessageUpdate function handles various kinds of messages and update its state // it will also send new PBFT message (if not null) to its peers. // in the same loop, the node will also check whether it should send view changing message to new leader // finally, it will periodically try to publish new block into blockchain func (consensus *Consensus) Start(stopChan chan struct{}, stoppedChan chan struct{}) { defer close(stoppedChan) tick := time.NewTicker(blockDuration) consensus.idleTimeout.Start() for { select { default: msg := consensus.recvWithTimeout(receiveTimeout) consensus.handleMessageUpdate(msg) if consensus.idleTimeout.CheckExpire() { consensus.startViewChange(consensus.viewID + 1) } if consensus.commitTimeout.CheckExpire() { consensus.startViewChange(consensus.viewID + 1) } if consensus.viewChangeTimeout.CheckExpire() { if consensus.mode.Mode() == Normal { continue } viewID := consensus.mode.ViewID() consensus.startViewChange(viewID + 1) } case <-tick.C: consensus.tryPublishBlock() case <-stopChan: return } } } Reference Material Implementation is here Level of Effort - High Developer or Partner Identified - N/A Harmony Owner - Core Team Developer Guide","title":"Consensus"},{"location":"contribute/core/consensus/#core-protocol-consensus","text":"","title":"Core Protocol - Consensus"},{"location":"contribute/core/consensus/#overview","text":"Consensus package includes the Harmony BFT consensus protocol code, which uses BLS-based multi-signature to cosign the new block. The details are in Harmony's new consensus protocol design .","title":"Overview"},{"location":"contribute/core/consensus/#status-launched-mainnet-one","text":"","title":"Status - Launched Mainnet ONE"},{"location":"contribute/core/consensus/#business-driver-fastest-most-secure-layer-1-blockchain-protocol","text":"","title":"Business Driver - Fastest Most Secure Layer 1 Blockchain Protocol"},{"location":"contribute/core/consensus/#ecosystem-grant-na","text":"","title":"Ecosystem Grant - N/A"},{"location":"contribute/core/consensus/#delieverable","text":"Block Time - less than 5 seconds Validators - geeater than 250 per shard Shards - 4","title":"Delieverable"},{"location":"contribute/core/consensus/#technical-specification","text":"","title":"Technical Specification"},{"location":"contribute/core/consensus/#introduction-to-harmony-bft-with-bls-signatures","text":"Harmony BFT consensus protocol consist of normal mode and view changing mode which is same as the PBFT(practical byzantine fault tolerance) protocol. The difference is we use the BLS aggregated signature to reduce O(N^2) communications to O(N), which is more efficient and scalable to traditional PBFT. For brevity, we will still call the whole process as PBFT.","title":"Introduction to Harmony BFT with BLS signatures"},{"location":"contribute/core/consensus/#normal-mode","text":"To reach the consensus of the next block, there are 3 phases: announce(i.e. pre-prepare in PBFT), prepare and commit. Announce(leader): The leader broadcasts ANNOUNCE message along with candidate of the next block. Prepare(validator): The validator will validate the block sent by leader and send PREPARE message; if the block is invalid, the validator will propose view change. If the prepare timeout, the validator will also propose view change. Prepared(leader): The leader will collect 2f+1 PREPARE message including itself and broadcast PREPARED message with the aggregated signature Commit(validator): The validator will check the validity of aggregated signature (# of signatures >= 2f+1) and send COMMIT message; if the commit timeout, the validator will also propose view change. Committed(leader): The leader will collect 2f+1 COMMIT message including itself and broadcast COMMITTED message with the aggregated signature Finalize(leader and validators): Both the leader and validators will finalize the block into blockchain together with 2f+1 aggregated signatures.","title":"Normal mode"},{"location":"contribute/core/consensus/#view-changing-mode","text":"ViewChange(validator): whenever a validator receives invalid block/signature from the leader, it should send VIEWCHANGE message with view v+1 together with its own prepared message(>=2f+1 aggregated prepare signatures) from previous views. NewView(new leader): when the new leader (uniquely determined) collect enough (2f+1) view change messages, it broadcasts the NEWVIEW message with aggregated VIEWCHANGE signatures. During the view changing process, if the new leader not send NEWVIEW message on time, the validator will propose ViewChange for the next view v+2 and so on...","title":"View changing mode"},{"location":"contribute/core/consensus/#state-machine","text":"The whole process of PBFT can be described as a state machine. We don't separate the roles of leader and validators, instead we use PBFTState structure to describe the role and phase of a given node who is joining the consensus process. When a node receives a new message from its peer, its state will be updated. i.e. pbft_state --(upon receive new PBFTMessage)--> new_pbft_state. Thus the most nature and clear way is to describe the whole process as state machine. // PBFTState holds the state of a node in PBFT process type PBFTState struct { IsLeader bool phase PBFTPhase // Announce, Prepare(d), Commit(ted) ... } // PBFTLog stores the data in PBFT process, it will be used in different phases in order to determine whether a new PBFTMessage is valid or not. type PBFTLog struct { blocks []*types.Block messages []*PBFTMessage } // entry point and main loop; // in each loop, the node will receive PBFT message from peers with timeout, // then update its state accordingly. handleMessageUpdate function handles various kinds of messages and update its state // it will also send new PBFT message (if not null) to its peers. // in the same loop, the node will also check whether it should send view changing message to new leader // finally, it will periodically try to publish new block into blockchain func (consensus *Consensus) Start(stopChan chan struct{}, stoppedChan chan struct{}) { defer close(stoppedChan) tick := time.NewTicker(blockDuration) consensus.idleTimeout.Start() for { select { default: msg := consensus.recvWithTimeout(receiveTimeout) consensus.handleMessageUpdate(msg) if consensus.idleTimeout.CheckExpire() { consensus.startViewChange(consensus.viewID + 1) } if consensus.commitTimeout.CheckExpire() { consensus.startViewChange(consensus.viewID + 1) } if consensus.viewChangeTimeout.CheckExpire() { if consensus.mode.Mode() == Normal { continue } viewID := consensus.mode.ViewID() consensus.startViewChange(viewID + 1) } case <-tick.C: consensus.tryPublishBlock() case <-stopChan: return } } }","title":"State Machine"},{"location":"contribute/core/consensus/#reference-material","text":"Implementation is here","title":"Reference Material"},{"location":"contribute/core/consensus/#level-of-effort-high","text":"","title":"Level of Effort - High"},{"location":"contribute/core/consensus/#developer-or-partner-identified-na","text":"","title":"Developer or Partner Identified - N/A"},{"location":"contribute/core/consensus/#harmony-owner-core-team","text":"","title":"Harmony Owner - Core Team"},{"location":"contribute/core/consensus/#developer-guide","text":"","title":"Developer Guide"},{"location":"contribute/core/contractshard/","text":"Component Name Overview Functional overview of what this component does Status - Built, Q2, Roadmap, Tenative Business Driver Ecosystem Grant - Eligible, Priority, Amount Deliverable Technical Specification Reference Material Level of Effort Developer or Partner Identified Harmony Owner Developer Guide","title":"Contract Sharding"},{"location":"contribute/core/contractshard/#component-name","text":"","title":"Component Name"},{"location":"contribute/core/contractshard/#overview","text":"Functional overview of what this component does","title":"Overview"},{"location":"contribute/core/contractshard/#status-built-q2-roadmap-tenative","text":"","title":"Status - Built, Q2, Roadmap, Tenative"},{"location":"contribute/core/contractshard/#business-driver","text":"","title":"Business Driver"},{"location":"contribute/core/contractshard/#ecosystem-grant-eligible-priority-amount","text":"","title":"Ecosystem Grant - Eligible, Priority, Amount"},{"location":"contribute/core/contractshard/#deliverable","text":"","title":"Deliverable"},{"location":"contribute/core/contractshard/#technical-specification","text":"","title":"Technical Specification"},{"location":"contribute/core/contractshard/#reference-material","text":"","title":"Reference Material"},{"location":"contribute/core/contractshard/#level-of-effort","text":"","title":"Level of Effort"},{"location":"contribute/core/contractshard/#developer-or-partner-identified","text":"","title":"Developer or Partner Identified"},{"location":"contribute/core/contractshard/#harmony-owner","text":"","title":"Harmony Owner"},{"location":"contribute/core/contractshard/#developer-guide","text":"","title":"Developer Guide"},{"location":"contribute/core/execution/","text":"Component Name Overview Functional overview of what this component does Status - Built, Q2, Roadmap, Tenative Business Driver Ecosystem Grant - Eligible, Priority, Amount Deliverable Technical Specification Reference Material Level of Effort Developer or Partner Identified Harmony Owner Developer Guide","title":"Execution (EVM)"},{"location":"contribute/core/execution/#component-name","text":"","title":"Component Name"},{"location":"contribute/core/execution/#overview","text":"Functional overview of what this component does","title":"Overview"},{"location":"contribute/core/execution/#status-built-q2-roadmap-tenative","text":"","title":"Status - Built, Q2, Roadmap, Tenative"},{"location":"contribute/core/execution/#business-driver","text":"","title":"Business Driver"},{"location":"contribute/core/execution/#ecosystem-grant-eligible-priority-amount","text":"","title":"Ecosystem Grant - Eligible, Priority, Amount"},{"location":"contribute/core/execution/#deliverable","text":"","title":"Deliverable"},{"location":"contribute/core/execution/#technical-specification","text":"","title":"Technical Specification"},{"location":"contribute/core/execution/#reference-material","text":"","title":"Reference Material"},{"location":"contribute/core/execution/#level-of-effort","text":"","title":"Level of Effort"},{"location":"contribute/core/execution/#developer-or-partner-identified","text":"","title":"Developer or Partner Identified"},{"location":"contribute/core/execution/#harmony-owner","text":"","title":"Harmony Owner"},{"location":"contribute/core/execution/#developer-guide","text":"","title":"Developer Guide"},{"location":"contribute/core/openstaking/","text":"Component Name Overview Functional overview of what this component does Status - Built, Q2, Roadmap, Tenative Business Driver Ecosystem Grant - Eligible, Priority, Amount Deliverable Technical Specification Reference Material Level of Effort Developer or Partner Identified Harmony Owner Developer Guide","title":"Open Staking"},{"location":"contribute/core/openstaking/#component-name","text":"","title":"Component Name"},{"location":"contribute/core/openstaking/#overview","text":"Functional overview of what this component does","title":"Overview"},{"location":"contribute/core/openstaking/#status-built-q2-roadmap-tenative","text":"","title":"Status - Built, Q2, Roadmap, Tenative"},{"location":"contribute/core/openstaking/#business-driver","text":"","title":"Business Driver"},{"location":"contribute/core/openstaking/#ecosystem-grant-eligible-priority-amount","text":"","title":"Ecosystem Grant - Eligible, Priority, Amount"},{"location":"contribute/core/openstaking/#deliverable","text":"","title":"Deliverable"},{"location":"contribute/core/openstaking/#technical-specification","text":"","title":"Technical Specification"},{"location":"contribute/core/openstaking/#reference-material","text":"","title":"Reference Material"},{"location":"contribute/core/openstaking/#level-of-effort","text":"","title":"Level of Effort"},{"location":"contribute/core/openstaking/#developer-or-partner-identified","text":"","title":"Developer or Partner Identified"},{"location":"contribute/core/openstaking/#harmony-owner","text":"","title":"Harmony Owner"},{"location":"contribute/core/openstaking/#developer-guide","text":"","title":"Developer Guide"},{"location":"contribute/core/overview/","text":"Core Protocol Overview","title":"Overview"},{"location":"contribute/core/overview/#core-protocol-overview","text":"","title":"Core Protocol Overview"},{"location":"contribute/core/p2p/","text":"Component Name Overview Functional overview of what this component does Status - Built, Q2, Roadmap, Tenative Business Driver Ecosystem Grant - Eligible, Priority, Amount Deliverable Technical Specification Reference Material Level of Effort Developer or Partner Identified Harmony Owner Developer Guide","title":"Libp2p networking"},{"location":"contribute/core/p2p/#component-name","text":"","title":"Component Name"},{"location":"contribute/core/p2p/#overview","text":"Functional overview of what this component does","title":"Overview"},{"location":"contribute/core/p2p/#status-built-q2-roadmap-tenative","text":"","title":"Status - Built, Q2, Roadmap, Tenative"},{"location":"contribute/core/p2p/#business-driver","text":"","title":"Business Driver"},{"location":"contribute/core/p2p/#ecosystem-grant-eligible-priority-amount","text":"","title":"Ecosystem Grant - Eligible, Priority, Amount"},{"location":"contribute/core/p2p/#deliverable","text":"","title":"Deliverable"},{"location":"contribute/core/p2p/#technical-specification","text":"","title":"Technical Specification"},{"location":"contribute/core/p2p/#reference-material","text":"","title":"Reference Material"},{"location":"contribute/core/p2p/#level-of-effort","text":"","title":"Level of Effort"},{"location":"contribute/core/p2p/#developer-or-partner-identified","text":"","title":"Developer or Partner Identified"},{"location":"contribute/core/p2p/#harmony-owner","text":"","title":"Harmony Owner"},{"location":"contribute/core/p2p/#developer-guide","text":"","title":"Developer Guide"},{"location":"contribute/core/p2p2/","text":"Component Name Overview Functional overview of what this component does Status - Built, Q2, Roadmap, Tenative Business Driver Ecosystem Grant - Eligible, Priority, Amount Deliverable Technical Specification Reference Material Level of Effort Developer or Partner Identified Harmony Owner Developer Guide","title":"Libp2p improvements"},{"location":"contribute/core/p2p2/#component-name","text":"","title":"Component Name"},{"location":"contribute/core/p2p2/#overview","text":"Functional overview of what this component does","title":"Overview"},{"location":"contribute/core/p2p2/#status-built-q2-roadmap-tenative","text":"","title":"Status - Built, Q2, Roadmap, Tenative"},{"location":"contribute/core/p2p2/#business-driver","text":"","title":"Business Driver"},{"location":"contribute/core/p2p2/#ecosystem-grant-eligible-priority-amount","text":"","title":"Ecosystem Grant - Eligible, Priority, Amount"},{"location":"contribute/core/p2p2/#deliverable","text":"","title":"Deliverable"},{"location":"contribute/core/p2p2/#technical-specification","text":"","title":"Technical Specification"},{"location":"contribute/core/p2p2/#reference-material","text":"","title":"Reference Material"},{"location":"contribute/core/p2p2/#level-of-effort","text":"","title":"Level of Effort"},{"location":"contribute/core/p2p2/#developer-or-partner-identified","text":"","title":"Developer or Partner Identified"},{"location":"contribute/core/p2p2/#harmony-owner","text":"","title":"Harmony Owner"},{"location":"contribute/core/p2p2/#developer-guide","text":"","title":"Developer Guide"},{"location":"contribute/core/privacy/","text":"Component Name Overview Functional overview of what this component does Status - Built, Q2, Roadmap, Tenative Business Driver Ecosystem Grant - Eligible, Priority, Amount Deliverable Technical Specification Reference Material Level of Effort Developer or Partner Identified Harmony Owner Developer Guide","title":"Privacy Primitives"},{"location":"contribute/core/privacy/#component-name","text":"","title":"Component Name"},{"location":"contribute/core/privacy/#overview","text":"Functional overview of what this component does","title":"Overview"},{"location":"contribute/core/privacy/#status-built-q2-roadmap-tenative","text":"","title":"Status - Built, Q2, Roadmap, Tenative"},{"location":"contribute/core/privacy/#business-driver","text":"","title":"Business Driver"},{"location":"contribute/core/privacy/#ecosystem-grant-eligible-priority-amount","text":"","title":"Ecosystem Grant - Eligible, Priority, Amount"},{"location":"contribute/core/privacy/#deliverable","text":"","title":"Deliverable"},{"location":"contribute/core/privacy/#technical-specification","text":"","title":"Technical Specification"},{"location":"contribute/core/privacy/#reference-material","text":"","title":"Reference Material"},{"location":"contribute/core/privacy/#level-of-effort","text":"","title":"Level of Effort"},{"location":"contribute/core/privacy/#developer-or-partner-identified","text":"","title":"Developer or Partner Identified"},{"location":"contribute/core/privacy/#harmony-owner","text":"","title":"Harmony Owner"},{"location":"contribute/core/privacy/#developer-guide","text":"","title":"Developer Guide"},{"location":"contribute/core/reshard/","text":"Component Name Overview Functional overview of what this component does Status - Built, Q2, Roadmap, Tenative Business Driver Ecosystem Grant - Eligible, Priority, Amount Deliverable Technical Specification Reference Material Level of Effort Developer or Partner Identified Harmony Owner Developer Guide","title":"Resharding"},{"location":"contribute/core/reshard/#component-name","text":"","title":"Component Name"},{"location":"contribute/core/reshard/#overview","text":"Functional overview of what this component does","title":"Overview"},{"location":"contribute/core/reshard/#status-built-q2-roadmap-tenative","text":"","title":"Status - Built, Q2, Roadmap, Tenative"},{"location":"contribute/core/reshard/#business-driver","text":"","title":"Business Driver"},{"location":"contribute/core/reshard/#ecosystem-grant-eligible-priority-amount","text":"","title":"Ecosystem Grant - Eligible, Priority, Amount"},{"location":"contribute/core/reshard/#deliverable","text":"","title":"Deliverable"},{"location":"contribute/core/reshard/#technical-specification","text":"","title":"Technical Specification"},{"location":"contribute/core/reshard/#reference-material","text":"","title":"Reference Material"},{"location":"contribute/core/reshard/#level-of-effort","text":"","title":"Level of Effort"},{"location":"contribute/core/reshard/#developer-or-partner-identified","text":"","title":"Developer or Partner Identified"},{"location":"contribute/core/reshard/#harmony-owner","text":"","title":"Harmony Owner"},{"location":"contribute/core/reshard/#developer-guide","text":"","title":"Developer Guide"},{"location":"contribute/tools/api/","text":"API and RPC Development Overview Harmony have a robust set of API's which are currently documented using Postman and moving forward will be transitions to swagger . Postman is the easiest way to familiarize yourself with the API's. Status - Built Business Driver: Partner and Developer adoption Ecosystem Grant N/A Deliverable Complete set of documented API's Technical Specification Reference Material API Documentation Mainnet ONE OSTN Release Harmony Postman Team - OSTN Swagger UI Redux UI API Docs - John Harmony Owner Ganesha Developer Guide - API and RPC Familiarization Quickstart - testing API's The easiest way to test API's is to go to Harmony Postman Team select the documentation and download the mac version and run on your machine. API Development Roles and Permissions Admin - Admins are responsible for publishing to Postman and managing team members Leo, RJ, Daniel, Ganesha Editor - Editors develop API's and update documentation Janet, Daniel, Minh, Matt, Dennis Viewer Viewers use API's in testing or developers can use the public repository as detailed below Changing and Documenting API's Any changes should begin with a github issue and pull Github Issue Complete the Work Walk through for New API's (example - GetValidatorInformation) Include the definition in backend.go ( v1 and v2 ) Include the definition in blockchain.go ( v1 and v2 ) Include the definitions in hmyapi backend.go and hmyapi README.md Write the API logic in hmy/api_backend.go Create unit test and test locally Update Postman current release to include the API definition and test with localhost Pull Request Create Pull request Note components impacted (block explorer, staking dashboard, wallets, etc) Approve and merge Validation Once deployed to a testnet environment Ensure the API works as expected Add an example to the Postman collection for the testnet environment net_version example rpc.go - starts the http endpoint and receives all requests api_backend.go - holds the api call and return parameters backend.go - holds the function definition (json-rpc) net.go - is where the function logic is held Deploying a new Release We have documented two releases in Postman - each release is managed in it's own collection and published with it's own URL. 1.0 - Mainnet One - Postman Collection - Endpoint - https://apitest.harmony.one/ 2.0 - Open Staking - Postman Collection - Endpoint - https://api.os.hmny.io/ Ongoing we will either continue the process of a new collection and endpoint moving forward or replace or augment this with swagger. Developer check list Ensure all staking API Parameter and Return values are up to date with latest sample request and response Ensure that v1 and v2 - all have the same API's i.e. duplicate the API's from v1 and include in v2 if there not there Republish Postman to update https://api.os.hmny.io/ Review all APIs to ensure that Postman is complete and all API's have up to date request and responses Republish https://api.os.hmny.io/ Update open api specification Redploy to Swagger and Redux hosted sites","title":"Harmony API"},{"location":"contribute/tools/api/#api-and-rpc-development","text":"","title":"API and RPC Development"},{"location":"contribute/tools/api/#overview","text":"Harmony have a robust set of API's which are currently documented using Postman and moving forward will be transitions to swagger . Postman is the easiest way to familiarize yourself with the API's.","title":"Overview"},{"location":"contribute/tools/api/#status-built","text":"","title":"Status - Built"},{"location":"contribute/tools/api/#business-driver-partner-and-developer-adoption","text":"","title":"Business Driver: Partner and Developer adoption"},{"location":"contribute/tools/api/#ecosystem-grant-na","text":"","title":"Ecosystem Grant N/A"},{"location":"contribute/tools/api/#deliverable","text":"Complete set of documented API's","title":"Deliverable"},{"location":"contribute/tools/api/#technical-specification","text":"","title":"Technical Specification"},{"location":"contribute/tools/api/#reference-material","text":"API Documentation Mainnet ONE OSTN Release Harmony Postman Team - OSTN Swagger UI Redux UI API Docs - John","title":"Reference Material"},{"location":"contribute/tools/api/#harmony-owner","text":"Ganesha","title":"Harmony Owner"},{"location":"contribute/tools/api/#developer-guide-api-and-rpc-familiarization","text":"","title":"Developer Guide -  API and RPC Familiarization"},{"location":"contribute/tools/api/#quickstart-testing-apis","text":"The easiest way to test API's is to go to Harmony Postman Team select the documentation and download the mac version and run on your machine.","title":"Quickstart - testing API's"},{"location":"contribute/tools/api/#api-development-roles-and-permissions","text":"Admin - Admins are responsible for publishing to Postman and managing team members Leo, RJ, Daniel, Ganesha Editor - Editors develop API's and update documentation Janet, Daniel, Minh, Matt, Dennis Viewer Viewers use API's in testing or developers can use the public repository as detailed below","title":"API Development Roles and Permissions"},{"location":"contribute/tools/api/#changing-and-documenting-apis","text":"Any changes should begin with a github issue and pull Github Issue Complete the Work Walk through for New API's (example - GetValidatorInformation) Include the definition in backend.go ( v1 and v2 ) Include the definition in blockchain.go ( v1 and v2 ) Include the definitions in hmyapi backend.go and hmyapi README.md Write the API logic in hmy/api_backend.go Create unit test and test locally Update Postman current release to include the API definition and test with localhost Pull Request Create Pull request Note components impacted (block explorer, staking dashboard, wallets, etc) Approve and merge Validation Once deployed to a testnet environment Ensure the API works as expected Add an example to the Postman collection for the testnet environment","title":"Changing and Documenting API's"},{"location":"contribute/tools/api/#net_version-example","text":"rpc.go - starts the http endpoint and receives all requests api_backend.go - holds the api call and return parameters backend.go - holds the function definition (json-rpc) net.go - is where the function logic is held","title":"net_version example"},{"location":"contribute/tools/api/#deploying-a-new-release","text":"We have documented two releases in Postman - each release is managed in it's own collection and published with it's own URL. 1.0 - Mainnet One - Postman Collection - Endpoint - https://apitest.harmony.one/ 2.0 - Open Staking - Postman Collection - Endpoint - https://api.os.hmny.io/ Ongoing we will either continue the process of a new collection and endpoint moving forward or replace or augment this with swagger.","title":"Deploying a new Release"},{"location":"contribute/tools/api/#developer-check-list","text":"Ensure all staking API Parameter and Return values are up to date with latest sample request and response Ensure that v1 and v2 - all have the same API's i.e. duplicate the API's from v1 and include in v2 if there not there Republish Postman to update https://api.os.hmny.io/ Review all APIs to ensure that Postman is complete and all API's have up to date request and responses Republish https://api.os.hmny.io/ Update open api specification Redploy to Swagger and Redux hosted sites","title":"Developer check list"},{"location":"contribute/tools/coldwallet/","text":"Component Name Overview Functional overview of what this component does Status - Built, Q2, Roadmap, Tenative Business Driver Ecosystem Grant - Eligible, Priority, Amount Deliverable Technical Specification Reference Material Level of Effort Developer or Partner Identified Harmony Owner Developer Guide","title":"Cold Wallets"},{"location":"contribute/tools/coldwallet/#component-name","text":"","title":"Component Name"},{"location":"contribute/tools/coldwallet/#overview","text":"Functional overview of what this component does","title":"Overview"},{"location":"contribute/tools/coldwallet/#status-built-q2-roadmap-tenative","text":"","title":"Status - Built, Q2, Roadmap, Tenative"},{"location":"contribute/tools/coldwallet/#business-driver","text":"","title":"Business Driver"},{"location":"contribute/tools/coldwallet/#ecosystem-grant-eligible-priority-amount","text":"","title":"Ecosystem Grant - Eligible, Priority, Amount"},{"location":"contribute/tools/coldwallet/#deliverable","text":"","title":"Deliverable"},{"location":"contribute/tools/coldwallet/#technical-specification","text":"","title":"Technical Specification"},{"location":"contribute/tools/coldwallet/#reference-material","text":"","title":"Reference Material"},{"location":"contribute/tools/coldwallet/#level-of-effort","text":"","title":"Level of Effort"},{"location":"contribute/tools/coldwallet/#developer-or-partner-identified","text":"","title":"Developer or Partner Identified"},{"location":"contribute/tools/coldwallet/#harmony-owner","text":"","title":"Harmony Owner"},{"location":"contribute/tools/coldwallet/#developer-guide","text":"","title":"Developer Guide"},{"location":"contribute/tools/contractstandards/","text":"Component Name Overview Functional overview of what this component does Status - Built, Q2, Roadmap, Tenative Business Driver Ecosystem Grant - Eligible, Priority, Amount Deliverable Technical Specification Reference Material Level of Effort Developer or Partner Identified Harmony Owner Developer Guide","title":"Contract Standards"},{"location":"contribute/tools/contractstandards/#component-name","text":"","title":"Component Name"},{"location":"contribute/tools/contractstandards/#overview","text":"Functional overview of what this component does","title":"Overview"},{"location":"contribute/tools/contractstandards/#status-built-q2-roadmap-tenative","text":"","title":"Status - Built, Q2, Roadmap, Tenative"},{"location":"contribute/tools/contractstandards/#business-driver","text":"","title":"Business Driver"},{"location":"contribute/tools/contractstandards/#ecosystem-grant-eligible-priority-amount","text":"","title":"Ecosystem Grant - Eligible, Priority, Amount"},{"location":"contribute/tools/contractstandards/#deliverable","text":"","title":"Deliverable"},{"location":"contribute/tools/contractstandards/#technical-specification","text":"","title":"Technical Specification"},{"location":"contribute/tools/contractstandards/#reference-material","text":"","title":"Reference Material"},{"location":"contribute/tools/contractstandards/#level-of-effort","text":"","title":"Level of Effort"},{"location":"contribute/tools/contractstandards/#developer-or-partner-identified","text":"","title":"Developer or Partner Identified"},{"location":"contribute/tools/contractstandards/#harmony-owner","text":"","title":"Harmony Owner"},{"location":"contribute/tools/contractstandards/#developer-guide","text":"","title":"Developer Guide"},{"location":"contribute/tools/dappgas/","text":"Component Name Overview Functional overview of what this component does Status - Built, Q2, Roadmap, Tenative Business Driver Ecosystem Grant - Eligible, Priority, Amount Deliverable Technical Specification Reference Material Level of Effort Developer or Partner Identified Harmony Owner Developer Guide","title":"DApp Developer Gas"},{"location":"contribute/tools/dappgas/#component-name","text":"","title":"Component Name"},{"location":"contribute/tools/dappgas/#overview","text":"Functional overview of what this component does","title":"Overview"},{"location":"contribute/tools/dappgas/#status-built-q2-roadmap-tenative","text":"","title":"Status - Built, Q2, Roadmap, Tenative"},{"location":"contribute/tools/dappgas/#business-driver","text":"","title":"Business Driver"},{"location":"contribute/tools/dappgas/#ecosystem-grant-eligible-priority-amount","text":"","title":"Ecosystem Grant - Eligible, Priority, Amount"},{"location":"contribute/tools/dappgas/#deliverable","text":"","title":"Deliverable"},{"location":"contribute/tools/dappgas/#technical-specification","text":"","title":"Technical Specification"},{"location":"contribute/tools/dappgas/#reference-material","text":"","title":"Reference Material"},{"location":"contribute/tools/dappgas/#level-of-effort","text":"","title":"Level of Effort"},{"location":"contribute/tools/dappgas/#developer-or-partner-identified","text":"","title":"Developer or Partner Identified"},{"location":"contribute/tools/dappgas/#harmony-owner","text":"","title":"Harmony Owner"},{"location":"contribute/tools/dappgas/#developer-guide","text":"","title":"Developer Guide"},{"location":"contribute/tools/dappstarter/","text":"TryCrypto DappStarter: Overview DappStarter is a full stack development environment for blockchains. Status - Built Business Drive - Developer Adoption Ecosystem Grant Eligible - N/A Priority - N/A Amount - N/A Deliverable A Decentralized Application (DApp) Generator based of composable units. Including smart contract and User Interface. Technical Specification Reference Material Other products photokey dappconnector Level of Effort Developer or Partner Identified Nik Kalyani : TRYCRYPTO Harmony Owner Developer Guide DAppStarter application","title":"TryCrypto Dapp Starter"},{"location":"contribute/tools/dappstarter/#trycrypto-dappstarter","text":"","title":"TryCrypto DappStarter:"},{"location":"contribute/tools/dappstarter/#overview","text":"DappStarter is a full stack development environment for blockchains.","title":"Overview"},{"location":"contribute/tools/dappstarter/#status-built","text":"","title":"Status - Built"},{"location":"contribute/tools/dappstarter/#business-drive-developer-adoption","text":"","title":"Business Drive - Developer Adoption"},{"location":"contribute/tools/dappstarter/#ecosystem-grant","text":"Eligible - N/A Priority - N/A Amount - N/A","title":"Ecosystem Grant"},{"location":"contribute/tools/dappstarter/#deliverable","text":"A Decentralized Application (DApp) Generator based of composable units. Including smart contract and User Interface.","title":"Deliverable"},{"location":"contribute/tools/dappstarter/#technical-specification","text":"","title":"Technical Specification"},{"location":"contribute/tools/dappstarter/#reference-material","text":"Other products photokey dappconnector","title":"Reference Material"},{"location":"contribute/tools/dappstarter/#level-of-effort","text":"","title":"Level of Effort"},{"location":"contribute/tools/dappstarter/#developer-or-partner-identified","text":"Nik Kalyani : TRYCRYPTO","title":"Developer or Partner Identified"},{"location":"contribute/tools/dappstarter/#harmony-owner","text":"","title":"Harmony Owner"},{"location":"contribute/tools/dappstarter/#developer-guide","text":"DAppStarter application","title":"Developer Guide"},{"location":"contribute/tools/endpoints/","text":"Component Name Overview Functional overview of what this component does Status - Built, Q2, Roadmap, Tenative Business Driver Ecosystem Grant - Eligible, Priority, Amount Deliverable Technical Specification Reference Material Level of Effort Developer or Partner Identified Harmony Owner Developer Guide","title":"Hosted API endpoints"},{"location":"contribute/tools/endpoints/#component-name","text":"","title":"Component Name"},{"location":"contribute/tools/endpoints/#overview","text":"Functional overview of what this component does","title":"Overview"},{"location":"contribute/tools/endpoints/#status-built-q2-roadmap-tenative","text":"","title":"Status - Built, Q2, Roadmap, Tenative"},{"location":"contribute/tools/endpoints/#business-driver","text":"","title":"Business Driver"},{"location":"contribute/tools/endpoints/#ecosystem-grant-eligible-priority-amount","text":"","title":"Ecosystem Grant - Eligible, Priority, Amount"},{"location":"contribute/tools/endpoints/#deliverable","text":"","title":"Deliverable"},{"location":"contribute/tools/endpoints/#technical-specification","text":"","title":"Technical Specification"},{"location":"contribute/tools/endpoints/#reference-material","text":"","title":"Reference Material"},{"location":"contribute/tools/endpoints/#level-of-effort","text":"","title":"Level of Effort"},{"location":"contribute/tools/endpoints/#developer-or-partner-identified","text":"","title":"Developer or Partner Identified"},{"location":"contribute/tools/endpoints/#harmony-owner","text":"","title":"Harmony Owner"},{"location":"contribute/tools/endpoints/#developer-guide","text":"","title":"Developer Guide"},{"location":"contribute/tools/fiat/","text":"Component Name Overview Functional overview of what this component does Status - Built, Q2, Roadmap, Tenative Business Driver Ecosystem Grant - Eligible, Priority, Amount Deliverable Technical Specification Reference Material Level of Effort Developer or Partner Identified Harmony Owner Developer Guide","title":"fiat on ramps"},{"location":"contribute/tools/fiat/#component-name","text":"","title":"Component Name"},{"location":"contribute/tools/fiat/#overview","text":"Functional overview of what this component does","title":"Overview"},{"location":"contribute/tools/fiat/#status-built-q2-roadmap-tenative","text":"","title":"Status - Built, Q2, Roadmap, Tenative"},{"location":"contribute/tools/fiat/#business-driver","text":"","title":"Business Driver"},{"location":"contribute/tools/fiat/#ecosystem-grant-eligible-priority-amount","text":"","title":"Ecosystem Grant - Eligible, Priority, Amount"},{"location":"contribute/tools/fiat/#deliverable","text":"","title":"Deliverable"},{"location":"contribute/tools/fiat/#technical-specification","text":"","title":"Technical Specification"},{"location":"contribute/tools/fiat/#reference-material","text":"","title":"Reference Material"},{"location":"contribute/tools/fiat/#level-of-effort","text":"","title":"Level of Effort"},{"location":"contribute/tools/fiat/#developer-or-partner-identified","text":"","title":"Developer or Partner Identified"},{"location":"contribute/tools/fiat/#harmony-owner","text":"","title":"Harmony Owner"},{"location":"contribute/tools/fiat/#developer-guide","text":"","title":"Developer Guide"},{"location":"contribute/tools/ganache/","text":"Harmony Truffle Integration Overview Trufflesuite is the most widely adoopted Smart Contract and DApp development tool. The goal of this initiaitve is to fully integrate Harmony into truffle suite and drive developer adoption. Note this ties in heavily with Harmony Truffle Status -Tenative Business Driver - Developer Adoption Ecosystem Grant Eligible - Yes Priority Amount Deliverable Harmony local deployment integrateed with an easy to install developer environment similar to truffle suite. HarmonyGanache - Deploys Harmony Local Environment Harmony Ganache CLI Harmony Drizzle - Supports Harmony.one Harmony Dapp Marketplace Technical Specification Leverage the interface adapter Reference Material Truffle is making enhancements as part of Tezos onboarding which may be useful Tezos Grants Tezos Truffle Grant Github Trufflesuite Truffle : Smart Contract Development Ganache : Local Blockchain Ganache CLI : Command Line Interface Drizzle : Web Application development Level of Effort Developer or Partner Identified Technical Lead - Nick - gnidan@trufflesuite.com Partner relations - David Clark Harmony Owner Developer Guide","title":"Harmony Ganache"},{"location":"contribute/tools/ganache/#harmony-truffle-integration","text":"","title":"Harmony Truffle Integration"},{"location":"contribute/tools/ganache/#overview","text":"Trufflesuite is the most widely adoopted Smart Contract and DApp development tool. The goal of this initiaitve is to fully integrate Harmony into truffle suite and drive developer adoption. Note this ties in heavily with Harmony Truffle","title":"Overview"},{"location":"contribute/tools/ganache/#status-tenative","text":"","title":"Status -Tenative"},{"location":"contribute/tools/ganache/#business-driver-developer-adoption","text":"","title":"Business Driver - Developer Adoption"},{"location":"contribute/tools/ganache/#ecosystem-grant","text":"Eligible - Yes Priority Amount","title":"Ecosystem Grant"},{"location":"contribute/tools/ganache/#deliverable","text":"Harmony local deployment integrateed with an easy to install developer environment similar to truffle suite. HarmonyGanache - Deploys Harmony Local Environment Harmony Ganache CLI Harmony Drizzle - Supports Harmony.one Harmony Dapp Marketplace","title":"Deliverable"},{"location":"contribute/tools/ganache/#technical-specification","text":"Leverage the interface adapter","title":"Technical Specification"},{"location":"contribute/tools/ganache/#reference-material","text":"Truffle is making enhancements as part of Tezos onboarding which may be useful Tezos Grants Tezos Truffle Grant Github Trufflesuite Truffle : Smart Contract Development Ganache : Local Blockchain Ganache CLI : Command Line Interface Drizzle : Web Application development","title":"Reference Material"},{"location":"contribute/tools/ganache/#level-of-effort","text":"","title":"Level of Effort"},{"location":"contribute/tools/ganache/#developer-or-partner-identified","text":"Technical Lead - Nick - gnidan@trufflesuite.com Partner relations - David Clark","title":"Developer or Partner Identified"},{"location":"contribute/tools/ganache/#harmony-owner","text":"","title":"Harmony Owner"},{"location":"contribute/tools/ganache/#developer-guide","text":"","title":"Developer Guide"},{"location":"contribute/tools/golib/","text":"Component Name Overview Functional overview of what this component does Status - Built, Q2, Roadmap, Tenative Business Driver Ecosystem Grant - Eligible, Priority, Amount Deliverable Technical Specification Reference Material Level of Effort Developer or Partner Identified Harmony Owner Developer Guide","title":"GO Library"},{"location":"contribute/tools/golib/#component-name","text":"","title":"Component Name"},{"location":"contribute/tools/golib/#overview","text":"Functional overview of what this component does","title":"Overview"},{"location":"contribute/tools/golib/#status-built-q2-roadmap-tenative","text":"","title":"Status - Built, Q2, Roadmap, Tenative"},{"location":"contribute/tools/golib/#business-driver","text":"","title":"Business Driver"},{"location":"contribute/tools/golib/#ecosystem-grant-eligible-priority-amount","text":"","title":"Ecosystem Grant - Eligible, Priority, Amount"},{"location":"contribute/tools/golib/#deliverable","text":"","title":"Deliverable"},{"location":"contribute/tools/golib/#technical-specification","text":"","title":"Technical Specification"},{"location":"contribute/tools/golib/#reference-material","text":"","title":"Reference Material"},{"location":"contribute/tools/golib/#level-of-effort","text":"","title":"Level of Effort"},{"location":"contribute/tools/golib/#developer-or-partner-identified","text":"","title":"Developer or Partner Identified"},{"location":"contribute/tools/golib/#harmony-owner","text":"","title":"Harmony Owner"},{"location":"contribute/tools/golib/#developer-guide","text":"","title":"Developer Guide"},{"location":"contribute/tools/gosdk/","text":"Component Name Overview Functional overview of what this component does Status - Built, Q2, Roadmap, Tenative Business Driver Ecosystem Grant - Eligible, Priority, Amount Deliverable Technical Specification Reference Material Level of Effort Developer or Partner Identified Harmony Owner Developer Guide","title":"GO SDK"},{"location":"contribute/tools/gosdk/#component-name","text":"","title":"Component Name"},{"location":"contribute/tools/gosdk/#overview","text":"Functional overview of what this component does","title":"Overview"},{"location":"contribute/tools/gosdk/#status-built-q2-roadmap-tenative","text":"","title":"Status - Built, Q2, Roadmap, Tenative"},{"location":"contribute/tools/gosdk/#business-driver","text":"","title":"Business Driver"},{"location":"contribute/tools/gosdk/#ecosystem-grant-eligible-priority-amount","text":"","title":"Ecosystem Grant - Eligible, Priority, Amount"},{"location":"contribute/tools/gosdk/#deliverable","text":"","title":"Deliverable"},{"location":"contribute/tools/gosdk/#technical-specification","text":"","title":"Technical Specification"},{"location":"contribute/tools/gosdk/#reference-material","text":"","title":"Reference Material"},{"location":"contribute/tools/gosdk/#level-of-effort","text":"","title":"Level of Effort"},{"location":"contribute/tools/gosdk/#developer-or-partner-identified","text":"","title":"Developer or Partner Identified"},{"location":"contribute/tools/gosdk/#harmony-owner","text":"","title":"Harmony Owner"},{"location":"contribute/tools/gosdk/#developer-guide","text":"","title":"Developer Guide"},{"location":"contribute/tools/graphql/","text":"Component Name Overview Functional overview of what this component does Status - Built, Q2, Roadmap, Tenative Business Driver Ecosystem Grant - Eligible, Priority, Amount Deliverable Technical Specification Reference Material Level of Effort Developer or Partner Identified Harmony Owner Developer Guide","title":"Harmony GraphQL"},{"location":"contribute/tools/graphql/#component-name","text":"","title":"Component Name"},{"location":"contribute/tools/graphql/#overview","text":"Functional overview of what this component does","title":"Overview"},{"location":"contribute/tools/graphql/#status-built-q2-roadmap-tenative","text":"","title":"Status - Built, Q2, Roadmap, Tenative"},{"location":"contribute/tools/graphql/#business-driver","text":"","title":"Business Driver"},{"location":"contribute/tools/graphql/#ecosystem-grant-eligible-priority-amount","text":"","title":"Ecosystem Grant - Eligible, Priority, Amount"},{"location":"contribute/tools/graphql/#deliverable","text":"","title":"Deliverable"},{"location":"contribute/tools/graphql/#technical-specification","text":"","title":"Technical Specification"},{"location":"contribute/tools/graphql/#reference-material","text":"","title":"Reference Material"},{"location":"contribute/tools/graphql/#level-of-effort","text":"","title":"Level of Effort"},{"location":"contribute/tools/graphql/#developer-or-partner-identified","text":"","title":"Developer or Partner Identified"},{"location":"contribute/tools/graphql/#harmony-owner","text":"","title":"Harmony Owner"},{"location":"contribute/tools/graphql/#developer-guide","text":"","title":"Developer Guide"},{"location":"contribute/tools/harmonyide/","text":"Harmony IDE (web) Overview Harmony Branded Web Based Integrated Development environment Status - In progress Business Driver - Developer Adoption Ecosystem Grant Eligible - No Priority - High Amount - N/A Deliverable A web based IDE - see here Technical Specification Reference Material Level of Effort Developer or Partner Identified Dicussions and an agreement has entered into with White Matrix to build this functionality. Harmony Owner RJ Developer Guide","title":"Harmony IDE"},{"location":"contribute/tools/harmonyide/#harmony-ide-web","text":"","title":"Harmony IDE (web)"},{"location":"contribute/tools/harmonyide/#overview","text":"Harmony Branded Web Based Integrated Development environment","title":"Overview"},{"location":"contribute/tools/harmonyide/#status-in-progress","text":"","title":"Status - In progress"},{"location":"contribute/tools/harmonyide/#business-driver-developer-adoption","text":"","title":"Business Driver - Developer Adoption"},{"location":"contribute/tools/harmonyide/#ecosystem-grant","text":"Eligible - No Priority - High Amount - N/A","title":"Ecosystem Grant"},{"location":"contribute/tools/harmonyide/#deliverable","text":"A web based IDE - see here","title":"Deliverable"},{"location":"contribute/tools/harmonyide/#technical-specification","text":"","title":"Technical Specification"},{"location":"contribute/tools/harmonyide/#reference-material","text":"","title":"Reference Material"},{"location":"contribute/tools/harmonyide/#level-of-effort","text":"","title":"Level of Effort"},{"location":"contribute/tools/harmonyide/#developer-or-partner-identified","text":"Dicussions and an agreement has entered into with White Matrix to build this functionality.","title":"Developer or Partner Identified"},{"location":"contribute/tools/harmonyide/#harmony-owner","text":"RJ","title":"Harmony Owner"},{"location":"contribute/tools/harmonyide/#developer-guide","text":"","title":"Developer Guide"},{"location":"contribute/tools/hotwallet/","text":"Component Name Overview Functional overview of what this component does Status - Built, Q2, Roadmap, Tenative Business Driver Ecosystem Grant - Eligible, Priority, Amount Deliverable Technical Specification Reference Material Level of Effort Developer or Partner Identified Harmony Owner Developer Guide","title":"Hot Wallets"},{"location":"contribute/tools/hotwallet/#component-name","text":"","title":"Component Name"},{"location":"contribute/tools/hotwallet/#overview","text":"Functional overview of what this component does","title":"Overview"},{"location":"contribute/tools/hotwallet/#status-built-q2-roadmap-tenative","text":"","title":"Status - Built, Q2, Roadmap, Tenative"},{"location":"contribute/tools/hotwallet/#business-driver","text":"","title":"Business Driver"},{"location":"contribute/tools/hotwallet/#ecosystem-grant-eligible-priority-amount","text":"","title":"Ecosystem Grant - Eligible, Priority, Amount"},{"location":"contribute/tools/hotwallet/#deliverable","text":"","title":"Deliverable"},{"location":"contribute/tools/hotwallet/#technical-specification","text":"","title":"Technical Specification"},{"location":"contribute/tools/hotwallet/#reference-material","text":"","title":"Reference Material"},{"location":"contribute/tools/hotwallet/#level-of-effort","text":"","title":"Level of Effort"},{"location":"contribute/tools/hotwallet/#developer-or-partner-identified","text":"","title":"Developer or Partner Identified"},{"location":"contribute/tools/hotwallet/#harmony-owner","text":"","title":"Harmony Owner"},{"location":"contribute/tools/hotwallet/#developer-guide","text":"","title":"Developer Guide"},{"location":"contribute/tools/hrc/","text":"Component Name Overview Functional overview of what this component does Status - Built, Q2, Roadmap, Tenative Business Driver Ecosystem Grant - Eligible, Priority, Amount Deliverable Technical Specification Reference Material Level of Effort Developer or Partner Identified Harmony Owner Developer Guide","title":"HRC Contract Examples"},{"location":"contribute/tools/hrc/#component-name","text":"","title":"Component Name"},{"location":"contribute/tools/hrc/#overview","text":"Functional overview of what this component does","title":"Overview"},{"location":"contribute/tools/hrc/#status-built-q2-roadmap-tenative","text":"","title":"Status - Built, Q2, Roadmap, Tenative"},{"location":"contribute/tools/hrc/#business-driver","text":"","title":"Business Driver"},{"location":"contribute/tools/hrc/#ecosystem-grant-eligible-priority-amount","text":"","title":"Ecosystem Grant - Eligible, Priority, Amount"},{"location":"contribute/tools/hrc/#deliverable","text":"","title":"Deliverable"},{"location":"contribute/tools/hrc/#technical-specification","text":"","title":"Technical Specification"},{"location":"contribute/tools/hrc/#reference-material","text":"","title":"Reference Material"},{"location":"contribute/tools/hrc/#level-of-effort","text":"","title":"Level of Effort"},{"location":"contribute/tools/hrc/#developer-or-partner-identified","text":"","title":"Developer or Partner Identified"},{"location":"contribute/tools/hrc/#harmony-owner","text":"","title":"Harmony Owner"},{"location":"contribute/tools/hrc/#developer-guide","text":"","title":"Developer Guide"},{"location":"contribute/tools/hrcwallet/","text":"HRC Wallet Support (Metamask) Overview This provides HRC20 and HRC721 support for wallets enabling developers to launch tokens on our platform and have transfer supported natively. It is a key enable for stablecoins, exchanges, fundrasing, defi and crossfi. Status - Tenative Business Driver - Broad Platform Adoption Ecosystem Grant Eligible: Yes Priority: High Amount: TBD Deliverable HRC Token support on Shard 0 for Metamask. Technical Specification This will be built using the Metamask Plugin Framework Reference Material Introducing Web3 Plugins Metamask snaps wiki Metamask snaps github Twitter Message with Metamask Level of Effort 6 weeks Developer or Partner Identified John Whitton Dan Finlay- Metamask Aaron- Metamask Harmony Owner Sahil Dewan Developer Guide","title":"HRC Wallets"},{"location":"contribute/tools/hrcwallet/#hrc-wallet-support-metamask","text":"","title":"HRC Wallet Support (Metamask)"},{"location":"contribute/tools/hrcwallet/#overview","text":"This provides HRC20 and HRC721 support for wallets enabling developers to launch tokens on our platform and have transfer supported natively. It is a key enable for stablecoins, exchanges, fundrasing, defi and crossfi.","title":"Overview"},{"location":"contribute/tools/hrcwallet/#status-tenative","text":"","title":"Status -  Tenative"},{"location":"contribute/tools/hrcwallet/#business-driver-broad-platform-adoption","text":"","title":"Business Driver - Broad Platform Adoption"},{"location":"contribute/tools/hrcwallet/#ecosystem-grant","text":"Eligible: Yes Priority: High Amount: TBD","title":"Ecosystem Grant"},{"location":"contribute/tools/hrcwallet/#deliverable","text":"HRC Token support on Shard 0 for Metamask.","title":"Deliverable"},{"location":"contribute/tools/hrcwallet/#technical-specification","text":"This will be built using the Metamask Plugin Framework","title":"Technical Specification"},{"location":"contribute/tools/hrcwallet/#reference-material","text":"Introducing Web3 Plugins Metamask snaps wiki Metamask snaps github Twitter Message with Metamask","title":"Reference Material"},{"location":"contribute/tools/hrcwallet/#level-of-effort","text":"6 weeks","title":"Level of Effort"},{"location":"contribute/tools/hrcwallet/#developer-or-partner-identified","text":"John Whitton Dan Finlay- Metamask Aaron- Metamask","title":"Developer or Partner Identified"},{"location":"contribute/tools/hrcwallet/#harmony-owner","text":"Sahil Dewan","title":"Harmony Owner"},{"location":"contribute/tools/hrcwallet/#developer-guide","text":"","title":"Developer Guide"},{"location":"contribute/tools/identitykyc/","text":"Component Name Overview Functional overview of what this component does Status - Built, Q2, Roadmap, Tenative Business Driver Ecosystem Grant - Eligible, Priority, Amount Deliverable Technical Specification Reference Material Level of Effort Developer or Partner Identified Harmony Owner Developer Guide","title":"Identity KYC"},{"location":"contribute/tools/identitykyc/#component-name","text":"","title":"Component Name"},{"location":"contribute/tools/identitykyc/#overview","text":"Functional overview of what this component does","title":"Overview"},{"location":"contribute/tools/identitykyc/#status-built-q2-roadmap-tenative","text":"","title":"Status - Built, Q2, Roadmap, Tenative"},{"location":"contribute/tools/identitykyc/#business-driver","text":"","title":"Business Driver"},{"location":"contribute/tools/identitykyc/#ecosystem-grant-eligible-priority-amount","text":"","title":"Ecosystem Grant - Eligible, Priority, Amount"},{"location":"contribute/tools/identitykyc/#deliverable","text":"","title":"Deliverable"},{"location":"contribute/tools/identitykyc/#technical-specification","text":"","title":"Technical Specification"},{"location":"contribute/tools/identitykyc/#reference-material","text":"","title":"Reference Material"},{"location":"contribute/tools/identitykyc/#level-of-effort","text":"","title":"Level of Effort"},{"location":"contribute/tools/identitykyc/#developer-or-partner-identified","text":"","title":"Developer or Partner Identified"},{"location":"contribute/tools/identitykyc/#harmony-owner","text":"","title":"Harmony Owner"},{"location":"contribute/tools/identitykyc/#developer-guide","text":"","title":"Developer Guide"},{"location":"contribute/tools/interchain/","text":"Component Name Overview Functional overview of what this component does Status - Built, Q2, Roadmap, Tenative Business Driver Ecosystem Grant - Eligible, Priority, Amount Deliverable Technical Specification Reference Material Level of Effort Developer or Partner Identified Harmony Owner Developer Guide","title":"Interchain"},{"location":"contribute/tools/interchain/#component-name","text":"","title":"Component Name"},{"location":"contribute/tools/interchain/#overview","text":"Functional overview of what this component does","title":"Overview"},{"location":"contribute/tools/interchain/#status-built-q2-roadmap-tenative","text":"","title":"Status - Built, Q2, Roadmap, Tenative"},{"location":"contribute/tools/interchain/#business-driver","text":"","title":"Business Driver"},{"location":"contribute/tools/interchain/#ecosystem-grant-eligible-priority-amount","text":"","title":"Ecosystem Grant - Eligible, Priority, Amount"},{"location":"contribute/tools/interchain/#deliverable","text":"","title":"Deliverable"},{"location":"contribute/tools/interchain/#technical-specification","text":"","title":"Technical Specification"},{"location":"contribute/tools/interchain/#reference-material","text":"","title":"Reference Material"},{"location":"contribute/tools/interchain/#level-of-effort","text":"","title":"Level of Effort"},{"location":"contribute/tools/interchain/#developer-or-partner-identified","text":"","title":"Developer or Partner Identified"},{"location":"contribute/tools/interchain/#harmony-owner","text":"","title":"Harmony Owner"},{"location":"contribute/tools/interchain/#developer-guide","text":"","title":"Developer Guide"},{"location":"contribute/tools/javascriptsdk/","text":"Component Name Overview Functional overview of what this component does Status - Built, Q2, Roadmap, Tenative Business Driver Ecosystem Grant - Eligible, Priority, Amount Deliverable Technical Specification Reference Material Level of Effort Developer or Partner Identified Harmony Owner Developer Guide","title":"Javascript SDK"},{"location":"contribute/tools/javascriptsdk/#component-name","text":"","title":"Component Name"},{"location":"contribute/tools/javascriptsdk/#overview","text":"Functional overview of what this component does","title":"Overview"},{"location":"contribute/tools/javascriptsdk/#status-built-q2-roadmap-tenative","text":"","title":"Status - Built, Q2, Roadmap, Tenative"},{"location":"contribute/tools/javascriptsdk/#business-driver","text":"","title":"Business Driver"},{"location":"contribute/tools/javascriptsdk/#ecosystem-grant-eligible-priority-amount","text":"","title":"Ecosystem Grant - Eligible, Priority, Amount"},{"location":"contribute/tools/javascriptsdk/#deliverable","text":"","title":"Deliverable"},{"location":"contribute/tools/javascriptsdk/#technical-specification","text":"","title":"Technical Specification"},{"location":"contribute/tools/javascriptsdk/#reference-material","text":"","title":"Reference Material"},{"location":"contribute/tools/javascriptsdk/#level-of-effort","text":"","title":"Level of Effort"},{"location":"contribute/tools/javascriptsdk/#developer-or-partner-identified","text":"","title":"Developer or Partner Identified"},{"location":"contribute/tools/javascriptsdk/#harmony-owner","text":"","title":"Harmony Owner"},{"location":"contribute/tools/javascriptsdk/#developer-guide","text":"","title":"Developer Guide"},{"location":"contribute/tools/javasdk/","text":"Component Name Overview Functional overview of what this component does Status - Built, Q2, Roadmap, Tenative Business Driver Ecosystem Grant - Eligible, Priority, Amount Deliverable Technical Specification Reference Material Level of Effort Developer or Partner Identified Harmony Owner Developer Guide","title":"Java SDK"},{"location":"contribute/tools/javasdk/#component-name","text":"","title":"Component Name"},{"location":"contribute/tools/javasdk/#overview","text":"Functional overview of what this component does","title":"Overview"},{"location":"contribute/tools/javasdk/#status-built-q2-roadmap-tenative","text":"","title":"Status - Built, Q2, Roadmap, Tenative"},{"location":"contribute/tools/javasdk/#business-driver","text":"","title":"Business Driver"},{"location":"contribute/tools/javasdk/#ecosystem-grant-eligible-priority-amount","text":"","title":"Ecosystem Grant - Eligible, Priority, Amount"},{"location":"contribute/tools/javasdk/#deliverable","text":"","title":"Deliverable"},{"location":"contribute/tools/javasdk/#technical-specification","text":"","title":"Technical Specification"},{"location":"contribute/tools/javasdk/#reference-material","text":"","title":"Reference Material"},{"location":"contribute/tools/javasdk/#level-of-effort","text":"","title":"Level of Effort"},{"location":"contribute/tools/javasdk/#developer-or-partner-identified","text":"","title":"Developer or Partner Identified"},{"location":"contribute/tools/javasdk/#harmony-owner","text":"","title":"Harmony Owner"},{"location":"contribute/tools/javasdk/#developer-guide","text":"","title":"Developer Guide"},{"location":"contribute/tools/liquiditypool/","text":"Component Name Overview Functional overview of what this component does Status - Built, Q2, Roadmap, Tenative Business Driver Ecosystem Grant - Eligible, Priority, Amount Deliverable Technical Specification Reference Material Level of Effort Developer or Partner Identified Harmony Owner Developer Guide","title":"Liquidity Pools"},{"location":"contribute/tools/liquiditypool/#component-name","text":"","title":"Component Name"},{"location":"contribute/tools/liquiditypool/#overview","text":"Functional overview of what this component does","title":"Overview"},{"location":"contribute/tools/liquiditypool/#status-built-q2-roadmap-tenative","text":"","title":"Status - Built, Q2, Roadmap, Tenative"},{"location":"contribute/tools/liquiditypool/#business-driver","text":"","title":"Business Driver"},{"location":"contribute/tools/liquiditypool/#ecosystem-grant-eligible-priority-amount","text":"","title":"Ecosystem Grant - Eligible, Priority, Amount"},{"location":"contribute/tools/liquiditypool/#deliverable","text":"","title":"Deliverable"},{"location":"contribute/tools/liquiditypool/#technical-specification","text":"","title":"Technical Specification"},{"location":"contribute/tools/liquiditypool/#reference-material","text":"","title":"Reference Material"},{"location":"contribute/tools/liquiditypool/#level-of-effort","text":"","title":"Level of Effort"},{"location":"contribute/tools/liquiditypool/#developer-or-partner-identified","text":"","title":"Developer or Partner Identified"},{"location":"contribute/tools/liquiditypool/#harmony-owner","text":"","title":"Harmony Owner"},{"location":"contribute/tools/liquiditypool/#developer-guide","text":"","title":"Developer Guide"},{"location":"contribute/tools/localdeploy/","text":"Component Name Overview Functional overview of what this component does Status - Built, Q2, Roadmap, Tenative Business Driver Ecosystem Grant - Eligible, Priority, Amount Deliverable Technical Specification Reference Material Level of Effort Developer or Partner Identified Harmony Owner Developer Guide","title":"Harmony Deploy"},{"location":"contribute/tools/localdeploy/#component-name","text":"","title":"Component Name"},{"location":"contribute/tools/localdeploy/#overview","text":"Functional overview of what this component does","title":"Overview"},{"location":"contribute/tools/localdeploy/#status-built-q2-roadmap-tenative","text":"","title":"Status - Built, Q2, Roadmap, Tenative"},{"location":"contribute/tools/localdeploy/#business-driver","text":"","title":"Business Driver"},{"location":"contribute/tools/localdeploy/#ecosystem-grant-eligible-priority-amount","text":"","title":"Ecosystem Grant - Eligible, Priority, Amount"},{"location":"contribute/tools/localdeploy/#deliverable","text":"","title":"Deliverable"},{"location":"contribute/tools/localdeploy/#technical-specification","text":"","title":"Technical Specification"},{"location":"contribute/tools/localdeploy/#reference-material","text":"","title":"Reference Material"},{"location":"contribute/tools/localdeploy/#level-of-effort","text":"","title":"Level of Effort"},{"location":"contribute/tools/localdeploy/#developer-or-partner-identified","text":"","title":"Developer or Partner Identified"},{"location":"contribute/tools/localdeploy/#harmony-owner","text":"","title":"Harmony Owner"},{"location":"contribute/tools/localdeploy/#developer-guide","text":"","title":"Developer Guide"},{"location":"contribute/tools/openapi/","text":"Harmony Open API Specification Overview Provide a hosted interactive website for developers to prototype on Harmony. Also create a framework to increase productivity when generating client SDK's. Enhance design and build process to start from specification. Evaluate testing tools and automation that can be leveraged. Status - Tenative Business Driver - Partner Adoption and Developer Productivity Ecosystem Grant Eligible Priority Amount Deliverable Hosted Website for Harmony APIs Subsequent phases may include API test tools SDK client generation API development process enhancements Technical Specification See Below for current implementation Reference Material Level of Effort 2 weeks Developer or Partner Identified John Whitton Harmony Owner Ganesha Upadhyaya Developer Guide - open API specifications Overview The goal of the OpenAPI initiative is to Provide comprehensive API documentation for Hamony API's Provide an interactive UI for developers protoytping on Harmony Provide an automation suite for testing Provide the ability to generate clients or code from the specification moving forward. Phases The delivery will be broken down into the following milestones. Generate OpenAPI 3.0 specification for Harmony API's Generate Postman Collection from Open API Specification Generate an Interactive developer playground using Swagger Generate the OpenAPI 3.0 specification from the codebase Generate clients automatically Optionally generate code from the open API spec Approach and Progress Note: openapi typically has unique endpoints for each method as Harmony uses one endpoint for all API's workaround was done to create the documentation by suffixing method names. Generate OpenAPI 3.0 specification for Harmony API's First approach - geneate from code This is the Redux . The site is generated using runredux.sh swagger generate spec -w ../cmd/harmony/ -o swagger.json : reads through the codebase and genrates swagger.json Documentation was added to doc.go : high level project information net.go : API specific documentation Notes : goswagger only supports openAPI spec 2.0 and is not actively maintained Second approach: document all APIs in swagger.yml and generate UI from this - see section 3 Generate Postman Collection from Open API Specification The generated Postman collection can be found here This was done by manually importing the swagger.yml and publishing it Generate an Interactive developer playground using Swagger This is the Swaagger site which is interactive The site is generated using runSwagger.sh High level process flow is manually document the APIs in swagger.yml we clone the swager ui repository point the ui to our swagger.yml by copyin a modified index.html turn the updated sit into a go package using statik build the swagger ui and run it Generate the OpenAPI 3.0 specification from the codebase This is still to be done and estimated two to three days to document all the API's Generate clients automatically Some prototyping has been done on this and is exciting for future SDK development. Please see the following OpenAPI and gRPC Side-by-Side How to build a REST API with gRPC and get the best of two worlds Support for Open API spec 3.0 #1122 gnostic - openapi to protobuf gnostic go generator Optionally generate code from the open API spec Once the API layer was completely specified other tools such as code generation could be used. Hosted Endpoints Currently there are two hosted endpoints Swaagger : This allows interactive prototyping for developers Redux : This provides developer documentation but is not interactive. Postman - openapi Postman complete documentation Installation install goswagger For example on AWS linux download_url=$(curl -s https://api.github.com/repos/go-swagger/go-swagger/releases/latest | \\ jq -r '.assets[] | select(.name | contains(\"'\"$(uname | tr '[:upper:]' '[:lower:]')\"'_amd64\")) | .browser_download_url') sudo curl -o /usr/local/bin/swagger -L'#' \"$download_url\" sudo chmod +x /usr/local/bin/swagger Installing Swagger UI cd /home/ec2-user/go/src/github.com/harmony-one/harmony/swagger git clone git@github.com:swagger-api/swagger-ui.git mv ./swagger-ui/dist swaggerui rm -rf ./swagger-ui cp swagger.json ./swaggerui/. # build the [statik](https://github.com/rakyll/statik) file go get github.com/rakyll/statik statik -src=/home/ec2-user/go/src/github.com/harmony-one/harmony/swagger/swaggerui #statik -src=/Users/ribice/go/src/github.com/ribice/golang-swaggerui-example/cmd/swaggerui Initialize spec file swagger init spec Running Building and serving swagger documentation swagger generate spec -o swagger.json swagger serve swagger.json --port 8082 --host=0.0.0.0 --no-open Contributing When documenting each API method use operation_id Reference Material Open API Specification Swagger.io user guide Swagger hub editor Swagger Supporting Fragment in Path Object Swagger Support an operation having multiple specs per path Support for Open API spec 3.0 #1122 gnostic - openapi to protobuf gnostic go generator Generate Postman Collection from Open API goswagger.io documentation goswagger.io github Create golang documentation with SwaggerUI Generation from go source code Serve Swagger UI within go application OpenAPI and gRPC Side-by-Side How to build a REST API with gRPC and get the best of two worlds","title":"Open API Specification"},{"location":"contribute/tools/openapi/#harmony-open-api-specification","text":"","title":"Harmony Open API Specification"},{"location":"contribute/tools/openapi/#overview","text":"Provide a hosted interactive website for developers to prototype on Harmony. Also create a framework to increase productivity when generating client SDK's. Enhance design and build process to start from specification. Evaluate testing tools and automation that can be leveraged.","title":"Overview"},{"location":"contribute/tools/openapi/#status-tenative","text":"","title":"Status - Tenative"},{"location":"contribute/tools/openapi/#business-driver-partner-adoption-and-developer-productivity","text":"","title":"Business Driver - Partner Adoption and Developer Productivity"},{"location":"contribute/tools/openapi/#ecosystem-grant","text":"Eligible Priority Amount","title":"Ecosystem Grant"},{"location":"contribute/tools/openapi/#deliverable","text":"Hosted Website for Harmony APIs Subsequent phases may include API test tools SDK client generation API development process enhancements","title":"Deliverable"},{"location":"contribute/tools/openapi/#technical-specification","text":"See Below for current implementation","title":"Technical Specification"},{"location":"contribute/tools/openapi/#reference-material","text":"","title":"Reference Material"},{"location":"contribute/tools/openapi/#level-of-effort","text":"2 weeks","title":"Level of Effort"},{"location":"contribute/tools/openapi/#developer-or-partner-identified","text":"John Whitton","title":"Developer or Partner Identified"},{"location":"contribute/tools/openapi/#harmony-owner","text":"Ganesha Upadhyaya","title":"Harmony Owner"},{"location":"contribute/tools/openapi/#developer-guide-open-api-specifications","text":"","title":"Developer Guide - open API specifications"},{"location":"contribute/tools/openapi/#overview_1","text":"The goal of the OpenAPI initiative is to Provide comprehensive API documentation for Hamony API's Provide an interactive UI for developers protoytping on Harmony Provide an automation suite for testing Provide the ability to generate clients or code from the specification moving forward.","title":"Overview"},{"location":"contribute/tools/openapi/#phases","text":"The delivery will be broken down into the following milestones. Generate OpenAPI 3.0 specification for Harmony API's Generate Postman Collection from Open API Specification Generate an Interactive developer playground using Swagger Generate the OpenAPI 3.0 specification from the codebase Generate clients automatically Optionally generate code from the open API spec","title":"Phases"},{"location":"contribute/tools/openapi/#approach-and-progress","text":"Note: openapi typically has unique endpoints for each method as Harmony uses one endpoint for all API's workaround was done to create the documentation by suffixing method names. Generate OpenAPI 3.0 specification for Harmony API's First approach - geneate from code This is the Redux . The site is generated using runredux.sh swagger generate spec -w ../cmd/harmony/ -o swagger.json : reads through the codebase and genrates swagger.json Documentation was added to doc.go : high level project information net.go : API specific documentation Notes : goswagger only supports openAPI spec 2.0 and is not actively maintained Second approach: document all APIs in swagger.yml and generate UI from this - see section 3 Generate Postman Collection from Open API Specification The generated Postman collection can be found here This was done by manually importing the swagger.yml and publishing it Generate an Interactive developer playground using Swagger This is the Swaagger site which is interactive The site is generated using runSwagger.sh High level process flow is manually document the APIs in swagger.yml we clone the swager ui repository point the ui to our swagger.yml by copyin a modified index.html turn the updated sit into a go package using statik build the swagger ui and run it Generate the OpenAPI 3.0 specification from the codebase This is still to be done and estimated two to three days to document all the API's Generate clients automatically Some prototyping has been done on this and is exciting for future SDK development. Please see the following OpenAPI and gRPC Side-by-Side How to build a REST API with gRPC and get the best of two worlds Support for Open API spec 3.0 #1122 gnostic - openapi to protobuf gnostic go generator Optionally generate code from the open API spec Once the API layer was completely specified other tools such as code generation could be used.","title":"Approach and Progress"},{"location":"contribute/tools/openapi/#hosted-endpoints","text":"Currently there are two hosted endpoints Swaagger : This allows interactive prototyping for developers Redux : This provides developer documentation but is not interactive. Postman - openapi Postman complete documentation","title":"Hosted Endpoints"},{"location":"contribute/tools/openapi/#installation","text":"install goswagger For example on AWS linux download_url=$(curl -s https://api.github.com/repos/go-swagger/go-swagger/releases/latest | \\ jq -r '.assets[] | select(.name | contains(\"'\"$(uname | tr '[:upper:]' '[:lower:]')\"'_amd64\")) | .browser_download_url') sudo curl -o /usr/local/bin/swagger -L'#' \"$download_url\" sudo chmod +x /usr/local/bin/swagger Installing Swagger UI cd /home/ec2-user/go/src/github.com/harmony-one/harmony/swagger git clone git@github.com:swagger-api/swagger-ui.git mv ./swagger-ui/dist swaggerui rm -rf ./swagger-ui cp swagger.json ./swaggerui/. # build the [statik](https://github.com/rakyll/statik) file go get github.com/rakyll/statik statik -src=/home/ec2-user/go/src/github.com/harmony-one/harmony/swagger/swaggerui #statik -src=/Users/ribice/go/src/github.com/ribice/golang-swaggerui-example/cmd/swaggerui Initialize spec file swagger init spec","title":"Installation"},{"location":"contribute/tools/openapi/#running","text":"Building and serving swagger documentation swagger generate spec -o swagger.json swagger serve swagger.json --port 8082 --host=0.0.0.0 --no-open","title":"Running"},{"location":"contribute/tools/openapi/#contributing","text":"When documenting each API method use operation_id","title":"Contributing"},{"location":"contribute/tools/openapi/#reference-material_1","text":"Open API Specification Swagger.io user guide Swagger hub editor Swagger Supporting Fragment in Path Object Swagger Support an operation having multiple specs per path Support for Open API spec 3.0 #1122 gnostic - openapi to protobuf gnostic go generator Generate Postman Collection from Open API goswagger.io documentation goswagger.io github Create golang documentation with SwaggerUI Generation from go source code Serve Swagger UI within go application OpenAPI and gRPC Side-by-Side How to build a REST API with gRPC and get the best of two worlds","title":"Reference Material"},{"location":"contribute/tools/oracle/","text":"Component Name Overview Functional overview of what this component does Status - Built, Q2, Roadmap, Tenative Business Driver Ecosystem Grant - Eligible, Priority, Amount Deliverable Technical Specification Reference Material Level of Effort Developer or Partner Identified Harmony Owner Developer Guide","title":"Oracles"},{"location":"contribute/tools/oracle/#component-name","text":"","title":"Component Name"},{"location":"contribute/tools/oracle/#overview","text":"Functional overview of what this component does","title":"Overview"},{"location":"contribute/tools/oracle/#status-built-q2-roadmap-tenative","text":"","title":"Status - Built, Q2, Roadmap, Tenative"},{"location":"contribute/tools/oracle/#business-driver","text":"","title":"Business Driver"},{"location":"contribute/tools/oracle/#ecosystem-grant-eligible-priority-amount","text":"","title":"Ecosystem Grant - Eligible, Priority, Amount"},{"location":"contribute/tools/oracle/#deliverable","text":"","title":"Deliverable"},{"location":"contribute/tools/oracle/#technical-specification","text":"","title":"Technical Specification"},{"location":"contribute/tools/oracle/#reference-material","text":"","title":"Reference Material"},{"location":"contribute/tools/oracle/#level-of-effort","text":"","title":"Level of Effort"},{"location":"contribute/tools/oracle/#developer-or-partner-identified","text":"","title":"Developer or Partner Identified"},{"location":"contribute/tools/oracle/#harmony-owner","text":"","title":"Harmony Owner"},{"location":"contribute/tools/oracle/#developer-guide","text":"","title":"Developer Guide"},{"location":"contribute/tools/overview/","text":"Tool Overview","title":"Overview"},{"location":"contribute/tools/overview/#tool-overview","text":"","title":"Tool Overview"},{"location":"contribute/tools/postman/","text":"Component Name Overview Functional overview of what this component does Status - Built, Q2, Roadmap, Tenative Business Driver Ecosystem Grant - Eligible, Priority, Amount Deliverable Technical Specification Reference Material Level of Effort Developer or Partner Identified Harmony Owner Developer Guide","title":"Postman Client"},{"location":"contribute/tools/postman/#component-name","text":"","title":"Component Name"},{"location":"contribute/tools/postman/#overview","text":"Functional overview of what this component does","title":"Overview"},{"location":"contribute/tools/postman/#status-built-q2-roadmap-tenative","text":"","title":"Status - Built, Q2, Roadmap, Tenative"},{"location":"contribute/tools/postman/#business-driver","text":"","title":"Business Driver"},{"location":"contribute/tools/postman/#ecosystem-grant-eligible-priority-amount","text":"","title":"Ecosystem Grant - Eligible, Priority, Amount"},{"location":"contribute/tools/postman/#deliverable","text":"","title":"Deliverable"},{"location":"contribute/tools/postman/#technical-specification","text":"","title":"Technical Specification"},{"location":"contribute/tools/postman/#reference-material","text":"","title":"Reference Material"},{"location":"contribute/tools/postman/#level-of-effort","text":"","title":"Level of Effort"},{"location":"contribute/tools/postman/#developer-or-partner-identified","text":"","title":"Developer or Partner Identified"},{"location":"contribute/tools/postman/#harmony-owner","text":"","title":"Harmony Owner"},{"location":"contribute/tools/postman/#developer-guide","text":"","title":"Developer Guide"},{"location":"contribute/tools/privatetx/","text":"Component Name Overview Functional overview of what this component does Status - Built, Q2, Roadmap, Tenative Business Driver Ecosystem Grant - Eligible, Priority, Amount Deliverable Technical Specification Reference Material Level of Effort Developer or Partner Identified Harmony Owner Developer Guide","title":"Private Transactions"},{"location":"contribute/tools/privatetx/#component-name","text":"","title":"Component Name"},{"location":"contribute/tools/privatetx/#overview","text":"Functional overview of what this component does","title":"Overview"},{"location":"contribute/tools/privatetx/#status-built-q2-roadmap-tenative","text":"","title":"Status - Built, Q2, Roadmap, Tenative"},{"location":"contribute/tools/privatetx/#business-driver","text":"","title":"Business Driver"},{"location":"contribute/tools/privatetx/#ecosystem-grant-eligible-priority-amount","text":"","title":"Ecosystem Grant - Eligible, Priority, Amount"},{"location":"contribute/tools/privatetx/#deliverable","text":"","title":"Deliverable"},{"location":"contribute/tools/privatetx/#technical-specification","text":"","title":"Technical Specification"},{"location":"contribute/tools/privatetx/#reference-material","text":"","title":"Reference Material"},{"location":"contribute/tools/privatetx/#level-of-effort","text":"","title":"Level of Effort"},{"location":"contribute/tools/privatetx/#developer-or-partner-identified","text":"","title":"Developer or Partner Identified"},{"location":"contribute/tools/privatetx/#harmony-owner","text":"","title":"Harmony Owner"},{"location":"contribute/tools/privatetx/#developer-guide","text":"","title":"Developer Guide"},{"location":"contribute/tools/profiling/","text":"Component Name Overview Functional overview of what this component does Status - Built, Q2, Roadmap, Tenative Business Driver Ecosystem Grant - Eligible, Priority, Amount Deliverable Technical Specification Reference Material Level of Effort Developer or Partner Identified Harmony Owner Developer Guide","title":"Profiling Suite"},{"location":"contribute/tools/profiling/#component-name","text":"","title":"Component Name"},{"location":"contribute/tools/profiling/#overview","text":"Functional overview of what this component does","title":"Overview"},{"location":"contribute/tools/profiling/#status-built-q2-roadmap-tenative","text":"","title":"Status - Built, Q2, Roadmap, Tenative"},{"location":"contribute/tools/profiling/#business-driver","text":"","title":"Business Driver"},{"location":"contribute/tools/profiling/#ecosystem-grant-eligible-priority-amount","text":"","title":"Ecosystem Grant - Eligible, Priority, Amount"},{"location":"contribute/tools/profiling/#deliverable","text":"","title":"Deliverable"},{"location":"contribute/tools/profiling/#technical-specification","text":"","title":"Technical Specification"},{"location":"contribute/tools/profiling/#reference-material","text":"","title":"Reference Material"},{"location":"contribute/tools/profiling/#level-of-effort","text":"","title":"Level of Effort"},{"location":"contribute/tools/profiling/#developer-or-partner-identified","text":"","title":"Developer or Partner Identified"},{"location":"contribute/tools/profiling/#harmony-owner","text":"","title":"Harmony Owner"},{"location":"contribute/tools/profiling/#developer-guide","text":"","title":"Developer Guide"},{"location":"contribute/tools/protobuf/","text":"Component Name Overview Functional overview of what this component does Status - Built, Q2, Roadmap, Tenative Business Driver Ecosystem Grant - Eligible, Priority, Amount Deliverable Technical Specification Reference Material Level of Effort Developer or Partner Identified Harmony Owner Developer Guide","title":"Protobuf Client"},{"location":"contribute/tools/protobuf/#component-name","text":"","title":"Component Name"},{"location":"contribute/tools/protobuf/#overview","text":"Functional overview of what this component does","title":"Overview"},{"location":"contribute/tools/protobuf/#status-built-q2-roadmap-tenative","text":"","title":"Status - Built, Q2, Roadmap, Tenative"},{"location":"contribute/tools/protobuf/#business-driver","text":"","title":"Business Driver"},{"location":"contribute/tools/protobuf/#ecosystem-grant-eligible-priority-amount","text":"","title":"Ecosystem Grant - Eligible, Priority, Amount"},{"location":"contribute/tools/protobuf/#deliverable","text":"","title":"Deliverable"},{"location":"contribute/tools/protobuf/#technical-specification","text":"","title":"Technical Specification"},{"location":"contribute/tools/protobuf/#reference-material","text":"","title":"Reference Material"},{"location":"contribute/tools/protobuf/#level-of-effort","text":"","title":"Level of Effort"},{"location":"contribute/tools/protobuf/#developer-or-partner-identified","text":"","title":"Developer or Partner Identified"},{"location":"contribute/tools/protobuf/#harmony-owner","text":"","title":"Harmony Owner"},{"location":"contribute/tools/protobuf/#developer-guide","text":"","title":"Developer Guide"},{"location":"contribute/tools/remix/","text":"Deliverable A working REMIX plugin which enables harmony developers to develop and deploy solidity contracts on harmony testnet and mainnet environments. Technical Specification Build and test a remix plugin for the Harmony network * Review the remix plugin repository and complete tutorial * Develop the Harmony IDE Plugin * Integrate with Harmony API and/or js sdk * Test on alpha version of Remix-IDE. * Publish plugin Reference Material Remix IDE Remix Plugin Repository Remix Update 0.8.7 \u2014 plugins and more Level of Effort 15-20 days Developer or Partner Identified Francois Guezengar - lead remix developer Yann Lavreau - remix developer and wrote the medium article Consensys - Ejaaz Ahamadeen : Consenys contact could identify the right people in consensys. Harmony Owner Developer Guide Found here","title":"Remix IDE"},{"location":"contribute/tools/remix/#deliverable","text":"A working REMIX plugin which enables harmony developers to develop and deploy solidity contracts on harmony testnet and mainnet environments.","title":"Deliverable"},{"location":"contribute/tools/remix/#technical-specification","text":"Build and test a remix plugin for the Harmony network * Review the remix plugin repository and complete tutorial * Develop the Harmony IDE Plugin * Integrate with Harmony API and/or js sdk * Test on alpha version of Remix-IDE. * Publish plugin","title":"Technical Specification"},{"location":"contribute/tools/remix/#reference-material","text":"Remix IDE Remix Plugin Repository Remix Update 0.8.7 \u2014 plugins and more","title":"Reference Material"},{"location":"contribute/tools/remix/#level-of-effort","text":"15-20 days","title":"Level of Effort"},{"location":"contribute/tools/remix/#developer-or-partner-identified","text":"Francois Guezengar - lead remix developer Yann Lavreau - remix developer and wrote the medium article Consensys - Ejaaz Ahamadeen : Consenys contact could identify the right people in consensys.","title":"Developer or Partner Identified"},{"location":"contribute/tools/remix/#harmony-owner","text":"","title":"Harmony Owner"},{"location":"contribute/tools/remix/#developer-guide","text":"Found here","title":"Developer Guide"},{"location":"contribute/tools/stablecoin/","text":"Component Name Overview Functional overview of what this component does Status - Built, Q2, Roadmap, Tenative Business Driver Ecosystem Grant - Eligible, Priority, Amount Deliverable Technical Specification Reference Material Level of Effort Developer or Partner Identified Harmony Owner Developer Guide","title":"Stable Coins"},{"location":"contribute/tools/stablecoin/#component-name","text":"","title":"Component Name"},{"location":"contribute/tools/stablecoin/#overview","text":"Functional overview of what this component does","title":"Overview"},{"location":"contribute/tools/stablecoin/#status-built-q2-roadmap-tenative","text":"","title":"Status - Built, Q2, Roadmap, Tenative"},{"location":"contribute/tools/stablecoin/#business-driver","text":"","title":"Business Driver"},{"location":"contribute/tools/stablecoin/#ecosystem-grant-eligible-priority-amount","text":"","title":"Ecosystem Grant - Eligible, Priority, Amount"},{"location":"contribute/tools/stablecoin/#deliverable","text":"","title":"Deliverable"},{"location":"contribute/tools/stablecoin/#technical-specification","text":"","title":"Technical Specification"},{"location":"contribute/tools/stablecoin/#reference-material","text":"","title":"Reference Material"},{"location":"contribute/tools/stablecoin/#level-of-effort","text":"","title":"Level of Effort"},{"location":"contribute/tools/stablecoin/#developer-or-partner-identified","text":"","title":"Developer or Partner Identified"},{"location":"contribute/tools/stablecoin/#harmony-owner","text":"","title":"Harmony Owner"},{"location":"contribute/tools/stablecoin/#developer-guide","text":"","title":"Developer Guide"},{"location":"contribute/tools/testnets/","text":"Component Name Overview Functional overview of what this component does Status - Built, Q2, Roadmap, Tenative Business Driver Ecosystem Grant - Eligible, Priority, Amount Deliverable Technical Specification Reference Material Level of Effort Developer or Partner Identified Harmony Owner Developer Guide","title":"Testnets"},{"location":"contribute/tools/testnets/#component-name","text":"","title":"Component Name"},{"location":"contribute/tools/testnets/#overview","text":"Functional overview of what this component does","title":"Overview"},{"location":"contribute/tools/testnets/#status-built-q2-roadmap-tenative","text":"","title":"Status - Built, Q2, Roadmap, Tenative"},{"location":"contribute/tools/testnets/#business-driver","text":"","title":"Business Driver"},{"location":"contribute/tools/testnets/#ecosystem-grant-eligible-priority-amount","text":"","title":"Ecosystem Grant - Eligible, Priority, Amount"},{"location":"contribute/tools/testnets/#deliverable","text":"","title":"Deliverable"},{"location":"contribute/tools/testnets/#technical-specification","text":"","title":"Technical Specification"},{"location":"contribute/tools/testnets/#reference-material","text":"","title":"Reference Material"},{"location":"contribute/tools/testnets/#level-of-effort","text":"","title":"Level of Effort"},{"location":"contribute/tools/testnets/#developer-or-partner-identified","text":"","title":"Developer or Partner Identified"},{"location":"contribute/tools/testnets/#harmony-owner","text":"","title":"Harmony Owner"},{"location":"contribute/tools/testnets/#developer-guide","text":"","title":"Developer Guide"},{"location":"contribute/tools/truffle/","text":"Harmony Truffle Integration Overview Trufflesuite is the most widely adoopted Smart Contract and DApp development tool. The goal of this initiaitve is to fully integrate Harmony into truffle suite and drive developer adoption. Status -Tenative Business Driver - Developer Adoption Ecosystem Grant Eligible - Yes Priority Amount Deliverable Harmony fully integrated into truffle suite. Truffle Natively supports Harmony Ganache - Deploys Harmony Local Environment Ganache CLI Drizzle - Supports Harmony.one TruffleBox for Harmony Remix - Harmony Technical Specification Leverage the interface adapter Reference Material Truffle is making enhancements as part of Tezos onboarding which may be useful Tezos Grants Tezos Truffle Grant Github Trufflesuite Truffle : Smart Contract Development Ganache : Local Blockchain Ganache CLI : Command Line Interface Drizzle : Web Application development Level of Effort Developer or Partner Identified Technical Lead - Nick - gnidan@trufflesuite.com Partner relations - David Clark Harmony Owner Developer Guide","title":"Harmony Truffle"},{"location":"contribute/tools/truffle/#harmony-truffle-integration","text":"","title":"Harmony Truffle Integration"},{"location":"contribute/tools/truffle/#overview","text":"Trufflesuite is the most widely adoopted Smart Contract and DApp development tool. The goal of this initiaitve is to fully integrate Harmony into truffle suite and drive developer adoption.","title":"Overview"},{"location":"contribute/tools/truffle/#status-tenative","text":"","title":"Status -Tenative"},{"location":"contribute/tools/truffle/#business-driver-developer-adoption","text":"","title":"Business Driver - Developer Adoption"},{"location":"contribute/tools/truffle/#ecosystem-grant","text":"Eligible - Yes Priority Amount","title":"Ecosystem Grant"},{"location":"contribute/tools/truffle/#deliverable","text":"Harmony fully integrated into truffle suite. Truffle Natively supports Harmony Ganache - Deploys Harmony Local Environment Ganache CLI Drizzle - Supports Harmony.one TruffleBox for Harmony Remix - Harmony","title":"Deliverable"},{"location":"contribute/tools/truffle/#technical-specification","text":"Leverage the interface adapter","title":"Technical Specification"},{"location":"contribute/tools/truffle/#reference-material","text":"Truffle is making enhancements as part of Tezos onboarding which may be useful Tezos Grants Tezos Truffle Grant Github Trufflesuite Truffle : Smart Contract Development Ganache : Local Blockchain Ganache CLI : Command Line Interface Drizzle : Web Application development","title":"Reference Material"},{"location":"contribute/tools/truffle/#level-of-effort","text":"","title":"Level of Effort"},{"location":"contribute/tools/truffle/#developer-or-partner-identified","text":"Technical Lead - Nick - gnidan@trufflesuite.com Partner relations - David Clark","title":"Developer or Partner Identified"},{"location":"contribute/tools/truffle/#harmony-owner","text":"","title":"Harmony Owner"},{"location":"contribute/tools/truffle/#developer-guide","text":"","title":"Developer Guide"},{"location":"contribute/tools/trufflebox/","text":"Harmony Dapp Developer Boxes Overview Trufflesuite is the most widely adoopted Smart Contract and DApp development tool. TruffleBoxes provide ethereum developers with a marketplace of applications and tutorials to develop on ethereum using a number of development fameworks. The goal of this initiaitve is to add Harmony Examples to the existing truffle box area and then create a similar marketplace for Harmony DApp developers. Status -Tenative Business Driver - Developer Adoption Ecosystem Grant Eligible - Yes Priority Amount Deliverable Harmony Dapp Developer Boxes. Three harmony boxes published on Truffle Boxes - Petshop, ERC20 and NFT Harmony DApp Boxes created Technical Specification Follow the create a box tutorial to create the Harmony Truffle Boxes leveraging the HRC repository for the example apps. Prototype a harmony DApp Developer Marketplace by cloning the trufflesuite.com repository and modifying for Harmony Branding. Incorporate the website into Hamony's online strategy. Reference Material Truffle is making enhancements as part of Tezos onboarding which may be useful Tezos Grants Tezos Truffle Grant Github Trufflesuite Truffle : Smart Contract Development Ganache : Local Blockchain Ganache CLI : Command Line Interface Drizzle : Web Application development Level of Effort - 15-20 days TruffleBoxes: 3 * 1-2 days per box (5 days) Harmony DApp Developer Marketplace: (5 - 10 days) Incorporate into Harmony web site: (5 - 10 days) Developer or Partner Identified Technical Lead - Nick - gnidan@trufflesuite.com Partner relations - David Clark Harmony Owner Developer Guide","title":"Harmony Truffle Box"},{"location":"contribute/tools/trufflebox/#harmony-dapp-developer-boxes","text":"","title":"Harmony Dapp Developer Boxes"},{"location":"contribute/tools/trufflebox/#overview","text":"Trufflesuite is the most widely adoopted Smart Contract and DApp development tool. TruffleBoxes provide ethereum developers with a marketplace of applications and tutorials to develop on ethereum using a number of development fameworks. The goal of this initiaitve is to add Harmony Examples to the existing truffle box area and then create a similar marketplace for Harmony DApp developers.","title":"Overview"},{"location":"contribute/tools/trufflebox/#status-tenative","text":"","title":"Status -Tenative"},{"location":"contribute/tools/trufflebox/#business-driver-developer-adoption","text":"","title":"Business Driver - Developer Adoption"},{"location":"contribute/tools/trufflebox/#ecosystem-grant","text":"Eligible - Yes Priority Amount","title":"Ecosystem Grant"},{"location":"contribute/tools/trufflebox/#deliverable","text":"Harmony Dapp Developer Boxes. Three harmony boxes published on Truffle Boxes - Petshop, ERC20 and NFT Harmony DApp Boxes created","title":"Deliverable"},{"location":"contribute/tools/trufflebox/#technical-specification","text":"Follow the create a box tutorial to create the Harmony Truffle Boxes leveraging the HRC repository for the example apps. Prototype a harmony DApp Developer Marketplace by cloning the trufflesuite.com repository and modifying for Harmony Branding. Incorporate the website into Hamony's online strategy.","title":"Technical Specification"},{"location":"contribute/tools/trufflebox/#reference-material","text":"Truffle is making enhancements as part of Tezos onboarding which may be useful Tezos Grants Tezos Truffle Grant Github Trufflesuite Truffle : Smart Contract Development Ganache : Local Blockchain Ganache CLI : Command Line Interface Drizzle : Web Application development","title":"Reference Material"},{"location":"contribute/tools/trufflebox/#level-of-effort-15-20-days","text":"TruffleBoxes: 3 * 1-2 days per box (5 days) Harmony DApp Developer Marketplace: (5 - 10 days) Incorporate into Harmony web site: (5 - 10 days)","title":"Level of Effort - 15-20 days"},{"location":"contribute/tools/trufflebox/#developer-or-partner-identified","text":"Technical Lead - Nick - gnidan@trufflesuite.com Partner relations - David Clark","title":"Developer or Partner Identified"},{"location":"contribute/tools/trufflebox/#harmony-owner","text":"","title":"Harmony Owner"},{"location":"contribute/tools/trufflebox/#developer-guide","text":"","title":"Developer Guide"},{"location":"contribute/tools/tutorials/","text":"Component Name Overview Functional overview of what this component does Status - Built, Q2, Roadmap, Tenative Business Driver Ecosystem Grant - Eligible, Priority, Amount Deliverable Technical Specification Reference Material Level of Effort Developer or Partner Identified Harmony Owner Developer Guide","title":"Developer Tutorials"},{"location":"contribute/tools/tutorials/#component-name","text":"","title":"Component Name"},{"location":"contribute/tools/tutorials/#overview","text":"Functional overview of what this component does","title":"Overview"},{"location":"contribute/tools/tutorials/#status-built-q2-roadmap-tenative","text":"","title":"Status - Built, Q2, Roadmap, Tenative"},{"location":"contribute/tools/tutorials/#business-driver","text":"","title":"Business Driver"},{"location":"contribute/tools/tutorials/#ecosystem-grant-eligible-priority-amount","text":"","title":"Ecosystem Grant - Eligible, Priority, Amount"},{"location":"contribute/tools/tutorials/#deliverable","text":"","title":"Deliverable"},{"location":"contribute/tools/tutorials/#technical-specification","text":"","title":"Technical Specification"},{"location":"contribute/tools/tutorials/#reference-material","text":"","title":"Reference Material"},{"location":"contribute/tools/tutorials/#level-of-effort","text":"","title":"Level of Effort"},{"location":"contribute/tools/tutorials/#developer-or-partner-identified","text":"","title":"Developer or Partner Identified"},{"location":"contribute/tools/tutorials/#harmony-owner","text":"","title":"Harmony Owner"},{"location":"contribute/tools/tutorials/#developer-guide","text":"","title":"Developer Guide"},{"location":"contribute/tools/wrappedone/","text":"Component Name Overview Functional overview of what this component does Status - Built, Q2, Roadmap, Tenative Business Driver Ecosystem Grant - Eligible, Priority, Amount Deliverable Technical Specification Reference Material Level of Effort Developer or Partner Identified Harmony Owner Developer Guide","title":"Wrapped ONE"},{"location":"contribute/tools/wrappedone/#component-name","text":"","title":"Component Name"},{"location":"contribute/tools/wrappedone/#overview","text":"Functional overview of what this component does","title":"Overview"},{"location":"contribute/tools/wrappedone/#status-built-q2-roadmap-tenative","text":"","title":"Status - Built, Q2, Roadmap, Tenative"},{"location":"contribute/tools/wrappedone/#business-driver","text":"","title":"Business Driver"},{"location":"contribute/tools/wrappedone/#ecosystem-grant-eligible-priority-amount","text":"","title":"Ecosystem Grant - Eligible, Priority, Amount"},{"location":"contribute/tools/wrappedone/#deliverable","text":"","title":"Deliverable"},{"location":"contribute/tools/wrappedone/#technical-specification","text":"","title":"Technical Specification"},{"location":"contribute/tools/wrappedone/#reference-material","text":"","title":"Reference Material"},{"location":"contribute/tools/wrappedone/#level-of-effort","text":"","title":"Level of Effort"},{"location":"contribute/tools/wrappedone/#developer-or-partner-identified","text":"","title":"Developer or Partner Identified"},{"location":"contribute/tools/wrappedone/#harmony-owner","text":"","title":"Harmony Owner"},{"location":"contribute/tools/wrappedone/#developer-guide","text":"","title":"Developer Guide"},{"location":"deploy/overview/","text":"Network Deployment Runbook Overview Over the past month the deployment process for a Network Deployment is being refined. This involves four phases Validation - Validating the build process and ensuring all components are identified Deployment - Documenting all the steps for the current deployment process Consolidation - Optimizing the deployment process Automation - Automating the deployment process - see hard_reset.sh Phase 1 and 2 have been completed for the current process with phase 3 and 4 ready to commence. This documentation includes latest deployment information for components and also summarizes in a cheat sheet the process for a network deploy. Action items for the consolidation and automation process can be captured below. Also please review the reference material at the bottom of this page. Deployment Components harmony - Harmony protocol scripts folder contains deployment utilities with nodes.sh being key to node deployment harmony-ops - Documentation and utilities for external validators as well as devops tools and grafana monitoring tools and additional monitoring tools . Finally it also contains test-automation for both api and cli tests. experiment-deploy - Pipeline is the backbone of the deploy process and is run from the devops machine whenever deploying new networks. These scripts now include automation of complete network refresh using hard_reset.sh jenkins - The jenkins repository is leveraged by jenkins.harmony.one and calls various script from experiment deploy. For an understanding of this look at the jenkins setup for testnet_hard_reset which calls the hard_reset jenkinsfile which integrates with the devops machine leveraging hard_reset.sh in experiment-deploy pipeline . Network Components Harmony Nodes Sentry Nodes Validator Nodes Watchdog Funding Faucet Blockchain Explorer Staking Explorer CLI Network Deployment Phases Announce Network Deployment Protocol Release Protocol Validation Network Release Network Validation Announce completion of deployment","title":"Overview"},{"location":"deploy/overview/#network-deployment-runbook","text":"","title":"Network Deployment Runbook"},{"location":"deploy/overview/#overview","text":"Over the past month the deployment process for a Network Deployment is being refined. This involves four phases Validation - Validating the build process and ensuring all components are identified Deployment - Documenting all the steps for the current deployment process Consolidation - Optimizing the deployment process Automation - Automating the deployment process - see hard_reset.sh Phase 1 and 2 have been completed for the current process with phase 3 and 4 ready to commence. This documentation includes latest deployment information for components and also summarizes in a cheat sheet the process for a network deploy. Action items for the consolidation and automation process can be captured below. Also please review the reference material at the bottom of this page.","title":"Overview"},{"location":"deploy/overview/#deployment-components","text":"harmony - Harmony protocol scripts folder contains deployment utilities with nodes.sh being key to node deployment harmony-ops - Documentation and utilities for external validators as well as devops tools and grafana monitoring tools and additional monitoring tools . Finally it also contains test-automation for both api and cli tests. experiment-deploy - Pipeline is the backbone of the deploy process and is run from the devops machine whenever deploying new networks. These scripts now include automation of complete network refresh using hard_reset.sh jenkins - The jenkins repository is leveraged by jenkins.harmony.one and calls various script from experiment deploy. For an understanding of this look at the jenkins setup for testnet_hard_reset which calls the hard_reset jenkinsfile which integrates with the devops machine leveraging hard_reset.sh in experiment-deploy pipeline .","title":"Deployment Components"},{"location":"deploy/overview/#network-components","text":"Harmony Nodes Sentry Nodes Validator Nodes Watchdog Funding Faucet Blockchain Explorer Staking Explorer CLI","title":"Network Components"},{"location":"deploy/overview/#network-deployment-phases","text":"Announce Network Deployment Protocol Release Protocol Validation Network Release Network Validation Announce completion of deployment","title":"Network Deployment  Phases"},{"location":"deploy/temp/","text":"Component Name Overview Functional overview of what this component does Status - Built, Q2, Roadmap, Tenative Business Driver Ecosystem Grant - Eligible, Priority, Amount Deliverable Technical Specification Reference Material Level of Effort Developer or Partner Identified Harmony Owner Developer Guide","title":"Component Name"},{"location":"deploy/temp/#component-name","text":"","title":"Component Name"},{"location":"deploy/temp/#overview","text":"Functional overview of what this component does","title":"Overview"},{"location":"deploy/temp/#status-built-q2-roadmap-tenative","text":"","title":"Status - Built, Q2, Roadmap, Tenative"},{"location":"deploy/temp/#business-driver","text":"","title":"Business Driver"},{"location":"deploy/temp/#ecosystem-grant-eligible-priority-amount","text":"","title":"Ecosystem Grant - Eligible, Priority, Amount"},{"location":"deploy/temp/#deliverable","text":"","title":"Deliverable"},{"location":"deploy/temp/#technical-specification","text":"","title":"Technical Specification"},{"location":"deploy/temp/#reference-material","text":"","title":"Reference Material"},{"location":"deploy/temp/#level-of-effort","text":"","title":"Level of Effort"},{"location":"deploy/temp/#developer-or-partner-identified","text":"","title":"Developer or Partner Identified"},{"location":"deploy/temp/#harmony-owner","text":"","title":"Harmony Owner"},{"location":"deploy/temp/#developer-guide","text":"","title":"Developer Guide"},{"location":"deploy/cicd/inframgmt/","text":"Component Name Overview Functional overview of what this component does Status - Built, Q2, Roadmap, Tenative Business Driver Ecosystem Grant - Eligible, Priority, Amount Deliverable Technical Specification Reference Material Level of Effort Developer or Partner Identified Harmony Owner Developer Guide","title":"Infrastructure Management"},{"location":"deploy/cicd/inframgmt/#component-name","text":"","title":"Component Name"},{"location":"deploy/cicd/inframgmt/#overview","text":"Functional overview of what this component does","title":"Overview"},{"location":"deploy/cicd/inframgmt/#status-built-q2-roadmap-tenative","text":"","title":"Status - Built, Q2, Roadmap, Tenative"},{"location":"deploy/cicd/inframgmt/#business-driver","text":"","title":"Business Driver"},{"location":"deploy/cicd/inframgmt/#ecosystem-grant-eligible-priority-amount","text":"","title":"Ecosystem Grant - Eligible, Priority, Amount"},{"location":"deploy/cicd/inframgmt/#deliverable","text":"","title":"Deliverable"},{"location":"deploy/cicd/inframgmt/#technical-specification","text":"","title":"Technical Specification"},{"location":"deploy/cicd/inframgmt/#reference-material","text":"","title":"Reference Material"},{"location":"deploy/cicd/inframgmt/#level-of-effort","text":"","title":"Level of Effort"},{"location":"deploy/cicd/inframgmt/#developer-or-partner-identified","text":"","title":"Developer or Partner Identified"},{"location":"deploy/cicd/inframgmt/#harmony-owner","text":"","title":"Harmony Owner"},{"location":"deploy/cicd/inframgmt/#developer-guide","text":"","title":"Developer Guide"},{"location":"deploy/cicd/netdeploy/","text":"Network Deployment Runbook Overview Over the past month the deployment process for a Network Deployment is being refined. This involves four phases Validation - Validating the build process and ensuring all components are identified Deployment - Documenting all the steps for the current deployment process Consolidation - Optimizing the deployment process Automation - Automating the deployment process - see hard_reset.sh Phase 1 and 2 have been completed for the current process with phase 3 and 4 ready to commence. This documentation includes latest deployment information for components and also summarizes in a cheat sheet the process for a network deploy. Action items for the consolidation and automation process can be captured below. Also please review the reference material at the bottom of this page. Deployment Components harmony - Harmony protocol scripts folder contains deployment utilities with nodes.sh being key to node deployment harmony-ops - Documentation and utilities for external validators as well as devops tools and grafana monitoring tools and additional monitoring tools . Finally it also contains test-automation for both api and cli tests. experiment-deploy - Pipeline is the backbone of the deploy process and is run from the devops machine whenever deploying new networks. These scripts now include automation of complete network refresh using hard_reset.sh jenkins - The jenkins repository is leveraged by jenkins.harmony.one and calls various script from experiment deploy. For an understanding of this look at the jenkins setup for testnet_hard_reset which calls the hard_reset jenkinsfile which integrates with the devops machine leveraging hard_reset.sh in experiment-deploy pipeline . Network Components Harmony Nodes Sentry Nodes Validator Nodes Watchdog Funding Faucet Blockchain Explorer Staking Explorer CLI Network Deployment Phases Announce Network Deployment Protocol Release Protocol Validation Network Release Network Validation Announce completion of deployment","title":"Network Deploy"},{"location":"deploy/cicd/netdeploy/#network-deployment-runbook","text":"","title":"Network Deployment Runbook"},{"location":"deploy/cicd/netdeploy/#overview","text":"Over the past month the deployment process for a Network Deployment is being refined. This involves four phases Validation - Validating the build process and ensuring all components are identified Deployment - Documenting all the steps for the current deployment process Consolidation - Optimizing the deployment process Automation - Automating the deployment process - see hard_reset.sh Phase 1 and 2 have been completed for the current process with phase 3 and 4 ready to commence. This documentation includes latest deployment information for components and also summarizes in a cheat sheet the process for a network deploy. Action items for the consolidation and automation process can be captured below. Also please review the reference material at the bottom of this page.","title":"Overview"},{"location":"deploy/cicd/netdeploy/#deployment-components","text":"harmony - Harmony protocol scripts folder contains deployment utilities with nodes.sh being key to node deployment harmony-ops - Documentation and utilities for external validators as well as devops tools and grafana monitoring tools and additional monitoring tools . Finally it also contains test-automation for both api and cli tests. experiment-deploy - Pipeline is the backbone of the deploy process and is run from the devops machine whenever deploying new networks. These scripts now include automation of complete network refresh using hard_reset.sh jenkins - The jenkins repository is leveraged by jenkins.harmony.one and calls various script from experiment deploy. For an understanding of this look at the jenkins setup for testnet_hard_reset which calls the hard_reset jenkinsfile which integrates with the devops machine leveraging hard_reset.sh in experiment-deploy pipeline .","title":"Deployment Components"},{"location":"deploy/cicd/netdeploy/#network-components","text":"Harmony Nodes Sentry Nodes Validator Nodes Watchdog Funding Faucet Blockchain Explorer Staking Explorer CLI","title":"Network Components"},{"location":"deploy/cicd/netdeploy/#network-deployment-phases","text":"Announce Network Deployment Protocol Release Protocol Validation Network Release Network Validation Announce completion of deployment","title":"Network Deployment  Phases"},{"location":"deploy/cicd/stress/","text":"Component Name Overview Functional overview of what this component does Status - Built, Q2, Roadmap, Tenative Business Driver Ecosystem Grant - Eligible, Priority, Amount Deliverable Technical Specification Reference Material Level of Effort Developer or Partner Identified Harmony Owner Developer Guide","title":"Stress Testing Tools"},{"location":"deploy/cicd/stress/#component-name","text":"","title":"Component Name"},{"location":"deploy/cicd/stress/#overview","text":"Functional overview of what this component does","title":"Overview"},{"location":"deploy/cicd/stress/#status-built-q2-roadmap-tenative","text":"","title":"Status - Built, Q2, Roadmap, Tenative"},{"location":"deploy/cicd/stress/#business-driver","text":"","title":"Business Driver"},{"location":"deploy/cicd/stress/#ecosystem-grant-eligible-priority-amount","text":"","title":"Ecosystem Grant - Eligible, Priority, Amount"},{"location":"deploy/cicd/stress/#deliverable","text":"","title":"Deliverable"},{"location":"deploy/cicd/stress/#technical-specification","text":"","title":"Technical Specification"},{"location":"deploy/cicd/stress/#reference-material","text":"","title":"Reference Material"},{"location":"deploy/cicd/stress/#level-of-effort","text":"","title":"Level of Effort"},{"location":"deploy/cicd/stress/#developer-or-partner-identified","text":"","title":"Developer or Partner Identified"},{"location":"deploy/cicd/stress/#harmony-owner","text":"","title":"Harmony Owner"},{"location":"deploy/cicd/stress/#developer-guide","text":"","title":"Developer Guide"},{"location":"deploy/cicd/testframework/","text":"Component Name Overview Functional overview of what this component does Status - Built, Q2, Roadmap, Tenative Business Driver Ecosystem Grant - Eligible, Priority, Amount Deliverable Technical Specification Reference Material Level of Effort Developer or Partner Identified Harmony Owner Developer Guide","title":"Test Framework"},{"location":"deploy/cicd/testframework/#component-name","text":"","title":"Component Name"},{"location":"deploy/cicd/testframework/#overview","text":"Functional overview of what this component does","title":"Overview"},{"location":"deploy/cicd/testframework/#status-built-q2-roadmap-tenative","text":"","title":"Status - Built, Q2, Roadmap, Tenative"},{"location":"deploy/cicd/testframework/#business-driver","text":"","title":"Business Driver"},{"location":"deploy/cicd/testframework/#ecosystem-grant-eligible-priority-amount","text":"","title":"Ecosystem Grant - Eligible, Priority, Amount"},{"location":"deploy/cicd/testframework/#deliverable","text":"","title":"Deliverable"},{"location":"deploy/cicd/testframework/#technical-specification","text":"","title":"Technical Specification"},{"location":"deploy/cicd/testframework/#reference-material","text":"","title":"Reference Material"},{"location":"deploy/cicd/testframework/#level-of-effort","text":"","title":"Level of Effort"},{"location":"deploy/cicd/testframework/#developer-or-partner-identified","text":"","title":"Developer or Partner Identified"},{"location":"deploy/cicd/testframework/#harmony-owner","text":"","title":"Harmony Owner"},{"location":"deploy/cicd/testframework/#developer-guide","text":"","title":"Developer Guide"},{"location":"deploy/cicd/netdeploy/block-explorer-deployment/","text":"Block Explorer Deployment Updating the IP's when we do a Rebuild with new IP's - get ips from devops {% tabs %} {% tab title=\"OSTN\" %} exec ssh -i ~/.ssh/keys/oregon-key-benchmark.pem ec2-user@35.160.64.190 pwd cd /home/ec2-user/experiment-deploy/pipeline/logs/os grep explorer distribution_config.txt # Will return 3.84.119.155 9000 explorer_node 0 1-OS-explorer_node-od-2020-03-18_21_24_05 \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 54.197.198.245 9000 explorer_node 1 1-OS-explorer_node-od-2020-03-18_21_24_05 \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 18.208.144.30 9000 explorer_node 2 1-OS-explorer_node-od-2020-03-18_21_24_05 \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 3.83.10.40 9000 explorer_node 3 1-OS-explorer_node-od-2020-03-18_21_24_05 {% endtab %} {% tab title=\"STN\" %} profile_print grep /home/ec2-user/JL/experiment-deploy/pipeline/logs/stn/explorer distribution_config.txt # Will return 54.202.250.192 9000 explorer_node 0 4-STN-explorer_node-od-2020-04-01_01_55_15 18.144.64.209 9000 explorer_node 1 3-STN-explorer_node-od-2020-04-01_01_55_15 {% endtab %} {% endtabs %} Login to Block Explorer {% tabs %} {% tab title=\"OSTN\" %} exec ssh -i ~/.ssh/keys/oregon-key-benchmark.pem ec2-user@44.232.43.231 {% endtab %} {% tab title=\"STN\" %} exec ssh -i ~/.ssh/keys/oregon-key-benchmark.pem ec2-user@35.164.26.115 {% endtab %} {% endtabs %} Replace the IPS in leaders.json exec ssh -i ~/.ssh/keys/oregon-key-benchmark.pem ec2-user@44.232.43.231 cd ~/projects/harmony-dashboard-backend vim leaders.json #Update the IPS in the json file e.g. for stn [\"18.144.45.107\",\"34.222.92.61\"] Refreshing the database # Get the pid by using check ports check_ports # Gives this 2000 frontend 8080 https and 8888 web socket # node 23041 ec2-user 22u IPv6 72359909 0t0 TCP *:8888 (LISTEN) # node 23041 ec2-user 23u IPv6 72360567 0t0 TCP *:8080 (LISTEN) \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7node 23041 ec2-user 23u IPv6 72360567 0t0 TCP *:8080 (LISTEN) \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7http-serv 26020 ec2-user 22u IPv4 72586772 0t0 TCP *:2000 (LISTEN) # http-serv 26020 ec2-user 22u IPv4 72586772 0t0 TCP *:2000 (LISTEN) # Stop the backend you get the pid from the ports command kill -9 23041 # Reset the db cd ~/projects/harmony-dashboard-backend npm run db-reset # Restart the backend npm run start Building a new version git pull npm run build npm run start","title":"Block Explorer Deployment"},{"location":"deploy/cicd/netdeploy/block-explorer-deployment/#block-explorer-deployment","text":"","title":"Block Explorer Deployment"},{"location":"deploy/cicd/netdeploy/block-explorer-deployment/#updating-the-ips-when-we-do-a-rebuild-with-new-ips-get-ips-from-devops","text":"{% tabs %} {% tab title=\"OSTN\" %} exec ssh -i ~/.ssh/keys/oregon-key-benchmark.pem ec2-user@35.160.64.190 pwd cd /home/ec2-user/experiment-deploy/pipeline/logs/os grep explorer distribution_config.txt # Will return 3.84.119.155 9000 explorer_node 0 1-OS-explorer_node-od-2020-03-18_21_24_05 \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 54.197.198.245 9000 explorer_node 1 1-OS-explorer_node-od-2020-03-18_21_24_05 \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 18.208.144.30 9000 explorer_node 2 1-OS-explorer_node-od-2020-03-18_21_24_05 \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 3.83.10.40 9000 explorer_node 3 1-OS-explorer_node-od-2020-03-18_21_24_05 {% endtab %} {% tab title=\"STN\" %} profile_print grep /home/ec2-user/JL/experiment-deploy/pipeline/logs/stn/explorer distribution_config.txt # Will return 54.202.250.192 9000 explorer_node 0 4-STN-explorer_node-od-2020-04-01_01_55_15 18.144.64.209 9000 explorer_node 1 3-STN-explorer_node-od-2020-04-01_01_55_15 {% endtab %} {% endtabs %}","title":"Updating the IP's when we do a Rebuild with new IP's - get ips from devops"},{"location":"deploy/cicd/netdeploy/block-explorer-deployment/#login-to-block-explorer","text":"{% tabs %} {% tab title=\"OSTN\" %} exec ssh -i ~/.ssh/keys/oregon-key-benchmark.pem ec2-user@44.232.43.231 {% endtab %} {% tab title=\"STN\" %} exec ssh -i ~/.ssh/keys/oregon-key-benchmark.pem ec2-user@35.164.26.115 {% endtab %} {% endtabs %}","title":"Login to Block Explorer"},{"location":"deploy/cicd/netdeploy/block-explorer-deployment/#replace-the-ips-in-leadersjson","text":"exec ssh -i ~/.ssh/keys/oregon-key-benchmark.pem ec2-user@44.232.43.231 cd ~/projects/harmony-dashboard-backend vim leaders.json #Update the IPS in the json file e.g. for stn [\"18.144.45.107\",\"34.222.92.61\"]","title":"Replace the IPS in leaders.json"},{"location":"deploy/cicd/netdeploy/block-explorer-deployment/#refreshing-the-database","text":"# Get the pid by using check ports check_ports # Gives this 2000 frontend 8080 https and 8888 web socket # node 23041 ec2-user 22u IPv6 72359909 0t0 TCP *:8888 (LISTEN) # node 23041 ec2-user 23u IPv6 72360567 0t0 TCP *:8080 (LISTEN) \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7node 23041 ec2-user 23u IPv6 72360567 0t0 TCP *:8080 (LISTEN) \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7http-serv 26020 ec2-user 22u IPv4 72586772 0t0 TCP *:2000 (LISTEN) # http-serv 26020 ec2-user 22u IPv4 72586772 0t0 TCP *:2000 (LISTEN) # Stop the backend you get the pid from the ports command kill -9 23041 # Reset the db cd ~/projects/harmony-dashboard-backend npm run db-reset # Restart the backend npm run start Building a new version git pull npm run build npm run start","title":"Refreshing the database"},{"location":"deploy/cicd/netdeploy/faucet-deployment/","text":"Faucet Deployment Faucet Overview The faucet is used to allow developers, validators and delegators to fund their account on Harmony's test networks so that they can participate in Harmony testing and development. It consists of a smart contract layer, a backend and a simple front end hosted by Harmony. Economics Funding is 30M ONE at each hard refresh Issuance is 10,000 ONE per wallet address every 450 blocks This enables 3000 faucet transactions of 10,000 each Top up is 30M ONE using the same mechanism as above e.g https://faucet.os.hmny.io/exposeAddress get the address and then fund the account from any account Components Smart Contract Layer - Code can be found in node-faucet with faucet.sol containing the key functionality Backend - Also found in node-faucet with app.js being the entry point Frontend - Also found in node-faucet with index.html being the entry point Deployment Environments OSTN - website PSTN - website Deployment Setup Clone the HRC REPOSITORY git clone https://github.com/harmony-one/HRC.git Spin up a new instance for the faucet This will be an AWS instance t3.small 8GB with ports 80, 443 22 open see here for an example from STN deployed in Oregon List of Instances # STN - 54.200.244.64 (harmony-testnet.pem) ./node_ssh.sh 54.200.244.64 # OSTN ./node_ssh.sh 3.133.82.52 # PTN Host faucet IdentityFile ~/.ssh/harmony-keys/cem_harmony_key2.pem User ubuntu HostName ec2-3-133-82-52.us-east-2.compute.amazonaws.com Host p-faucet IdentityFile ~/.ssh/harmony-keys/cem_harmony_key2.pem User ubuntu HostName ec2-3-134-93-91.us-east-2.compute.amazonaws.com Host t-faucet IdentityFile ~/.ssh/harmony-keys/cem_harmony_key2.pem User ubuntu HostName ec2-18-221-19-29.us-east-2.compute.amazonaws.com Deployment Process cd /Users/johnwhitton/projects/HRC/examples/node-faucet Overview of funding process: run the deploy script (included separately) in the examples/node-faucet directory of the up to date HRC repo OSTN: OSTN_deploy.sh PSTN: PSTN_deploy.sh LRTN: LRTN_deploy.sh run the output command in the respective faucet instance kill the current running faucet first ( tmux attach ) either reuse the same tmux instance or start a new one in the faucet directory: ~/HRC2/examples/node-faucet copy the last command from the output [OSTN | PSTN]_cmd_log.txt and run it in the tmux window detach the tmux window with <ctrl-b>, d fund the contract account OSTN: https://faucet.os.hmny.io/exposeAddress PSTN: https://faucet.ps.hmny.io/exposeAddress funding process can be automated by grabbing the hex faucet address from the deploy script and converting it to bech32. can check that the faucet is successfully deployed by checking that amount in shard 0 is the initial funded amount (currently 0.01 ONE) Areas for Improvement Funding increase amount of funds by 10x Timeouts - analyze whether we can send multiple transactions per block - nonce issue Deploy multiple(5) faucets with different end points and tree structure Modify process to remove smart contract and sign transactions directly (if this enables multi transactions per block) Enhance further to send from multiple accounts.","title":"Faucet Deployment"},{"location":"deploy/cicd/netdeploy/faucet-deployment/#faucet-deployment","text":"","title":"Faucet Deployment"},{"location":"deploy/cicd/netdeploy/faucet-deployment/#faucet-overview","text":"The faucet is used to allow developers, validators and delegators to fund their account on Harmony's test networks so that they can participate in Harmony testing and development. It consists of a smart contract layer, a backend and a simple front end hosted by Harmony.","title":"Faucet Overview"},{"location":"deploy/cicd/netdeploy/faucet-deployment/#economics","text":"Funding is 30M ONE at each hard refresh Issuance is 10,000 ONE per wallet address every 450 blocks This enables 3000 faucet transactions of 10,000 each Top up is 30M ONE using the same mechanism as above e.g https://faucet.os.hmny.io/exposeAddress get the address and then fund the account from any account","title":"Economics"},{"location":"deploy/cicd/netdeploy/faucet-deployment/#components","text":"Smart Contract Layer - Code can be found in node-faucet with faucet.sol containing the key functionality Backend - Also found in node-faucet with app.js being the entry point Frontend - Also found in node-faucet with index.html being the entry point","title":"Components"},{"location":"deploy/cicd/netdeploy/faucet-deployment/#deployment-environments","text":"OSTN - website PSTN - website","title":"Deployment Environments"},{"location":"deploy/cicd/netdeploy/faucet-deployment/#deployment-setup","text":"Clone the HRC REPOSITORY git clone https://github.com/harmony-one/HRC.git Spin up a new instance for the faucet This will be an AWS instance t3.small 8GB with ports 80, 443 22 open see here for an example from STN deployed in Oregon","title":"Deployment Setup"},{"location":"deploy/cicd/netdeploy/faucet-deployment/#list-of-instances","text":"# STN - 54.200.244.64 (harmony-testnet.pem) ./node_ssh.sh 54.200.244.64 # OSTN ./node_ssh.sh 3.133.82.52 # PTN Host faucet IdentityFile ~/.ssh/harmony-keys/cem_harmony_key2.pem User ubuntu HostName ec2-3-133-82-52.us-east-2.compute.amazonaws.com Host p-faucet IdentityFile ~/.ssh/harmony-keys/cem_harmony_key2.pem User ubuntu HostName ec2-3-134-93-91.us-east-2.compute.amazonaws.com Host t-faucet IdentityFile ~/.ssh/harmony-keys/cem_harmony_key2.pem User ubuntu HostName ec2-18-221-19-29.us-east-2.compute.amazonaws.com","title":"List of Instances"},{"location":"deploy/cicd/netdeploy/faucet-deployment/#deployment-process","text":"cd /Users/johnwhitton/projects/HRC/examples/node-faucet","title":"Deployment Process"},{"location":"deploy/cicd/netdeploy/faucet-deployment/#overview-of-funding-process","text":"run the deploy script (included separately) in the examples/node-faucet directory of the up to date HRC repo OSTN: OSTN_deploy.sh PSTN: PSTN_deploy.sh LRTN: LRTN_deploy.sh run the output command in the respective faucet instance kill the current running faucet first ( tmux attach ) either reuse the same tmux instance or start a new one in the faucet directory: ~/HRC2/examples/node-faucet copy the last command from the output [OSTN | PSTN]_cmd_log.txt and run it in the tmux window detach the tmux window with <ctrl-b>, d fund the contract account OSTN: https://faucet.os.hmny.io/exposeAddress PSTN: https://faucet.ps.hmny.io/exposeAddress funding process can be automated by grabbing the hex faucet address from the deploy script and converting it to bech32. can check that the faucet is successfully deployed by checking that amount in shard 0 is the initial funded amount (currently 0.01 ONE)","title":"Overview of funding process:"},{"location":"deploy/cicd/netdeploy/faucet-deployment/#areas-for-improvement","text":"Funding increase amount of funds by 10x Timeouts - analyze whether we can send multiple transactions per block - nonce issue Deploy multiple(5) faucets with different end points and tree structure Modify process to remove smart contract and sign transactions directly (if this enables multi transactions per block) Enhance further to send from multiple accounts.","title":"Areas for Improvement"},{"location":"deploy/cicd/netdeploy/harmony-chrome-extension/","text":"Harmony Chrome extension Overview Download the version from here and unzip Go to chrome://extensions Ensure Developer Mode is on (toggle upper right corner) Press Load unpacked and point to the directory you unzipped to Reference Material Harmony Chrome Extension Build","title":"Harmony Chrome extension"},{"location":"deploy/cicd/netdeploy/harmony-chrome-extension/#harmony-chrome-extension","text":"","title":"Harmony Chrome extension"},{"location":"deploy/cicd/netdeploy/harmony-chrome-extension/#overview","text":"Download the version from here and unzip Go to chrome://extensions Ensure Developer Mode is on (toggle upper right corner) Press Load unpacked and point to the directory you unzipped to","title":"Overview"},{"location":"deploy/cicd/netdeploy/harmony-chrome-extension/#reference-material","text":"Harmony Chrome Extension Build","title":"Reference Material"},{"location":"deploy/cicd/netdeploy/netdeploy/","text":"Network Deployment Runbook Overview Over the past month the deployment process for a Network Deployment is being refined. This involves four phases Validation - Validating the build process and ensuring all components are identified Deployment - Documenting all the steps for the current deployment process Consolidation - Optimizing the deployment process Automation - Automating the deployment process - see hard_reset.sh Phase 1 and 2 have been completed for the current process with phase 3 and 4 ready to commence. This documentation includes latest deployment information for components and also summarizes in a cheat sheet the process for a network deploy. Action items for the consolidation and automation process can be captured below. Also please review the reference material at the bottom of this page. Deployment Components harmony - Harmony protocol scripts folder contains deployment utilities with nodes.sh being key to node deployment harmony-ops - Documentation and utilities for external validators as well as devops tools and grafana monitoring tools and additional monitoring tools . Finally it also contains test-automation for both api and cli tests. experiment-deploy - Pipeline is the backbone of the deploy process and is run from the devops machine whenever deploying new networks. These scripts now include automation of complete network refresh using hard_reset.sh jenkins - The jenkins repository is leveraged by jenkins.harmony.one and calls various script from experiment deploy. For an understanding of this look at the jenkins setup for testnet_hard_reset which calls the hard_reset jenkinsfile which integrates with the devops machine leveraging hard_reset.sh in experiment-deploy pipeline . Network Components Harmony Nodes Sentry Nodes Validator Nodes Watchdog Funding Faucet Blockchain Explorer Staking Explorer CLI Network Deployment Phases Announce Network Deployment Protocol Release Protocol Validation Network Release Network Validation Announce completion of deployment","title":"Network Deployment Runbook"},{"location":"deploy/cicd/netdeploy/netdeploy/#network-deployment-runbook","text":"","title":"Network Deployment Runbook"},{"location":"deploy/cicd/netdeploy/netdeploy/#overview","text":"Over the past month the deployment process for a Network Deployment is being refined. This involves four phases Validation - Validating the build process and ensuring all components are identified Deployment - Documenting all the steps for the current deployment process Consolidation - Optimizing the deployment process Automation - Automating the deployment process - see hard_reset.sh Phase 1 and 2 have been completed for the current process with phase 3 and 4 ready to commence. This documentation includes latest deployment information for components and also summarizes in a cheat sheet the process for a network deploy. Action items for the consolidation and automation process can be captured below. Also please review the reference material at the bottom of this page.","title":"Overview"},{"location":"deploy/cicd/netdeploy/netdeploy/#deployment-components","text":"harmony - Harmony protocol scripts folder contains deployment utilities with nodes.sh being key to node deployment harmony-ops - Documentation and utilities for external validators as well as devops tools and grafana monitoring tools and additional monitoring tools . Finally it also contains test-automation for both api and cli tests. experiment-deploy - Pipeline is the backbone of the deploy process and is run from the devops machine whenever deploying new networks. These scripts now include automation of complete network refresh using hard_reset.sh jenkins - The jenkins repository is leveraged by jenkins.harmony.one and calls various script from experiment deploy. For an understanding of this look at the jenkins setup for testnet_hard_reset which calls the hard_reset jenkinsfile which integrates with the devops machine leveraging hard_reset.sh in experiment-deploy pipeline .","title":"Deployment Components"},{"location":"deploy/cicd/netdeploy/netdeploy/#network-components","text":"Harmony Nodes Sentry Nodes Validator Nodes Watchdog Funding Faucet Blockchain Explorer Staking Explorer CLI","title":"Network Components"},{"location":"deploy/cicd/netdeploy/netdeploy/#network-deployment-phases","text":"Announce Network Deployment Protocol Release Protocol Validation Network Release Network Validation Announce completion of deployment","title":"Network Deployment  Phases"},{"location":"deploy/cicd/netdeploy/network-monitoring/","text":"Network Monitoring Overview Monitoring Tools Watchdog After a refresh (or at any time) watchdog provides detailed information about Harmony Nodes including consensus, number of nodes, software version and any down nodes. Note : Watchdog is password protected. The userid and password for watchdog are pinned to the devops discord channel. All Environments - http://monitor.hmny.io/status Mainnet: http://watchdog.hmny.io/report-mainnet - mainnet LRTN: http://watchdog.hmny.io/report-lrtn - lrtn OSTN: http://watchdog.hmny.io/report-ostn - os PSTN: http://watchdog.hmny.io/report-pstn - pstn STN: http://watchdog.hmny.io/report-stn - stn Grafana https://monitor.harmony.one/login - provides grafana dashboards which monitor cpu, memory usage and disk space utilization for harmony nodes (see stressnet discord channel pinned messages for credentials) CLI Validation After a refresh you can validate that consensus has been formed via the CLI by looking for HOORAY in the log files for all the shards as follows, this will also identify the leader shard as it will be the IP that has the latest HOORAY. {% tabs %} {% tab title=\"OSTN\" %} ./run_on_shard.sh -p os -T 0 'tac ../tmp_log/*/zerolog*.log | grep -m 1 HOORAY' ./run_on_shard.sh -p os -T 1 'tac ../tmp_log/*/zerolog*.log | grep -m 1 HOORAY' ./run_on_shard.sh -p os -T 2 'tac ../tmp_log/*/zerolog*.log | grep -m 1 HOORAY' ./run_on_shard.sh -p os -T 3 'tac ../tmp_log/*/zerolog*.log | grep -m 1 HOORAY' {% endtab %} {% tab title=\"STN\" %} ./run_on_shard.sh -p stn -y -T 0 'tac ../tmp_log/*/zerolog*.log | grep -m 1 HOORAY' ./run_on_shard.sh -p stn -y -T 1 'tac ../tmp_log/*/zerolog*.log | grep -m 1 HOORAY' {% endtab %} {% endtabs %}","title":"Network Monitoring"},{"location":"deploy/cicd/netdeploy/network-monitoring/#network-monitoring","text":"","title":"Network Monitoring"},{"location":"deploy/cicd/netdeploy/network-monitoring/#overview","text":"","title":"Overview"},{"location":"deploy/cicd/netdeploy/network-monitoring/#monitoring-tools","text":"","title":"Monitoring Tools"},{"location":"deploy/cicd/netdeploy/network-monitoring/#watchdog","text":"After a refresh (or at any time) watchdog provides detailed information about Harmony Nodes including consensus, number of nodes, software version and any down nodes. Note : Watchdog is password protected. The userid and password for watchdog are pinned to the devops discord channel. All Environments - http://monitor.hmny.io/status Mainnet: http://watchdog.hmny.io/report-mainnet - mainnet LRTN: http://watchdog.hmny.io/report-lrtn - lrtn OSTN: http://watchdog.hmny.io/report-ostn - os PSTN: http://watchdog.hmny.io/report-pstn - pstn STN: http://watchdog.hmny.io/report-stn - stn","title":"Watchdog"},{"location":"deploy/cicd/netdeploy/network-monitoring/#grafana","text":"https://monitor.harmony.one/login - provides grafana dashboards which monitor cpu, memory usage and disk space utilization for harmony nodes (see stressnet discord channel pinned messages for credentials)","title":"Grafana"},{"location":"deploy/cicd/netdeploy/network-monitoring/#cli-validation","text":"After a refresh you can validate that consensus has been formed via the CLI by looking for HOORAY in the log files for all the shards as follows, this will also identify the leader shard as it will be the IP that has the latest HOORAY. {% tabs %} {% tab title=\"OSTN\" %} ./run_on_shard.sh -p os -T 0 'tac ../tmp_log/*/zerolog*.log | grep -m 1 HOORAY' ./run_on_shard.sh -p os -T 1 'tac ../tmp_log/*/zerolog*.log | grep -m 1 HOORAY' ./run_on_shard.sh -p os -T 2 'tac ../tmp_log/*/zerolog*.log | grep -m 1 HOORAY' ./run_on_shard.sh -p os -T 3 'tac ../tmp_log/*/zerolog*.log | grep -m 1 HOORAY' {% endtab %} {% tab title=\"STN\" %} ./run_on_shard.sh -p stn -y -T 0 'tac ../tmp_log/*/zerolog*.log | grep -m 1 HOORAY' ./run_on_shard.sh -p stn -y -T 1 'tac ../tmp_log/*/zerolog*.log | grep -m 1 HOORAY' {% endtab %} {% endtabs %}","title":"CLI Validation"},{"location":"deploy/cicd/netdeploy/reference-material/","text":"Reference Material Reference Material p2 state of emergency on dev & ops Fixit Edgars Deployment Proposal OSTN Checklist - OSTN Release Log Post Mortem Post-Mortem: Mar-31-2020 Mainnet Shards Down Post-Mortem: Apr 3-4-2020 OSTN Refresh issues Previous Documentation Testnet Deployment How to Launch Existing nodes for Mainnet How to Launch a Double Signing Network endpoint creation on AWS DevOps Runbook Daniels GIST for deployment Janet's gist for sentries Staking Dashboard deployment Harmony Chrome Extension Build","title":"Reference Material"},{"location":"deploy/cicd/netdeploy/reference-material/#reference-material","text":"","title":"Reference Material"},{"location":"deploy/cicd/netdeploy/reference-material/#reference-material_1","text":"p2 state of emergency on dev & ops Fixit Edgars Deployment Proposal OSTN Checklist - OSTN Release Log Post Mortem Post-Mortem: Mar-31-2020 Mainnet Shards Down Post-Mortem: Apr 3-4-2020 OSTN Refresh issues","title":"Reference Material"},{"location":"deploy/cicd/netdeploy/reference-material/#previous-documentation","text":"Testnet Deployment How to Launch Existing nodes for Mainnet How to Launch a Double Signing Network endpoint creation on AWS DevOps Runbook Daniels GIST for deployment Janet's gist for sentries Staking Dashboard deployment Harmony Chrome Extension Build","title":"Previous Documentation"},{"location":"deploy/cicd/netdeploy/release-strategy/","text":"Release Strategy Overview Ideal Process Local Development Stress Testing Community Testing Production Migration Challenges Mainnet ONE Launched - Open Staking cannot needs a migration path Harmony Network includes multiple components (protocol, watchdog, faucet, funding, block explorer, staking dashboard, CLI, autonode, harmony extension) Development Process does not include upgrade path without refresh for data changes does not include deployment as a part of signoff does not include documentation sign off for APIs Network uptime (all components) is not a priority for the entire team Network deployment involves multiple components Pager duty calls are not being responded to Deployment Process FUD Mitigations Reference Material Review - p2 state of emergency on dev & ops Review Fixit Review Edgars Deployment Proposal Review OSTN Refresh Post Mortem Action Items [x] API Documentation Updated for Staking [x] AWS Familiarization Guide [ ] Consolidation [x] Harmony Wallet -> S3 [ ] Test Hard Refresh script on STN [ ] Staking Dashboard Deployment -> Devops [ ] Sentry Deployment to Devops [ ] Faucet Deployment Ownership and Automation [ ] Explorer UI Auto Refreshes [ ] node_ssh.sh -> capability to enter a tmux session and restart running processes [ ] Harmony Extension - script to release from Harmony - Release Portal Page - lists all components. [ ] **** Automation **** [x] AutoRestart for Sentries [ ] Monitoring [ ] Pager Duty - split schedule [ ] Analysis's /Troubleshooting Tools [ ] Profiling Sentry Setup [ ] Developer Debug Environment setup [ ] Debug Signing Issue - STN [ ] Debug P2P Issue - STN","title":"Release Strategy"},{"location":"deploy/cicd/netdeploy/release-strategy/#release-strategy","text":"","title":"Release Strategy"},{"location":"deploy/cicd/netdeploy/release-strategy/#overview","text":"","title":"Overview"},{"location":"deploy/cicd/netdeploy/release-strategy/#ideal-process","text":"Local Development Stress Testing Community Testing Production Migration","title":"Ideal Process"},{"location":"deploy/cicd/netdeploy/release-strategy/#challenges","text":"Mainnet ONE Launched - Open Staking cannot needs a migration path Harmony Network includes multiple components (protocol, watchdog, faucet, funding, block explorer, staking dashboard, CLI, autonode, harmony extension) Development Process does not include upgrade path without refresh for data changes does not include deployment as a part of signoff does not include documentation sign off for APIs Network uptime (all components) is not a priority for the entire team Network deployment involves multiple components Pager duty calls are not being responded to Deployment Process FUD","title":"Challenges"},{"location":"deploy/cicd/netdeploy/release-strategy/#mitigations","text":"","title":"Mitigations"},{"location":"deploy/cicd/netdeploy/release-strategy/#reference-material","text":"Review - p2 state of emergency on dev & ops Review Fixit Review Edgars Deployment Proposal Review OSTN Refresh Post Mortem","title":"Reference Material"},{"location":"deploy/cicd/netdeploy/release-strategy/#action-items","text":"[x] API Documentation Updated for Staking [x] AWS Familiarization Guide [ ] Consolidation [x] Harmony Wallet -> S3 [ ] Test Hard Refresh script on STN [ ] Staking Dashboard Deployment -> Devops [ ] Sentry Deployment to Devops [ ] Faucet Deployment Ownership and Automation [ ] Explorer UI Auto Refreshes [ ] node_ssh.sh -> capability to enter a tmux session and restart running processes [ ] Harmony Extension - script to release from Harmony - Release Portal Page - lists all components. [ ] **** Automation **** [x] AutoRestart for Sentries [ ] Monitoring [ ] Pager Duty - split schedule [ ] Analysis's /Troubleshooting Tools [ ] Profiling Sentry Setup [ ] Developer Debug Environment setup [ ] Debug Signing Issue - STN [ ] Debug P2P Issue - STN","title":"Action  Items"},{"location":"deploy/cicd/netdeploy/sdk-and-cli-deployment/","text":"SDK and CLI Deployment","title":"SDK and CLI Deployment"},{"location":"deploy/cicd/netdeploy/sdk-and-cli-deployment/#sdk-and-cli-deployment","text":"","title":"SDK and CLI Deployment"},{"location":"deploy/cicd/netdeploy/sentry-deployment/","text":"Sentry Deployment {% hint style=\"info\" %} For access to the Sentry node ask john@harmony.one {% endhint %} {% hint style=\"info\" %} To run in profiling mode use -R localhost:6070 and here are instructions on how to query it {% endhint %} {% hint style=\"success\" %} For docker autocreation of sentries see https://github.com/harmony-one/harmony-ops/tree/master/devops/auto_node {% endhint %} Overview Harmony runs a sentry node for each shard on OSTN. This is spun up using the same process as the validators to ensure that validates can earn rewards. These sentry nodes are critical for rolling upgrades and should be upgraded before the rolling upgrade begins. Also here is a sample script to register validators written by Edgar. The four sentries are listed below as well as a link to the pem key to connect to them. Sentry 0 - one1m6j80t6rhc3ypaumtsfmqwjwp0mrqk9ff50prh {% tabs %} {% tab title=\"OSTN\" %} exec ssh -i ~/.ssh/keys/SentryOSTN.pem ec2-user@3.21.53.63 # tmux attach tmux att Register the Validator ./hmy --node=\"https://api.s0.os.hmny.io\" staking create-validator --validator-addr one1m6j80t6rhc3ypaumtsfmqwjwp0mrqk9ff50prh --name OSTNSentry0 --identity OSTNSentry0 --website sentry@harmony.one --security-contact Sentry --details \"OSTN Sentry for Shard 0 t3.small\" --rate 0.05 --max-rate 0.8 --max-change-rate 0.02 --min-self-delegation 10000 --max-total-delegation 100000 --bls-pubkeys afc4d81ab636323b04893c23d3404f38e95e9291b3d5299dade3d03822edd3a2b799bd6d64265a9a9cac025d5dbd600c --amount 100000 # Restart the node ./node.sh -S -z -I -P -N staking -k afc4d81ab636323b04893c23d3404f38e95e9291b3d5299dade3d03822edd3a2b799bd6d64265a9a9cac025d5dbd600c.key # Restart the node and CLEAN out blockchain curl -LO https://raw.githubusercontent.com/harmony-one/harmony/master/scripts/node.sh && chmod a+x node.sh rm -rf harmony_db* ./node.sh -S -c -z -I -P -r localhost:6060 -N staking -k afc4d81ab636323b04893c23d3404f38e95e9291b3d5299dade3d03822edd3a2b799bd6d64265a9a9cac025d5dbd600c.key # Check that it's earning ./hmy --node=\"https://api.s0.os.hmny.io\" blockchain validator information one1m6j80t6rhc3ypaumtsfmqwjwp0mrqk9ff50prh # Mark it active ./hmy -n https://api.s0.os.hmny.io staking edit-validator --validator-addr one1m6j80t6rhc3ypaumtsfmqwjwp0mrqk9ff50prh --active true # Check the node version ./node.sh -V # Look at the logs tail -f ./latest/*.log {% endtab %} {% tab title=\"STN\" %} # https://gist.github.com/Daniel-VDM/fe15ccd0561ba23ef7e0007b33b08d8f # https://github.com/harmony-one/harmony-ops/tree/master/devops/auto_node ./node_ssh.sh 52.11.85.154 tmux att ./auto_node.sh run --shard 0 --auto-active --clean --network stress --beacon-endpoint https://api.s0.stn.hmny.io/ # Get validator information ./hmy --node=\"https://api.s0.stn.hmny.io\" blockchain validator information one1m6j80t6rhc3ypaumtsfmqwjwp0mrqk9ff50prh # Removing a bls key ./hmy staking --node=\"https://api.s0.stn.hmny.io\" edit-validator --validator-addr one1m6j80t6rhc3ypaumtsfmqwjwp0mrqk9ff50prh --remove-bls-key 605569a402ff52e703cd3d66f3bc0a08be4955c8d2700d1581740ffed8e545f73736de350183cd30e50b06e1b880d605 # Validator Config { \"validator-addr\": \"one1m6j80t6rhc3ypaumtsfmqwjwp0mrqk9ff50prh\", \"name\": \"STN-Sentry-0-autonode-t3.small\", \"website\": \"harmony.one\", \"security-contact\": \"john@harmony.one\", \"identity\": \"STN-Sentry-0-auto-node\", \"amount\": 10100, \"min-self-delegation\": 10000, \"rate\": 0.1, \"max-rate\": 0.75, \"max-change-rate\": 0.05, \"max-total-delegation\": 1000000.0, \"details\": \"None\" } {% endtab %} {% endtabs %} Sentry 1 - one10fjqteq6q75nm62cx8vejqsk7mc8t5hle8ewnl {% tabs %} {% tab title=\"OSTN\" %} ssh -i ~/.ssh/keys/SentryOSTN.pem ec2-user@18.218.200.47 # tmux attach tmux att # Fund the account ./hmy --node=\"\"https://api.s0.os.hmny.io/\"\" transfer --from one14hd35aj7xvuq3vg4grnv2umkxkazcmjq68hpwh --to one10fjqteq6q75nm62cx8vejqsk7mc8t5hle8ewnl --from-shard 0 --to-shard 0 --amount 110000 Register the Validator ./hmy --node=\"https://api.s0.os.hmny.io\" staking create-validator --validator-addr one10fjqteq6q75nm62cx8vejqsk7mc8t5hle8ewnl --name OSTNSentry1 --identity OSTNSentry1 --website sentry@harmony.one --security-contact Sentry --details \"OSTN Sentry for Shard 1 t3.small\" --rate 0.05 --max-rate 0.8 --max-change-rate 0.02 --min-self-delegation 10000 --max-total-delegation 1000000 --bls-pubkeys 552f8aa65835f04e4bc3a04a4bd1f5c67dcd562513b6728c5b9fd258d9fdb054c10008b14a739818d0c234d37b8f1301 --amount 10000 # Restart the node ./node.sh -S -z -I -P -N staking -k 552f8aa65835f04e4bc3a04a4bd1f5c67dcd562513b6728c5b9fd258d9fdb054c10008b14a739818d0c234d37b8f1301.key # Restart the node and CLEAN out blockchain curl -LO https://raw.githubusercontent.com/harmony-one/harmony/master/scripts/node.sh && chmod a+x node.sh rm -rf harmony_db* ./node.sh -S -c -z -I -P -r localhost:6060 -N staking -k 552f8aa65835f04e4bc3a04a4bd1f5c67dcd562513b6728c5b9fd258d9fdb054c10008b14a739818d0c234d37b8f1301.key # Check that it's earning ./hmy --node=\"https://api.s0.os.hmny.io\" blockchain validator information one10fjqteq6q75nm62cx8vejqsk7mc8t5hle8ewnl # Mark it active ./hmy -n https://api.s0.os.hmny.io staking edit-validator --validator-addr one10fjqteq6q75nm62cx8vejqsk7mc8t5hle8ewnl --active true # Check the node version ./node.sh -V # Look at the logs tail -f ./latest/*.log {% endtab %} {% tab title=\"STN\" %} # https://gist.github.com/Daniel-VDM/fe15ccd0561ba23ef7e0007b33b08d8f # https://github.com/harmony-one/harmony-ops/tree/master/devops/auto_node ./node_ssh.sh 54.202.197.141 curl -LO https://harmony.one/hmycli && mv hmycli hmy && chmod +x hmy && sudo yum update -y && sudo yum install -y docker && sudo usermod -aG docker ec2-user && sudo service docker start && sudo yum install -y tmux && exit curl -O https://raw.githubusercontent.com/harmony-one/harmony-ops/master/devops/auto_node/scripts/auto_node.sh && chmod +x ./auto_node.sh && ./auto_node.sh setup ./hmy keys list ./hmy keys import-private-key <<KEY>> STNSentry1 tmux att ./auto_node.sh run --shard 1 --auto-active --clean --network stress --beacon-endpoint https://api.s0.stn.hmny.io/ # Get validator information ./hmy --node=\"https://api.s0.stn.hmny.io\" blockchain validator information one10fjqteq6q75nm62cx8vejqsk7mc8t5hle8ewnl # Removing a bls key ./hmy staking --node=\"https://api.s0.stn.hmny.io\" edit-validator --validator-addr one10fjqteq6q75nm62cx8vejqsk7mc8t5hle8ewnl --remove-bls-key 567fb7398184c382d92bf6b568e79363c9d7c238b261b456d280882c6a0ad42e7367ec57596b366a86b454dd53a93215 # Validator Config { \"validator-addr\": \"one10fjqteq6q75nm62cx8vejqsk7mc8t5hle8ewnl\", \"name\": \"STN-Sentry-1-autonode-t3.small\", \"website\": \"harmony.one\", \"security-contact\": \"john@harmony.one\", \"identity\": \"STN-Sentry-1-auto-node\", \"amount\": 10100, \"min-self-delegation\": 10000, \"rate\": 0.1, \"max-rate\": 0.75, \"max-change-rate\": 0.05, \"max-total-delegation\": 1000000.0, \"details\": \"None\" } {% endtab %} {% endtabs %} Sentry 2 - one1vzsj3julf0ljcj3hhxuqpu6zvadu488zfrtttz {% tabs %} {% tab title=\"OSTN\" %} exec ssh -i ~/.ssh/keys/SentryOSTN.pem ec2-user@3.21.169.132 # tmux attach tmux att # Fund the account ./hmy --node=\"\"https://api.s0.os.hmny.io/\"\" transfer --from one14hd35aj7xvuq3vg4grnv2umkxkazcmjq68hpwh --to one1vzsj3julf0ljcj3hhxuqpu6zvadu488zfrtttz --from-shard 0 --to-shard 0 --amount 1000 Register the Validator ./hmy --node=\"https://api.s0.os.hmny.io\" staking create-validator --validator-addr one1vzsj3julf0ljcj3hhxuqpu6zvadu488zfrtttz --name OSTNSentry2 --identity OSTNSentry2 --website sentry@harmony.one --security-contact Sentry --details \"OSTN Sentry for Shard 2 t3.small\" --rate 0.05 --max-rate 0.8 --max-change-rate 0.02 --min-self-delegation 10000 --max-total-delegation 10000000 --bls-pubkeys a2232487bbf16dd01c5743700712819984d036bf3e39960c85045920784ba0d24149c93591dd4017ada3155e8105d402 --amount 10000 # Restart the node ./node.sh -S -z -I -P -r localhost:6060 -N staking -k a2232487bbf16dd01c5743700712819984d036bf3e39960c85045920784ba0d24149c93591dd4017ada3155e8105d402.key # Restart the node and CLEAN out blockchain curl -LO https://raw.githubusercontent.com/harmony-one/harmony/master/scripts/node.sh && chmod a+x node.sh rm -rf harmony_db* ./node.sh -S -c -z -I -P -r localhost:6060 -N staking -k a2232487bbf16dd01c5743700712819984d036bf3e39960c85045920784ba0d24149c93591dd4017ada3155e8105d402.key # Check that it's earning ./hmy --node=\"https://api.s0.os.hmny.io\" blockchain validator information one1vzsj3julf0ljcj3hhxuqpu6zvadu488zfrtttz # Mark it active ./hmy -n https://api.s0.os.hmny.io staking edit-validator --validator-addr one1vzsj3julf0ljcj3hhxuqpu6zvadu488zfrtttz --active true # Check the node version ./node.sh -V # Look at the logs tail -f ./latest/*.log {% endtab %} {% tab title=\"STN\" %} ./node_ssh.sh 52.42.43.150 tmux attach -t node Register the Validator ./hmy --node=\"https://api.s0.stn.hmny.io\" staking create-validator --validator-addr one1vzsj3julf0ljcj3hhxuqpu6zvadu488zfrtttz --name OSTNSentry0.1 --identity OSTNSentry2 --website sentry@harmony.one --security-contact Sentry --details \"OSTN Sentry for Shard 2 t3.small\" --rate 0.05 --max-rate 0.8 --max-change-rate 0.02 --min-self-delegation 10000 --max-total-delegation 10000000 --bls-pubkeys 463298d9357ddb336038a122b84549b0589597214e28f12b7816f09b554fd4c935437f25eb1720bae923fcb070b3e596 --amount 10000 # Restart the node ./node.sh -S -z -I -P -r localhost:6060 -N stress -k 463298d9357ddb336038a122b84549b0589597214e28f12b7816f09b554fd4c935437f25eb1720bae923fcb070b3e596.key # Restart the node and CLEAN out blockchain curl -LO https://harmony.one/hmycli && mv hmycli hmy && chmod +x hmy curl -LO https://raw.githubusercontent.com/harmony-one/harmony/master/scripts/node.sh && chmod a+x node.sh rm -rf harmony_db* ./node.sh -S -c -z -I -P -R localhost:6060 -N stress -k 463298d9357ddb336038a122b84549b0589597214e28f12b7816f09b554fd4c935437f25eb1720bae923fcb070b3e596.key # Check that it's earning ./hmy --node=\"https://api.s0.stn.hmny.io\" blockchain validator information one1vzsj3julf0ljcj3hhxuqpu6zvadu488zfrtttz # Mark it active ./hmy -n https://api.s0.stn.hmny.io staking edit-validator --validator-addr one1vzsj3julf0ljcj3hhxuqpu6zvadu488zfrtttz --active true # Check the node version ./node.sh -V # Look at the logs tail -f ./latest/*.log {% endtab %} {% endtabs %} Sentry 3 one1marnnvc8hywmfxhrc8mtpjkvvdt32x9kxtwkvv {% tabs %} {% tab title=\"OSTN\" %} exec ssh -i ~/.ssh/keys/SentryOSTN.pem ec2-user@18.221.69.247 # tmux attach tmux att # Fund the account ./hmy --node=\"\"https://api.s0.os.hmny.io/\"\" transfer --from one14hd35aj7xvuq3vg4grnv2umkxkazcmjq68hpwh --to one1marnnvc8hywmfxhrc8mtpjkvvdt32x9kxtwkvv --from-shard 0 --to-shard 0 --amount 1000 Register the Validator ./hmy --node=\"https://api.s0.os.hmny.io\" staking create-validator --validator-addr one1marnnvc8hywmfxhrc8mtpjkvvdt32x9kxtwkvv --name OSTNSentry3 --identity OSTNSentry3 --website sentry@harmony.one --security-contact Sentry --details \"OSTN Sentry for Shard 3 t3.small\" --rate 0.05 --max-rate 0.8 --max-change-rate 0.02 --min-self-delegation 10000 --max-total-delegation 10000000 --bls-pubkeys 5aff3653958fdddefe04aaeb5e9c4a4fc7dda03538a04fd8dfd139c66d18ec31c7deb846cb67077fde48921ddb07a387 --amount 10000 # Restart the node ./node.sh -S -z -I -P -N staking -k 5aff3653958fdddefe04aaeb5e9c4a4fc7dda03538a04fd8dfd139c66d18ec31c7deb846cb67077fde48921ddb07a387.key # Restart the node and CLEAN out blockchain curl -LO https://raw.githubusercontent.com/harmony-one/harmony/master/scripts/node.sh && chmod a+x node.sh rm -rf harmony_db* ./node.sh -S -c -z -I -P -r localhost:6060 -N staking -k 5aff3653958fdddefe04aaeb5e9c4a4fc7dda03538a04fd8dfd139c66d18ec31c7deb846cb67077fde48921ddb07a387.key # Check that it's earning ./hmy --node=\"https://api.s0.os.hmny.io\" blockchain validator information one1marnnvc8hywmfxhrc8mtpjkvvdt32x9kxtwkvv # Mark it active ./hmy -n https://api.s0.os.hmny.io staking edit-validator --validator-addr one1marnnvc8hywmfxhrc8mtpjkvvdt32x9kxtwkvv --active true # Check the node version ./node.sh -V # Look at the logs tail -f ./latest/*.log {% endtab %} {% tab title=\"STN\" %} ./node_ssh.sh 54.188.46.48 {% endtab %} {% endtabs %} Johns own validator - one1y5n7p8a845v96xyx2gh75wn5eyhtw5002lah27 {% tabs %} {% tab title=\"OSTN\" %} cd /Users/johnwhitton/projects/staking/OSTN ssh -i \"JOHN_OSTN_VALIDATOR_1.pem\" ec2-user@ec2-3-16-31-148.us-east-2.compute.amazonaws.com # Restart the node and CLEAN out blockchain curl -LO https://raw.githubusercontent.com/harmony-one/harmony/master/scripts/node.sh && chmod a+x node.sh rm -rf harmony_db* ./node.sh -S -c -z -I -P -r localhost:6060 -N staking -M # Check the node version ./node.sh -V # Check that it's earning ./hmy --node=\"https://api.s0.os.hmny.io\" blockchain validator information one1y5n7p8a845v96xyx2gh75wn5eyhtw5002lah27 # Register the Validator ./hmy --node=\"https://api.s0.os.hmny.io\" staking create-validator --validator-addr one1y5n7p8a845v96xyx2gh75wn5eyhtw5002lah27 --name JohnV1 --identity JohnV1 --website john@harmony.one --security-contact Sentry --details \"John Validator t3.small\" --rate 0.05 --max-rate 0.8 --max-change-rate 0.02 --min-self-delegation 10000 --max-total-delegation 10000000 --bls-pubkeys e65ce96e41d54d49243e2294fb306768862cccd5be80347f88bafe13aa4d3582c21c613fc26f6908ed1faa0dd0c27381,b3815c62affe89560ecabb2f30de46742c927e8a951f37f080264d0b394e16b55ea0786629798d0170c713a9779e4585,b9626bcf02210e8979b0e661bbdbf2e5a691105761fd8800bd1e96087a57c393285af91dcf3c3d6763a643d874f14599 --amount 10000 # Mark it active ./hmy -n https://api.s0.os.hmny.io staking edit-validator --validator-addr one1y5n7p8a845v96xyx2gh75wn5eyhtw5002lah27 --active true # Look at the logs tail -f ./latest/*.log {% endtab %} {% tab title=\"STN\" %} mydesktop.sh tmux attach -t node Register the Validator ./hmy --node=\"https://api.s0.stn.hmny.io\" staking create-validator --validator-addr one1y5n7p8a845v96xyx2gh75wn5eyhtw5002lah27 --name JWValidator0 --identity JWValidator0 --website john@harmony.one --security-contact Sentry --details \"STN John Validator run from mydesktop c5a\" --rate 0.05 --max-rate 0.8 --max-change-rate 0.02 --min-self-delegation 10000 --max-total-delegation 10000000 --bls-pubkeys fce9a848df51e04e03db27de7b65bbaed950afee7b0b063d00849cc3500c2dbe0ad69639ed8c66210ab0b9ab752c9d0f --amount 10000 # Restart the node ./node.sh -S -z -I -P -R localhost:6060 -N stress -k fce9a848df51e04e03db27de7b65bbaed950afee7b0b063d00849cc3500c2dbe0ad69639ed8c66210ab0b9ab752c9d0f.key # Restart the node and CLEAN out blockchain curl -LO https://harmony.one/hmycli && mv hmycli hmy && chmod +x hmy curl -LO https://raw.githubusercontent.com/harmony-one/harmony/master/scripts/node.sh && chmod a+x node.sh rm -rf harmony_db* ./node.sh -S -c -z -I -P -R localhost:6060 -N stress -k fce9a848df51e04e03db27de7b65bbaed950afee7b0b063d00849cc3500c2dbe0ad69639ed8c66210ab0b9ab752c9d0f.key # Check that it's earning ./hmy --node=\"https://api.s0.stn.hmny.io\" blockchain validator information one1y5n7p8a845v96xyx2gh75wn5eyhtw5002lah27 # Mark it active ./hmy -n https://api.s0.stn.hmny.io staking edit-validator --validator-addr one1y5n7p8a845v96xyx2gh75wn5eyhtw5002lah27 --active true # Check the node version ./node.sh -V # Look at the logs tail -f ./latest/*.log {% endtab %} {% endtabs %} Multi BLS Key Setup # Create Multiple keys for the same shard ## Create the Keys ./hmy keys generate-bls-key ## Check the shard ./hmy --node=\"https://api.s0.os.hmny.io\" utility shard-for-bls b3815c62affe89560ecabb2f30de46742c927e8a951f37f080264d0b394e16b55ea0786629798d0170c713a9779e4585 # Stop the node ## Set up the BLS Key Folders mkdir -p .hmy/blskeys ## Move the BLS Keys into the folder cp *.key .hmy/blskeys ## Start the node ./node.sh -S -c -z -I -P -R localhost:6070 -N staking -M ## Update your Validator ./hmy -n https://api.s0.os.hmny.io staking edit-validator --validator-addr one1y5n7p8a845v96xyx2gh75wn5eyhtw5002lah27 --add-bls-key b3815c62affe89560ecabb2f30de46742c927e8a951f37f080264d0b394e16b55ea0786629798d0170c713a9779e4585 ./hmy -n https://api.s0.os.hmny.io staking edit-validator --validator-addr one1y5n7p8a845v96xyx2gh75wn5eyhtw5002lah27 --add-bls-key b9626bcf02210e8979b0e661bbdbf2e5a691105761fd8800bd1e96087a57c393285af91dcf3c3d6763a643d874f14599 # Check your validator ./hmy --node=\"https://api.s0.os.hmny.io\" blockchain validator information one1y5n7p8a845v96xyx2gh75wn5eyhtw5002lah27 Troubleshooting tail -f ./latest/*.log tail -f ./latest/*.log | grep Height tail -f ./latest/*.log | grep SYNC tail -f ./latest/*.log | grep OnAnnounce tail -f ./latest/*.log | grep OnPrepared ./hmy --node=\"https://api.s0.os.hmny.io\" blockchain validator information one1m6j80t6rhc3ypaumtsfmqwjwp0mrqk9ff50prh tac ./latest/*.log | grep invalid cat ./latest/*.log | grep invalid cat ./latest/*.log | grep \"error\" ./run_on_shard.sh -p os -T 2 \"tac ../tmp_log/*/zerolog-*.log | grep -m 1 myViewID\"","title":"Sentry Deployment"},{"location":"deploy/cicd/netdeploy/sentry-deployment/#sentry-deployment","text":"{% hint style=\"info\" %} For access to the Sentry node ask john@harmony.one {% endhint %} {% hint style=\"info\" %} To run in profiling mode use -R localhost:6070 and here are instructions on how to query it {% endhint %} {% hint style=\"success\" %} For docker autocreation of sentries see https://github.com/harmony-one/harmony-ops/tree/master/devops/auto_node {% endhint %} Overview Harmony runs a sentry node for each shard on OSTN. This is spun up using the same process as the validators to ensure that validates can earn rewards. These sentry nodes are critical for rolling upgrades and should be upgraded before the rolling upgrade begins. Also here is a sample script to register validators written by Edgar. The four sentries are listed below as well as a link to the pem key to connect to them.","title":"Sentry Deployment"},{"location":"deploy/cicd/netdeploy/sentry-deployment/#sentry-0-one1m6j80t6rhc3ypaumtsfmqwjwp0mrqk9ff50prh","text":"{% tabs %} {% tab title=\"OSTN\" %} exec ssh -i ~/.ssh/keys/SentryOSTN.pem ec2-user@3.21.53.63 # tmux attach tmux att Register the Validator ./hmy --node=\"https://api.s0.os.hmny.io\" staking create-validator --validator-addr one1m6j80t6rhc3ypaumtsfmqwjwp0mrqk9ff50prh --name OSTNSentry0 --identity OSTNSentry0 --website sentry@harmony.one --security-contact Sentry --details \"OSTN Sentry for Shard 0 t3.small\" --rate 0.05 --max-rate 0.8 --max-change-rate 0.02 --min-self-delegation 10000 --max-total-delegation 100000 --bls-pubkeys afc4d81ab636323b04893c23d3404f38e95e9291b3d5299dade3d03822edd3a2b799bd6d64265a9a9cac025d5dbd600c --amount 100000 # Restart the node ./node.sh -S -z -I -P -N staking -k afc4d81ab636323b04893c23d3404f38e95e9291b3d5299dade3d03822edd3a2b799bd6d64265a9a9cac025d5dbd600c.key # Restart the node and CLEAN out blockchain curl -LO https://raw.githubusercontent.com/harmony-one/harmony/master/scripts/node.sh && chmod a+x node.sh rm -rf harmony_db* ./node.sh -S -c -z -I -P -r localhost:6060 -N staking -k afc4d81ab636323b04893c23d3404f38e95e9291b3d5299dade3d03822edd3a2b799bd6d64265a9a9cac025d5dbd600c.key # Check that it's earning ./hmy --node=\"https://api.s0.os.hmny.io\" blockchain validator information one1m6j80t6rhc3ypaumtsfmqwjwp0mrqk9ff50prh # Mark it active ./hmy -n https://api.s0.os.hmny.io staking edit-validator --validator-addr one1m6j80t6rhc3ypaumtsfmqwjwp0mrqk9ff50prh --active true # Check the node version ./node.sh -V # Look at the logs tail -f ./latest/*.log {% endtab %} {% tab title=\"STN\" %} # https://gist.github.com/Daniel-VDM/fe15ccd0561ba23ef7e0007b33b08d8f # https://github.com/harmony-one/harmony-ops/tree/master/devops/auto_node ./node_ssh.sh 52.11.85.154 tmux att ./auto_node.sh run --shard 0 --auto-active --clean --network stress --beacon-endpoint https://api.s0.stn.hmny.io/ # Get validator information ./hmy --node=\"https://api.s0.stn.hmny.io\" blockchain validator information one1m6j80t6rhc3ypaumtsfmqwjwp0mrqk9ff50prh # Removing a bls key ./hmy staking --node=\"https://api.s0.stn.hmny.io\" edit-validator --validator-addr one1m6j80t6rhc3ypaumtsfmqwjwp0mrqk9ff50prh --remove-bls-key 605569a402ff52e703cd3d66f3bc0a08be4955c8d2700d1581740ffed8e545f73736de350183cd30e50b06e1b880d605 # Validator Config { \"validator-addr\": \"one1m6j80t6rhc3ypaumtsfmqwjwp0mrqk9ff50prh\", \"name\": \"STN-Sentry-0-autonode-t3.small\", \"website\": \"harmony.one\", \"security-contact\": \"john@harmony.one\", \"identity\": \"STN-Sentry-0-auto-node\", \"amount\": 10100, \"min-self-delegation\": 10000, \"rate\": 0.1, \"max-rate\": 0.75, \"max-change-rate\": 0.05, \"max-total-delegation\": 1000000.0, \"details\": \"None\" } {% endtab %} {% endtabs %}","title":"Sentry 0 - one1m6j80t6rhc3ypaumtsfmqwjwp0mrqk9ff50prh"},{"location":"deploy/cicd/netdeploy/sentry-deployment/#sentry-1-one10fjqteq6q75nm62cx8vejqsk7mc8t5hle8ewnl","text":"{% tabs %} {% tab title=\"OSTN\" %} ssh -i ~/.ssh/keys/SentryOSTN.pem ec2-user@18.218.200.47 # tmux attach tmux att # Fund the account ./hmy --node=\"\"https://api.s0.os.hmny.io/\"\" transfer --from one14hd35aj7xvuq3vg4grnv2umkxkazcmjq68hpwh --to one10fjqteq6q75nm62cx8vejqsk7mc8t5hle8ewnl --from-shard 0 --to-shard 0 --amount 110000 Register the Validator ./hmy --node=\"https://api.s0.os.hmny.io\" staking create-validator --validator-addr one10fjqteq6q75nm62cx8vejqsk7mc8t5hle8ewnl --name OSTNSentry1 --identity OSTNSentry1 --website sentry@harmony.one --security-contact Sentry --details \"OSTN Sentry for Shard 1 t3.small\" --rate 0.05 --max-rate 0.8 --max-change-rate 0.02 --min-self-delegation 10000 --max-total-delegation 1000000 --bls-pubkeys 552f8aa65835f04e4bc3a04a4bd1f5c67dcd562513b6728c5b9fd258d9fdb054c10008b14a739818d0c234d37b8f1301 --amount 10000 # Restart the node ./node.sh -S -z -I -P -N staking -k 552f8aa65835f04e4bc3a04a4bd1f5c67dcd562513b6728c5b9fd258d9fdb054c10008b14a739818d0c234d37b8f1301.key # Restart the node and CLEAN out blockchain curl -LO https://raw.githubusercontent.com/harmony-one/harmony/master/scripts/node.sh && chmod a+x node.sh rm -rf harmony_db* ./node.sh -S -c -z -I -P -r localhost:6060 -N staking -k 552f8aa65835f04e4bc3a04a4bd1f5c67dcd562513b6728c5b9fd258d9fdb054c10008b14a739818d0c234d37b8f1301.key # Check that it's earning ./hmy --node=\"https://api.s0.os.hmny.io\" blockchain validator information one10fjqteq6q75nm62cx8vejqsk7mc8t5hle8ewnl # Mark it active ./hmy -n https://api.s0.os.hmny.io staking edit-validator --validator-addr one10fjqteq6q75nm62cx8vejqsk7mc8t5hle8ewnl --active true # Check the node version ./node.sh -V # Look at the logs tail -f ./latest/*.log {% endtab %} {% tab title=\"STN\" %} # https://gist.github.com/Daniel-VDM/fe15ccd0561ba23ef7e0007b33b08d8f # https://github.com/harmony-one/harmony-ops/tree/master/devops/auto_node ./node_ssh.sh 54.202.197.141 curl -LO https://harmony.one/hmycli && mv hmycli hmy && chmod +x hmy && sudo yum update -y && sudo yum install -y docker && sudo usermod -aG docker ec2-user && sudo service docker start && sudo yum install -y tmux && exit curl -O https://raw.githubusercontent.com/harmony-one/harmony-ops/master/devops/auto_node/scripts/auto_node.sh && chmod +x ./auto_node.sh && ./auto_node.sh setup ./hmy keys list ./hmy keys import-private-key <<KEY>> STNSentry1 tmux att ./auto_node.sh run --shard 1 --auto-active --clean --network stress --beacon-endpoint https://api.s0.stn.hmny.io/ # Get validator information ./hmy --node=\"https://api.s0.stn.hmny.io\" blockchain validator information one10fjqteq6q75nm62cx8vejqsk7mc8t5hle8ewnl # Removing a bls key ./hmy staking --node=\"https://api.s0.stn.hmny.io\" edit-validator --validator-addr one10fjqteq6q75nm62cx8vejqsk7mc8t5hle8ewnl --remove-bls-key 567fb7398184c382d92bf6b568e79363c9d7c238b261b456d280882c6a0ad42e7367ec57596b366a86b454dd53a93215 # Validator Config { \"validator-addr\": \"one10fjqteq6q75nm62cx8vejqsk7mc8t5hle8ewnl\", \"name\": \"STN-Sentry-1-autonode-t3.small\", \"website\": \"harmony.one\", \"security-contact\": \"john@harmony.one\", \"identity\": \"STN-Sentry-1-auto-node\", \"amount\": 10100, \"min-self-delegation\": 10000, \"rate\": 0.1, \"max-rate\": 0.75, \"max-change-rate\": 0.05, \"max-total-delegation\": 1000000.0, \"details\": \"None\" } {% endtab %} {% endtabs %}","title":"Sentry 1 - one10fjqteq6q75nm62cx8vejqsk7mc8t5hle8ewnl"},{"location":"deploy/cicd/netdeploy/sentry-deployment/#sentry-2-one1vzsj3julf0ljcj3hhxuqpu6zvadu488zfrtttz","text":"{% tabs %} {% tab title=\"OSTN\" %} exec ssh -i ~/.ssh/keys/SentryOSTN.pem ec2-user@3.21.169.132 # tmux attach tmux att # Fund the account ./hmy --node=\"\"https://api.s0.os.hmny.io/\"\" transfer --from one14hd35aj7xvuq3vg4grnv2umkxkazcmjq68hpwh --to one1vzsj3julf0ljcj3hhxuqpu6zvadu488zfrtttz --from-shard 0 --to-shard 0 --amount 1000 Register the Validator ./hmy --node=\"https://api.s0.os.hmny.io\" staking create-validator --validator-addr one1vzsj3julf0ljcj3hhxuqpu6zvadu488zfrtttz --name OSTNSentry2 --identity OSTNSentry2 --website sentry@harmony.one --security-contact Sentry --details \"OSTN Sentry for Shard 2 t3.small\" --rate 0.05 --max-rate 0.8 --max-change-rate 0.02 --min-self-delegation 10000 --max-total-delegation 10000000 --bls-pubkeys a2232487bbf16dd01c5743700712819984d036bf3e39960c85045920784ba0d24149c93591dd4017ada3155e8105d402 --amount 10000 # Restart the node ./node.sh -S -z -I -P -r localhost:6060 -N staking -k a2232487bbf16dd01c5743700712819984d036bf3e39960c85045920784ba0d24149c93591dd4017ada3155e8105d402.key # Restart the node and CLEAN out blockchain curl -LO https://raw.githubusercontent.com/harmony-one/harmony/master/scripts/node.sh && chmod a+x node.sh rm -rf harmony_db* ./node.sh -S -c -z -I -P -r localhost:6060 -N staking -k a2232487bbf16dd01c5743700712819984d036bf3e39960c85045920784ba0d24149c93591dd4017ada3155e8105d402.key # Check that it's earning ./hmy --node=\"https://api.s0.os.hmny.io\" blockchain validator information one1vzsj3julf0ljcj3hhxuqpu6zvadu488zfrtttz # Mark it active ./hmy -n https://api.s0.os.hmny.io staking edit-validator --validator-addr one1vzsj3julf0ljcj3hhxuqpu6zvadu488zfrtttz --active true # Check the node version ./node.sh -V # Look at the logs tail -f ./latest/*.log {% endtab %} {% tab title=\"STN\" %} ./node_ssh.sh 52.42.43.150 tmux attach -t node Register the Validator ./hmy --node=\"https://api.s0.stn.hmny.io\" staking create-validator --validator-addr one1vzsj3julf0ljcj3hhxuqpu6zvadu488zfrtttz --name OSTNSentry0.1 --identity OSTNSentry2 --website sentry@harmony.one --security-contact Sentry --details \"OSTN Sentry for Shard 2 t3.small\" --rate 0.05 --max-rate 0.8 --max-change-rate 0.02 --min-self-delegation 10000 --max-total-delegation 10000000 --bls-pubkeys 463298d9357ddb336038a122b84549b0589597214e28f12b7816f09b554fd4c935437f25eb1720bae923fcb070b3e596 --amount 10000 # Restart the node ./node.sh -S -z -I -P -r localhost:6060 -N stress -k 463298d9357ddb336038a122b84549b0589597214e28f12b7816f09b554fd4c935437f25eb1720bae923fcb070b3e596.key # Restart the node and CLEAN out blockchain curl -LO https://harmony.one/hmycli && mv hmycli hmy && chmod +x hmy curl -LO https://raw.githubusercontent.com/harmony-one/harmony/master/scripts/node.sh && chmod a+x node.sh rm -rf harmony_db* ./node.sh -S -c -z -I -P -R localhost:6060 -N stress -k 463298d9357ddb336038a122b84549b0589597214e28f12b7816f09b554fd4c935437f25eb1720bae923fcb070b3e596.key # Check that it's earning ./hmy --node=\"https://api.s0.stn.hmny.io\" blockchain validator information one1vzsj3julf0ljcj3hhxuqpu6zvadu488zfrtttz # Mark it active ./hmy -n https://api.s0.stn.hmny.io staking edit-validator --validator-addr one1vzsj3julf0ljcj3hhxuqpu6zvadu488zfrtttz --active true # Check the node version ./node.sh -V # Look at the logs tail -f ./latest/*.log {% endtab %} {% endtabs %}","title":"Sentry 2 - one1vzsj3julf0ljcj3hhxuqpu6zvadu488zfrtttz"},{"location":"deploy/cicd/netdeploy/sentry-deployment/#sentry-3-one1marnnvc8hywmfxhrc8mtpjkvvdt32x9kxtwkvv","text":"{% tabs %} {% tab title=\"OSTN\" %} exec ssh -i ~/.ssh/keys/SentryOSTN.pem ec2-user@18.221.69.247 # tmux attach tmux att # Fund the account ./hmy --node=\"\"https://api.s0.os.hmny.io/\"\" transfer --from one14hd35aj7xvuq3vg4grnv2umkxkazcmjq68hpwh --to one1marnnvc8hywmfxhrc8mtpjkvvdt32x9kxtwkvv --from-shard 0 --to-shard 0 --amount 1000 Register the Validator ./hmy --node=\"https://api.s0.os.hmny.io\" staking create-validator --validator-addr one1marnnvc8hywmfxhrc8mtpjkvvdt32x9kxtwkvv --name OSTNSentry3 --identity OSTNSentry3 --website sentry@harmony.one --security-contact Sentry --details \"OSTN Sentry for Shard 3 t3.small\" --rate 0.05 --max-rate 0.8 --max-change-rate 0.02 --min-self-delegation 10000 --max-total-delegation 10000000 --bls-pubkeys 5aff3653958fdddefe04aaeb5e9c4a4fc7dda03538a04fd8dfd139c66d18ec31c7deb846cb67077fde48921ddb07a387 --amount 10000 # Restart the node ./node.sh -S -z -I -P -N staking -k 5aff3653958fdddefe04aaeb5e9c4a4fc7dda03538a04fd8dfd139c66d18ec31c7deb846cb67077fde48921ddb07a387.key # Restart the node and CLEAN out blockchain curl -LO https://raw.githubusercontent.com/harmony-one/harmony/master/scripts/node.sh && chmod a+x node.sh rm -rf harmony_db* ./node.sh -S -c -z -I -P -r localhost:6060 -N staking -k 5aff3653958fdddefe04aaeb5e9c4a4fc7dda03538a04fd8dfd139c66d18ec31c7deb846cb67077fde48921ddb07a387.key # Check that it's earning ./hmy --node=\"https://api.s0.os.hmny.io\" blockchain validator information one1marnnvc8hywmfxhrc8mtpjkvvdt32x9kxtwkvv # Mark it active ./hmy -n https://api.s0.os.hmny.io staking edit-validator --validator-addr one1marnnvc8hywmfxhrc8mtpjkvvdt32x9kxtwkvv --active true # Check the node version ./node.sh -V # Look at the logs tail -f ./latest/*.log {% endtab %} {% tab title=\"STN\" %} ./node_ssh.sh 54.188.46.48 {% endtab %} {% endtabs %}","title":"Sentry 3 one1marnnvc8hywmfxhrc8mtpjkvvdt32x9kxtwkvv"},{"location":"deploy/cicd/netdeploy/sentry-deployment/#johns-own-validator-one1y5n7p8a845v96xyx2gh75wn5eyhtw5002lah27","text":"{% tabs %} {% tab title=\"OSTN\" %} cd /Users/johnwhitton/projects/staking/OSTN ssh -i \"JOHN_OSTN_VALIDATOR_1.pem\" ec2-user@ec2-3-16-31-148.us-east-2.compute.amazonaws.com # Restart the node and CLEAN out blockchain curl -LO https://raw.githubusercontent.com/harmony-one/harmony/master/scripts/node.sh && chmod a+x node.sh rm -rf harmony_db* ./node.sh -S -c -z -I -P -r localhost:6060 -N staking -M # Check the node version ./node.sh -V # Check that it's earning ./hmy --node=\"https://api.s0.os.hmny.io\" blockchain validator information one1y5n7p8a845v96xyx2gh75wn5eyhtw5002lah27 # Register the Validator ./hmy --node=\"https://api.s0.os.hmny.io\" staking create-validator --validator-addr one1y5n7p8a845v96xyx2gh75wn5eyhtw5002lah27 --name JohnV1 --identity JohnV1 --website john@harmony.one --security-contact Sentry --details \"John Validator t3.small\" --rate 0.05 --max-rate 0.8 --max-change-rate 0.02 --min-self-delegation 10000 --max-total-delegation 10000000 --bls-pubkeys e65ce96e41d54d49243e2294fb306768862cccd5be80347f88bafe13aa4d3582c21c613fc26f6908ed1faa0dd0c27381,b3815c62affe89560ecabb2f30de46742c927e8a951f37f080264d0b394e16b55ea0786629798d0170c713a9779e4585,b9626bcf02210e8979b0e661bbdbf2e5a691105761fd8800bd1e96087a57c393285af91dcf3c3d6763a643d874f14599 --amount 10000 # Mark it active ./hmy -n https://api.s0.os.hmny.io staking edit-validator --validator-addr one1y5n7p8a845v96xyx2gh75wn5eyhtw5002lah27 --active true # Look at the logs tail -f ./latest/*.log {% endtab %} {% tab title=\"STN\" %} mydesktop.sh tmux attach -t node Register the Validator ./hmy --node=\"https://api.s0.stn.hmny.io\" staking create-validator --validator-addr one1y5n7p8a845v96xyx2gh75wn5eyhtw5002lah27 --name JWValidator0 --identity JWValidator0 --website john@harmony.one --security-contact Sentry --details \"STN John Validator run from mydesktop c5a\" --rate 0.05 --max-rate 0.8 --max-change-rate 0.02 --min-self-delegation 10000 --max-total-delegation 10000000 --bls-pubkeys fce9a848df51e04e03db27de7b65bbaed950afee7b0b063d00849cc3500c2dbe0ad69639ed8c66210ab0b9ab752c9d0f --amount 10000 # Restart the node ./node.sh -S -z -I -P -R localhost:6060 -N stress -k fce9a848df51e04e03db27de7b65bbaed950afee7b0b063d00849cc3500c2dbe0ad69639ed8c66210ab0b9ab752c9d0f.key # Restart the node and CLEAN out blockchain curl -LO https://harmony.one/hmycli && mv hmycli hmy && chmod +x hmy curl -LO https://raw.githubusercontent.com/harmony-one/harmony/master/scripts/node.sh && chmod a+x node.sh rm -rf harmony_db* ./node.sh -S -c -z -I -P -R localhost:6060 -N stress -k fce9a848df51e04e03db27de7b65bbaed950afee7b0b063d00849cc3500c2dbe0ad69639ed8c66210ab0b9ab752c9d0f.key # Check that it's earning ./hmy --node=\"https://api.s0.stn.hmny.io\" blockchain validator information one1y5n7p8a845v96xyx2gh75wn5eyhtw5002lah27 # Mark it active ./hmy -n https://api.s0.stn.hmny.io staking edit-validator --validator-addr one1y5n7p8a845v96xyx2gh75wn5eyhtw5002lah27 --active true # Check the node version ./node.sh -V # Look at the logs tail -f ./latest/*.log {% endtab %} {% endtabs %}","title":"Johns own validator - one1y5n7p8a845v96xyx2gh75wn5eyhtw5002lah27"},{"location":"deploy/cicd/netdeploy/sentry-deployment/#multi-bls-key-setup","text":"# Create Multiple keys for the same shard ## Create the Keys ./hmy keys generate-bls-key ## Check the shard ./hmy --node=\"https://api.s0.os.hmny.io\" utility shard-for-bls b3815c62affe89560ecabb2f30de46742c927e8a951f37f080264d0b394e16b55ea0786629798d0170c713a9779e4585 # Stop the node ## Set up the BLS Key Folders mkdir -p .hmy/blskeys ## Move the BLS Keys into the folder cp *.key .hmy/blskeys ## Start the node ./node.sh -S -c -z -I -P -R localhost:6070 -N staking -M ## Update your Validator ./hmy -n https://api.s0.os.hmny.io staking edit-validator --validator-addr one1y5n7p8a845v96xyx2gh75wn5eyhtw5002lah27 --add-bls-key b3815c62affe89560ecabb2f30de46742c927e8a951f37f080264d0b394e16b55ea0786629798d0170c713a9779e4585 ./hmy -n https://api.s0.os.hmny.io staking edit-validator --validator-addr one1y5n7p8a845v96xyx2gh75wn5eyhtw5002lah27 --add-bls-key b9626bcf02210e8979b0e661bbdbf2e5a691105761fd8800bd1e96087a57c393285af91dcf3c3d6763a643d874f14599 # Check your validator ./hmy --node=\"https://api.s0.os.hmny.io\" blockchain validator information one1y5n7p8a845v96xyx2gh75wn5eyhtw5002lah27","title":"Multi BLS Key Setup"},{"location":"deploy/cicd/netdeploy/sentry-deployment/#troubleshooting","text":"tail -f ./latest/*.log tail -f ./latest/*.log | grep Height tail -f ./latest/*.log | grep SYNC tail -f ./latest/*.log | grep OnAnnounce tail -f ./latest/*.log | grep OnPrepared ./hmy --node=\"https://api.s0.os.hmny.io\" blockchain validator information one1m6j80t6rhc3ypaumtsfmqwjwp0mrqk9ff50prh tac ./latest/*.log | grep invalid cat ./latest/*.log | grep invalid cat ./latest/*.log | grep \"error\" ./run_on_shard.sh -p os -T 2 \"tac ../tmp_log/*/zerolog-*.log | grep -m 1 myViewID\"","title":"Troubleshooting"},{"location":"deploy/cicd/netdeploy/staking-dashboard-deployment/","text":"Staking Dashboard Deployment {% hint style=\"info\" %} When refreshing a network you can delete staking history via a web browser. For example for Stressnet click here and then press delete collection. Note you will still need to restart the appengine to flush the cache (see below) {% endhint %} Overview The staking explorer is provides the ability to stake validators on the Harmony Protocol. It supports multiple networks and is integrated with multiple wallets including the Harmony Chrome Extension. The code is open source and is stored in staking-dashboard . This document will give an overview of the key components, repositories and the deployment Process Components Persistance Layer The Persistence Layer uses firebase Backend Logic The staking dashboard backend is written using node.js and is deployed on Google App Engine . Frontend Logic The staking dashboard frontend is written in vue.js Deployment Environments All networks are supported by the one app engine project and one firebase project with configuration being held at the firebase level for the network information Google App Engine Project - staking explorer2 Firebase Project - staking explorer Network Configuration - Mainnet - Partner Testnet , OSTN Deployment Setup Administrative Credentials In order to deploy and administer staking explorer you will need to have your harmony google account authorized to the above Projects Gcloud SDK You will also need to install the gcloud SDK . Clone Staking Dashboard You will need to clone the staking dashboard git clone https://github.com/harmony-one/staking-dashboard.git Install Firebase CLI You will need to install the firebase CLI NPM Version and Node Version You will need to set the correct version for npm and node. NVM is useful for this. Currently we are running on npm 6.14 and node v10.17.0 Johns-MacBook-Pro:appengine johnwhitton$ npm -v 6.14.2 Johns-MacBook-Pro:appengine johnwhitton$ node -v v10.17.0 Johns-MacBook-Pro:appengine johnwhitton$ nvm list v0.10.48 v0.12.18 v10.15.1 -> v10.17.0 v12.10.0 system default -> v12.10.0 node -> stable (-> v12.10.0) (default) stable -> 12.10 (-> v12.10.0) (default) iojs -> N/A (default) unstable -> N/A (default) lts/* -> lts/erbium (-> N/A) lts/argon -> v4.9.1 (-> N/A) lts/boron -> v6.17.1 (-> N/A) lts/carbon -> v8.17.0 (-> N/A) lts/dubnium -> v10.19.0 (-> N/A) lts/erbium -> v12.16.1 (-> N/A) Johns-MacBook-Pro:appengine johnwhitton$ Deploying a new Staking Explorer Persistence Layer Update dns end-point in firebase Go to firebase project staking-explorer database Look at database/networks OSTN , Mainnet , PTN Need to update Chaintitle Rpc_url Explorer_url chain_id Backend Deployment Go to staking-dashboard/appengine project on your local machine and update the codebase Login into the project by gcloud auth login (make should that you are able to access staking-explorer2-268108) gcloud config set project staking-explorer2-268108 gcloud config list for checking Remove database npm run clear-db (carefull) Deploy Run `deploy1.sh` It will ask you to confirm if we will deploy to an url (for example https://staking-explorer2-268108.appspot.com ) Say yes That url will be the end point for the frontend It takes about 5min # Login to gcloud and ensure you're in the correct project gcloud auth login gcloud config set project staking-explorer2-268108 gcloud config list # Go to staking-dashboard and update to latest codebase cd /Users/johnwhitton/projects/staking-dashboard git status git log --pretty=oneline git stash git pull git log --pretty=oneline cd appengine/ npm install cd /Users/johnwhitton/projects/staking-dashboard/appengine/keys cp ~/Downloads/staking_explorer.json . cd /Users/johnwhitton/projects/staking-dashboard/appengine #Remove Database # npm run clear-db # see https://github.com/harmony-one/staking-dashboard/pull/334/files # Choose one of the following ./clear_openstaking.sh ./clear_partnernet.sh ./clear_stressnet.sh # Run Deploy.sh ./deploy1.sh FrontEnd Deployment Install firebase cli Login into the project firebase use staking-explorer Make sure the url above ( https://staking-explorer2-268108.appspot.com ) produced from the appengine deployment is used in frontend/.env.production `npm run build` for building Deploy to dev env ( https://staking-explorer.firebaseapp.com/ ) ./dev_deploy.sh Deploy to prod env ( https://staking.harmony.one ) ./prod_deploy.sh # Log in to firebase project firebase login # Check frontend URL cat .env.production # Build the release npm run build # Deploy to Development or Production ./dev_deploy.sh ./prod_deploy.sh Troubleshooting / FAQS","title":"Staking Dashboard  Deployment"},{"location":"deploy/cicd/netdeploy/staking-dashboard-deployment/#staking-dashboard-deployment","text":"{% hint style=\"info\" %} When refreshing a network you can delete staking history via a web browser. For example for Stressnet click here and then press delete collection. Note you will still need to restart the appengine to flush the cache (see below) {% endhint %}","title":"Staking Dashboard  Deployment"},{"location":"deploy/cicd/netdeploy/staking-dashboard-deployment/#overview","text":"The staking explorer is provides the ability to stake validators on the Harmony Protocol. It supports multiple networks and is integrated with multiple wallets including the Harmony Chrome Extension. The code is open source and is stored in staking-dashboard . This document will give an overview of the key components, repositories and the deployment Process","title":"Overview"},{"location":"deploy/cicd/netdeploy/staking-dashboard-deployment/#components","text":"","title":"Components"},{"location":"deploy/cicd/netdeploy/staking-dashboard-deployment/#persistance-layer","text":"The Persistence Layer uses firebase","title":"Persistance Layer"},{"location":"deploy/cicd/netdeploy/staking-dashboard-deployment/#backend-logic","text":"The staking dashboard backend is written using node.js and is deployed on Google App Engine .","title":"Backend Logic"},{"location":"deploy/cicd/netdeploy/staking-dashboard-deployment/#frontend-logic","text":"The staking dashboard frontend is written in vue.js","title":"Frontend Logic"},{"location":"deploy/cicd/netdeploy/staking-dashboard-deployment/#deployment-environments","text":"All networks are supported by the one app engine project and one firebase project with configuration being held at the firebase level for the network information Google App Engine Project - staking explorer2 Firebase Project - staking explorer Network Configuration - Mainnet - Partner Testnet , OSTN","title":"Deployment Environments"},{"location":"deploy/cicd/netdeploy/staking-dashboard-deployment/#deployment-setup","text":"","title":"Deployment Setup"},{"location":"deploy/cicd/netdeploy/staking-dashboard-deployment/#administrative-credentials","text":"In order to deploy and administer staking explorer you will need to have your harmony google account authorized to the above Projects","title":"Administrative Credentials"},{"location":"deploy/cicd/netdeploy/staking-dashboard-deployment/#gcloud-sdk","text":"You will also need to install the gcloud SDK .","title":"Gcloud SDK"},{"location":"deploy/cicd/netdeploy/staking-dashboard-deployment/#clone-staking-dashboard","text":"You will need to clone the staking dashboard git clone https://github.com/harmony-one/staking-dashboard.git","title":"Clone Staking Dashboard"},{"location":"deploy/cicd/netdeploy/staking-dashboard-deployment/#install-firebase-cli","text":"You will need to install the firebase CLI","title":"Install Firebase CLI"},{"location":"deploy/cicd/netdeploy/staking-dashboard-deployment/#npm-version-and-node-version","text":"You will need to set the correct version for npm and node. NVM is useful for this. Currently we are running on npm 6.14 and node v10.17.0 Johns-MacBook-Pro:appengine johnwhitton$ npm -v 6.14.2 Johns-MacBook-Pro:appengine johnwhitton$ node -v v10.17.0 Johns-MacBook-Pro:appengine johnwhitton$ nvm list v0.10.48 v0.12.18 v10.15.1 -> v10.17.0 v12.10.0 system default -> v12.10.0 node -> stable (-> v12.10.0) (default) stable -> 12.10 (-> v12.10.0) (default) iojs -> N/A (default) unstable -> N/A (default) lts/* -> lts/erbium (-> N/A) lts/argon -> v4.9.1 (-> N/A) lts/boron -> v6.17.1 (-> N/A) lts/carbon -> v8.17.0 (-> N/A) lts/dubnium -> v10.19.0 (-> N/A) lts/erbium -> v12.16.1 (-> N/A) Johns-MacBook-Pro:appengine johnwhitton$","title":"NPM Version and Node Version"},{"location":"deploy/cicd/netdeploy/staking-dashboard-deployment/#deploying-a-new-staking-explorer","text":"","title":"Deploying a new Staking Explorer"},{"location":"deploy/cicd/netdeploy/staking-dashboard-deployment/#persistence-layer","text":"Update dns end-point in firebase Go to firebase project staking-explorer database Look at database/networks OSTN , Mainnet , PTN Need to update Chaintitle Rpc_url Explorer_url chain_id","title":"Persistence Layer"},{"location":"deploy/cicd/netdeploy/staking-dashboard-deployment/#backend-deployment","text":"Go to staking-dashboard/appengine project on your local machine and update the codebase Login into the project by gcloud auth login (make should that you are able to access staking-explorer2-268108) gcloud config set project staking-explorer2-268108 gcloud config list for checking Remove database npm run clear-db (carefull) Deploy Run `deploy1.sh` It will ask you to confirm if we will deploy to an url (for example https://staking-explorer2-268108.appspot.com ) Say yes That url will be the end point for the frontend It takes about 5min # Login to gcloud and ensure you're in the correct project gcloud auth login gcloud config set project staking-explorer2-268108 gcloud config list # Go to staking-dashboard and update to latest codebase cd /Users/johnwhitton/projects/staking-dashboard git status git log --pretty=oneline git stash git pull git log --pretty=oneline cd appengine/ npm install cd /Users/johnwhitton/projects/staking-dashboard/appengine/keys cp ~/Downloads/staking_explorer.json . cd /Users/johnwhitton/projects/staking-dashboard/appengine #Remove Database # npm run clear-db # see https://github.com/harmony-one/staking-dashboard/pull/334/files # Choose one of the following ./clear_openstaking.sh ./clear_partnernet.sh ./clear_stressnet.sh # Run Deploy.sh ./deploy1.sh","title":"Backend Deployment"},{"location":"deploy/cicd/netdeploy/staking-dashboard-deployment/#frontend-deployment","text":"Install firebase cli Login into the project firebase use staking-explorer Make sure the url above ( https://staking-explorer2-268108.appspot.com ) produced from the appengine deployment is used in frontend/.env.production `npm run build` for building Deploy to dev env ( https://staking-explorer.firebaseapp.com/ ) ./dev_deploy.sh Deploy to prod env ( https://staking.harmony.one ) ./prod_deploy.sh # Log in to firebase project firebase login # Check frontend URL cat .env.production # Build the release npm run build # Deploy to Development or Production ./dev_deploy.sh ./prod_deploy.sh","title":"FrontEnd Deployment"},{"location":"deploy/cicd/netdeploy/staking-dashboard-deployment/#troubleshooting-faqs","text":"","title":"Troubleshooting / FAQS"},{"location":"deploy/cicd/netdeploy/stressnet-stn-cheatsheat/","text":"StressNet Testing cheatsheat Overview Profiling Information - instructions # Copy files from Stressnet Monitor cd /Users/johnwhitton/projects/staking/STN scp -i ~/.ssh/keys/harmony-testnet.pem ec2-user@52.42.43.150:/home/ec2-user/pprof/* . pprof -http=localhost:8003 pprof.harmony.samples.cpu.007.pb.gz Local Machine setup ### Local Machine setup ### go get -u github.com/google/pprof brew install Graphviz Running a sentry ### Node Management commands #### Register the Validator ./hmy --node=\"https://api.s0.stn.hmny.io\" staking create-validator --validator-addr one1vzsj3julf0ljcj3hhxuqpu6zvadu488zfrtttz --name OSTNSentry0.1 --identity OSTNSentry2 --website sentry@harmony.one --security-contact Sentry --details \"OSTN Sentry for Shard 2 t3.small\" --rate 0.05 --max-rate 0.8 --max-change-rate 0.02 --min-self-delegation 10000 --max-total-delegation 10000000 --bls-pubkeys 463298d9357ddb336038a122b84549b0589597214e28f12b7816f09b554fd4c935437f25eb1720bae923fcb070b3e596 --amount 10000 # Restart the node ./node.sh -S -z -I -P -r localhost:6060 -N stress -k 463298d9357ddb336038a122b84549b0589597214e28f12b7816f09b554fd4c935437f25eb1720bae923fcb070b3e596.key # Restart the node and CLEAN out blockchain curl -LO https://harmony.one/hmycli && mv hmycli hmy && chmod +x hmy curl -LO https://raw.githubusercontent.com/harmony-one/harmony/master/scripts/node.sh && chmod a+x node.sh ./node.sh -S -c -z -I -P -R localhost:6060 -N stress -k 463298d9357ddb336038a122b84549b0589597214e28f12b7816f09b554fd4c935437f25eb1720bae923fcb070b3e596.key # Check that it's earning ./hmy --node=\"https://api.s0.os.hmny.io\" blockchain validator information one1vzsj3julf0ljcj3hhxuqpu6zvadu488zfrtttz # Mark it active ./hmy -n https://api.s0.os.hmny.io staking edit-validator --validator-addr one1vzsj3julf0ljcj3hhxuqpu6zvadu488zfrtttz --active true # Check the node version ./node.sh -V # Look at the logs tail -f ./latest/*.log Monitoring machine setup #### Stressnet Machine setup ### devops.sh export WHOAMI=STN; export HMY_PROFILE=stn; profile_print cd ~/john/experiment-deploy/pipeline ./node_ssh.sh 52.42.43.150 sudo yum install -y golang sudo yum install git go get -u github.com/google/pprof sudo yum install graphviz tmux new-session -s stress-node-s0-pprof bash <(curl -sSL https://raw.githubusercontent.com/SebastianJ/harmony-tools/master/pprof/report.sh) --address localhost:6060 --interval 5m go tool pprof --pdf http://localhost:6060/debug/pprof/profile?seconds=60 > cpu.pdf Capturing Data # http://localhost:6060/debug/pprof/allocs # A sampling of all past memory allocations go tool pprof --pdf http://localhost:6060/debug/pprof/allocs?seconds=600 > allocs.pdf # Stack traces of all current goroutines go tool pprof --pdf http://localhost:6060/debug/pprof/goroutine?seconds=600 > goroutine.pdf # A sampling of memory allocations of live objects. You can specify the gc GET parameter to run GC before taking the heap sample. go tool pprof --pdf http://localhost:6060/debug/pprof/heap?seconds=600 > heap.pdf # Stack traces that led to blocking on synchronization primitives go tool pprof --pdf http://localhost:6060/debug/pprof/block?seconds=600 > block.pdf # The command line invocation of the current program go tool pprof --pdf http://localhost:6060/debug/pprof/cmdline?seconds=60 > cmdline.pdf # Stack traces of holders of contended mutexes go tool pprof --pdf http://localhost:6060/debug/pprof/mutex?seconds=600 > mutex.pdf # Stack traces that led to the creation of new OS threads go tool pprof --pdf http://localhost:6060/debug/pprof/threadcreate?seconds=600 > threadcreate.pdf #scp files down from sentries scp -i ~/.ssh/keys/SentryOSTN.pem ec2-user@3.21.169.132:/home/ec2-user/*.pdf . exec ssh -i ~/.ssh/keys/SentryOSTN.pem ec2-user@3.21.169.132 Interactive mode scp -i ~/.ssh/keys/SentryOSTN.pem ec2-user@3.21.169.132:/home/ec2-user/pprof/* . go tool pprof -http=localhost:6060 pprof.harmony.alloc_objects.alloc_space.inuse_objects.inuse_space.010.pb.gz # On AWS instance go tool pprof -http=localhost:6070 pprof.harmony.contentions.delay.007.pb.gz Running Stress Tests - instructions # Log into the stress net machine ./node_ssh.sh 52.42.43.150 #Log into my desktop mydesktop.sh #See sentries for running nodes Additional Material Sebs Testing Instructions Double Signing Issue text bash <(curl -sSL https://raw.githubusercontent.com/SebastianJ/harmony-tools/master/double-signing/setup.sh) --network stress --shard 1 --address one1y5n7p8a845v96xyx2gh75wn5eyhtw5002lah27 Sebs Harmony tests repo Pangaea testing Sebs original ticket Sebs stress repo Sebs testing spreadsheet Daniels Autonode - instruction gist","title":"StressNet Testing cheatsheat"},{"location":"deploy/cicd/netdeploy/stressnet-stn-cheatsheat/#stressnet-testing-cheatsheat","text":"","title":"StressNet Testing cheatsheat"},{"location":"deploy/cicd/netdeploy/stressnet-stn-cheatsheat/#overview","text":"","title":"Overview"},{"location":"deploy/cicd/netdeploy/stressnet-stn-cheatsheat/#profiling-information-instructions","text":"# Copy files from Stressnet Monitor cd /Users/johnwhitton/projects/staking/STN scp -i ~/.ssh/keys/harmony-testnet.pem ec2-user@52.42.43.150:/home/ec2-user/pprof/* . pprof -http=localhost:8003 pprof.harmony.samples.cpu.007.pb.gz","title":"Profiling Information - instructions"},{"location":"deploy/cicd/netdeploy/stressnet-stn-cheatsheat/#local-machine-setup","text":"### Local Machine setup ### go get -u github.com/google/pprof brew install Graphviz","title":"Local Machine setup"},{"location":"deploy/cicd/netdeploy/stressnet-stn-cheatsheat/#running-a-sentry","text":"### Node Management commands #### Register the Validator ./hmy --node=\"https://api.s0.stn.hmny.io\" staking create-validator --validator-addr one1vzsj3julf0ljcj3hhxuqpu6zvadu488zfrtttz --name OSTNSentry0.1 --identity OSTNSentry2 --website sentry@harmony.one --security-contact Sentry --details \"OSTN Sentry for Shard 2 t3.small\" --rate 0.05 --max-rate 0.8 --max-change-rate 0.02 --min-self-delegation 10000 --max-total-delegation 10000000 --bls-pubkeys 463298d9357ddb336038a122b84549b0589597214e28f12b7816f09b554fd4c935437f25eb1720bae923fcb070b3e596 --amount 10000 # Restart the node ./node.sh -S -z -I -P -r localhost:6060 -N stress -k 463298d9357ddb336038a122b84549b0589597214e28f12b7816f09b554fd4c935437f25eb1720bae923fcb070b3e596.key # Restart the node and CLEAN out blockchain curl -LO https://harmony.one/hmycli && mv hmycli hmy && chmod +x hmy curl -LO https://raw.githubusercontent.com/harmony-one/harmony/master/scripts/node.sh && chmod a+x node.sh ./node.sh -S -c -z -I -P -R localhost:6060 -N stress -k 463298d9357ddb336038a122b84549b0589597214e28f12b7816f09b554fd4c935437f25eb1720bae923fcb070b3e596.key # Check that it's earning ./hmy --node=\"https://api.s0.os.hmny.io\" blockchain validator information one1vzsj3julf0ljcj3hhxuqpu6zvadu488zfrtttz # Mark it active ./hmy -n https://api.s0.os.hmny.io staking edit-validator --validator-addr one1vzsj3julf0ljcj3hhxuqpu6zvadu488zfrtttz --active true # Check the node version ./node.sh -V # Look at the logs tail -f ./latest/*.log","title":"Running a sentry"},{"location":"deploy/cicd/netdeploy/stressnet-stn-cheatsheat/#monitoring-machine-setup","text":"#### Stressnet Machine setup ### devops.sh export WHOAMI=STN; export HMY_PROFILE=stn; profile_print cd ~/john/experiment-deploy/pipeline ./node_ssh.sh 52.42.43.150 sudo yum install -y golang sudo yum install git go get -u github.com/google/pprof sudo yum install graphviz tmux new-session -s stress-node-s0-pprof bash <(curl -sSL https://raw.githubusercontent.com/SebastianJ/harmony-tools/master/pprof/report.sh) --address localhost:6060 --interval 5m go tool pprof --pdf http://localhost:6060/debug/pprof/profile?seconds=60 > cpu.pdf","title":"Monitoring machine setup"},{"location":"deploy/cicd/netdeploy/stressnet-stn-cheatsheat/#capturing-data","text":"# http://localhost:6060/debug/pprof/allocs # A sampling of all past memory allocations go tool pprof --pdf http://localhost:6060/debug/pprof/allocs?seconds=600 > allocs.pdf # Stack traces of all current goroutines go tool pprof --pdf http://localhost:6060/debug/pprof/goroutine?seconds=600 > goroutine.pdf # A sampling of memory allocations of live objects. You can specify the gc GET parameter to run GC before taking the heap sample. go tool pprof --pdf http://localhost:6060/debug/pprof/heap?seconds=600 > heap.pdf # Stack traces that led to blocking on synchronization primitives go tool pprof --pdf http://localhost:6060/debug/pprof/block?seconds=600 > block.pdf # The command line invocation of the current program go tool pprof --pdf http://localhost:6060/debug/pprof/cmdline?seconds=60 > cmdline.pdf # Stack traces of holders of contended mutexes go tool pprof --pdf http://localhost:6060/debug/pprof/mutex?seconds=600 > mutex.pdf # Stack traces that led to the creation of new OS threads go tool pprof --pdf http://localhost:6060/debug/pprof/threadcreate?seconds=600 > threadcreate.pdf #scp files down from sentries scp -i ~/.ssh/keys/SentryOSTN.pem ec2-user@3.21.169.132:/home/ec2-user/*.pdf . exec ssh -i ~/.ssh/keys/SentryOSTN.pem ec2-user@3.21.169.132 Interactive mode scp -i ~/.ssh/keys/SentryOSTN.pem ec2-user@3.21.169.132:/home/ec2-user/pprof/* . go tool pprof -http=localhost:6060 pprof.harmony.alloc_objects.alloc_space.inuse_objects.inuse_space.010.pb.gz # On AWS instance go tool pprof -http=localhost:6070 pprof.harmony.contentions.delay.007.pb.gz","title":"Capturing Data"},{"location":"deploy/cicd/netdeploy/stressnet-stn-cheatsheat/#running-stress-tests-instructions","text":"# Log into the stress net machine ./node_ssh.sh 52.42.43.150 #Log into my desktop mydesktop.sh #See sentries for running nodes","title":"Running Stress Tests - instructions"},{"location":"deploy/cicd/netdeploy/stressnet-stn-cheatsheat/#additional-material","text":"Sebs Testing Instructions Double Signing Issue text bash <(curl -sSL https://raw.githubusercontent.com/SebastianJ/harmony-tools/master/double-signing/setup.sh) --network stress --shard 1 --address one1y5n7p8a845v96xyx2gh75wn5eyhtw5002lah27 Sebs Harmony tests repo Pangaea testing Sebs original ticket Sebs stress repo Sebs testing spreadsheet Daniels Autonode - instruction gist","title":"Additional Material"},{"location":"deploy/cicd/netdeploy/watchdog-deployment/","text":"Watchdog Deployment Watchdog IP Update Copy IP address files from devops to watchdog {% tabs %} {% tab title=\"OSTN\" %} ./update_watchdog.sh -u -p -r -y ./update_watchdog.sh -w OS -t os -u -p -r -y {% endtab %} {% tab title=\"STN\" %} ./update_watchdog.sh -w STN -t stn -u -p -r -y {% endtab %} {% endtabs %} Usage: ./update_watchdog.sh -w [whoami] -t [target chain] -u -p -r -w WHOAMI (default = OS) -t Target directory in nodedb (default = ostn) -u Update the nodedb repo (default = false) -p Push the nodedb update (default = false) -r Restart Watchdog (default = false) -y Force yes (default = false) Troubleshooting Machine Login exec ssh -i ~/.ssh/keys/california-key-benchmark.pem ec2-user@watchdog.hmny.io Start Mini Explorer - No longer needed tmux a -t mini_explorer ctlr+a + 5 python3 -u mini_explorer_tmp2.py --shards 2 --endpoints http://<s0-explorer>:9500/,http://<s1-explorer>:9500/ --sleep 4 2>&1 | tee data/<today's date>_stress.log Watchdog Environments Mainnet: http://watchdog.hmny.io/report-mainnet - mainnet LRTN: http://watchdog.hmny.io/report-lrtn - lrtn OSTN: http://watchdog.hmny.io/report-ostn - os PSTN: http://watchdog.hmny.io/report-pstn - pstn STN: http://watchdog.hmny.io/report-stn - stn","title":"Watchdog Deployment"},{"location":"deploy/cicd/netdeploy/watchdog-deployment/#watchdog-deployment","text":"","title":"Watchdog Deployment"},{"location":"deploy/cicd/netdeploy/watchdog-deployment/#watchdog-ip-update","text":"Copy IP address files from devops to watchdog {% tabs %} {% tab title=\"OSTN\" %} ./update_watchdog.sh -u -p -r -y ./update_watchdog.sh -w OS -t os -u -p -r -y {% endtab %} {% tab title=\"STN\" %} ./update_watchdog.sh -w STN -t stn -u -p -r -y {% endtab %} {% endtabs %} Usage: ./update_watchdog.sh -w [whoami] -t [target chain] -u -p -r -w WHOAMI (default = OS) -t Target directory in nodedb (default = ostn) -u Update the nodedb repo (default = false) -p Push the nodedb update (default = false) -r Restart Watchdog (default = false) -y Force yes (default = false)","title":"Watchdog IP Update"},{"location":"deploy/cicd/netdeploy/watchdog-deployment/#troubleshooting","text":"Machine Login exec ssh -i ~/.ssh/keys/california-key-benchmark.pem ec2-user@watchdog.hmny.io","title":"Troubleshooting"},{"location":"deploy/cicd/netdeploy/watchdog-deployment/#start-mini-explorer-no-longer-needed","text":"tmux a -t mini_explorer ctlr+a + 5 python3 -u mini_explorer_tmp2.py --shards 2 --endpoints http://<s0-explorer>:9500/,http://<s1-explorer>:9500/ --sleep 4 2>&1 | tee data/<today's date>_stress.log","title":"Start Mini Explorer - No longer needed"},{"location":"deploy/cicd/netdeploy/watchdog-deployment/#watchdog-environments","text":"Mainnet: http://watchdog.hmny.io/report-mainnet - mainnet LRTN: http://watchdog.hmny.io/report-lrtn - lrtn OSTN: http://watchdog.hmny.io/report-ostn - os PSTN: http://watchdog.hmny.io/report-pstn - pstn STN: http://watchdog.hmny.io/report-stn - stn","title":"Watchdog Environments"},{"location":"deploy/cicd/netdeploy/cheat-sheets/","text":"Cheat Sheets Overview Just want to get up and running and do a deploy follow the below cheat sheets. Pre-requisites The following cheat sheets assume that you have completed the Pre-build Steps The codebase to deploy has been Synched to t3 You are building from the latest t3 branch You are building from the devops machine Experiment Deploy has been updated to the latest version on the devops machine You are releasing to OSTN You have captured the Log and validator Information You are logging the upgrade https://harmony.one/checklist Cheat Sheets Rolling Upgrade Refresh Network Launch or Upgrade","title":"Cheat Sheets"},{"location":"deploy/cicd/netdeploy/cheat-sheets/#cheat-sheets","text":"","title":"Cheat Sheets"},{"location":"deploy/cicd/netdeploy/cheat-sheets/#overview","text":"Just want to get up and running and do a deploy follow the below cheat sheets.","title":"Overview"},{"location":"deploy/cicd/netdeploy/cheat-sheets/#pre-requisites","text":"The following cheat sheets assume that you have completed the Pre-build Steps The codebase to deploy has been Synched to t3 You are building from the latest t3 branch You are building from the devops machine Experiment Deploy has been updated to the latest version on the devops machine You are releasing to OSTN You have captured the Log and validator Information You are logging the upgrade https://harmony.one/checklist","title":"Pre-requisites"},{"location":"deploy/cicd/netdeploy/cheat-sheets/#cheat-sheets_1","text":"Rolling Upgrade Refresh Network Launch or Upgrade","title":"Cheat Sheets"},{"location":"deploy/cicd/netdeploy/cheat-sheets/network-launch-or-upgrade/","text":"Network Launch or Upgrade","title":"Network Launch or Upgrade"},{"location":"deploy/cicd/netdeploy/cheat-sheets/network-launch-or-upgrade/#network-launch-or-upgrade","text":"","title":"Network Launch or Upgrade"},{"location":"deploy/cicd/netdeploy/cheat-sheets/refresh/","text":"Refresh Overview Over the past month the deployment process for a Network Deployment is being refined. This involves four phases Validation - Validating the build process and ensuring all components are identified Deployment - Documenting all the steps for the current deployment process Consolidation - Optimizing the deployment process Automation - Automating the deployment process Phase 1 and 2 have been completed for the current process with phase 3 and 4 ready to commence. This document summarizes in a cheat sheet the current deployment process. Action items for the consolidation and automation process can be captured below. Also please review the reference material at the bottom of this page. Action Items Review - p2 state of emergency on dev & ops Review Fixit Review Edgars Deployment Proposal Review OSTN Refresh Post Mortem Pre-requisites The following cheat sheets assume that you have completed the Pre-build Steps The codebase to deploy has been Synched to t3 You are building from the latest t3 branch You are building from the devops machine Experiment Deploy has been updated to the latest version on the devops machine You are releasing to OSTN You have captured the Log and validator Information You are logging the upgrade https://harmony.one/checklist Refresh Phases Announce Refresh Protocol Release Protocol Validation Network Release Network Validation Announce completion of refresh Refresh Cheat Sheet {% tabs %} {% tab title=\"OSTN\" %} # Announce Refresh ## Discord channels - team-staking, p-ops, testnet-nodes ## Telegram channels - [P-OPS] Pangaea OPS team & tech support, Open staking volunteers - Pangaea ### Message - OSTN Refresh starting now - will let you know when complete - changes are here https://gist.github.com/fxfactorial/981d1716ed623984946b52a46f39dc5d and https://github.com/harmony-one/harmony/commits/t3 # Protocol Release ## Log in to the devops Machine, set profile and go to experiment deploy exec ssh -i ~/.ssh/keys/oregon-key-benchmark.pem ec2-user@devop.hmny.io tmux ls tmux attach-session -t os profile_print export WHOAMI=OS; export HMY_PROFILE=os; profile_print ##cd ~/experiment-deploy/pipeline/ cd /home/ec2-user/go/src/github.com/harmony-one/experiment-deploy/pipeline ## Release the Protocol ### Remove Existing Network ./run_on_shard.sh -p os -T 0 'sudo killall -9 harmony; sudo rm -rf harmony_db_*; sudo rm -rf .dht*; sudo rm harmony.err; sudo rm -rf ../tmp_log/*/*' ./run_on_shard.sh -p os -T 1 'sudo killall -9 harmony; sudo rm -rf harmony_db_*; sudo rm -rf .dht*; sudo rm harmony.err; sudo rm -rf ../tmp_log/*/*' ./run_on_shard.sh -p os -T 2 'sudo killall -9 harmony; sudo rm -rf harmony_db_*; sudo rm -rf .dht*; sudo rm harmony.err; sudo rm -rf ../tmp_log/*/*' ./run_on_shard.sh -p os -T 3 'sudo killall -9 harmony; sudo rm -rf harmony_db_*; sudo rm -rf .dht*; sudo rm harmony.err; sudo rm -rf ../tmp_log/*/*' ### Reset bootnodes ./go.sh -p os bootnode ### Upgrade Harmony Nodes cat logs/os/shard0.txt | xargs -i{} -P50 bash -c './restart_node.sh -U -y -d logs/os -p os -t 0 -r 0 -R 0 {}' cat logs/os/shard1.txt | xargs -i{} -P50 bash -c './restart_node.sh -U -y -d logs/os -p os -t 0 -r 0 -R 0 {}' cat logs/os/shard2.txt | xargs -i{} -P50 bash -c './restart_node.sh -U -y -d logs/os -p os -t 0 -r 0 -R 0 {}' cat logs/os/shard3.txt | xargs -i{} -P50 bash -c './restart_node.sh -U -y -d logs/os -p os -t 0 -r 0 -R 0 {}' # Protocol Validation ## Check Consensus ./run_on_shard.sh -p os -T 0 'tac ../tmp_log/*/zerolog*.log | grep -m 1 HOORAY' ./run_on_shard.sh -p os -T 1 'tac ../tmp_log/*/zerolog*.log | grep -m 1 HOORAY' ./run_on_shard.sh -p os -T 2 'tac ../tmp_log/*/zerolog*.log | grep -m 1 HOORAY' ./run_on_shard.sh -p os -T 3 'tac ../tmp_log/*/zerolog*.log | grep -m 1 HOORAY' ## Check the correct version of the Code was deployed ./run_on_shard.sh -p os -T 0 \"./harmony -version\" ./run_on_shard.sh -p os -T 1 \"./harmony -version\" ./run_on_shard.sh -p os -T 2 \"./harmony -version\" ./run_on_shard.sh -p os -T 3 \"./harmony -version\" # Network Release ## Restart Watchdog ./update_watchdog.sh -w STN -t stn -u -p -r -y ## Release Validator Build ### Run Jenkins Harmony Release - https://jenkins.harmony.one/job/harmony-release/ ### Parameters #### Branch : t3 #### Branch Release : Check #### Build Type : release #### Network : pangaea #### STATIC_BINARY : Checked ### Run a second Jenkins Harmony release job with above paramaters but STATIC_BINARY unchecked ## Fund Accounts ./fund.sh -f -c ## Restart Faucet cd /home/ec2-user/CF ./faucet_deploy.sh os cd /home/ec2-user/go/src/github.com/harmony-one/experiment-deploy/pipeline ## Build Sentries - Done on Sentry Machines ### Sentry - Shard 0 exec ssh -i ~/.ssh/keys/SentryOSTN.pem ec2-user@3.21.53.63 tmux att curl -LO https://raw.githubusercontent.com/harmony-one/harmony/master/scripts/node.sh && chmod a+x node.sh rm -rf harmony_db* ./node.sh -S -c -z -I -P -r localhost:6060 -N staking -k afc4d81ab636323b04893c23d3404f38e95e9291b3d5299dade3d03822edd3a2b799bd6d64265a9a9cac025d5dbd600c.key <CTRL>b d ./node.sh -V ./hmy --node=\"https://api.s0.os.hmny.io\" staking create-validator --validator-addr one1m6j80t6rhc3ypaumtsfmqwjwp0mrqk9ff50prh --name OSTNSentry0 --identity OSTNSentry0 --website sentry@harmony.one --security-contact Sentry --details \"OSTN Sentry for Shard 0 t3.small\" --rate 0.05 --max-rate 0.8 --max-change-rate 0.02 --min-self-delegation 10000 --max-total-delegation 100000 --bls-pubkeys afc4d81ab636323b04893c23d3404f38e95e9291b3d5299dade3d03822edd3a2b799bd6d64265a9a9cac025d5dbd600c --amount 100000 ### Sentry - Shard 1 ssh -i ~/.ssh/keys/SentryOSTN.pem ec2-user@18.218.200.47 tmux att curl -LO https://raw.githubusercontent.com/harmony-one/harmony/master/scripts/node.sh && chmod a+x node.s rm -rf harmony_db* ./node.sh -S -c -z -I -P -r localhost:6060 -N staking -k 552f8aa65835f04e4bc3a04a4bd1f5c67dcd562513b6728c5b9fd258d9fdb054c10008b14a739818d0c234d37b8f1301.key <CTRL>b d ./node.sh -V ./hmy --node=\"https://api.s0.os.hmny.io\" staking create-validator --validator-addr one10fjqteq6q75nm62cx8vejqsk7mc8t5hle8ewnl --name OSTNSentry1 --identity OSTNSentry1 --website sentry@harmony.one --security-contact Sentry --details \"OSTN Sentry for Shard 1 t3.small\" --rate 0.05 --max-rate 0.8 --max-change-rate 0.02 --min-self-delegation 10000 --max-total-delegation 1000000 --bls-pubkeys 552f8aa65835f04e4bc3a04a4bd1f5c67dcd562513b6728c5b9fd258d9fdb054c10008b14a739818d0c234d37b8f1301 --amount 10000 ### Sentry - Shard 2 exec ssh -i ~/.ssh/keys/SentryOSTN.pem ec2-user@3.21.169.132 tmux att curl -LO https://raw.githubusercontent.com/harmony-one/harmony/master/scripts/node.sh && chmod a+x node.s rm -rf harmony_db* ./node.sh -S -c -z -I -P -r localhost:6060 -N staking -k a2232487bbf16dd01c5743700712819984d036bf3e39960c85045920784ba0d24149c93591dd4017ada3155e8105d402.key <CTRL>b d ./node.sh -V ./hmy --node=\"https://api.s0.os.hmny.io\" staking create-validator --validator-addr one1vzsj3julf0ljcj3hhxuqpu6zvadu488zfrtttz --name OSTNSentry2 --identity OSTNSentry2 --website sentry@harmony.one --security-contact Sentry --details \"OSTN Sentry for Shard 2 t3.small\" --rate 0.05 --max-rate 0.8 --max-change-rate 0.02 --min-self-delegation 10000 --max-total-delegation 10000000 --bls-pubkeys a2232487bbf16dd01c5743700712819984d036bf3e39960c85045920784ba0d24149c93591dd4017ada3155e8105d402 --amount 10000 ### Sentry - Shard 3 exec ssh -i ~/.ssh/keys/SentryOSTN.pem ec2-user@18.221.69.247 tmux att curl -LO https://raw.githubusercontent.com/harmony-one/harmony/master/scripts/node.sh && chmod a+x node.s rm -rf harmony_db* ./node.sh -S -c -z -I -P -r localhost:6060 -N staking -k 5aff3653958fdddefe04aaeb5e9c4a4fc7dda03538a04fd8dfd139c66d18ec31c7deb846cb67077fde48921ddb07a387.key <CTRL>b d ./node.sh -V ./hmy --node=\"https://api.s0.os.hmny.io\" staking create-validator --validator-addr one1marnnvc8hywmfxhrc8mtpjkvvdt32x9kxtwkvv --name OSTNSentry3 --identity OSTNSentry3 --website sentry@harmony.one --security-contact Sentry --details \"OSTN Sentry for Shard 3 t3.small\" --rate 0.05 --max-rate 0.8 --max-change-rate 0.02 --min-self-delegation 10000 --max-total-delegation 10000000 --bls-pubkeys 5aff3653958fdddefe04aaeb5e9c4a4fc7dda03538a04fd8dfd139c66d18ec31c7deb846cb67077fde48921ddb07a387 --amount 10000 ### MultiKey - Shard 1 cd /Users/johnwhitton/projects/staking/OSTN ssh -i \"JOHN_OSTN_VALIDATOR_1.pem\" ec2-user@ec2-3-16-31-148.us-east-2.compute.amazonaws.com tmux att curl -LO https://raw.githubusercontent.com/harmony-one/harmony/master/scripts/node.sh && chmod a+x node.s rm -rf harmony_db* ./node.sh -S -c -z -I -P -4 localhost:6060 -N staking -M <CTRL>b d ./node.sh -V ./hmy --node=\"https://api.s0.os.hmny.io\" staking create-validator --validator-addr one1y5n7p8a845v96xyx2gh75wn5eyhtw5002lah27 --name JohnV1 --identity JohnV1 --website john@harmony.one --security-contact Sentry --details \"John Validator t3.small\" --rate 0.05 --max-rate 0.8 --max-change-rate 0.02 --min-self-delegation 10000 --max-total-delegation 10000000 --bls-pubkeys e65ce96e41d54d49243e2294fb306768862cccd5be80347f88bafe13aa4d3582c21c613fc26f6908ed1faa0dd0c27381,b3815c62affe89560ecabb2f30de46742c927e8a951f37f080264d0b394e16b55ea0786629798d0170c713a9779e4585,b9626bcf02210e8979b0e661bbdbf2e5a691105761fd8800bd1e96087a57c393285af91dcf3c3d6763a643d874f14599 --amount 10000 ## Refresh Block Explorer - Done on Block Explorer exec ssh -i ~/.ssh/keys/oregon-key-benchmark.pem ec2-user@44.232.43.231 tmux att ### Go to the be session and kill the running process ### Usually you can then up arrow twice to run the following two commands npm run db-reset npm run start ## Refresh Staking Dashbaord - Done on Local Machine ### If problems with this check Block explorer deplpoyment to set up local instance cd /Users/johnwhitton/projects/staking-dashboard/appengine ### Clean the db ./clear_openstaking.sh ### Launch the backend (optional) ./deploy1.sh ### Launch the frontend (optional) #### Log in to firebase project firebase login #### Check frontend URL cat .env.production #### Build the release npm run build #### Deploy Frontend to Production ./prod_deploy.sh # Network Validation ## Validate Watchdog - http://watchdog.hmny.io/report-ostn ## Validate Validator Build - e.g. https://jenkins.harmony.one/job/harmony-release/412/console ### Go to the console and check that the commit you are building is correct #### e.g https://jenkins.harmony.one/job/harmony-release/412/console and find the below text under [harmony] #### Checking out Revision 0c46e086734aea2140f306d28ca3aa10e73c2153 (refs/remotesorigin/t3) ## Validate Accounts Funded ### fund.sh has confirms balances so check the output when you run the command ### Check a balance on explorer one1m6j80t6rhc3ypaumtsfmqwjwp0mrqk9ff50prh ## Validate Faucet ### Fund an account on https://faucet.os.hmny.io/ e.g one1m6j80t6rhc3ypaumtsfmqwjwp0mrqk9ff50prh ## Validate Sentries ### Check they are elected on https://staking.harmony.one/validators #### Check they are earning ./hmy --node=\"https://api.s0.os.hmny.io\" blockchain validator information one1m6j80t6rhc3ypaumtsfmqwjwp0mrqk9ff50prh ./hmy --node=\"https://api.s0.os.hmny.io\" blockchain validator information one10fjqteq6q75nm62cx8vejqsk7mc8t5hle8ewnl ./hmy --node=\"https://api.s0.os.hmny.io\" blockchain validator information one1vzsj3julf0ljcj3hhxuqpu6zvadu488zfrtttz ./hmy --node=\"https://api.s0.os.hmny.io\" blockchain validator information one1marnnvc8hywmfxhrc8mtpjkvvdt32x9kxtwkvv ./hmy --node=\"https://api.s0.os.hmny.io\" blockchain validator information one1y5n7p8a845v96xyx2gh75wn5eyhtw5002lah27 ## Validate Block Explorer - https://explorer.os.hmny.io/#/ ### Check blocks are being update ## Validate Staking Explorer - https://staking.harmony.one/validators ### Check Validators ### Delegate to a validator # Announce completion of Refresh ## Discord channels - team-staking, p-ops, testnet-nodes ## Telegram channels - [P-OPS] Pangaea OPS team & tech support, Open staking volunteers - Pangaea ### Message - \"OSTN Refresh is now complete - please reset your validators\" {% endtab %} {% tab title=\"STN\" %} # Announce Refresh ## Discord channels - stressnet ### Message - STN Refresh starting now - will let you know when complete - changes are here https://gist.github.com/fxfactorial/981d1716ed623984946b52a46f39dc5d and https://github.com/harmony-one/harmony/commits/t3 # Protocol Release ## Log in to the devops Machine, set profile and go to experiment deploy exec ssh -i ~/.ssh/keys/oregon-key-benchmark.pem ec2-user@devop.hmny.io tmux ls tmux attach-session -t STN profile_print export WHOAMI=STN; export HMY_PROFILE=stn; profile_print cd /home/ec2-user/go/src/github.com/harmony-one/experiment-deploy/pipeline ## Release the Protocol ### Remove Existing Network ./run_on_shard.sh -p stn -T 0 'sudo killall -9 harmony; sudo rm -rf harmony_db_*; sudo rm -rf .dht*; sudo rm harmony.err; sudo rm -rf ../tmp_log/*/*' ./run_on_shard.sh -p stn -T 1 'sudo killall -9 harmony; sudo rm -rf harmony_db_*; sudo rm -rf .dht*; sudo rm harmony.err; sudo rm -rf ../tmp_log/*/*' ### Reset bootnodes ./go.sh -p stn bootnode ### Upgrade Harmony Nodes cat logs/stn/shard0.txt | xargs -i{} -P50 bash -c './restart_node.sh -U -y -d logs/stn -p stn -t 0 -r 0 -R 0 {}' cat logs/stn/shard1.txt | xargs -i{} -P50 bash -c './restart_node.sh -U -y -d logs/stn -p stn -t 1 -r 0 -R 0 {}' # Protocol Validation ## Check Consensus ./run_on_shard.sh -p stn -y -T 0 'tac ../tmp_log/*/zerolog*.log | grep -m 1 HOORAY' ./run_on_shard.sh -p stn -y -T 1 'tac ../tmp_log/*/zerolog*.log | grep -m 1 HOORAY' ## Check the correct version of the Code was deployed ./run_on_shard.sh -p stn -y -T 0 \"LD_LIBRARY_PATH=. ./harmony -version\" ./run_on_shard.sh -p stn -y -T 1 \"LD_LIBRARY_PATH=. ./harmony -version\" # Network Release ## Restart Watchdog ./update_watchdog.sh -w STN -t stn -u -p -r -y ## Release Validator Build ### Run Jenkins Harmony Release - https://jenkins.harmony.one/job/harmony-release/ ### Parameters #### Branch : t3 #### Branch Release : Check #### Build Type : release #### Network : pangaea #### STATIC_BINARY : Checked ### Run a second Jenkins Harmony release job with above paramaters but STATIC_BINARY unchecked ## Fund Accounts chmod a+x ./fund.sh ./fund.sh -f -c ## Restart Faucet - https://faucet.stn.hmny.io/ cd /home/ec2-user/CF ./faucet_deploy.sh stn cd /home/ec2-user/go/src/github.com/harmony-one/experiment-deploy/pipeline ## Build Sentries - Done on Sentry Machines ### Reset Sentry0 ./node_ssh.sh 52.11.85.154 tmux att ./auto_node.sh run --shard 0 --auto-active --clean --network stress --beacon-endpoint https://api.s0.stn.hmny.io/ <CTL>b d exit ### Reset Sentry1 ./node_ssh.sh 54.202.197.141 tmux att ./auto_node.sh run --shard 1 --auto-active --clean --network stress --beacon-endpoint https://api.s0.stn.hmny.io/ <CTL>b d exit ## Reset sentry 0-1 with monitoring ./node_ssh.sh 52.42.43.150 tmux attach - t node <CTL> c curl -LO https://harmony.one/hmycli && mv hmycli hmy && chmod +x hmy curl -LO https://raw.githubusercontent.com/harmony-one/harmony/master/scripts/node.sh && chmod a+x node.sh rm -rf harmony_db* ./node.sh -S -c -z -I -P -R localhost:6060 -N stress -k 463298d9357ddb336038a122b84549b0589597214e28f12b7816f09b554fd4c935437f25eb1720bae923fcb070b3e596.key <CTL> b ./node.sh -V ./hmy --node=\"https://api.s0.stn.hmny.io\" staking create-validator --validator-addr one1vzsj3julf0ljcj3hhxuqpu6zvadu488zfrtttz --name OSTNSentry0.1 --identity OSTNSentry2 --website sentry@harmony.one --security-contact Sentry --details \"OSTN Sentry for Shard 2 t3.small\" --rate 0.05 --max-rate 0.8 --max-change-rate 0.02 --min-self-delegation 10000 --max-total-delegation 10000000 --bls-pubkeys 463298d9357ddb336038a122b84549b0589597214e28f12b7816f09b554fd4c935437f25eb1720bae923fcb070b3e596 --amount 10000 ./hmy --node=\"https://api.s0.stn.hmny.io\" blockchain validator information one1vzsj3julf0ljcj3hhxuqpu6zvadu488zfrtttz ### Sentries not yet configured ./node_ssh.sh 54.188.46.48 ### Refresh Staking Explorer ./clear_stressnet.sh ## Refresh Block Explorer - Done on Block Explorer - Have to connect from Devops exec ssh -i ~/.ssh/keys/oregon-key-benchmark.pem ec2-user@35.164.26.115 tmux att ### Go to the be session and kill the running process ### Usually you can then up arrow twice to run the following two commands npm run db-reset npm run rebuild; npm run start # Network Validation ## Validate Watchdog - http://watchdog.hmny.io/report-ostn ## Validate Validator Build - e.g. https://jenkins.harmony.one/job/harmony-release/412/console ### Go to the console and check that the commit you are building is correct #### e.g https://jenkins.harmony.one/job/harmony-release/412/console and find the below text under [harmony] #### Checking out Revision 0c46e086734aea2140f306d28ca3aa10e73c2153 (refs/remotesorigin/t3) ## Validate Accounts Funded ### fund.sh has confirms balances so check the output when you run the command ### Check a balance on explorer one1m6j80t6rhc3ypaumtsfmqwjwp0mrqk9ff50prh ## Validate Faucet ### Fund an account on https://faucet.stn.hmny.io/ e.g one1m6j80t6rhc3ypaumtsfmqwjwp0mrqk9ff50prh ## Validate Sentries ### Check they are elected on https://staking.harmony.one/validators #### Check they are earning ./hmy --node=\"https://api.s0.os.hmny.io\" blockchain validator information one1m6j80t6rhc3ypaumtsfmqwjwp0mrqk9ff50prh ./hmy --node=\"https://api.s0.os.hmny.io\" blockchain validator information one10fjqteq6q75nm62cx8vejqsk7mc8t5hle8ewnl ./hmy --node=\"https://api.s0.os.hmny.io\" blockchain validator information one1vzsj3julf0ljcj3hhxuqpu6zvadu488zfrtttz ./hmy --node=\"https://api.s0.os.hmny.io\" blockchain validator information one1marnnvc8hywmfxhrc8mtpjkvvdt32x9kxtwkvv ./hmy --node=\"https://api.s0.os.hmny.io\" blockchain validator information one1y5n7p8a845v96xyx2gh75wn5eyhtw5002lah27 ## Validate Block Explorer - https://explorer.os.hmny.io/#/ ### Check blocks are being update ## Validate Staking Explorer - https://staking.harmony.one/validators ### Check Validators ### Delegate to a validator # Announce completion of Refresh ## Discord channels - team-staking, p-ops, testnet-nodes ## Telegram channels - [P-OPS] Pangaea OPS team & tech support, Open staking volunteers - Pangaea ### Message - \"OSTN Refresh is now complete - please reset your validators\" {% endtab %} {% endtabs %} Reference Material p2 state of emergency on dev & ops Fixit Edgars Deployment Proposal OSTN Checklist - OSTN Release Log Post Mortem Post-Mortem: Mar-31-2020 Mainnet Shards Down Post-Mortem: Apr 3-4-2020 OSTN Refresh issues","title":"Refresh"},{"location":"deploy/cicd/netdeploy/cheat-sheets/refresh/#refresh","text":"","title":"Refresh"},{"location":"deploy/cicd/netdeploy/cheat-sheets/refresh/#overview","text":"Over the past month the deployment process for a Network Deployment is being refined. This involves four phases Validation - Validating the build process and ensuring all components are identified Deployment - Documenting all the steps for the current deployment process Consolidation - Optimizing the deployment process Automation - Automating the deployment process Phase 1 and 2 have been completed for the current process with phase 3 and 4 ready to commence. This document summarizes in a cheat sheet the current deployment process. Action items for the consolidation and automation process can be captured below. Also please review the reference material at the bottom of this page.","title":"Overview"},{"location":"deploy/cicd/netdeploy/cheat-sheets/refresh/#action-items","text":"Review - p2 state of emergency on dev & ops Review Fixit Review Edgars Deployment Proposal Review OSTN Refresh Post Mortem","title":"Action Items"},{"location":"deploy/cicd/netdeploy/cheat-sheets/refresh/#pre-requisites","text":"The following cheat sheets assume that you have completed the Pre-build Steps The codebase to deploy has been Synched to t3 You are building from the latest t3 branch You are building from the devops machine Experiment Deploy has been updated to the latest version on the devops machine You are releasing to OSTN You have captured the Log and validator Information You are logging the upgrade https://harmony.one/checklist","title":"Pre-requisites"},{"location":"deploy/cicd/netdeploy/cheat-sheets/refresh/#refresh-phases","text":"Announce Refresh Protocol Release Protocol Validation Network Release Network Validation Announce completion of refresh","title":"Refresh Phases"},{"location":"deploy/cicd/netdeploy/cheat-sheets/refresh/#refresh-cheat-sheet","text":"{% tabs %} {% tab title=\"OSTN\" %} # Announce Refresh ## Discord channels - team-staking, p-ops, testnet-nodes ## Telegram channels - [P-OPS] Pangaea OPS team & tech support, Open staking volunteers - Pangaea ### Message - OSTN Refresh starting now - will let you know when complete - changes are here https://gist.github.com/fxfactorial/981d1716ed623984946b52a46f39dc5d and https://github.com/harmony-one/harmony/commits/t3 # Protocol Release ## Log in to the devops Machine, set profile and go to experiment deploy exec ssh -i ~/.ssh/keys/oregon-key-benchmark.pem ec2-user@devop.hmny.io tmux ls tmux attach-session -t os profile_print export WHOAMI=OS; export HMY_PROFILE=os; profile_print ##cd ~/experiment-deploy/pipeline/ cd /home/ec2-user/go/src/github.com/harmony-one/experiment-deploy/pipeline ## Release the Protocol ### Remove Existing Network ./run_on_shard.sh -p os -T 0 'sudo killall -9 harmony; sudo rm -rf harmony_db_*; sudo rm -rf .dht*; sudo rm harmony.err; sudo rm -rf ../tmp_log/*/*' ./run_on_shard.sh -p os -T 1 'sudo killall -9 harmony; sudo rm -rf harmony_db_*; sudo rm -rf .dht*; sudo rm harmony.err; sudo rm -rf ../tmp_log/*/*' ./run_on_shard.sh -p os -T 2 'sudo killall -9 harmony; sudo rm -rf harmony_db_*; sudo rm -rf .dht*; sudo rm harmony.err; sudo rm -rf ../tmp_log/*/*' ./run_on_shard.sh -p os -T 3 'sudo killall -9 harmony; sudo rm -rf harmony_db_*; sudo rm -rf .dht*; sudo rm harmony.err; sudo rm -rf ../tmp_log/*/*' ### Reset bootnodes ./go.sh -p os bootnode ### Upgrade Harmony Nodes cat logs/os/shard0.txt | xargs -i{} -P50 bash -c './restart_node.sh -U -y -d logs/os -p os -t 0 -r 0 -R 0 {}' cat logs/os/shard1.txt | xargs -i{} -P50 bash -c './restart_node.sh -U -y -d logs/os -p os -t 0 -r 0 -R 0 {}' cat logs/os/shard2.txt | xargs -i{} -P50 bash -c './restart_node.sh -U -y -d logs/os -p os -t 0 -r 0 -R 0 {}' cat logs/os/shard3.txt | xargs -i{} -P50 bash -c './restart_node.sh -U -y -d logs/os -p os -t 0 -r 0 -R 0 {}' # Protocol Validation ## Check Consensus ./run_on_shard.sh -p os -T 0 'tac ../tmp_log/*/zerolog*.log | grep -m 1 HOORAY' ./run_on_shard.sh -p os -T 1 'tac ../tmp_log/*/zerolog*.log | grep -m 1 HOORAY' ./run_on_shard.sh -p os -T 2 'tac ../tmp_log/*/zerolog*.log | grep -m 1 HOORAY' ./run_on_shard.sh -p os -T 3 'tac ../tmp_log/*/zerolog*.log | grep -m 1 HOORAY' ## Check the correct version of the Code was deployed ./run_on_shard.sh -p os -T 0 \"./harmony -version\" ./run_on_shard.sh -p os -T 1 \"./harmony -version\" ./run_on_shard.sh -p os -T 2 \"./harmony -version\" ./run_on_shard.sh -p os -T 3 \"./harmony -version\" # Network Release ## Restart Watchdog ./update_watchdog.sh -w STN -t stn -u -p -r -y ## Release Validator Build ### Run Jenkins Harmony Release - https://jenkins.harmony.one/job/harmony-release/ ### Parameters #### Branch : t3 #### Branch Release : Check #### Build Type : release #### Network : pangaea #### STATIC_BINARY : Checked ### Run a second Jenkins Harmony release job with above paramaters but STATIC_BINARY unchecked ## Fund Accounts ./fund.sh -f -c ## Restart Faucet cd /home/ec2-user/CF ./faucet_deploy.sh os cd /home/ec2-user/go/src/github.com/harmony-one/experiment-deploy/pipeline ## Build Sentries - Done on Sentry Machines ### Sentry - Shard 0 exec ssh -i ~/.ssh/keys/SentryOSTN.pem ec2-user@3.21.53.63 tmux att curl -LO https://raw.githubusercontent.com/harmony-one/harmony/master/scripts/node.sh && chmod a+x node.sh rm -rf harmony_db* ./node.sh -S -c -z -I -P -r localhost:6060 -N staking -k afc4d81ab636323b04893c23d3404f38e95e9291b3d5299dade3d03822edd3a2b799bd6d64265a9a9cac025d5dbd600c.key <CTRL>b d ./node.sh -V ./hmy --node=\"https://api.s0.os.hmny.io\" staking create-validator --validator-addr one1m6j80t6rhc3ypaumtsfmqwjwp0mrqk9ff50prh --name OSTNSentry0 --identity OSTNSentry0 --website sentry@harmony.one --security-contact Sentry --details \"OSTN Sentry for Shard 0 t3.small\" --rate 0.05 --max-rate 0.8 --max-change-rate 0.02 --min-self-delegation 10000 --max-total-delegation 100000 --bls-pubkeys afc4d81ab636323b04893c23d3404f38e95e9291b3d5299dade3d03822edd3a2b799bd6d64265a9a9cac025d5dbd600c --amount 100000 ### Sentry - Shard 1 ssh -i ~/.ssh/keys/SentryOSTN.pem ec2-user@18.218.200.47 tmux att curl -LO https://raw.githubusercontent.com/harmony-one/harmony/master/scripts/node.sh && chmod a+x node.s rm -rf harmony_db* ./node.sh -S -c -z -I -P -r localhost:6060 -N staking -k 552f8aa65835f04e4bc3a04a4bd1f5c67dcd562513b6728c5b9fd258d9fdb054c10008b14a739818d0c234d37b8f1301.key <CTRL>b d ./node.sh -V ./hmy --node=\"https://api.s0.os.hmny.io\" staking create-validator --validator-addr one10fjqteq6q75nm62cx8vejqsk7mc8t5hle8ewnl --name OSTNSentry1 --identity OSTNSentry1 --website sentry@harmony.one --security-contact Sentry --details \"OSTN Sentry for Shard 1 t3.small\" --rate 0.05 --max-rate 0.8 --max-change-rate 0.02 --min-self-delegation 10000 --max-total-delegation 1000000 --bls-pubkeys 552f8aa65835f04e4bc3a04a4bd1f5c67dcd562513b6728c5b9fd258d9fdb054c10008b14a739818d0c234d37b8f1301 --amount 10000 ### Sentry - Shard 2 exec ssh -i ~/.ssh/keys/SentryOSTN.pem ec2-user@3.21.169.132 tmux att curl -LO https://raw.githubusercontent.com/harmony-one/harmony/master/scripts/node.sh && chmod a+x node.s rm -rf harmony_db* ./node.sh -S -c -z -I -P -r localhost:6060 -N staking -k a2232487bbf16dd01c5743700712819984d036bf3e39960c85045920784ba0d24149c93591dd4017ada3155e8105d402.key <CTRL>b d ./node.sh -V ./hmy --node=\"https://api.s0.os.hmny.io\" staking create-validator --validator-addr one1vzsj3julf0ljcj3hhxuqpu6zvadu488zfrtttz --name OSTNSentry2 --identity OSTNSentry2 --website sentry@harmony.one --security-contact Sentry --details \"OSTN Sentry for Shard 2 t3.small\" --rate 0.05 --max-rate 0.8 --max-change-rate 0.02 --min-self-delegation 10000 --max-total-delegation 10000000 --bls-pubkeys a2232487bbf16dd01c5743700712819984d036bf3e39960c85045920784ba0d24149c93591dd4017ada3155e8105d402 --amount 10000 ### Sentry - Shard 3 exec ssh -i ~/.ssh/keys/SentryOSTN.pem ec2-user@18.221.69.247 tmux att curl -LO https://raw.githubusercontent.com/harmony-one/harmony/master/scripts/node.sh && chmod a+x node.s rm -rf harmony_db* ./node.sh -S -c -z -I -P -r localhost:6060 -N staking -k 5aff3653958fdddefe04aaeb5e9c4a4fc7dda03538a04fd8dfd139c66d18ec31c7deb846cb67077fde48921ddb07a387.key <CTRL>b d ./node.sh -V ./hmy --node=\"https://api.s0.os.hmny.io\" staking create-validator --validator-addr one1marnnvc8hywmfxhrc8mtpjkvvdt32x9kxtwkvv --name OSTNSentry3 --identity OSTNSentry3 --website sentry@harmony.one --security-contact Sentry --details \"OSTN Sentry for Shard 3 t3.small\" --rate 0.05 --max-rate 0.8 --max-change-rate 0.02 --min-self-delegation 10000 --max-total-delegation 10000000 --bls-pubkeys 5aff3653958fdddefe04aaeb5e9c4a4fc7dda03538a04fd8dfd139c66d18ec31c7deb846cb67077fde48921ddb07a387 --amount 10000 ### MultiKey - Shard 1 cd /Users/johnwhitton/projects/staking/OSTN ssh -i \"JOHN_OSTN_VALIDATOR_1.pem\" ec2-user@ec2-3-16-31-148.us-east-2.compute.amazonaws.com tmux att curl -LO https://raw.githubusercontent.com/harmony-one/harmony/master/scripts/node.sh && chmod a+x node.s rm -rf harmony_db* ./node.sh -S -c -z -I -P -4 localhost:6060 -N staking -M <CTRL>b d ./node.sh -V ./hmy --node=\"https://api.s0.os.hmny.io\" staking create-validator --validator-addr one1y5n7p8a845v96xyx2gh75wn5eyhtw5002lah27 --name JohnV1 --identity JohnV1 --website john@harmony.one --security-contact Sentry --details \"John Validator t3.small\" --rate 0.05 --max-rate 0.8 --max-change-rate 0.02 --min-self-delegation 10000 --max-total-delegation 10000000 --bls-pubkeys e65ce96e41d54d49243e2294fb306768862cccd5be80347f88bafe13aa4d3582c21c613fc26f6908ed1faa0dd0c27381,b3815c62affe89560ecabb2f30de46742c927e8a951f37f080264d0b394e16b55ea0786629798d0170c713a9779e4585,b9626bcf02210e8979b0e661bbdbf2e5a691105761fd8800bd1e96087a57c393285af91dcf3c3d6763a643d874f14599 --amount 10000 ## Refresh Block Explorer - Done on Block Explorer exec ssh -i ~/.ssh/keys/oregon-key-benchmark.pem ec2-user@44.232.43.231 tmux att ### Go to the be session and kill the running process ### Usually you can then up arrow twice to run the following two commands npm run db-reset npm run start ## Refresh Staking Dashbaord - Done on Local Machine ### If problems with this check Block explorer deplpoyment to set up local instance cd /Users/johnwhitton/projects/staking-dashboard/appengine ### Clean the db ./clear_openstaking.sh ### Launch the backend (optional) ./deploy1.sh ### Launch the frontend (optional) #### Log in to firebase project firebase login #### Check frontend URL cat .env.production #### Build the release npm run build #### Deploy Frontend to Production ./prod_deploy.sh # Network Validation ## Validate Watchdog - http://watchdog.hmny.io/report-ostn ## Validate Validator Build - e.g. https://jenkins.harmony.one/job/harmony-release/412/console ### Go to the console and check that the commit you are building is correct #### e.g https://jenkins.harmony.one/job/harmony-release/412/console and find the below text under [harmony] #### Checking out Revision 0c46e086734aea2140f306d28ca3aa10e73c2153 (refs/remotesorigin/t3) ## Validate Accounts Funded ### fund.sh has confirms balances so check the output when you run the command ### Check a balance on explorer one1m6j80t6rhc3ypaumtsfmqwjwp0mrqk9ff50prh ## Validate Faucet ### Fund an account on https://faucet.os.hmny.io/ e.g one1m6j80t6rhc3ypaumtsfmqwjwp0mrqk9ff50prh ## Validate Sentries ### Check they are elected on https://staking.harmony.one/validators #### Check they are earning ./hmy --node=\"https://api.s0.os.hmny.io\" blockchain validator information one1m6j80t6rhc3ypaumtsfmqwjwp0mrqk9ff50prh ./hmy --node=\"https://api.s0.os.hmny.io\" blockchain validator information one10fjqteq6q75nm62cx8vejqsk7mc8t5hle8ewnl ./hmy --node=\"https://api.s0.os.hmny.io\" blockchain validator information one1vzsj3julf0ljcj3hhxuqpu6zvadu488zfrtttz ./hmy --node=\"https://api.s0.os.hmny.io\" blockchain validator information one1marnnvc8hywmfxhrc8mtpjkvvdt32x9kxtwkvv ./hmy --node=\"https://api.s0.os.hmny.io\" blockchain validator information one1y5n7p8a845v96xyx2gh75wn5eyhtw5002lah27 ## Validate Block Explorer - https://explorer.os.hmny.io/#/ ### Check blocks are being update ## Validate Staking Explorer - https://staking.harmony.one/validators ### Check Validators ### Delegate to a validator # Announce completion of Refresh ## Discord channels - team-staking, p-ops, testnet-nodes ## Telegram channels - [P-OPS] Pangaea OPS team & tech support, Open staking volunteers - Pangaea ### Message - \"OSTN Refresh is now complete - please reset your validators\" {% endtab %} {% tab title=\"STN\" %} # Announce Refresh ## Discord channels - stressnet ### Message - STN Refresh starting now - will let you know when complete - changes are here https://gist.github.com/fxfactorial/981d1716ed623984946b52a46f39dc5d and https://github.com/harmony-one/harmony/commits/t3 # Protocol Release ## Log in to the devops Machine, set profile and go to experiment deploy exec ssh -i ~/.ssh/keys/oregon-key-benchmark.pem ec2-user@devop.hmny.io tmux ls tmux attach-session -t STN profile_print export WHOAMI=STN; export HMY_PROFILE=stn; profile_print cd /home/ec2-user/go/src/github.com/harmony-one/experiment-deploy/pipeline ## Release the Protocol ### Remove Existing Network ./run_on_shard.sh -p stn -T 0 'sudo killall -9 harmony; sudo rm -rf harmony_db_*; sudo rm -rf .dht*; sudo rm harmony.err; sudo rm -rf ../tmp_log/*/*' ./run_on_shard.sh -p stn -T 1 'sudo killall -9 harmony; sudo rm -rf harmony_db_*; sudo rm -rf .dht*; sudo rm harmony.err; sudo rm -rf ../tmp_log/*/*' ### Reset bootnodes ./go.sh -p stn bootnode ### Upgrade Harmony Nodes cat logs/stn/shard0.txt | xargs -i{} -P50 bash -c './restart_node.sh -U -y -d logs/stn -p stn -t 0 -r 0 -R 0 {}' cat logs/stn/shard1.txt | xargs -i{} -P50 bash -c './restart_node.sh -U -y -d logs/stn -p stn -t 1 -r 0 -R 0 {}' # Protocol Validation ## Check Consensus ./run_on_shard.sh -p stn -y -T 0 'tac ../tmp_log/*/zerolog*.log | grep -m 1 HOORAY' ./run_on_shard.sh -p stn -y -T 1 'tac ../tmp_log/*/zerolog*.log | grep -m 1 HOORAY' ## Check the correct version of the Code was deployed ./run_on_shard.sh -p stn -y -T 0 \"LD_LIBRARY_PATH=. ./harmony -version\" ./run_on_shard.sh -p stn -y -T 1 \"LD_LIBRARY_PATH=. ./harmony -version\" # Network Release ## Restart Watchdog ./update_watchdog.sh -w STN -t stn -u -p -r -y ## Release Validator Build ### Run Jenkins Harmony Release - https://jenkins.harmony.one/job/harmony-release/ ### Parameters #### Branch : t3 #### Branch Release : Check #### Build Type : release #### Network : pangaea #### STATIC_BINARY : Checked ### Run a second Jenkins Harmony release job with above paramaters but STATIC_BINARY unchecked ## Fund Accounts chmod a+x ./fund.sh ./fund.sh -f -c ## Restart Faucet - https://faucet.stn.hmny.io/ cd /home/ec2-user/CF ./faucet_deploy.sh stn cd /home/ec2-user/go/src/github.com/harmony-one/experiment-deploy/pipeline ## Build Sentries - Done on Sentry Machines ### Reset Sentry0 ./node_ssh.sh 52.11.85.154 tmux att ./auto_node.sh run --shard 0 --auto-active --clean --network stress --beacon-endpoint https://api.s0.stn.hmny.io/ <CTL>b d exit ### Reset Sentry1 ./node_ssh.sh 54.202.197.141 tmux att ./auto_node.sh run --shard 1 --auto-active --clean --network stress --beacon-endpoint https://api.s0.stn.hmny.io/ <CTL>b d exit ## Reset sentry 0-1 with monitoring ./node_ssh.sh 52.42.43.150 tmux attach - t node <CTL> c curl -LO https://harmony.one/hmycli && mv hmycli hmy && chmod +x hmy curl -LO https://raw.githubusercontent.com/harmony-one/harmony/master/scripts/node.sh && chmod a+x node.sh rm -rf harmony_db* ./node.sh -S -c -z -I -P -R localhost:6060 -N stress -k 463298d9357ddb336038a122b84549b0589597214e28f12b7816f09b554fd4c935437f25eb1720bae923fcb070b3e596.key <CTL> b ./node.sh -V ./hmy --node=\"https://api.s0.stn.hmny.io\" staking create-validator --validator-addr one1vzsj3julf0ljcj3hhxuqpu6zvadu488zfrtttz --name OSTNSentry0.1 --identity OSTNSentry2 --website sentry@harmony.one --security-contact Sentry --details \"OSTN Sentry for Shard 2 t3.small\" --rate 0.05 --max-rate 0.8 --max-change-rate 0.02 --min-self-delegation 10000 --max-total-delegation 10000000 --bls-pubkeys 463298d9357ddb336038a122b84549b0589597214e28f12b7816f09b554fd4c935437f25eb1720bae923fcb070b3e596 --amount 10000 ./hmy --node=\"https://api.s0.stn.hmny.io\" blockchain validator information one1vzsj3julf0ljcj3hhxuqpu6zvadu488zfrtttz ### Sentries not yet configured ./node_ssh.sh 54.188.46.48 ### Refresh Staking Explorer ./clear_stressnet.sh ## Refresh Block Explorer - Done on Block Explorer - Have to connect from Devops exec ssh -i ~/.ssh/keys/oregon-key-benchmark.pem ec2-user@35.164.26.115 tmux att ### Go to the be session and kill the running process ### Usually you can then up arrow twice to run the following two commands npm run db-reset npm run rebuild; npm run start # Network Validation ## Validate Watchdog - http://watchdog.hmny.io/report-ostn ## Validate Validator Build - e.g. https://jenkins.harmony.one/job/harmony-release/412/console ### Go to the console and check that the commit you are building is correct #### e.g https://jenkins.harmony.one/job/harmony-release/412/console and find the below text under [harmony] #### Checking out Revision 0c46e086734aea2140f306d28ca3aa10e73c2153 (refs/remotesorigin/t3) ## Validate Accounts Funded ### fund.sh has confirms balances so check the output when you run the command ### Check a balance on explorer one1m6j80t6rhc3ypaumtsfmqwjwp0mrqk9ff50prh ## Validate Faucet ### Fund an account on https://faucet.stn.hmny.io/ e.g one1m6j80t6rhc3ypaumtsfmqwjwp0mrqk9ff50prh ## Validate Sentries ### Check they are elected on https://staking.harmony.one/validators #### Check they are earning ./hmy --node=\"https://api.s0.os.hmny.io\" blockchain validator information one1m6j80t6rhc3ypaumtsfmqwjwp0mrqk9ff50prh ./hmy --node=\"https://api.s0.os.hmny.io\" blockchain validator information one10fjqteq6q75nm62cx8vejqsk7mc8t5hle8ewnl ./hmy --node=\"https://api.s0.os.hmny.io\" blockchain validator information one1vzsj3julf0ljcj3hhxuqpu6zvadu488zfrtttz ./hmy --node=\"https://api.s0.os.hmny.io\" blockchain validator information one1marnnvc8hywmfxhrc8mtpjkvvdt32x9kxtwkvv ./hmy --node=\"https://api.s0.os.hmny.io\" blockchain validator information one1y5n7p8a845v96xyx2gh75wn5eyhtw5002lah27 ## Validate Block Explorer - https://explorer.os.hmny.io/#/ ### Check blocks are being update ## Validate Staking Explorer - https://staking.harmony.one/validators ### Check Validators ### Delegate to a validator # Announce completion of Refresh ## Discord channels - team-staking, p-ops, testnet-nodes ## Telegram channels - [P-OPS] Pangaea OPS team & tech support, Open staking volunteers - Pangaea ### Message - \"OSTN Refresh is now complete - please reset your validators\" {% endtab %} {% endtabs %}","title":"Refresh Cheat Sheet"},{"location":"deploy/cicd/netdeploy/cheat-sheets/refresh/#reference-material","text":"p2 state of emergency on dev & ops Fixit Edgars Deployment Proposal OSTN Checklist - OSTN Release Log Post Mortem Post-Mortem: Mar-31-2020 Mainnet Shards Down Post-Mortem: Apr 3-4-2020 OSTN Refresh issues","title":"Reference Material"},{"location":"deploy/cicd/netdeploy/cheat-sheets/rolling-upgrade/","text":"Rolling Upgrade","title":"Rolling Upgrade"},{"location":"deploy/cicd/netdeploy/cheat-sheets/rolling-upgrade/#rolling-upgrade","text":"","title":"Rolling Upgrade"},{"location":"deploy/cicd/netdeploy/faucet-deployment/","text":"Faucet Deployment {% hint style=\"info\" %} Quick restart on deploy of a new network # Connect to the devops Machine /cd home/ec2-user/CF ./faucet_deploy.sh os {% endhint %} Faucet Overview The faucet is used to allow developers, validators and delegators to fund their account on Harmony's test networks so that they can participate in Harmony testing and development. It consists of a smart contract layer, a backend and a simple front end hosted by Harmony. Economics Funding is 30M ONE at each hard refresh Issuance is 10,000 ONE per wallet address every 450 blocks This enables 3000 faucet transactions of 10,000 each Top up is 30M ONE using the same mechanism as above e.g https://faucet.os.hmny.io/exposeAddress get the address and then fund the account from any account Components Smart Contract Layer - Code can be found in node-faucet with faucet.sol containing the key functionality Backend - Also found in node-faucet with app.js being the entry point Frontend - Also found in node-faucet with index.html being the entry point Deployment Environments OSTN - website PSTN - website Deployment Setup Clone the HRC REPOSITORY git clone https://github.com/harmony-one/HRC.git Spin up a new instance for the faucet This will be an AWS instance t3.small 8GB with ports 80, 443 22 open see here for an example from STN deployed in Oregon List of Instances # STN - 18.237.99.236 (harmony-testnet.pem) ./node_ssh.sh 18.237.99.236 # OSTN ./node_ssh.sh 3.133.82.52 # PTN Host faucet IdentityFile ~/.ssh/harmony-keys/cem_harmony_key2.pem User ubuntu HostName ec2-3-133-82-52.us-east-2.compute.amazonaws.com Host p-faucet IdentityFile ~/.ssh/harmony-keys/cem_harmony_key2.pem User ubuntu HostName ec2-3-134-93-91.us-east-2.compute.amazonaws.com Host t-faucet IdentityFile ~/.ssh/harmony-keys/cem_harmony_key2.pem User ubuntu HostName ec2-18-221-19-29.us-east-2.compute.amazonaws.com Faucet Machine Setup {% tabs %} {% tab title=\"OSTN\" %} ho {% endtab %} {% tab title=\"STN\" %} # Log into devops machine devops.sh # Log into STN tmux tmux att -t STN profile_print cd /home/ec2-user/JL/experiment-deploy/pipeline ./node_ssh.sh 54.200.244.64 # {% endtab %} {% endtabs %} Deployment Process # For a restart cd /Users/johnwhitton/projects/HRC/examples/node-faucet-no-contract # run a deployment script npm run clean-start Overview of funding process: run the deploy script (included separately) in the examples/node-faucet directory of the up to date HRC repo OSTN: OSTN_deploy.sh PSTN: PSTN_deploy.sh LRTN: LRTN_deploy.sh run the output command in the respective faucet instance kill the current running faucet first ( tmux attach ) either reuse the same tmux instance or start a new one in the faucet directory: ~/HRC2/examples/node-faucet copy the last command from the output [OSTN | PSTN]_cmd_log.txt and run it in the tmux window detach the tmux window with <ctrl-b>, d fund the contract account OSTN: https://faucet.os.hmny.io/exposeAddress PSTN: https://faucet.ps.hmny.io/exposeAddress funding process can be automated by grabbing the hex faucet address from the deploy script and converting it to bech32. can check that the faucet is successfully deployed by checking that amount in shard 0 is the initial funded amount (currently 0.01 ONE) Areas for Improvement Funding increase amount of funds by 10x Timeouts - analyze whether we can send multiple transactions per block - nonce issue Deploy multiple(5) faucets with different end points and tree structure Modify process to remove smart contract and sign transactions directly (if this enables multi transactions per block) Enhance further to send from multiple accounts.","title":"Faucet Deployment"},{"location":"deploy/cicd/netdeploy/faucet-deployment/#faucet-deployment","text":"{% hint style=\"info\" %} Quick restart on deploy of a new network # Connect to the devops Machine /cd home/ec2-user/CF ./faucet_deploy.sh os {% endhint %}","title":"Faucet Deployment"},{"location":"deploy/cicd/netdeploy/faucet-deployment/#faucet-overview","text":"The faucet is used to allow developers, validators and delegators to fund their account on Harmony's test networks so that they can participate in Harmony testing and development. It consists of a smart contract layer, a backend and a simple front end hosted by Harmony.","title":"Faucet Overview"},{"location":"deploy/cicd/netdeploy/faucet-deployment/#economics","text":"Funding is 30M ONE at each hard refresh Issuance is 10,000 ONE per wallet address every 450 blocks This enables 3000 faucet transactions of 10,000 each Top up is 30M ONE using the same mechanism as above e.g https://faucet.os.hmny.io/exposeAddress get the address and then fund the account from any account","title":"Economics"},{"location":"deploy/cicd/netdeploy/faucet-deployment/#components","text":"Smart Contract Layer - Code can be found in node-faucet with faucet.sol containing the key functionality Backend - Also found in node-faucet with app.js being the entry point Frontend - Also found in node-faucet with index.html being the entry point","title":"Components"},{"location":"deploy/cicd/netdeploy/faucet-deployment/#deployment-environments","text":"OSTN - website PSTN - website","title":"Deployment Environments"},{"location":"deploy/cicd/netdeploy/faucet-deployment/#deployment-setup","text":"Clone the HRC REPOSITORY git clone https://github.com/harmony-one/HRC.git Spin up a new instance for the faucet This will be an AWS instance t3.small 8GB with ports 80, 443 22 open see here for an example from STN deployed in Oregon","title":"Deployment Setup"},{"location":"deploy/cicd/netdeploy/faucet-deployment/#list-of-instances","text":"# STN - 18.237.99.236 (harmony-testnet.pem) ./node_ssh.sh 18.237.99.236 # OSTN ./node_ssh.sh 3.133.82.52 # PTN Host faucet IdentityFile ~/.ssh/harmony-keys/cem_harmony_key2.pem User ubuntu HostName ec2-3-133-82-52.us-east-2.compute.amazonaws.com Host p-faucet IdentityFile ~/.ssh/harmony-keys/cem_harmony_key2.pem User ubuntu HostName ec2-3-134-93-91.us-east-2.compute.amazonaws.com Host t-faucet IdentityFile ~/.ssh/harmony-keys/cem_harmony_key2.pem User ubuntu HostName ec2-18-221-19-29.us-east-2.compute.amazonaws.com","title":"List of Instances"},{"location":"deploy/cicd/netdeploy/faucet-deployment/#faucet-machine-setup","text":"{% tabs %} {% tab title=\"OSTN\" %} ho {% endtab %} {% tab title=\"STN\" %} # Log into devops machine devops.sh # Log into STN tmux tmux att -t STN profile_print cd /home/ec2-user/JL/experiment-deploy/pipeline ./node_ssh.sh 54.200.244.64 # {% endtab %} {% endtabs %}","title":"Faucet Machine Setup"},{"location":"deploy/cicd/netdeploy/faucet-deployment/#deployment-process","text":"# For a restart cd /Users/johnwhitton/projects/HRC/examples/node-faucet-no-contract # run a deployment script npm run clean-start","title":"Deployment Process"},{"location":"deploy/cicd/netdeploy/faucet-deployment/#overview-of-funding-process","text":"run the deploy script (included separately) in the examples/node-faucet directory of the up to date HRC repo OSTN: OSTN_deploy.sh PSTN: PSTN_deploy.sh LRTN: LRTN_deploy.sh run the output command in the respective faucet instance kill the current running faucet first ( tmux attach ) either reuse the same tmux instance or start a new one in the faucet directory: ~/HRC2/examples/node-faucet copy the last command from the output [OSTN | PSTN]_cmd_log.txt and run it in the tmux window detach the tmux window with <ctrl-b>, d fund the contract account OSTN: https://faucet.os.hmny.io/exposeAddress PSTN: https://faucet.ps.hmny.io/exposeAddress funding process can be automated by grabbing the hex faucet address from the deploy script and converting it to bech32. can check that the faucet is successfully deployed by checking that amount in shard 0 is the initial funded amount (currently 0.01 ONE)","title":"Overview of funding process:"},{"location":"deploy/cicd/netdeploy/faucet-deployment/#areas-for-improvement","text":"Funding increase amount of funds by 10x Timeouts - analyze whether we can send multiple transactions per block - nonce issue Deploy multiple(5) faucets with different end points and tree structure Modify process to remove smart contract and sign transactions directly (if this enables multi transactions per block) Enhance further to send from multiple accounts.","title":"Areas for Improvement"},{"location":"deploy/cicd/netdeploy/faucet-deployment/faucet-install-notes/","text":"Faucet Install Notes ENV setup AWS instance ubuntu 18.04 t3.small Open SSH for your ip/devop machine, http/https ports for anywhere keep track of PEM key SSH into your new instance bash $ chmod 400 <path-to-pem-key> $ ssh -i <path-to-pem-key> ubuntu@<your-host-name> 2. Install dependencies ```bash $ sudo apt update && sudo apt install g++ make nginx tmux -y ## AWS Linux notes 1 sudo yum update 2 sudo yum install g++ make nginx tmux -y 3 sudo yum install nginx1 4 sudo amazon-linux-extras install nginx1.12 5 sudo amazon-linux-extras install g++ 6 sudo yum install gcc-c++ ``` Setup node environment bash $ curl -o- https://raw.githubusercontent.com/creationix/nvm/v0.32.1/install.sh | bash $ source ~/.bashrc $ nvm install 13 Setup nginx bash $ sudo apt update && sudo apt install nginx -y $ sudo rm /etc/nginx/sites-enabled/default $ sudo echo \"server { listen 80; server_name faucet; location / { proxy_set_header X-Real-IP \\$remote_addr; proxy_set_header X-Forwarded-For \\$remote_addr; proxy_set_header Host \\$http_host; proxy_pass http://127.0.0.1:3000; } }\" | sudo tee /etc/nginx/sites-available/faucet $ sudo ln -s /etc/nginx/sites-available/faucet /etc/nginx/sites-enabled/faucet $ sudo service nginx restart Clone and initialize node-faucet directory bash $ git clone https://github.com/harmony-one/HRC.git $ cd HRC/examples/node-faucet-no-contract $ npm i open tmux bash $ tmux new -s faucet $ cd ~/HRC/examples/node-faucet-no-contract As of this point, the faucet environment is set up and ready to be deployed. Notes Domain name Ask Leo to set up a domain name with Route 53 for easier access You'll need to provide the host-name and the public IP of the faucet machine You can access this information from the AWS EC2 instance page (OPTIONAL) TLS for security You can follow this guide to setup https with certbot: https://certbot.eff.org/lets-encrypt/ubuntubionic-nginx","title":"Faucet Install Notes"},{"location":"deploy/cicd/netdeploy/faucet-deployment/faucet-install-notes/#faucet-install-notes","text":"","title":"Faucet Install Notes"},{"location":"deploy/cicd/netdeploy/faucet-deployment/faucet-install-notes/#env-setup","text":"AWS instance ubuntu 18.04 t3.small Open SSH for your ip/devop machine, http/https ports for anywhere keep track of PEM key SSH into your new instance bash $ chmod 400 <path-to-pem-key> $ ssh -i <path-to-pem-key> ubuntu@<your-host-name> 2. Install dependencies ```bash $ sudo apt update && sudo apt install g++ make nginx tmux -y ## AWS Linux notes 1 sudo yum update 2 sudo yum install g++ make nginx tmux -y 3 sudo yum install nginx1 4 sudo amazon-linux-extras install nginx1.12 5 sudo amazon-linux-extras install g++ 6 sudo yum install gcc-c++ ``` Setup node environment bash $ curl -o- https://raw.githubusercontent.com/creationix/nvm/v0.32.1/install.sh | bash $ source ~/.bashrc $ nvm install 13 Setup nginx bash $ sudo apt update && sudo apt install nginx -y $ sudo rm /etc/nginx/sites-enabled/default $ sudo echo \"server { listen 80; server_name faucet; location / { proxy_set_header X-Real-IP \\$remote_addr; proxy_set_header X-Forwarded-For \\$remote_addr; proxy_set_header Host \\$http_host; proxy_pass http://127.0.0.1:3000; } }\" | sudo tee /etc/nginx/sites-available/faucet $ sudo ln -s /etc/nginx/sites-available/faucet /etc/nginx/sites-enabled/faucet $ sudo service nginx restart Clone and initialize node-faucet directory bash $ git clone https://github.com/harmony-one/HRC.git $ cd HRC/examples/node-faucet-no-contract $ npm i open tmux bash $ tmux new -s faucet $ cd ~/HRC/examples/node-faucet-no-contract As of this point, the faucet environment is set up and ready to be deployed.","title":"ENV setup"},{"location":"deploy/cicd/netdeploy/faucet-deployment/faucet-install-notes/#notes","text":"Domain name Ask Leo to set up a domain name with Route 53 for easier access You'll need to provide the host-name and the public IP of the faucet machine You can access this information from the AWS EC2 instance page (OPTIONAL) TLS for security You can follow this guide to setup https with certbot: https://certbot.eff.org/lets-encrypt/ubuntubionic-nginx","title":"Notes"},{"location":"deploy/cicd/netdeploy/harmony-protocol-deployment/","text":"Harmony Protocol Deployment Build Process Overview This document describes the build process for a complete Harmony Network it includes the following key steps and components Preparation Deploys are done from devops machine and are highly dependent on WHOAMI and HMY_PROFILE environment variables Harmony Protocol Building Harmony Binary Deleting existing network REFRESH ONLY Deploying Binaries to Network SDK and CLI Build and deploy latest CLI Block Explorer Update Block Explorer Endpoints Watchdog Update Watch Explorer Endpoints Faucet Deploy Deploy Faucet Staking Explorer Deploy Staking Explorer Harmony Chrome Extension Updating to latest version of Harmony Chrome Extension Old documentation is here","title":"Harmony Protocol Deployment"},{"location":"deploy/cicd/netdeploy/harmony-protocol-deployment/#harmony-protocol-deployment","text":"","title":"Harmony Protocol Deployment"},{"location":"deploy/cicd/netdeploy/harmony-protocol-deployment/#build-process-overview","text":"This document describes the build process for a complete Harmony Network it includes the following key steps and components Preparation Deploys are done from devops machine and are highly dependent on WHOAMI and HMY_PROFILE environment variables Harmony Protocol Building Harmony Binary Deleting existing network REFRESH ONLY Deploying Binaries to Network SDK and CLI Build and deploy latest CLI Block Explorer Update Block Explorer Endpoints Watchdog Update Watch Explorer Endpoints Faucet Deploy Deploy Faucet Staking Explorer Deploy Staking Explorer Harmony Chrome Extension Updating to latest version of Harmony Chrome Extension Old documentation is here","title":"Build Process Overview"},{"location":"deploy/cicd/netdeploy/harmony-protocol-deployment/backups-and-snapshots-and-analysis/","text":"Backups and Snapshots and Analysis Overview This page list handy commands and mandatory data capture points before refreshing OSTN or restarting a shard. Backup Logs {% tabs %} {% tab title=\"OSTN\" %} cd experiment-deploy/pipeline/ ./go.sh -p os log # Wait for it to finish, then record the s3:// path {% endtab %} {% tab title=\"STN\" %} ./go.sh -p stn log # Wait for it to finish, then record the s3:// path {% endtab %} {% endtabs %} Capture Validator Information {% hint style=\"info\" %} From Janet In harmony-ops/devops/validator_stats I wrote a script to get validator stats for the network for the biz team you can run that instead of Stephens's shell scripting before restart to get stats if you want python3 validator_stats.py {% endhint %} {% tabs %} {% tab title=\"OSTN\" %} # Login to a validator (or anywhere you can run the cli) cd /Users/johnwhitton/projects/staking/OSTN ssh -i \"JOHN_OSTN_VALIDATOR_1.pem\" ec2-user@ec2-3-16-31-148.us-east-2.compute.amazonaws.com for x in `./hmy --node=https://api.s0.os.hmny.io blockchain validator all | grep one1 | tr -d '\",'`; do ./hmy --node=https://api.s0.os.hmny.io blockchain validator information $x | python -c 'import sys, json; print json.dumps(json.load(sys.stdin))'; done > info_ostn_20200403.json # Copy and paste the text into this gist # https://gist.github.com/john-harmony/3de1a5a264bc5f99dbc97347eca903a5 # Downloading to to a locak machine cd /Users/johnwhitton/projects/staking/OSTN scp -i ~/.ssh/keys/JOHN_OSTN_VALIDATOR_1.pem ec2-user@ec2-3-16-31-148.us-east-2.compute.amazonaws.com:/home/ec2-user/info_ostn_20200403.json . {% endtab %} {% tab title=\"STN\" %} # Login to a validator (or anywhere you can run the cli) cd /Users/johnwhitton/projects/staking/OSTN ssh -i \"JOHN_OSTN_VALIDATOR_1.pem\" ec2-user@ec2-3-16-31-148.us-east-2.compute.amazonaws.com for x in `./hmy --node=https://api.s0.stn.hmny.io blockchain validator all | grep one1 | tr -d '\",'`; do ./hmy --node=https://api.s0.stn.hmny.io blockchain validator information $x | python -c 'import sys, json; print json.dumps(json.load(sys.stdin))'; done > info_stn_20200403.json more info_date # Copy and paste the text into this gist # https://gist.github.com/john-harmony/3de1a5a264bc5f99dbc97347eca903a5 # Downloading to to a locak machine cd /Users/johnwhitton/projects/staking/OSTN scp -i ~/.ssh/keys/JOHN_OSTN_VALIDATOR_1.pem ec2-user@ec2-3-16-31-148.us-east-2.compute.amazonaws.com:/home/ec2-user/info_20200330.json . {% endtab %} {% endtabs %} Update Pager Duty to maintenance mode Go to service and select immediate maintenance mode Announce Build discord team-staking p-ops testnet-nodes telegram p-ops open staking volunteers Update Pager Duty Go to service and enable service Other Handy Gists CheckEarning.sh Realtime Economics Testing Validator and Watchdog utilities","title":"Backups and Snapshots and Analysis"},{"location":"deploy/cicd/netdeploy/harmony-protocol-deployment/backups-and-snapshots-and-analysis/#backups-and-snapshots-and-analysis","text":"","title":"Backups and Snapshots and Analysis"},{"location":"deploy/cicd/netdeploy/harmony-protocol-deployment/backups-and-snapshots-and-analysis/#overview","text":"This page list handy commands and mandatory data capture points before refreshing OSTN or restarting a shard.","title":"Overview"},{"location":"deploy/cicd/netdeploy/harmony-protocol-deployment/backups-and-snapshots-and-analysis/#backup-logs","text":"{% tabs %} {% tab title=\"OSTN\" %} cd experiment-deploy/pipeline/ ./go.sh -p os log # Wait for it to finish, then record the s3:// path {% endtab %} {% tab title=\"STN\" %} ./go.sh -p stn log # Wait for it to finish, then record the s3:// path {% endtab %} {% endtabs %}","title":"Backup Logs"},{"location":"deploy/cicd/netdeploy/harmony-protocol-deployment/backups-and-snapshots-and-analysis/#capture-validator-information","text":"{% hint style=\"info\" %} From Janet In harmony-ops/devops/validator_stats I wrote a script to get validator stats for the network for the biz team you can run that instead of Stephens's shell scripting before restart to get stats if you want python3 validator_stats.py {% endhint %} {% tabs %} {% tab title=\"OSTN\" %} # Login to a validator (or anywhere you can run the cli) cd /Users/johnwhitton/projects/staking/OSTN ssh -i \"JOHN_OSTN_VALIDATOR_1.pem\" ec2-user@ec2-3-16-31-148.us-east-2.compute.amazonaws.com for x in `./hmy --node=https://api.s0.os.hmny.io blockchain validator all | grep one1 | tr -d '\",'`; do ./hmy --node=https://api.s0.os.hmny.io blockchain validator information $x | python -c 'import sys, json; print json.dumps(json.load(sys.stdin))'; done > info_ostn_20200403.json # Copy and paste the text into this gist # https://gist.github.com/john-harmony/3de1a5a264bc5f99dbc97347eca903a5 # Downloading to to a locak machine cd /Users/johnwhitton/projects/staking/OSTN scp -i ~/.ssh/keys/JOHN_OSTN_VALIDATOR_1.pem ec2-user@ec2-3-16-31-148.us-east-2.compute.amazonaws.com:/home/ec2-user/info_ostn_20200403.json . {% endtab %} {% tab title=\"STN\" %} # Login to a validator (or anywhere you can run the cli) cd /Users/johnwhitton/projects/staking/OSTN ssh -i \"JOHN_OSTN_VALIDATOR_1.pem\" ec2-user@ec2-3-16-31-148.us-east-2.compute.amazonaws.com for x in `./hmy --node=https://api.s0.stn.hmny.io blockchain validator all | grep one1 | tr -d '\",'`; do ./hmy --node=https://api.s0.stn.hmny.io blockchain validator information $x | python -c 'import sys, json; print json.dumps(json.load(sys.stdin))'; done > info_stn_20200403.json more info_date # Copy and paste the text into this gist # https://gist.github.com/john-harmony/3de1a5a264bc5f99dbc97347eca903a5 # Downloading to to a locak machine cd /Users/johnwhitton/projects/staking/OSTN scp -i ~/.ssh/keys/JOHN_OSTN_VALIDATOR_1.pem ec2-user@ec2-3-16-31-148.us-east-2.compute.amazonaws.com:/home/ec2-user/info_20200330.json . {% endtab %} {% endtabs %}","title":"Capture Validator Information"},{"location":"deploy/cicd/netdeploy/harmony-protocol-deployment/backups-and-snapshots-and-analysis/#update-pager-duty-to-maintenance-mode","text":"Go to service and select immediate maintenance mode","title":"Update Pager Duty to maintenance mode"},{"location":"deploy/cicd/netdeploy/harmony-protocol-deployment/backups-and-snapshots-and-analysis/#announce-build","text":"discord team-staking p-ops testnet-nodes telegram p-ops open staking volunteers","title":"Announce Build"},{"location":"deploy/cicd/netdeploy/harmony-protocol-deployment/backups-and-snapshots-and-analysis/#update-pager-duty","text":"Go to service and enable service","title":"Update Pager Duty"},{"location":"deploy/cicd/netdeploy/harmony-protocol-deployment/backups-and-snapshots-and-analysis/#other-handy-gists","text":"CheckEarning.sh Realtime Economics Testing Validator and Watchdog utilities","title":"Other Handy Gists"},{"location":"deploy/cicd/netdeploy/harmony-protocol-deployment/release-validator-build/","text":"Release Validator Build {% hint style=\"info\" %} Note must build twice one for static_binary and one for normal release {% endhint %} Use Jenkins Harmony Release with the following Parameters {% tabs %} {% tab title=\"OSTN Static\" %} BRANCH - T3 BRANCH RELEASE - Check this box BUILD TYPE - RELEASE NETWORK - pangaea STATIC BINARY - Check this box {% endtab %} {% tab title=\"OSTN Normal\" %} BRANCH - T3 BRANCH RELEASE - Check this box BUILD TYPE - RELEASE NETWORK - pangaea STATIC BINARY - DO NOT Check this box {% endtab %} {% tab title=\"STN Static\" %} BRANCH - Master BRANCH RELEASE - Check this box BUILD TYPE - RELEASE NETWORK - stressnet STATIC BINARY - Check this box {% endtab %} {% tab title=\"STN Normal\" %} BRANCH - Master BRANCH RELEASE - Check this box BUILD TYPE - RELEASE NETWORK - stressnet STATIC BINARY - DO NOT Check this box {% endtab %} {% endtabs %} {% hint style=\"info\" %} If we have to build manually review this ticket for the script as a starting point. Also read the AWS CLI S3 instructions and go_executable_build.sh {% endhint %} Manual Validator Release {% tabs %} {% tab title=\"OSTN\" %} export WHOAMI=OS; export HMY_PROFILE=os; profile_print aws s3 ls s3:// aws s3 ls s3://pub.harmony.one/ {% endtab %} {% endtabs %}","title":"Release Validator Build"},{"location":"deploy/cicd/netdeploy/harmony-protocol-deployment/release-validator-build/#release-validator-build","text":"{% hint style=\"info\" %} Note must build twice one for static_binary and one for normal release {% endhint %} Use Jenkins Harmony Release with the following Parameters {% tabs %} {% tab title=\"OSTN Static\" %} BRANCH - T3 BRANCH RELEASE - Check this box BUILD TYPE - RELEASE NETWORK - pangaea STATIC BINARY - Check this box {% endtab %} {% tab title=\"OSTN Normal\" %} BRANCH - T3 BRANCH RELEASE - Check this box BUILD TYPE - RELEASE NETWORK - pangaea STATIC BINARY - DO NOT Check this box {% endtab %} {% tab title=\"STN Static\" %} BRANCH - Master BRANCH RELEASE - Check this box BUILD TYPE - RELEASE NETWORK - stressnet STATIC BINARY - Check this box {% endtab %} {% tab title=\"STN Normal\" %} BRANCH - Master BRANCH RELEASE - Check this box BUILD TYPE - RELEASE NETWORK - stressnet STATIC BINARY - DO NOT Check this box {% endtab %} {% endtabs %} {% hint style=\"info\" %} If we have to build manually review this ticket for the script as a starting point. Also read the AWS CLI S3 instructions and go_executable_build.sh {% endhint %}","title":"Release Validator Build"},{"location":"deploy/cicd/netdeploy/harmony-protocol-deployment/release-validator-build/#manual-validator-release","text":"{% tabs %} {% tab title=\"OSTN\" %} export WHOAMI=OS; export HMY_PROFILE=os; profile_print aws s3 ls s3:// aws s3 ls s3://pub.harmony.one/ {% endtab %} {% endtabs %}","title":"Manual Validator Release"},{"location":"deploy/cicd/netdeploy/harmony-protocol-deployment/validate-build/","text":"Validate Build Checks for consensus {% tabs %} {% tab title=\"OSTN\" %} ./run_on_shard.sh -p os -T 0 'tac ../tmp_log/*/zerolog*.log | grep -m 1 HOORAY' ./run_on_shard.sh -p os -T 1 'tac ../tmp_log/*/zerolog*.log | grep -m 1 HOORAY' ./run_on_shard.sh -p os -T 2 'tac ../tmp_log/*/zerolog*.log | grep -m 1 HOORAY' ./run_on_shard.sh -p os -T 3 'tac ../tmp_log/*/zerolog*.log | grep -m 1 HOORAY' {% endtab %} {% tab title=\"STN\" %} ./run_on_shard.sh -p stn -y -T 0 'tac ../tmp_log/*/zerolog*.log | grep -m 1 HOORAY' ./run_on_shard.sh -p stn -y -T 1 'tac ../tmp_log/*/zerolog*.log | grep -m 1 HOORAY' {% endtab %} {% endtabs %} {% hint style=\"info\" %} If consensus fails you can restart a shard using the following command cat logs/os/shard0.txt | xargs -i{} -P50 bash -c './restart_node.sh -y -d logs/os -p os -t 0 -r 0 -R 0 {}' {% endhint %}","title":"Validate Build"},{"location":"deploy/cicd/netdeploy/harmony-protocol-deployment/validate-build/#validate-build","text":"","title":"Validate Build"},{"location":"deploy/cicd/netdeploy/harmony-protocol-deployment/validate-build/#checks-for-consensus","text":"{% tabs %} {% tab title=\"OSTN\" %} ./run_on_shard.sh -p os -T 0 'tac ../tmp_log/*/zerolog*.log | grep -m 1 HOORAY' ./run_on_shard.sh -p os -T 1 'tac ../tmp_log/*/zerolog*.log | grep -m 1 HOORAY' ./run_on_shard.sh -p os -T 2 'tac ../tmp_log/*/zerolog*.log | grep -m 1 HOORAY' ./run_on_shard.sh -p os -T 3 'tac ../tmp_log/*/zerolog*.log | grep -m 1 HOORAY' {% endtab %} {% tab title=\"STN\" %} ./run_on_shard.sh -p stn -y -T 0 'tac ../tmp_log/*/zerolog*.log | grep -m 1 HOORAY' ./run_on_shard.sh -p stn -y -T 1 'tac ../tmp_log/*/zerolog*.log | grep -m 1 HOORAY' {% endtab %} {% endtabs %} {% hint style=\"info\" %} If consensus fails you can restart a shard using the following command cat logs/os/shard0.txt | xargs -i{} -P50 bash -c './restart_node.sh -y -d logs/os -p os -t 0 -r 0 -R 0 {}' {% endhint %}","title":"Checks for consensus"},{"location":"deploy/cicd/netdeploy/harmony-protocol-deployment/build/","text":"Build Updating T3 Branch {% hint style=\"info\" %} Note if ever a force push is done then all downstream repos can no longer just do a pull they instead need to git remote -v git fetch origin git log --pretty=oneline git branch -a git reset --hard origin/t3 git log --pretty=oneline {% endhint %} Build Preparation We will connect to the devops machine, set our profile and check which branch we are on Connect to devops machine exec ssh -i ~/.ssh/keys/oregon-key-benchmark.pem ec2-user@devop.hmny.io # or exec ssh -i ~/.ssh/keys/oregon-key-benchmark.pem ec2-user@35.160.64.190 # or exec ssh -i ~/.ssh/id_rsa jw@devop.hmny.io Connect to tmux session {% tabs %} {% tab title=\"OSTN\" %} tmux ls tmux attach-session -t os {% endtab %} {% tab title=\"STN\" %} tmux ls tmux attach-session -t STN {% endtab %} {% endtabs %} Set Harmony Profile {% tabs %} {% tab title=\"OSTN\" %} export WHOAMI=OS; export HMY_PROFILE=os; profile_print {% endtab %} {% tab title=\"STN\" %} export WHOAMI=STN; export HMY_PROFILE=stn; profile_print {% endtab %} {% endtabs %} Merge the latest changes from Master to t3 {% hint style=\"info\" %} This is optional if you are building of t3 branch, see here for details. {% endhint %} Harmony Build We will pull the latest code, build and deploy latest binaries Ensure our profile is set correctly profile_print Build our binary - ensure you use the correct branch (master for OSTN currently) {% tabs %} {% tab title=\"OSTN\" %} cd $(go env GOPATH)/src/github.com/harmony-one/harmony # This goes somewhere like here # /home/ec2-user/go/src/github.com/harmony-one/harmony git status git checkout t3 git pull ## If there has been a forced update you also need to git remote -v git fetch origin git log --pretty=oneline git branch -a git reset --hard origin/t3 ## Check the version aligins with what you want to build git log --pretty=oneline ## Tag the release (only used when building from master) git tag -a v1.0-20200316.0 git push origin v1.0-20200316.0 # Build and upload Static Binary # Should only need to do this once make linux_static # Check whether the build is static or not file bin/harmony ldd bin/harmony ./scripts/go_executable_build.sh -s file bin/harmony ./scripts/go_executable_build.sh -s upload # Build and upload Dynamic Binary ./scripts/go_executable_build.sh file bin/harmony ldd bin/harmony ./scripts/go_executable_build.sh upload {% endtab %} {% tab title=\"STN\" %} cd ~/JL/harmony git status git clean -fdx git checkout master git pull ## If there has been a forced update you also need to git remote -v git fetch origin git log --pretty=oneline git branch -a git reset --hard origin/t3 ## Check the version aligins with what you want to build git log --pretty=oneline ## Tag the release (only used when building from master) git tag -a v1.0-20200316.0 git push origin v1.0-20200316.0 # Build and upload Static Binary # Should only need to do this once make linux_static # Check whether the build is static or not file bin/harmony ldd bin/harmony ./scripts/go_executable_build.sh -s file bin/harmony ./scripts/go_executable_build.sh -s upload # Build and upload Dynamic Binary ./scripts/go_executable_build.sh file bin/harmony ldd bin/harmony ./scripts/go_executable_build.sh upload {% endtab %} {% endtabs %} Update Experiment-deploy ready for upgrade process {% tabs %} {% tab title=\"OSTN\" %} cd ~/experiment-deploy/ git status git pull git log --pretty=oneline cd ~/experiment-deploy/pipeline/ git diff {% endtab %} {% tab title=\"STN\" %} cd ~/JL/experiment-deploy/ git status git pull git log --pretty=oneline cd ~/JL/experiment-deploy/pipeline/ git diff {% endtab %} {% endtabs %}","title":"Build"},{"location":"deploy/cicd/netdeploy/harmony-protocol-deployment/build/#build","text":"","title":"Build"},{"location":"deploy/cicd/netdeploy/harmony-protocol-deployment/build/#updating-t3-branch","text":"{% hint style=\"info\" %} Note if ever a force push is done then all downstream repos can no longer just do a pull they instead need to git remote -v git fetch origin git log --pretty=oneline git branch -a git reset --hard origin/t3 git log --pretty=oneline {% endhint %}","title":"Updating T3 Branch"},{"location":"deploy/cicd/netdeploy/harmony-protocol-deployment/build/#build_1","text":"","title":"Build"},{"location":"deploy/cicd/netdeploy/harmony-protocol-deployment/build/#preparation","text":"We will connect to the devops machine, set our profile and check which branch we are on Connect to devops machine exec ssh -i ~/.ssh/keys/oregon-key-benchmark.pem ec2-user@devop.hmny.io # or exec ssh -i ~/.ssh/keys/oregon-key-benchmark.pem ec2-user@35.160.64.190 # or exec ssh -i ~/.ssh/id_rsa jw@devop.hmny.io Connect to tmux session {% tabs %} {% tab title=\"OSTN\" %} tmux ls tmux attach-session -t os {% endtab %} {% tab title=\"STN\" %} tmux ls tmux attach-session -t STN {% endtab %} {% endtabs %} Set Harmony Profile {% tabs %} {% tab title=\"OSTN\" %} export WHOAMI=OS; export HMY_PROFILE=os; profile_print {% endtab %} {% tab title=\"STN\" %} export WHOAMI=STN; export HMY_PROFILE=stn; profile_print {% endtab %} {% endtabs %}","title":"Preparation"},{"location":"deploy/cicd/netdeploy/harmony-protocol-deployment/build/#merge-the-latest-changes-from-master-to-t3","text":"{% hint style=\"info\" %} This is optional if you are building of t3 branch, see here for details. {% endhint %}","title":"Merge the latest changes from Master to t3"},{"location":"deploy/cicd/netdeploy/harmony-protocol-deployment/build/#_1","text":"","title":""},{"location":"deploy/cicd/netdeploy/harmony-protocol-deployment/build/#harmony-build","text":"We will pull the latest code, build and deploy latest binaries Ensure our profile is set correctly profile_print Build our binary - ensure you use the correct branch (master for OSTN currently) {% tabs %} {% tab title=\"OSTN\" %} cd $(go env GOPATH)/src/github.com/harmony-one/harmony # This goes somewhere like here # /home/ec2-user/go/src/github.com/harmony-one/harmony git status git checkout t3 git pull ## If there has been a forced update you also need to git remote -v git fetch origin git log --pretty=oneline git branch -a git reset --hard origin/t3 ## Check the version aligins with what you want to build git log --pretty=oneline ## Tag the release (only used when building from master) git tag -a v1.0-20200316.0 git push origin v1.0-20200316.0 # Build and upload Static Binary # Should only need to do this once make linux_static # Check whether the build is static or not file bin/harmony ldd bin/harmony ./scripts/go_executable_build.sh -s file bin/harmony ./scripts/go_executable_build.sh -s upload # Build and upload Dynamic Binary ./scripts/go_executable_build.sh file bin/harmony ldd bin/harmony ./scripts/go_executable_build.sh upload {% endtab %} {% tab title=\"STN\" %} cd ~/JL/harmony git status git clean -fdx git checkout master git pull ## If there has been a forced update you also need to git remote -v git fetch origin git log --pretty=oneline git branch -a git reset --hard origin/t3 ## Check the version aligins with what you want to build git log --pretty=oneline ## Tag the release (only used when building from master) git tag -a v1.0-20200316.0 git push origin v1.0-20200316.0 # Build and upload Static Binary # Should only need to do this once make linux_static # Check whether the build is static or not file bin/harmony ldd bin/harmony ./scripts/go_executable_build.sh -s file bin/harmony ./scripts/go_executable_build.sh -s upload # Build and upload Dynamic Binary ./scripts/go_executable_build.sh file bin/harmony ldd bin/harmony ./scripts/go_executable_build.sh upload {% endtab %} {% endtabs %}","title":"Harmony Build"},{"location":"deploy/cicd/netdeploy/harmony-protocol-deployment/build/#update-experiment-deploy-ready-for-upgrade-process","text":"{% tabs %} {% tab title=\"OSTN\" %} cd ~/experiment-deploy/ git status git pull git log --pretty=oneline cd ~/experiment-deploy/pipeline/ git diff {% endtab %} {% tab title=\"STN\" %} cd ~/JL/experiment-deploy/ git status git pull git log --pretty=oneline cd ~/JL/experiment-deploy/pipeline/ git diff {% endtab %} {% endtabs %}","title":"Update Experiment-deploy ready for upgrade process"},{"location":"deploy/cicd/netdeploy/harmony-protocol-deployment/build/funding-acounts/","text":"Funding acounts From the pipeline directory run funds.sh {% tabs %} {% tab title=\"OSTN\" %} cd /home/ec2-user/experiment-deploy/pipeline chmod a+x fund.sh ./fund.sh # Or to force funding ./fund.sh -c -f {% endtab %} {% tab title=\"STN\" %} cd /home/ec2-user/JL/experiment-deploy/pipeline chmod a+x fund.sh ./fund.sh # Or to force funding ./fund.sh -c -f {% endtab %} {% endtabs %}","title":"Funding acounts"},{"location":"deploy/cicd/netdeploy/harmony-protocol-deployment/build/funding-acounts/#funding-acounts","text":"From the pipeline directory run funds.sh {% tabs %} {% tab title=\"OSTN\" %} cd /home/ec2-user/experiment-deploy/pipeline chmod a+x fund.sh ./fund.sh # Or to force funding ./fund.sh -c -f {% endtab %} {% tab title=\"STN\" %} cd /home/ec2-user/JL/experiment-deploy/pipeline chmod a+x fund.sh ./fund.sh # Or to force funding ./fund.sh -c -f {% endtab %} {% endtabs %}","title":"Funding acounts"},{"location":"deploy/cicd/netdeploy/harmony-protocol-deployment/build/hard-refresh/","text":"Hard Refresh Remove existing network - REFRESH ONLY {% hint style=\"info\" %} Place PAGER DUTY IN MAINTENANCE MODE {% endhint %} Check your profile {% tabs %} {% tab title=\"OSTN\" %} profile_print export WHOAMI=OS; export HMY_PROFILE=os; profile_print {% endtab %} {% tab title=\"STN\" %} export WHOAMI=STN; export HMY_PROFILE=stn; profile_print cd ~/JL/experiment-deploy/pipeline {% endtab %} {% endtabs %} Remove existing network {% tabs %} {% tab title=\"OSTN\" %} ./run_on_shard.sh -p os -T 0 'sudo killall -9 harmony; sudo rm -rf harmony_db_*; sudo rm -rf .dht*; sudo rm harmony.err; sudo rm -rf ../tmp_log/*/*' ./run_on_shard.sh -p os -T 1 'sudo killall -9 harmony; sudo rm -rf harmony_db_*; sudo rm -rf .dht*; sudo rm harmony.err; sudo rm -rf ../tmp_log/*/*' ./run_on_shard.sh -p os -T 2 'sudo killall -9 harmony; sudo rm -rf harmony_db_*; sudo rm -rf .dht*; sudo rm harmony.err; sudo rm -rf ../tmp_log/*/*' ./run_on_shard.sh -p os -T 3 'sudo killall -9 harmony; sudo rm -rf harmony_db_*; sudo rm -rf .dht*; sudo rm harmony.err; sudo rm -rf ../tmp_log/*/*' {% endtab %} {% tab title=\"STN\" %} ./run_on_shard.sh -p stn -T 0 'sudo killall -9 harmony; sudo rm -rf harmony_db_*; sudo rm -rf .dht*; sudo rm harmony.err; sudo rm -rf ../tmp_log/*/*' ./run_on_shard.sh -p stn -T 1 'sudo killall -9 harmony; sudo rm -rf harmony_db_*; sudo rm -rf .dht*; sudo rm harmony.err; sudo rm -rf ../tmp_log/*/*' {% endtab %} {% endtabs %} Reset bootnodes {% tabs %} {% tab title=\"OSTN\" %} ./go.sh -p os bootnode {% endtab %} {% tab title=\"STN\" %} ./go.sh -p stn bootnode {% endtab %} {% endtabs %} Upgrade nodes {% tabs %} {% tab title=\"OSTN\" %} cat logs/os/shard0.txt | xargs -i{} -P50 bash -c './restart_node.sh -U -y -d logs/os -p os -t 0 -r 0 -R 0 {}' cat logs/os/shard1.txt | xargs -i{} -P50 bash -c './restart_node.sh -U -y -d logs/os -p os -t 0 -r 0 -R 0 {}' cat logs/os/shard2.txt | xargs -i{} -P50 bash -c './restart_node.sh -U -y -d logs/os -p os -t 0 -r 0 -R 0 {}' cat logs/os/shard3.txt | xargs -i{} -P50 bash -c './restart_node.sh -U -y -d logs/os -p os -t 0 -r 0 -R 0 {}' {% endtab %} {% tab title=\"STN\" %} cat logs/stn/shard0.txt | xargs -i{} -P50 bash -c './restart_node.sh -U -y -d logs/stn -p stn -t 0 -r 0 -R 0 {}' cat logs/stn/shard1.txt | xargs -i{} -P50 bash -c './restart_node.sh -U -y -d logs/stn -p stn -t 1 -r 0 -R 0 {}' {% endtab %} {% endtabs %} {% hint style=\"info\" %} Turn PagerDuty on again {% endhint %}","title":"Hard Refresh"},{"location":"deploy/cicd/netdeploy/harmony-protocol-deployment/build/hard-refresh/#hard-refresh","text":"","title":"Hard Refresh"},{"location":"deploy/cicd/netdeploy/harmony-protocol-deployment/build/hard-refresh/#remove-existing-network-refresh-only","text":"{% hint style=\"info\" %} Place PAGER DUTY IN MAINTENANCE MODE {% endhint %} Check your profile {% tabs %} {% tab title=\"OSTN\" %} profile_print export WHOAMI=OS; export HMY_PROFILE=os; profile_print {% endtab %} {% tab title=\"STN\" %} export WHOAMI=STN; export HMY_PROFILE=stn; profile_print cd ~/JL/experiment-deploy/pipeline {% endtab %} {% endtabs %} Remove existing network {% tabs %} {% tab title=\"OSTN\" %} ./run_on_shard.sh -p os -T 0 'sudo killall -9 harmony; sudo rm -rf harmony_db_*; sudo rm -rf .dht*; sudo rm harmony.err; sudo rm -rf ../tmp_log/*/*' ./run_on_shard.sh -p os -T 1 'sudo killall -9 harmony; sudo rm -rf harmony_db_*; sudo rm -rf .dht*; sudo rm harmony.err; sudo rm -rf ../tmp_log/*/*' ./run_on_shard.sh -p os -T 2 'sudo killall -9 harmony; sudo rm -rf harmony_db_*; sudo rm -rf .dht*; sudo rm harmony.err; sudo rm -rf ../tmp_log/*/*' ./run_on_shard.sh -p os -T 3 'sudo killall -9 harmony; sudo rm -rf harmony_db_*; sudo rm -rf .dht*; sudo rm harmony.err; sudo rm -rf ../tmp_log/*/*' {% endtab %} {% tab title=\"STN\" %} ./run_on_shard.sh -p stn -T 0 'sudo killall -9 harmony; sudo rm -rf harmony_db_*; sudo rm -rf .dht*; sudo rm harmony.err; sudo rm -rf ../tmp_log/*/*' ./run_on_shard.sh -p stn -T 1 'sudo killall -9 harmony; sudo rm -rf harmony_db_*; sudo rm -rf .dht*; sudo rm harmony.err; sudo rm -rf ../tmp_log/*/*' {% endtab %} {% endtabs %}","title":"Remove existing network - REFRESH ONLY"},{"location":"deploy/cicd/netdeploy/harmony-protocol-deployment/build/hard-refresh/#reset-bootnodes","text":"{% tabs %} {% tab title=\"OSTN\" %} ./go.sh -p os bootnode {% endtab %} {% tab title=\"STN\" %} ./go.sh -p stn bootnode {% endtab %} {% endtabs %}","title":"Reset bootnodes"},{"location":"deploy/cicd/netdeploy/harmony-protocol-deployment/build/hard-refresh/#upgrade-nodes","text":"{% tabs %} {% tab title=\"OSTN\" %} cat logs/os/shard0.txt | xargs -i{} -P50 bash -c './restart_node.sh -U -y -d logs/os -p os -t 0 -r 0 -R 0 {}' cat logs/os/shard1.txt | xargs -i{} -P50 bash -c './restart_node.sh -U -y -d logs/os -p os -t 0 -r 0 -R 0 {}' cat logs/os/shard2.txt | xargs -i{} -P50 bash -c './restart_node.sh -U -y -d logs/os -p os -t 0 -r 0 -R 0 {}' cat logs/os/shard3.txt | xargs -i{} -P50 bash -c './restart_node.sh -U -y -d logs/os -p os -t 0 -r 0 -R 0 {}' {% endtab %} {% tab title=\"STN\" %} cat logs/stn/shard0.txt | xargs -i{} -P50 bash -c './restart_node.sh -U -y -d logs/stn -p stn -t 0 -r 0 -R 0 {}' cat logs/stn/shard1.txt | xargs -i{} -P50 bash -c './restart_node.sh -U -y -d logs/stn -p stn -t 1 -r 0 -R 0 {}' {% endtab %} {% endtabs %} {% hint style=\"info\" %} Turn PagerDuty on again {% endhint %}","title":"Upgrade nodes"},{"location":"deploy/cicd/netdeploy/harmony-protocol-deployment/build/network-upgrade/","text":"Network Upgrade Changing the network configuration We need to update https://github.com/harmony-one/experiment-deploy/blob/master/configs/benchmark-os.json and https://github.com/harmony-one/experiment-deploy/blob/master/configs/launch-os.json {% hint style=\"info\" %} Place Pager Duty in maintenance mode {% endhint %} Set Harmony Profile {% tabs %} {% tab title=\"OSTN\" %} export WHOAMI=OS; export HMY_PROFILE=os; profile_print {% endtab %} {% tab title=\"STN\" %} export WHOAMI=STN; export HMY_PROFILE=stn; profile_print cd ~/JL/experiment-deploy/ {% endtab %} {% endtabs %} Removing Existing Network - For Fresh Network - ONLY {% tabs %} {% tab title=\"OSTN\" %} cd ~/experiment-deploy/pipeline/ # Scan through all nodes with OS profile tag ./aws-instances.sh -g OS # Terminates all the nodes created in the list ./go.sh -p os deinit {% endtab %} {% tab title=\"STN\" %} cd ~/JL/experiment-deploy/pipeline/ # Scan through all nodes with STN profile tag ./aws-instances.sh -g STN # Terminates all the nodes created in the list ./go.sh -p stn deinit {% endtab %} {% endtabs %} Launch New Network For Fresh Network - ONLY {% tabs %} {% tab title=\"OSTN\" %} # Launches new instances ./go.sh -p os -k # Create the bls key list ./run_on_shard.sh -p os -y -T 0 'ip=$(curl http://169.254.169.254/latest/meta-data/public-ipv4); for k in $(ls ./.hmy/blskeys/); do echo $k, $ip; done' > ostn-s0-actual.txt ./run_on_shard.sh -p os -y -T 1 'ip=$(curl http://169.254.169.254/latest/meta-data/public-ipv4); for k in $(ls ./.hmy/blskeys/); do echo $k, $ip; done' > ostn-s1-actual.txt ./run_on_shard.sh -p os -y -T 2 'ip=$(curl http://169.254.169.254/latest/meta-data/public-ipv4); for k in $(ls ./.hmy/blskeys/); do echo $k, $ip; done' > ostn-s2-actual.txt ./run_on_shard.sh -p os -y -T 3 'ip=$(curl http://169.254.169.254/latest/meta-data/public-ipv4); for k in $(ls ./.hmy/blskeys/); do echo $k, $ip; done' > ostn-s3-actual.txt cat ostn*actual* ## To get the date time stamp for the log directory on the devops machine more /home/ec2-user/experiment-deploy/pipeline/logs/os/profile-os.json { \"bucket\": \"unique-bucket-bin\", \"folder\": \"OS\", \"sessionID\": \"20200326.180455\" } ## Manually create the temp logs with sessionID from above - NOT NEEDED USUALLY ## ls -ltr logs/os/ ## cd logs/os/ ## cd .. ## ./run_on_shard.sh -p os -T 0 'sudo mkdir -p ../tmp_log/log-20200318.173735;' ## ./run_on_shard.sh -p os -T 1 'sudo mkdir -p ../tmp_log/log-20200318.173735;' ## ./run_on_shard.sh -p os -T 2 'sudo mkdir -p ../tmp_log/log-20200318.173735;' ## ./run_on_shard.sh -p os -T 3 'sudo mkdir -p ../tmp_log/log-20200318.173735;' # Restart all the shards - NOT NEEDED USUALLY cat logs/os/shard0.txt | xargs -i{} -P50 bash -c './restart_node.sh -y -d logs/os -p os -t 0 -r 0 -R 0 {}' cat logs/os/shard1.txt | xargs -i{} -P50 bash -c './restart_node.sh -y -d logs/os -p os -t 0 -r 0 -R 0 {}' cat logs/os/shard2.txt | xargs -i{} -P50 bash -c './restart_node.sh -y -d logs/os -p os -t 0 -r 0 -R 0 {}' cat logs/os/shard3.txt | xargs -i{} -P50 bash -c './restart_node.sh -y -d logs/os -p os -t 0 -r 0 -R 0 {}' {% endtab %} {% tab title=\"STN\" %} # Launches new instances ./go.sh -p stn -k # Create the bls key list ./run_on_shard.sh -p stn -y -T 0 'ip=$(curl http://169.254.169.254/latest/meta-data/public-ipv4); for k in $(ls ./.hmy/blskeys/); do echo $k, $ip; done' > stn-s0-actual.txt ./run_on_shard.sh -p stn -y -T 1 'ip=$(curl http://169.254.169.254/latest/meta-data/public-ipv4); for k in $(ls ./.hmy/blskeys/); do echo $k, $ip; done' > stn-s1-actual.txt cat stn*actual* python3 bls.py ref ## To get the date time stamp for the log directory on the devops machine more /home/ec2-user/experiment-deploy/pipeline/logs/os/profile-os.json { \"bucket\": \"unique-bucket-bin\", \"folder\": \"OS\", \"sessionID\": \"20200326.180455\" } ## Manually create the temp logs with sessionID from above - NOT NEEDED USUALLY ## ls -ltr logs/os/ ## cd logs/os/ ## cd .. ## ./run_on_shard.sh -p os -T 0 'sudo mkdir -p ../tmp_log/log-20200318.173735;' ## ./run_on_shard.sh -p os -T 1 'sudo mkdir -p ../tmp_log/log-20200318.173735;' ## ./run_on_shard.sh -p os -T 2 'sudo mkdir -p ../tmp_log/log-20200318.173735;' ## ./run_on_shard.sh -p os -T 3 'sudo mkdir -p ../tmp_log/log-20200318.173735;' # Restart all the shards - NOT NEEDED USUALLY cat logs/stn/shard0.txt | xargs -i{} -P50 bash -c './restart_node.sh -y -d -c logs/stn -p stn -t 0 -r 0 -R 0 {}' cat logs/stn/shard1.txt | xargs -i{} -P50 bash -c './restart_node.sh -y -d -c logs/stn -p stn -t 0 -r 0 -R 0 {}' {% endtab %} {% endtabs %} Share the new network IP addresses with watchdog See here Update DNS Entries See here {% hint style=\"info\" %} Turn Pager duty on again {% endhint %} scp /home/ec2-user/experiment-deploy/pipeline/logs/os/shard?.txt watchdog:/home/ec2-user/staking ssh watchdog -- sudo systemctl restart harmony-watchdogd@staking.service Update the explorer information see this pull request { \"domain_name\": \"os.hmny.io\", \"num_of_shards\": 4, \"explorers_0\" : [\"54.184.36.85\"], \"explorers_1\" : [\"54.183.185.205\"], \"explorers_2\" : [\"18.189.185.176\"], \"explorers_3\" : [\"34.230.46.2\"], \"hosted_zone_id\" : \"Z1UEV9ND4IWBVM\", \"subnet_us-east-1\": [\"subnet-14da445e\", \"subnet-2c957212\", \"subnet-2f00cb73\", \"subnet-7b65f774\", \"subnet-7da3751a\", \"subnet-7e5c8950\"], \"subnet_us-east-2\": [\"subnet-45031908\", \"subnet-b38df5db\", \"subnet-c071c0ba\"], \"subnet_us-west-1\": [\"subnet-551f560e\", \"subnet-5be2df3c\"], \"subnet_us-west-2\": [\"subnet-1953d052\", \"subnet-6a6c1230\", \"subnet-c33554ba\", \"subnet-d73bdcfc\"], \"sg_us-east-1\": [\"sg-0a9f239987978e0eb\"], \"sg_us-east-2\": [\"sg-05c8f480d9a17574c\"], \"sg_us-west-1\": [\"sg-0fc2b150b51b313ec\"], \"sg_us-west-2\": [\"sg-03de0eb6b8f247581\"] } Notes hosted_zone_id -> comes from aws route53 -> hosted zones subnet -> comes from vpc -> subnets in aws sg are the security groups","title":"Network Upgrade"},{"location":"deploy/cicd/netdeploy/harmony-protocol-deployment/build/network-upgrade/#network-upgrade","text":"","title":"Network Upgrade"},{"location":"deploy/cicd/netdeploy/harmony-protocol-deployment/build/network-upgrade/#changing-the-network-configuration","text":"We need to update https://github.com/harmony-one/experiment-deploy/blob/master/configs/benchmark-os.json and https://github.com/harmony-one/experiment-deploy/blob/master/configs/launch-os.json {% hint style=\"info\" %} Place Pager Duty in maintenance mode {% endhint %} Set Harmony Profile {% tabs %} {% tab title=\"OSTN\" %} export WHOAMI=OS; export HMY_PROFILE=os; profile_print {% endtab %} {% tab title=\"STN\" %} export WHOAMI=STN; export HMY_PROFILE=stn; profile_print cd ~/JL/experiment-deploy/ {% endtab %} {% endtabs %}","title":"Changing the network configuration"},{"location":"deploy/cicd/netdeploy/harmony-protocol-deployment/build/network-upgrade/#_1","text":"","title":""},{"location":"deploy/cicd/netdeploy/harmony-protocol-deployment/build/network-upgrade/#removing-existing-network-for-fresh-network-only","text":"{% tabs %} {% tab title=\"OSTN\" %} cd ~/experiment-deploy/pipeline/ # Scan through all nodes with OS profile tag ./aws-instances.sh -g OS # Terminates all the nodes created in the list ./go.sh -p os deinit {% endtab %} {% tab title=\"STN\" %} cd ~/JL/experiment-deploy/pipeline/ # Scan through all nodes with STN profile tag ./aws-instances.sh -g STN # Terminates all the nodes created in the list ./go.sh -p stn deinit {% endtab %} {% endtabs %}","title":"Removing Existing Network - For Fresh Network - ONLY"},{"location":"deploy/cicd/netdeploy/harmony-protocol-deployment/build/network-upgrade/#launch-new-network-for-fresh-network-only","text":"{% tabs %} {% tab title=\"OSTN\" %} # Launches new instances ./go.sh -p os -k # Create the bls key list ./run_on_shard.sh -p os -y -T 0 'ip=$(curl http://169.254.169.254/latest/meta-data/public-ipv4); for k in $(ls ./.hmy/blskeys/); do echo $k, $ip; done' > ostn-s0-actual.txt ./run_on_shard.sh -p os -y -T 1 'ip=$(curl http://169.254.169.254/latest/meta-data/public-ipv4); for k in $(ls ./.hmy/blskeys/); do echo $k, $ip; done' > ostn-s1-actual.txt ./run_on_shard.sh -p os -y -T 2 'ip=$(curl http://169.254.169.254/latest/meta-data/public-ipv4); for k in $(ls ./.hmy/blskeys/); do echo $k, $ip; done' > ostn-s2-actual.txt ./run_on_shard.sh -p os -y -T 3 'ip=$(curl http://169.254.169.254/latest/meta-data/public-ipv4); for k in $(ls ./.hmy/blskeys/); do echo $k, $ip; done' > ostn-s3-actual.txt cat ostn*actual* ## To get the date time stamp for the log directory on the devops machine more /home/ec2-user/experiment-deploy/pipeline/logs/os/profile-os.json { \"bucket\": \"unique-bucket-bin\", \"folder\": \"OS\", \"sessionID\": \"20200326.180455\" } ## Manually create the temp logs with sessionID from above - NOT NEEDED USUALLY ## ls -ltr logs/os/ ## cd logs/os/ ## cd .. ## ./run_on_shard.sh -p os -T 0 'sudo mkdir -p ../tmp_log/log-20200318.173735;' ## ./run_on_shard.sh -p os -T 1 'sudo mkdir -p ../tmp_log/log-20200318.173735;' ## ./run_on_shard.sh -p os -T 2 'sudo mkdir -p ../tmp_log/log-20200318.173735;' ## ./run_on_shard.sh -p os -T 3 'sudo mkdir -p ../tmp_log/log-20200318.173735;' # Restart all the shards - NOT NEEDED USUALLY cat logs/os/shard0.txt | xargs -i{} -P50 bash -c './restart_node.sh -y -d logs/os -p os -t 0 -r 0 -R 0 {}' cat logs/os/shard1.txt | xargs -i{} -P50 bash -c './restart_node.sh -y -d logs/os -p os -t 0 -r 0 -R 0 {}' cat logs/os/shard2.txt | xargs -i{} -P50 bash -c './restart_node.sh -y -d logs/os -p os -t 0 -r 0 -R 0 {}' cat logs/os/shard3.txt | xargs -i{} -P50 bash -c './restart_node.sh -y -d logs/os -p os -t 0 -r 0 -R 0 {}' {% endtab %} {% tab title=\"STN\" %} # Launches new instances ./go.sh -p stn -k # Create the bls key list ./run_on_shard.sh -p stn -y -T 0 'ip=$(curl http://169.254.169.254/latest/meta-data/public-ipv4); for k in $(ls ./.hmy/blskeys/); do echo $k, $ip; done' > stn-s0-actual.txt ./run_on_shard.sh -p stn -y -T 1 'ip=$(curl http://169.254.169.254/latest/meta-data/public-ipv4); for k in $(ls ./.hmy/blskeys/); do echo $k, $ip; done' > stn-s1-actual.txt cat stn*actual* python3 bls.py ref ## To get the date time stamp for the log directory on the devops machine more /home/ec2-user/experiment-deploy/pipeline/logs/os/profile-os.json { \"bucket\": \"unique-bucket-bin\", \"folder\": \"OS\", \"sessionID\": \"20200326.180455\" } ## Manually create the temp logs with sessionID from above - NOT NEEDED USUALLY ## ls -ltr logs/os/ ## cd logs/os/ ## cd .. ## ./run_on_shard.sh -p os -T 0 'sudo mkdir -p ../tmp_log/log-20200318.173735;' ## ./run_on_shard.sh -p os -T 1 'sudo mkdir -p ../tmp_log/log-20200318.173735;' ## ./run_on_shard.sh -p os -T 2 'sudo mkdir -p ../tmp_log/log-20200318.173735;' ## ./run_on_shard.sh -p os -T 3 'sudo mkdir -p ../tmp_log/log-20200318.173735;' # Restart all the shards - NOT NEEDED USUALLY cat logs/stn/shard0.txt | xargs -i{} -P50 bash -c './restart_node.sh -y -d -c logs/stn -p stn -t 0 -r 0 -R 0 {}' cat logs/stn/shard1.txt | xargs -i{} -P50 bash -c './restart_node.sh -y -d -c logs/stn -p stn -t 0 -r 0 -R 0 {}' {% endtab %} {% endtabs %}","title":"Launch New Network For Fresh Network - ONLY"},{"location":"deploy/cicd/netdeploy/harmony-protocol-deployment/build/network-upgrade/#share-the-new-network-ip-addresses-with-watchdog","text":"See here","title":"Share the new network IP addresses with watchdog"},{"location":"deploy/cicd/netdeploy/harmony-protocol-deployment/build/network-upgrade/#update-dns-entries","text":"See here {% hint style=\"info\" %} Turn Pager duty on again {% endhint %} scp /home/ec2-user/experiment-deploy/pipeline/logs/os/shard?.txt watchdog:/home/ec2-user/staking ssh watchdog -- sudo systemctl restart harmony-watchdogd@staking.service","title":"Update DNS Entries"},{"location":"deploy/cicd/netdeploy/harmony-protocol-deployment/build/network-upgrade/#update-the-explorer-information-see-this-pull-request","text":"{ \"domain_name\": \"os.hmny.io\", \"num_of_shards\": 4, \"explorers_0\" : [\"54.184.36.85\"], \"explorers_1\" : [\"54.183.185.205\"], \"explorers_2\" : [\"18.189.185.176\"], \"explorers_3\" : [\"34.230.46.2\"], \"hosted_zone_id\" : \"Z1UEV9ND4IWBVM\", \"subnet_us-east-1\": [\"subnet-14da445e\", \"subnet-2c957212\", \"subnet-2f00cb73\", \"subnet-7b65f774\", \"subnet-7da3751a\", \"subnet-7e5c8950\"], \"subnet_us-east-2\": [\"subnet-45031908\", \"subnet-b38df5db\", \"subnet-c071c0ba\"], \"subnet_us-west-1\": [\"subnet-551f560e\", \"subnet-5be2df3c\"], \"subnet_us-west-2\": [\"subnet-1953d052\", \"subnet-6a6c1230\", \"subnet-c33554ba\", \"subnet-d73bdcfc\"], \"sg_us-east-1\": [\"sg-0a9f239987978e0eb\"], \"sg_us-east-2\": [\"sg-05c8f480d9a17574c\"], \"sg_us-west-1\": [\"sg-0fc2b150b51b313ec\"], \"sg_us-west-2\": [\"sg-03de0eb6b8f247581\"] } Notes hosted_zone_id -> comes from aws route53 -> hosted zones subnet -> comes from vpc -> subnets in aws sg are the security groups","title":"Update the explorer information see this pull request"},{"location":"deploy/cicd/netdeploy/harmony-protocol-deployment/build/rolling-upgrade/","text":"Rolling Upgrade Perform Rolling Upgrade - ROLLING UPGRADE ONLY Check your profile {% tabs %} {% tab title=\"OSTN\" %} profile_print export WHOAMI=OS; export HMY_PROFILE=os; profile_print {% endtab %} {% tab title=\"PTN\" %} profile_print export WHOAMI=STN; export HMY_PROFILE=stn; profile_print {% endtab %} {% endtabs %} Perform Rolling Upgrade {% tabs %} {% tab title=\"OSTN\" %} cd ~/experiment-deploy/pipeline/ ./rolling_restart_shard.sh -s 1 -d logs/os -p os -t 90 -r 1 -R 1 3 ./rolling_restart_shard.sh -s 1 -d logs/os -p os -t 90 -r 1 -R 1 2 ./rolling_restart_shard.sh -s 1 -d logs/os -p os -t 90 -r 1 -R 1 1 ./rolling_restart_shard.sh -s 1 -d logs/os -p os -t 90 -r 1 -R 1 0 {% endtab %} {% tab title=\"STN\" %} cd /home/ec2-user/JL/experiment-deploy/pipeline # Rolling Upgrade ./rolling_restart_shard.sh -s 1 -d logs/stn -p stn -t 90 -r 1 -R 1 1 ./rolling_restart_shard.sh -s 1 -d logs/stn -p stn -t 90 -r 1 -R 1 0 # Quick Shard Restart cat logs/stn/shard0.txt | xargs -i{} -P50 bash -c './restart_node.sh -U -y -t -c -d logs/stn -p stn -t 0 -r 0 -R 0 {}' cat logs/stn/shard1.txt | xargs -i{} -P50 bash -c './restart_node.sh -U -y -t -c -d logs/stn -p stn -t 0 -r 0 -R 0 {}' {% endtab %} {% endtabs %}","title":"Rolling Upgrade"},{"location":"deploy/cicd/netdeploy/harmony-protocol-deployment/build/rolling-upgrade/#rolling-upgrade","text":"","title":"Rolling Upgrade"},{"location":"deploy/cicd/netdeploy/harmony-protocol-deployment/build/rolling-upgrade/#perform-rolling-upgrade-rolling-upgrade-only","text":"Check your profile {% tabs %} {% tab title=\"OSTN\" %} profile_print export WHOAMI=OS; export HMY_PROFILE=os; profile_print {% endtab %} {% tab title=\"PTN\" %} profile_print export WHOAMI=STN; export HMY_PROFILE=stn; profile_print {% endtab %} {% endtabs %} Perform Rolling Upgrade {% tabs %} {% tab title=\"OSTN\" %} cd ~/experiment-deploy/pipeline/ ./rolling_restart_shard.sh -s 1 -d logs/os -p os -t 90 -r 1 -R 1 3 ./rolling_restart_shard.sh -s 1 -d logs/os -p os -t 90 -r 1 -R 1 2 ./rolling_restart_shard.sh -s 1 -d logs/os -p os -t 90 -r 1 -R 1 1 ./rolling_restart_shard.sh -s 1 -d logs/os -p os -t 90 -r 1 -R 1 0 {% endtab %} {% tab title=\"STN\" %} cd /home/ec2-user/JL/experiment-deploy/pipeline # Rolling Upgrade ./rolling_restart_shard.sh -s 1 -d logs/stn -p stn -t 90 -r 1 -R 1 1 ./rolling_restart_shard.sh -s 1 -d logs/stn -p stn -t 90 -r 1 -R 1 0 # Quick Shard Restart cat logs/stn/shard0.txt | xargs -i{} -P50 bash -c './restart_node.sh -U -y -t -c -d logs/stn -p stn -t 0 -r 0 -R 0 {}' cat logs/stn/shard1.txt | xargs -i{} -P50 bash -c './restart_node.sh -U -y -t -c -d logs/stn -p stn -t 0 -r 0 -R 0 {}' {% endtab %} {% endtabs %}","title":"Perform Rolling Upgrade - ROLLING UPGRADE ONLY"},{"location":"deploy/cicd/netdeploy/harmony-protocol-deployment/build/rolling-upgrade/#_1","text":"","title":""},{"location":"deploy/cicd/netdeploy/harmony-protocol-deployment/build/synch-t3-branch-with-master/","text":"Synch T3 Branch with Master {% hint style=\"info\" %} Note if ever a force push is done then all downstream repos can no longer just do a pull they instead need to git remote -v git fetch origin git log --pretty=oneline git branch -a git reset --hard origin/t3 {% endhint %} Synching Master Branch # Make sure you delete the old branch first from the prior pull request cdh git status git checkout t3 git log --pretty=oneline git clean -fdx git pull git log --pretty=oneline git checkout master git pull git log --pretty=oneline git fetch origin #==== Choose one or more of the following ====* ## To merge from master git merge origin/master ## To merge to a specific commit git merge 1fe41df8ab70381ae2a2ef2ab418270fdc49674d ## To cherry pick a commit git checkout merge-master-t3-0403 git cherry-pick 1fe41df8ab70381ae2a2ef2ab418270fdc49674d git push #========== End Choice ==============================* git log --pretty=oneline git tag -a v1.0-20200420.0 git push jw HEAD:merge-master-t3-0404 # Create PR # Merger the PR (do not squash merge) # Delete the branch {% hint style=\"info\" %} For more information including cherry-pick read the git documentation {% endhint %} Additional Ideas from Edgar git clean -fdx git fetch origin git checkout t3 git merge --squash origin/master git push ... so you want to add --squash for the merge for origin/master, the rest is the same right? Edgar | HarmonyToday at 11:49 AM and the clean -fdx in beginning just in case. If there is a situation when can't blindly merge from origin/master, do an individual git cherry-pick for the commits from master to bring into t3. If have situation like this 'just one more commit' , then don't need any git merge at all, just git cherry-pick at step right before git push , also have something git tag I think if we do deploys to ostn in this kind of way, it will be easier to conclusively know where a bad commit/bug was introduced and what to fall back to because more advanced features of git will more easily work, like git bisect Additional Ideas from Edgar April 5th some git knowledge. Because of the urgency of the deploy to get a fix out on t3, I went on devsops machine. Here is the flow I had and some special things happened that others have run into and I want to show ways around it. git clean -fdx git fetch origin git checkout t3 git reset --hard origin/t3 git merge --squash origin/master -X theirs git commit --no-edit ./scripts/go_executable_build.sh Doing a merge from master (regardless if squash or plain) would have done merge conflicts. But because we know that master is right and t3 is master code, its fine to accept the master version of code automatically instead of t3. Then i did a --no-edit commit to accept the default commit message made when you do a squash merge. After the deploy was done, then I opened PR to t3 because no reason to wait for jenkins when we know code already past master jenkins job.","title":"Synch T3 Branch with Master"},{"location":"deploy/cicd/netdeploy/harmony-protocol-deployment/build/synch-t3-branch-with-master/#synch-t3-branch-with-master","text":"{% hint style=\"info\" %} Note if ever a force push is done then all downstream repos can no longer just do a pull they instead need to git remote -v git fetch origin git log --pretty=oneline git branch -a git reset --hard origin/t3 {% endhint %}","title":"Synch T3 Branch with Master"},{"location":"deploy/cicd/netdeploy/harmony-protocol-deployment/build/synch-t3-branch-with-master/#synching-master-branch","text":"# Make sure you delete the old branch first from the prior pull request cdh git status git checkout t3 git log --pretty=oneline git clean -fdx git pull git log --pretty=oneline git checkout master git pull git log --pretty=oneline git fetch origin #==== Choose one or more of the following ====* ## To merge from master git merge origin/master ## To merge to a specific commit git merge 1fe41df8ab70381ae2a2ef2ab418270fdc49674d ## To cherry pick a commit git checkout merge-master-t3-0403 git cherry-pick 1fe41df8ab70381ae2a2ef2ab418270fdc49674d git push #========== End Choice ==============================* git log --pretty=oneline git tag -a v1.0-20200420.0 git push jw HEAD:merge-master-t3-0404 # Create PR # Merger the PR (do not squash merge) # Delete the branch {% hint style=\"info\" %} For more information including cherry-pick read the git documentation {% endhint %}","title":"Synching Master Branch"},{"location":"deploy/cicd/netdeploy/harmony-protocol-deployment/build/synch-t3-branch-with-master/#additional-ideas-from-edgar","text":"git clean -fdx git fetch origin git checkout t3 git merge --squash origin/master git push ... so you want to add --squash for the merge for origin/master, the rest is the same right? Edgar | HarmonyToday at 11:49 AM and the clean -fdx in beginning just in case. If there is a situation when can't blindly merge from origin/master, do an individual git cherry-pick for the commits from master to bring into t3. If have situation like this 'just one more commit' , then don't need any git merge at all, just git cherry-pick at step right before git push , also have something git tag I think if we do deploys to ostn in this kind of way, it will be easier to conclusively know where a bad commit/bug was introduced and what to fall back to because more advanced features of git will more easily work, like git bisect","title":"Additional Ideas from Edgar"},{"location":"deploy/cicd/netdeploy/harmony-protocol-deployment/build/synch-t3-branch-with-master/#additional-ideas-from-edgar-april-5th","text":"some git knowledge. Because of the urgency of the deploy to get a fix out on t3, I went on devsops machine. Here is the flow I had and some special things happened that others have run into and I want to show ways around it. git clean -fdx git fetch origin git checkout t3 git reset --hard origin/t3 git merge --squash origin/master -X theirs git commit --no-edit ./scripts/go_executable_build.sh Doing a merge from master (regardless if squash or plain) would have done merge conflicts. But because we know that master is right and t3 is master code, its fine to accept the master version of code automatically instead of t3. Then i did a --no-edit commit to accept the default commit message made when you do a squash merge. After the deploy was done, then I opened PR to t3 because no reason to wait for jenkins when we know code already past master jenkins job.","title":"Additional Ideas from Edgar April 5th"},{"location":"deploy/cicd/netdeploy/harmony-protocol-deployment/prepare-build/","text":"Prepare Build","title":"Prepare Build"},{"location":"deploy/cicd/netdeploy/harmony-protocol-deployment/prepare-build/#prepare-build","text":"","title":"Prepare Build"},{"location":"deploy/cicd/netdeploy/harmony-protocol-deployment/prepare-build/backups-and-snapshots-and-analysis/","text":"Backups and Snapshots and Analysis Overview This page list handy commands and mandatory data capture points before refreshing OSTN or restarting a shard. Backup Logs {% tabs %} {% tab title=\"OSTN\" %} cd experiment-deploy/pipeline/ ./go.sh -p os log # Wait for it to finish, then record the s3:// path {% endtab %} {% tab title=\"STN\" %} ./go.sh -p stn log # Wait for it to finish, then record the s3:// path {% endtab %} {% endtabs %} Capture Validator Information {% hint style=\"info\" %} From Janet In harmony-ops/devops/validator_stats I wrote a script to get validator stats for the network for the biz team you can run that instead of Stephens's shell scripting before restart to get stats if you want python3 validator_stats.py cd /Users/johnwhitton/projects/staking/OSTN source /Users/johnwhitton/go/src/github.com/harmony-one/harmony/scripts/setup_bls_build_flags.sh for x in `$(go env GOPATH)/src/github.com/harmony-one/go-sdk/hmy --node=https://api.s0.os.hmny.io blockchain validator all | grep one1 | tr -d '\",'`; do $(go env GOPATH)/src/github.com/harmony-one/go-sdk/hmy --node=https://api.s0.os.hmny.io blockchain validator information $x | python -c 'import sys, json; print json.dumps(json.load(sys.stdin))'; done > info_ostn_20200409.json # Copy and paste the text into this gist # https://gist.github.com/john-harmony/3de1a5a264bc5f99dbc97347eca903a5 # Downloading to to a local machine cd /Users/johnwhitton/projects/staking/OSTN scp -i ~/.ssh/keys/JOHN_OSTN_VALIDATOR_1.pem ec2-user@ec2-3-16-31-148.us-east-2.compute.amazonaws.com:/home/ec2-user/info_20200330.json . {% endhint %} {% tabs %} {% tab title=\"OSTN\" %} cd /Users/johnwhitton/projects/staking/OSTN/ source /Users/johnwhitton/go/src/github.com/harmony-one/harmony/scripts/setup_bls_build_flags.sh for x in `$(go env GOPATH)/src/github.com/harmony-one/go-sdk/hmy --node=https://api.s0.os.hmny.io blockchain validator all | grep one1 | tr -d '\",'`; do $(go env GOPATH)/src/github.com/harmony-one/go-sdk/hmy --node=https://api.s0.os.hmny.io blockchain validator information $x | python -c 'import sys, json; print json.dumps(json.load(sys.stdin))'; done > info_ostn_20200406_0715.json # Copy and paste the text into this gist # https://gist.github.com/john-harmony/3de1a5a264bc5f99dbc97347eca903a5 {% endtab %} {% tab title=\"STN\" %} cd /Users/johnwhitton/projects/staking/STN source /Users/johnwhitton/go/src/github.com/harmony-one/harmony/scripts/setup_bls_build_flags.sh for x in `$(go env GOPATH)/src/github.com/harmony-one/go-sdk/hmy --node=https://api.s0.stn.hmny.io blockchain validator all | grep one1 | tr -d '\",'`; do $(go env GOPATH)/src/github.com/harmony-one/go-sdk/hmy --node=https://api.s0.stn.hmny.io blockchain validator information $x | python -c 'import sys, json; print json.dumps(json.load(sys.stdin))'; done > info_stn_20200406.json # Copy and paste the text into this gist # https://gist.github.com/john-harmony/3de1a5a264bc5f99dbc97347eca903a5 # Downloading to to a local machine cd /Users/johnwhitton/projects/staking/OSTN scp -i ~/.ssh/keys/JOHN_OSTN_VALIDATOR_1.pem ec2-user@ec2-3-16-31-148.us-east-2.compute.amazonaws.com:/home/ec2-user/info_20200330.json . {% endtab %} {% endtabs %} Update Pager Duty to maintenance mode Go to service and select immediate maintenance mode Announce Build discord team-staking p-ops testnet-nodes telegram p-ops open staking volunteers Update Pager Duty Go to service and enable service Other Handy Gists CheckEarning.sh Realtime Economics Testing Validator and Watchdog utilities","title":"Backups and Snapshots and Analysis"},{"location":"deploy/cicd/netdeploy/harmony-protocol-deployment/prepare-build/backups-and-snapshots-and-analysis/#backups-and-snapshots-and-analysis","text":"","title":"Backups and Snapshots and Analysis"},{"location":"deploy/cicd/netdeploy/harmony-protocol-deployment/prepare-build/backups-and-snapshots-and-analysis/#overview","text":"This page list handy commands and mandatory data capture points before refreshing OSTN or restarting a shard.","title":"Overview"},{"location":"deploy/cicd/netdeploy/harmony-protocol-deployment/prepare-build/backups-and-snapshots-and-analysis/#backup-logs","text":"{% tabs %} {% tab title=\"OSTN\" %} cd experiment-deploy/pipeline/ ./go.sh -p os log # Wait for it to finish, then record the s3:// path {% endtab %} {% tab title=\"STN\" %} ./go.sh -p stn log # Wait for it to finish, then record the s3:// path {% endtab %} {% endtabs %}","title":"Backup Logs"},{"location":"deploy/cicd/netdeploy/harmony-protocol-deployment/prepare-build/backups-and-snapshots-and-analysis/#capture-validator-information","text":"{% hint style=\"info\" %} From Janet In harmony-ops/devops/validator_stats I wrote a script to get validator stats for the network for the biz team you can run that instead of Stephens's shell scripting before restart to get stats if you want python3 validator_stats.py cd /Users/johnwhitton/projects/staking/OSTN source /Users/johnwhitton/go/src/github.com/harmony-one/harmony/scripts/setup_bls_build_flags.sh for x in `$(go env GOPATH)/src/github.com/harmony-one/go-sdk/hmy --node=https://api.s0.os.hmny.io blockchain validator all | grep one1 | tr -d '\",'`; do $(go env GOPATH)/src/github.com/harmony-one/go-sdk/hmy --node=https://api.s0.os.hmny.io blockchain validator information $x | python -c 'import sys, json; print json.dumps(json.load(sys.stdin))'; done > info_ostn_20200409.json # Copy and paste the text into this gist # https://gist.github.com/john-harmony/3de1a5a264bc5f99dbc97347eca903a5 # Downloading to to a local machine cd /Users/johnwhitton/projects/staking/OSTN scp -i ~/.ssh/keys/JOHN_OSTN_VALIDATOR_1.pem ec2-user@ec2-3-16-31-148.us-east-2.compute.amazonaws.com:/home/ec2-user/info_20200330.json . {% endhint %} {% tabs %} {% tab title=\"OSTN\" %} cd /Users/johnwhitton/projects/staking/OSTN/ source /Users/johnwhitton/go/src/github.com/harmony-one/harmony/scripts/setup_bls_build_flags.sh for x in `$(go env GOPATH)/src/github.com/harmony-one/go-sdk/hmy --node=https://api.s0.os.hmny.io blockchain validator all | grep one1 | tr -d '\",'`; do $(go env GOPATH)/src/github.com/harmony-one/go-sdk/hmy --node=https://api.s0.os.hmny.io blockchain validator information $x | python -c 'import sys, json; print json.dumps(json.load(sys.stdin))'; done > info_ostn_20200406_0715.json # Copy and paste the text into this gist # https://gist.github.com/john-harmony/3de1a5a264bc5f99dbc97347eca903a5 {% endtab %} {% tab title=\"STN\" %} cd /Users/johnwhitton/projects/staking/STN source /Users/johnwhitton/go/src/github.com/harmony-one/harmony/scripts/setup_bls_build_flags.sh for x in `$(go env GOPATH)/src/github.com/harmony-one/go-sdk/hmy --node=https://api.s0.stn.hmny.io blockchain validator all | grep one1 | tr -d '\",'`; do $(go env GOPATH)/src/github.com/harmony-one/go-sdk/hmy --node=https://api.s0.stn.hmny.io blockchain validator information $x | python -c 'import sys, json; print json.dumps(json.load(sys.stdin))'; done > info_stn_20200406.json # Copy and paste the text into this gist # https://gist.github.com/john-harmony/3de1a5a264bc5f99dbc97347eca903a5 # Downloading to to a local machine cd /Users/johnwhitton/projects/staking/OSTN scp -i ~/.ssh/keys/JOHN_OSTN_VALIDATOR_1.pem ec2-user@ec2-3-16-31-148.us-east-2.compute.amazonaws.com:/home/ec2-user/info_20200330.json . {% endtab %} {% endtabs %}","title":"Capture Validator Information"},{"location":"deploy/cicd/netdeploy/harmony-protocol-deployment/prepare-build/backups-and-snapshots-and-analysis/#update-pager-duty-to-maintenance-mode","text":"Go to service and select immediate maintenance mode","title":"Update Pager Duty to maintenance mode"},{"location":"deploy/cicd/netdeploy/harmony-protocol-deployment/prepare-build/backups-and-snapshots-and-analysis/#announce-build","text":"discord team-staking p-ops testnet-nodes telegram p-ops open staking volunteers","title":"Announce Build"},{"location":"deploy/cicd/netdeploy/harmony-protocol-deployment/prepare-build/backups-and-snapshots-and-analysis/#update-pager-duty","text":"Go to service and enable service","title":"Update Pager Duty"},{"location":"deploy/cicd/netdeploy/harmony-protocol-deployment/prepare-build/backups-and-snapshots-and-analysis/#other-handy-gists","text":"CheckEarning.sh Realtime Economics Testing Validator and Watchdog utilities","title":"Other Handy Gists"},{"location":"deploy/cicd/netdeploy/harmony-protocol-deployment/prepare-build/synch-t3-branch-with-master/","text":"Synch T3 Branch with Master {% hint style=\"info\" %} Note if ever a force push is done then all downstream repos can no longer just do a pull they instead need to git remote -v git fetch origin git log --pretty=oneline git branch -a git reset --hard origin/t3 {% endhint %} Synching Master Branch # Make sure you delete the old branch first from the prior pull request cdh git status git checkout t3 git log --pretty=oneline git clean -fdx git pull git log --pretty=oneline git checkout master git pull git log --pretty=oneline git fetch origin #==== Choose one or more of the following ====* ## To merge from master git merge origin/master ## To merge to a specific commit git merge 1fe41df8ab70381ae2a2ef2ab418270fdc49674d ## To cherry pick a commit git checkout merge-master-t3-0403 git cherry-pick 1fe41df8ab70381ae2a2ef2ab418270fdc49674d git push #========== End Choice ==============================* git log --pretty=oneline git tag -a v1.0-20200420.0 git push jw HEAD:merge-master-t3-0404 # Create PR # Merger the PR (do not squash merge) # Delete the branch {% hint style=\"info\" %} For more information including cherry-pick read the git documentation {% endhint %} Additional Ideas from Edgar git clean -fdx git fetch origin git checkout t3 git merge --squash origin/master git push ... so you want to add --squash for the merge for origin/master, the rest is the same right? Edgar | HarmonyToday at 11:49 AM and the clean -fdx in beginning just in case. If there is a situation when can't blindly merge from origin/master, do an individual git cherry-pick for the commits from master to bring into t3. If have situation like this 'just one more commit' , then don't need any git merge at all, just git cherry-pick at step right before git push , also have something git tag I think if we do deploys to ostn in this kind of way, it will be easier to conclusively know where a bad commit/bug was introduced and what to fall back to because more advanced features of git will more easily work, like git bisect Additional Ideas from Edgar April 5th some git knowledge. Because of the urgency of the deploy to get a fix out on t3, I went on devsops machine. Here is the flow I had and some special things happened that others have run into and I want to show ways around it. git clean -fdx git fetch origin git checkout t3 git reset --hard origin/t3 git merge --squash origin/master -X theirs git commit --no-edit ./scripts/go_executable_build.sh Doing a merge from master (regardless if squash or plain) would have done merge conflicts. But because we know that master is right and t3 is master code, its fine to accept the master version of code automatically instead of t3. Then i did a --no-edit commit to accept the default commit message made when you do a squash merge. After the deploy was done, then I opened PR to t3 because no reason to wait for jenkins when we know code already past master jenkins job.","title":"Synch T3 Branch with Master"},{"location":"deploy/cicd/netdeploy/harmony-protocol-deployment/prepare-build/synch-t3-branch-with-master/#synch-t3-branch-with-master","text":"{% hint style=\"info\" %} Note if ever a force push is done then all downstream repos can no longer just do a pull they instead need to git remote -v git fetch origin git log --pretty=oneline git branch -a git reset --hard origin/t3 {% endhint %}","title":"Synch T3 Branch with Master"},{"location":"deploy/cicd/netdeploy/harmony-protocol-deployment/prepare-build/synch-t3-branch-with-master/#synching-master-branch","text":"# Make sure you delete the old branch first from the prior pull request cdh git status git checkout t3 git log --pretty=oneline git clean -fdx git pull git log --pretty=oneline git checkout master git pull git log --pretty=oneline git fetch origin #==== Choose one or more of the following ====* ## To merge from master git merge origin/master ## To merge to a specific commit git merge 1fe41df8ab70381ae2a2ef2ab418270fdc49674d ## To cherry pick a commit git checkout merge-master-t3-0403 git cherry-pick 1fe41df8ab70381ae2a2ef2ab418270fdc49674d git push #========== End Choice ==============================* git log --pretty=oneline git tag -a v1.0-20200420.0 git push jw HEAD:merge-master-t3-0404 # Create PR # Merger the PR (do not squash merge) # Delete the branch {% hint style=\"info\" %} For more information including cherry-pick read the git documentation {% endhint %}","title":"Synching Master Branch"},{"location":"deploy/cicd/netdeploy/harmony-protocol-deployment/prepare-build/synch-t3-branch-with-master/#additional-ideas-from-edgar","text":"git clean -fdx git fetch origin git checkout t3 git merge --squash origin/master git push ... so you want to add --squash for the merge for origin/master, the rest is the same right? Edgar | HarmonyToday at 11:49 AM and the clean -fdx in beginning just in case. If there is a situation when can't blindly merge from origin/master, do an individual git cherry-pick for the commits from master to bring into t3. If have situation like this 'just one more commit' , then don't need any git merge at all, just git cherry-pick at step right before git push , also have something git tag I think if we do deploys to ostn in this kind of way, it will be easier to conclusively know where a bad commit/bug was introduced and what to fall back to because more advanced features of git will more easily work, like git bisect","title":"Additional Ideas from Edgar"},{"location":"deploy/cicd/netdeploy/harmony-protocol-deployment/prepare-build/synch-t3-branch-with-master/#additional-ideas-from-edgar-april-5th","text":"some git knowledge. Because of the urgency of the deploy to get a fix out on t3, I went on devsops machine. Here is the flow I had and some special things happened that others have run into and I want to show ways around it. git clean -fdx git fetch origin git checkout t3 git reset --hard origin/t3 git merge --squash origin/master -X theirs git commit --no-edit ./scripts/go_executable_build.sh Doing a merge from master (regardless if squash or plain) would have done merge conflicts. But because we know that master is right and t3 is master code, its fine to accept the master version of code automatically instead of t3. Then i did a --no-edit commit to accept the default commit message made when you do a squash merge. After the deploy was done, then I opened PR to t3 because no reason to wait for jenkins when we know code already past master jenkins job.","title":"Additional Ideas from Edgar April 5th"},{"location":"deploy/cicd/netdeploy/network-release/","text":"Network Release Overview This section provides detailed information on how to deploy a harmony network. It is broken down into cheat sheets which provide all commands used to deploy a Network. there is additional detailed information including pre-requisites and setup for deploying each of the individual components. Finally there are also sections on trouble shooting, monitoring tools and stress testing for the Harmony Protocol. Network Deployment Types At the time of writing this, there are three main types of Network Deployments. Rolling Upgrade This can (and should) be performed whenever a new version of the software is deployed to the network. It requires an upgrade to the Harmony Protocol (including a validator release) only. It does not require a restart of any of the other Network components. The only time this is not appropriate is when there are data changes that break the existing network (see Hard Refresh) and when deploying a new Network or changing the configuration of an existing network (see Network Upgrade). Hard Refresh A hard refresh is necessary when there are breaking changes usually data related in the new version of the protocol software being deployed. This involves the removal of all data at the protocol level and also many network components which have their own persistent storage and caching layers that require cleaning out the applications database and restarting their applications. Finally all transactional data is lost and all validators need to reset their nodes and register themselves again on the network. Network Upgrade A network upgrade is necessary when deploying a new network or changing configuration of a network (e.g. additional shards or validators per shard). It can also be used as a quicker way to bring up an existing network which has lost a number of nodes (usually AWS spot instances) and as such can no longer gain consensus. This has the same effect as a hard refresh but with additional actions required to update the other network applications with new IP's for the new nodes as well as additional work required for DNS Configuration for both synching and api endpoints.","title":"Network Release"},{"location":"deploy/cicd/netdeploy/network-release/#network-release","text":"","title":"Network Release"},{"location":"deploy/cicd/netdeploy/network-release/#overview","text":"This section provides detailed information on how to deploy a harmony network. It is broken down into cheat sheets which provide all commands used to deploy a Network. there is additional detailed information including pre-requisites and setup for deploying each of the individual components. Finally there are also sections on trouble shooting, monitoring tools and stress testing for the Harmony Protocol.","title":"Overview"},{"location":"deploy/cicd/netdeploy/network-release/#network-deployment-types","text":"At the time of writing this, there are three main types of Network Deployments.","title":"Network Deployment Types"},{"location":"deploy/cicd/netdeploy/network-release/#rolling-upgrade","text":"This can (and should) be performed whenever a new version of the software is deployed to the network. It requires an upgrade to the Harmony Protocol (including a validator release) only. It does not require a restart of any of the other Network components. The only time this is not appropriate is when there are data changes that break the existing network (see Hard Refresh) and when deploying a new Network or changing the configuration of an existing network (see Network Upgrade).","title":"Rolling Upgrade"},{"location":"deploy/cicd/netdeploy/network-release/#hard-refresh","text":"A hard refresh is necessary when there are breaking changes usually data related in the new version of the protocol software being deployed. This involves the removal of all data at the protocol level and also many network components which have their own persistent storage and caching layers that require cleaning out the applications database and restarting their applications. Finally all transactional data is lost and all validators need to reset their nodes and register themselves again on the network.","title":"Hard Refresh"},{"location":"deploy/cicd/netdeploy/network-release/#network-upgrade","text":"A network upgrade is necessary when deploying a new network or changing configuration of a network (e.g. additional shards or validators per shard). It can also be used as a quicker way to bring up an existing network which has lost a number of nodes (usually AWS spot instances) and as such can no longer gain consensus. This has the same effect as a hard refresh but with additional actions required to update the other network applications with new IP's for the new nodes as well as additional work required for DNS Configuration for both synching and api endpoints.","title":"Network Upgrade"},{"location":"deploy/cicd/netdeploy/network-release/block-explorer-deployment/","text":"Block Explorer Deployment Updating the IP's when we do a Rebuild with new IP's - get ips from devops {% tabs %} {% tab title=\"OSTN\" %} exec ssh -i ~/.ssh/keys/oregon-key-benchmark.pem ec2-user@35.160.64.190 pwd cd /home/ec2-user/experiment-deploy/pipeline/logs/os grep explorer distribution_config.txt # Will return 3.84.119.155 9000 explorer_node 0 1-OS-explorer_node-od-2020-03-18_21_24_05 \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 54.197.198.245 9000 explorer_node 1 1-OS-explorer_node-od-2020-03-18_21_24_05 \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 18.208.144.30 9000 explorer_node 2 1-OS-explorer_node-od-2020-03-18_21_24_05 \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 3.83.10.40 9000 explorer_node 3 1-OS-explorer_node-od-2020-03-18_21_24_05 {% endtab %} {% tab title=\"STN\" %} profile_print grep /home/ec2-user/JL/experiment-deploy/pipeline/logs/stn/explorer distribution_config.txt # Will return 54.202.250.192 9000 explorer_node 0 4-STN-explorer_node-od-2020-04-01_01_55_15 18.144.64.209 9000 explorer_node 1 3-STN-explorer_node-od-2020-04-01_01_55_15 {% endtab %} {% endtabs %} Login to Block Explorer {% tabs %} {% tab title=\"OSTN\" %} exec ssh -i ~/.ssh/keys/oregon-key-benchmark.pem ec2-user@44.232.43.231 {% endtab %} {% tab title=\"STN\" %} exec ssh -i ~/.ssh/keys/oregon-key-benchmark.pem ec2-user@35.164.26.115 {% endtab %} {% endtabs %} Replace the IPS in leaders.json exec ssh -i ~/.ssh/keys/oregon-key-benchmark.pem ec2-user@44.232.43.231 cd ~/projects/harmony-dashboard-backend vim leaders.json #Update the IPS in the json file e.g. for stn [\"18.144.45.107\",\"34.222.92.61\"] Refreshing the database # Get the pid by using check ports check_ports # Gives this 2000 frontend 8080 https and 8888 web socket # node 23041 ec2-user 22u IPv6 72359909 0t0 TCP *:8888 (LISTEN) # node 23041 ec2-user 23u IPv6 72360567 0t0 TCP *:8080 (LISTEN) \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7node 23041 ec2-user 23u IPv6 72360567 0t0 TCP *:8080 (LISTEN) \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7http-serv 26020 ec2-user 22u IPv4 72586772 0t0 TCP *:2000 (LISTEN) # http-serv 26020 ec2-user 22u IPv4 72586772 0t0 TCP *:2000 (LISTEN) # Stop the backend you get the pid from the ports command kill -9 23041 # Reset the db cd ~/projects/harmony-dashboard-backend npm run db-reset # Restart the backend npm run start Building a new version git pull npm run build npm run start","title":"Block Explorer Deployment"},{"location":"deploy/cicd/netdeploy/network-release/block-explorer-deployment/#block-explorer-deployment","text":"","title":"Block Explorer Deployment"},{"location":"deploy/cicd/netdeploy/network-release/block-explorer-deployment/#updating-the-ips-when-we-do-a-rebuild-with-new-ips-get-ips-from-devops","text":"{% tabs %} {% tab title=\"OSTN\" %} exec ssh -i ~/.ssh/keys/oregon-key-benchmark.pem ec2-user@35.160.64.190 pwd cd /home/ec2-user/experiment-deploy/pipeline/logs/os grep explorer distribution_config.txt # Will return 3.84.119.155 9000 explorer_node 0 1-OS-explorer_node-od-2020-03-18_21_24_05 \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 54.197.198.245 9000 explorer_node 1 1-OS-explorer_node-od-2020-03-18_21_24_05 \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 18.208.144.30 9000 explorer_node 2 1-OS-explorer_node-od-2020-03-18_21_24_05 \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 3.83.10.40 9000 explorer_node 3 1-OS-explorer_node-od-2020-03-18_21_24_05 {% endtab %} {% tab title=\"STN\" %} profile_print grep /home/ec2-user/JL/experiment-deploy/pipeline/logs/stn/explorer distribution_config.txt # Will return 54.202.250.192 9000 explorer_node 0 4-STN-explorer_node-od-2020-04-01_01_55_15 18.144.64.209 9000 explorer_node 1 3-STN-explorer_node-od-2020-04-01_01_55_15 {% endtab %} {% endtabs %}","title":"Updating the IP's when we do a Rebuild with new IP's - get ips from devops"},{"location":"deploy/cicd/netdeploy/network-release/block-explorer-deployment/#login-to-block-explorer","text":"{% tabs %} {% tab title=\"OSTN\" %} exec ssh -i ~/.ssh/keys/oregon-key-benchmark.pem ec2-user@44.232.43.231 {% endtab %} {% tab title=\"STN\" %} exec ssh -i ~/.ssh/keys/oregon-key-benchmark.pem ec2-user@35.164.26.115 {% endtab %} {% endtabs %}","title":"Login to Block Explorer"},{"location":"deploy/cicd/netdeploy/network-release/block-explorer-deployment/#replace-the-ips-in-leadersjson","text":"exec ssh -i ~/.ssh/keys/oregon-key-benchmark.pem ec2-user@44.232.43.231 cd ~/projects/harmony-dashboard-backend vim leaders.json #Update the IPS in the json file e.g. for stn [\"18.144.45.107\",\"34.222.92.61\"]","title":"Replace the IPS in leaders.json"},{"location":"deploy/cicd/netdeploy/network-release/block-explorer-deployment/#refreshing-the-database","text":"# Get the pid by using check ports check_ports # Gives this 2000 frontend 8080 https and 8888 web socket # node 23041 ec2-user 22u IPv6 72359909 0t0 TCP *:8888 (LISTEN) # node 23041 ec2-user 23u IPv6 72360567 0t0 TCP *:8080 (LISTEN) \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7node 23041 ec2-user 23u IPv6 72360567 0t0 TCP *:8080 (LISTEN) \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7http-serv 26020 ec2-user 22u IPv4 72586772 0t0 TCP *:2000 (LISTEN) # http-serv 26020 ec2-user 22u IPv4 72586772 0t0 TCP *:2000 (LISTEN) # Stop the backend you get the pid from the ports command kill -9 23041 # Reset the db cd ~/projects/harmony-dashboard-backend npm run db-reset # Restart the backend npm run start Building a new version git pull npm run build npm run start","title":"Refreshing the database"},{"location":"deploy/cicd/netdeploy/network-release/harmony-chrome-extension/","text":"Harmony Chrome extension Overview The Harmony Chrome extension integrates with the staking dashboard to allow you to sign staking transactions and transfer funds. Instructions for installation are here and below. Installing the chrome extension Download the version from here and unzip Go to chrome://extensions Ensure Developer Mode is on (toggle upper right corner) Press Load unpacked and point to the directory you unzipped to Publishing Extension to S3 The harmony chrome extensions are stored in the staking-dashboard github repository and also at s3://pub.harmony.one/release/chrome_extension We will use the devops machine to copy the files from the staking dashboard to aws s3 ## Log into the devops machine devops.sh ## Make the AWS Folder (one time only) aws s3 ls s3://pub.harmony.one/release/ aws s3 cp *.zip s3://pub.harmony.one/release/chrome_extension/ --dryrun ## Get the latest copy of the extensions cd ~/staking-dashboard git pull cd ~/harmony/extensions ## Publish the latest files aws s3 ls s3://pub.harmony.one/release/chrome_extension/ aws s3 cp 0.0.8.zip s3://pub.harmony.one/release/chrome_extension/ --dryrun aws s3 cp 0.0.9.zip s3://pub.harmony.one/release/chrome_extension/ --dryrun aws s3 cp 0.0.10.zip s3://pub.harmony.one/release/chrome_extension/ --dryrun aws s3 cp 0.0.8.zip s3://pub.harmony.one/release/chrome_extension/ aws s3 cp 0.0.9.zip s3://pub.harmony.one/release/chrome_extension/ aws s3 cp 0.0.10.zip s3://pub.harmony.one/release/chrome_extension/ aws s3 ls s3://pub.harmony.one/release/chrome_extension/ Reference Material Harmony Chrome Extension Build","title":"Harmony Chrome extension"},{"location":"deploy/cicd/netdeploy/network-release/harmony-chrome-extension/#harmony-chrome-extension","text":"","title":"Harmony Chrome extension"},{"location":"deploy/cicd/netdeploy/network-release/harmony-chrome-extension/#overview","text":"The Harmony Chrome extension integrates with the staking dashboard to allow you to sign staking transactions and transfer funds. Instructions for installation are here and below.","title":"Overview"},{"location":"deploy/cicd/netdeploy/network-release/harmony-chrome-extension/#installing-the-chrome-extension","text":"Download the version from here and unzip Go to chrome://extensions Ensure Developer Mode is on (toggle upper right corner) Press Load unpacked and point to the directory you unzipped to","title":"Installing the chrome extension"},{"location":"deploy/cicd/netdeploy/network-release/harmony-chrome-extension/#publishing-extension-to-s3","text":"The harmony chrome extensions are stored in the staking-dashboard github repository and also at s3://pub.harmony.one/release/chrome_extension We will use the devops machine to copy the files from the staking dashboard to aws s3 ## Log into the devops machine devops.sh ## Make the AWS Folder (one time only) aws s3 ls s3://pub.harmony.one/release/ aws s3 cp *.zip s3://pub.harmony.one/release/chrome_extension/ --dryrun ## Get the latest copy of the extensions cd ~/staking-dashboard git pull cd ~/harmony/extensions ## Publish the latest files aws s3 ls s3://pub.harmony.one/release/chrome_extension/ aws s3 cp 0.0.8.zip s3://pub.harmony.one/release/chrome_extension/ --dryrun aws s3 cp 0.0.9.zip s3://pub.harmony.one/release/chrome_extension/ --dryrun aws s3 cp 0.0.10.zip s3://pub.harmony.one/release/chrome_extension/ --dryrun aws s3 cp 0.0.8.zip s3://pub.harmony.one/release/chrome_extension/ aws s3 cp 0.0.9.zip s3://pub.harmony.one/release/chrome_extension/ aws s3 cp 0.0.10.zip s3://pub.harmony.one/release/chrome_extension/ aws s3 ls s3://pub.harmony.one/release/chrome_extension/","title":"Publishing Extension to S3"},{"location":"deploy/cicd/netdeploy/network-release/harmony-chrome-extension/#reference-material","text":"Harmony Chrome Extension Build","title":"Reference Material"},{"location":"deploy/cicd/netdeploy/network-release/sdk-and-cli-deployment/","text":"SDK and CLI Deployment","title":"SDK and CLI Deployment"},{"location":"deploy/cicd/netdeploy/network-release/sdk-and-cli-deployment/#sdk-and-cli-deployment","text":"","title":"SDK and CLI Deployment"},{"location":"deploy/cicd/netdeploy/network-release/sentry-deployment/","text":"Sentry Deployment {% hint style=\"info\" %} For access to the Sentry node ask john@harmony.one {% endhint %} {% hint style=\"info\" %} To run in profiling mode use -R localhost:6070 and here are instructions on how to query it {% endhint %} {% hint style=\"success\" %} For docker autocreation of sentries see https://github.com/harmony-one/harmony-ops/tree/master/devops/auto_node {% endhint %} Overview Harmony runs a sentry node for each shard on OSTN. This is spun up using the same process as the validators to ensure that validates can earn rewards. These sentry nodes are critical for rolling upgrades and should be upgraded before the rolling upgrade begins. Also here is a sample script to register validators written by Edgar. The four sentries are listed below as well as a link to the pem key to connect to them. To copy a pem from your local machine to devops machine scp -i ~/.ssh/keys/oregon-key-benchmark.pem ~/.ssh/keys/JOHN_OSTN_VALIDATOR_1.pem ec2-user@35.160.64.190:/home/ec2-user/.ssh/keys/ Autonodes {% tabs %} {% tab title=\"OSTN\" %} # Sentry 0 - one1m6j80t6rhc3ypaumtsfmqwjwp0mrqk9ff50prh # afc4d81ab636323b04893c23d3404f38e95e9291b3d5299dade3d03822edd3a2b799bd6d64265a9a9cac025d5dbd600c.key exec ssh -i ~/.ssh/keys/harmony-testnet.pem ec2-user@13.59.156.175 # Sentry 1 - one10fjqteq6q75nm62cx8vejqsk7mc8t5hle8ewnl # 552f8aa65835f04e4bc3a04a4bd1f5c67dcd562513b6728c5b9fd258d9fdb054c10008b14a739818d0c234d37b8f1301.key exec ssh -i ~/.ssh/keys/harmony-testnet.pem ec2-user@18.188.241.110 # Sentry 2 - one1vzsj3julf0ljcj3hhxuqpu6zvadu488zfrtttz # a2232487bbf16dd01c5743700712819984d036bf3e39960c85045920784ba0d24149c93591dd4017ada3155e8105d402.key exec ssh -i ~/.ssh/keys/harmony-testnet.pem ec2-user@13.59.11.174 # Sentry 3 - Sentry 3 one1marnnvc8hywmfxhrc8mtpjkvvdt32x9kxt # 5aff3653958fdddefe04aaeb5e9c4a4fc7dda03538a04fd8dfd139c66d18ec31c7deb846cb67077fde48921ddb07a387.key exec ssh -i ~/.ssh/keys/harmony-testnet.pem ec2-user@3.22.97.78 ./auto_node.sh node-version ./auto_node.sh attach {% endtab %} {% tab title=\"STN\" %} {% endtab %} {% endtabs %} Sentry 0 - one1m6j80t6rhc3ypaumtsfmqwjwp0mrqk9ff50prh {% tabs %} {% tab title=\"OSTN\" %} # Log into the machine can do this from devops machine or your local exec ssh -i ~/.ssh/keys/SentryOSTN.pem ec2-user@3.21.53.63 # tmux attach tmux att Register the Validator ./hmy --node=\"https://api.s0.os.hmny.io\" staking create-validator --validator-addr one1m6j80t6rhc3ypaumtsfmqwjwp0mrqk9ff50prh --name OSTNSentry0 --identity OSTNSentry0 --website sentry@harmony.one --security-contact Sentry --details \"OSTN Sentry for Shard 0 t3.small\" --rate 0.05 --max-rate 0.8 --max-change-rate 0.02 --min-self-delegation 10000 --max-total-delegation 100000 --bls-pubkeys afc4d81ab636323b04893c23d3404f38e95e9291b3d5299dade3d03822edd3a2b799bd6d64265a9a9cac025d5dbd600c --amount 100000 # Restart the node ./node.sh -S -z -I -P -N staking -k afc4d81ab636323b04893c23d3404f38e95e9291b3d5299dade3d03822edd3a2b799bd6d64265a9a9cac025d5dbd600c.key # Restart the node and CLEAN out blockchain curl -LO https://raw.githubusercontent.com/harmony-one/harmony/master/scripts/node.sh && chmod a+x node.sh rm -rf harmony_db* ./node.sh -S -c -z -I -P -r localhost:6060 -N staking -k afc4d81ab636323b04893c23d3404f38e95e9291b3d5299dade3d03822edd3a2b799bd6d64265a9a9cac025d5dbd600c.key # Check that it's earning ./hmy --node=\"https://api.s0.os.hmny.io\" blockchain validator information one1m6j80t6rhc3ypaumtsfmqwjwp0mrqk9ff50prh # Mark it active ./hmy -n https://api.s0.os.hmny.io staking edit-validator --validator-addr one1m6j80t6rhc3ypaumtsfmqwjwp0mrqk9ff50prh --active true ./hmy -n https://api.s0.os.hmny.io staking edit-validator --validator-addr one1m6j80t6rhc3ypaumtsfmqwjwp0mrqk9ff50prh --name \"OSTN-SENTRY-0\" # Check the node version ./node.sh -V # Look at the logs tail -f ./latest/*.log # Grab the logs cd /Users/johnwhitton/projects/staking/OSTN/logs/sentry0 scp -i ~/.ssh/keys/SentryOSTN.pem ec2-user@3.21.53.63:/home/ec2-user/latest/* . {% endtab %} {% tab title=\"STN\" %} # https://gist.github.com/Daniel-VDM/fe15ccd0561ba23ef7e0007b33b08d8f # https://github.com/harmony-one/harmony-ops/tree/master/devops/auto_node ./node_ssh.sh 52.11.85.154 tmux att ./auto_node.sh run --shard 0 --auto-active --clean --network stress --beacon-endpoint https://api.s0.stn.hmny.io/ # Get validator information ./hmy --node=\"https://api.s0.stn.hmny.io\" blockchain validator information one1m6j80t6rhc3ypaumtsfmqwjwp0mrqk9ff50prh # Removing a bls key ./hmy staking --node=\"https://api.s0.stn.hmny.io\" edit-validator --validator-addr one1m6j80t6rhc3ypaumtsfmqwjwp0mrqk9ff50prh --remove-bls-key 605569a402ff52e703cd3d66f3bc0a08be4955c8d2700d1581740ffed8e545f73736de350183cd30e50b06e1b880d605 # Validator Config { \"validator-addr\": \"one1m6j80t6rhc3ypaumtsfmqwjwp0mrqk9ff50prh\", \"name\": \"STN-Sentry-0-autonode-t3.small\", \"website\": \"harmony.one\", \"security-contact\": \"john@harmony.one\", \"identity\": \"STN-Sentry-0-auto-node\", \"amount\": 10100, \"min-self-delegation\": 10000, \"rate\": 0.1, \"max-rate\": 0.75, \"max-change-rate\": 0.05, \"max-total-delegation\": 1000000.0, \"details\": \"None\" } {% endtab %} {% endtabs %} Sentry 1 - one10fjqteq6q75nm62cx8vejqsk7mc8t5hle8ewnl {% tabs %} {% tab title=\"OSTN\" %} ssh -i ~/.ssh/keys/SentryOSTN.pem ec2-user@18.218.200.47 # tmux attach tmux att # Fund the account ./hmy --node=\"\"https://api.s0.os.hmny.io/\"\" transfer --from one14hd35aj7xvuq3vg4grnv2umkxkazcmjq68hpwh --to one10fjqteq6q75nm62cx8vejqsk7mc8t5hle8ewnl --from-shard 0 --to-shard 0 --amount 110000 Register the Validator ./hmy --node=\"https://api.s0.os.hmny.io\" staking create-validator --validator-addr one10fjqteq6q75nm62cx8vejqsk7mc8t5hle8ewnl --name OSTNSentry1 --identity OSTNSentry1 --website sentry@harmony.one --security-contact Sentry --details \"OSTN Sentry for Shard 1 t3.small\" --rate 0.05 --max-rate 0.8 --max-change-rate 0.02 --min-self-delegation 10000 --max-total-delegation 1000000 --bls-pubkeys 552f8aa65835f04e4bc3a04a4bd1f5c67dcd562513b6728c5b9fd258d9fdb054c10008b14a739818d0c234d37b8f1301 --amount 10000 # Restart the node ./node.sh -S -z -I -P -N staking -k 552f8aa65835f04e4bc3a04a4bd1f5c67dcd562513b6728c5b9fd258d9fdb054c10008b14a739818d0c234d37b8f1301.key # Restart the node and CLEAN out blockchain curl -LO https://raw.githubusercontent.com/harmony-one/harmony/master/scripts/node.sh && chmod a+x node.sh rm -rf harmony_db* ./node.sh -S -c -z -I -P -r localhost:6060 -N staking -k 552f8aa65835f04e4bc3a04a4bd1f5c67dcd562513b6728c5b9fd258d9fdb054c10008b14a739818d0c234d37b8f1301.key # Check that it's earning ./hmy --node=\"https://api.s0.os.hmny.io\" blockchain validator information one10fjqteq6q75nm62cx8vejqsk7mc8t5hle8ewnl # Mark it active ./hmy -n https://api.s0.os.hmny.io staking edit-validator --validator-addr one10fjqteq6q75nm62cx8vejqsk7mc8t5hle8ewnl --active true # Check the node version ./node.sh -V # Look at the logs tail -f ./latest/*.log # Grab the logs cd /Users/johnwhitton/projects/staking/OSTN/logs/sentry1 scp -i ~/.ssh/keys/SentryOSTN.pem ec2-user@18.218.200.47:/home/ec2-user/latest/* . {% endtab %} {% tab title=\"STN\" %} # https://gist.github.com/Daniel-VDM/fe15ccd0561ba23ef7e0007b33b08d8f # https://github.com/harmony-one/harmony-ops/tree/master/devops/auto_node ./node_ssh.sh 54.202.197.141 curl -LO https://harmony.one/hmycli && mv hmycli hmy && chmod +x hmy && sudo yum update -y && sudo yum install -y docker && sudo usermod -aG docker ec2-user && sudo service docker start && sudo yum install -y tmux && exit curl -O https://raw.githubusercontent.com/harmony-one/harmony-ops/master/devops/auto_node/scripts/auto_node.sh && chmod +x ./auto_node.sh && ./auto_node.sh setup ./hmy keys list ./hmy keys import-private-key <<KEY>> STNSentry1 tmux att ./auto_node.sh run --shard 1 --auto-active --clean --network stress --beacon-endpoint https://api.s0.stn.hmny.io/ # Get validator information ./hmy --node=\"https://api.s0.stn.hmny.io\" blockchain validator information one10fjqteq6q75nm62cx8vejqsk7mc8t5hle8ewnl # Removing a bls key ./hmy staking --node=\"https://api.s0.stn.hmny.io\" edit-validator --validator-addr one10fjqteq6q75nm62cx8vejqsk7mc8t5hle8ewnl --remove-bls-key 567fb7398184c382d92bf6b568e79363c9d7c238b261b456d280882c6a0ad42e7367ec57596b366a86b454dd53a93215 # Validator Config { \"validator-addr\": \"one10fjqteq6q75nm62cx8vejqsk7mc8t5hle8ewnl\", \"name\": \"STN-Sentry-1-autonode-t3.small\", \"website\": \"harmony.one\", \"security-contact\": \"john@harmony.one\", \"identity\": \"STN-Sentry-1-auto-node\", \"amount\": 10100, \"min-self-delegation\": 10000, \"rate\": 0.1, \"max-rate\": 0.75, \"max-change-rate\": 0.05, \"max-total-delegation\": 1000000.0, \"details\": \"None\" } {% endtab %} {% endtabs %} Sentry 2 - one1vzsj3julf0ljcj3hhxuqpu6zvadu488zfrtttz {% tabs %} {% tab title=\"OSTN\" %} exec ssh -i ~/.ssh/keys/SentryOSTN.pem ec2-user@3.21.169.132 # tmux attach tmux att # Fund the account ./hmy --node=\"\"https://api.s0.os.hmny.io/\"\" transfer --from one14hd35aj7xvuq3vg4grnv2umkxkazcmjq68hpwh --to one1vzsj3julf0ljcj3hhxuqpu6zvadu488zfrtttz --from-shard 0 --to-shard 0 --amount 1000 Register the Validator ./hmy --node=\"https://api.s0.os.hmny.io\" staking create-validator --validator-addr one1vzsj3julf0ljcj3hhxuqpu6zvadu488zfrtttz --name OSTNSentry2 --identity OSTNSentry2 --website sentry@harmony.one --security-contact Sentry --details \"OSTN Sentry for Shard 2 t3.small\" --rate 0.05 --max-rate 0.8 --max-change-rate 0.02 --min-self-delegation 10000 --max-total-delegation 10000000 --bls-pubkeys a2232487bbf16dd01c5743700712819984d036bf3e39960c85045920784ba0d24149c93591dd4017ada3155e8105d402 --amount 10000 # Restart the node ./node.sh -S -z -I -P -r localhost:6060 -N staking -k a2232487bbf16dd01c5743700712819984d036bf3e39960c85045920784ba0d24149c93591dd4017ada3155e8105d402.key # Restart the node and CLEAN out blockchain curl -LO https://raw.githubusercontent.com/harmony-one/harmony/master/scripts/node.sh && chmod a+x node.sh rm -rf harmony_db* ./node.sh -S -c -z -I -P -r localhost:6060 -N staking -k a2232487bbf16dd01c5743700712819984d036bf3e39960c85045920784ba0d24149c93591dd4017ada3155e8105d402.key # Check that it's earning ./hmy --node=\"https://api.s0.os.hmny.io\" blockchain validator information one1vzsj3julf0ljcj3hhxuqpu6zvadu488zfrtttz # Mark it active ./hmy -n https://api.s0.os.hmny.io staking edit-validator --validator-addr one1vzsj3julf0ljcj3hhxuqpu6zvadu488zfrtttz --active true # Check the node version ./node.sh -V # Look at the logs tail -f ./latest/*.log # Grab the logs cd /Users/johnwhitton/projects/staking/OSTN/logs/sentry2 scp -i ~/.ssh/keys/SentryOSTN.pem ec2-user@3.21.169.132:/home/ec2-user/latest/* . {% endtab %} {% tab title=\"STN\" %} ./node_ssh.sh 52.42.43.150 tmux attach -t node Register the Validator ./hmy --node=\"https://api.s0.stn.hmny.io\" staking create-validator --validator-addr one1vzsj3julf0ljcj3hhxuqpu6zvadu488zfrtttz --name OSTNSentry0.1 --identity OSTNSentry2 --website sentry@harmony.one --security-contact Sentry --details \"OSTN Sentry for Shard 2 t3.small\" --rate 0.05 --max-rate 0.8 --max-change-rate 0.02 --min-self-delegation 10000 --max-total-delegation 10000000 --bls-pubkeys 463298d9357ddb336038a122b84549b0589597214e28f12b7816f09b554fd4c935437f25eb1720bae923fcb070b3e596 --amount 10000 # Restart the node ./node.sh -S -z -I -P -r localhost:6060 -N stress -k 463298d9357ddb336038a122b84549b0589597214e28f12b7816f09b554fd4c935437f25eb1720bae923fcb070b3e596.key # Restart the node and CLEAN out blockchain curl -LO https://harmony.one/hmycli && mv hmycli hmy && chmod +x hmy curl -LO https://raw.githubusercontent.com/harmony-one/harmony/master/scripts/node.sh && chmod a+x node.sh rm -rf harmony_db* ./node.sh -S -c -z -I -P -R localhost:6060 -N stress -k 463298d9357ddb336038a122b84549b0589597214e28f12b7816f09b554fd4c935437f25eb1720bae923fcb070b3e596.key # Check that it's earning ./hmy --node=\"https://api.s0.stn.hmny.io\" blockchain validator information one1vzsj3julf0ljcj3hhxuqpu6zvadu488zfrtttz # Mark it active ./hmy -n https://api.s0.stn.hmny.io staking edit-validator --validator-addr one1vzsj3julf0ljcj3hhxuqpu6zvadu488zfrtttz --active true # Check the node version ./node.sh -V # Look at the logs tail -f ./latest/*.log {% endtab %} {% endtabs %} Sentry 3 one1marnnvc8hywmfxhrc8mtpjkvvdt32x9kxtwkvv {% tabs %} {% tab title=\"OSTN\" %} exec ssh -i ~/.ssh/keys/SentryOSTN.pem ec2-user@18.221.69.247 # tmux attach tmux att # Fund the account ./hmy --node=\"\"https://api.s0.os.hmny.io/\"\" transfer --from one14hd35aj7xvuq3vg4grnv2umkxkazcmjq68hpwh --to one1marnnvc8hywmfxhrc8mtpjkvvdt32x9kxtwkvv --from-shard 0 --to-shard 0 --amount 1000 Register the Validator ./hmy --node=\"https://api.s0.os.hmny.io\" staking create-validator --validator-addr one1marnnvc8hywmfxhrc8mtpjkvvdt32x9kxtwkvv --name OSTNSentry3 --identity OSTNSentry3 --website sentry@harmony.one --security-contact Sentry --details \"OSTN Sentry for Shard 3 t3.small\" --rate 0.05 --max-rate 0.8 --max-change-rate 0.02 --min-self-delegation 10000 --max-total-delegation 10000000 --bls-pubkeys 5aff3653958fdddefe04aaeb5e9c4a4fc7dda03538a04fd8dfd139c66d18ec31c7deb846cb67077fde48921ddb07a387 --amount 10000 # Restart the node ./node.sh -S -z -I -P -N staking -k 5aff3653958fdddefe04aaeb5e9c4a4fc7dda03538a04fd8dfd139c66d18ec31c7deb846cb67077fde48921ddb07a387.key # Restart the node and CLEAN out blockchain curl -LO https://raw.githubusercontent.com/harmony-one/harmony/master/scripts/node.sh && chmod a+x node.sh rm -rf harmony_db* ./node.sh -S -c -z -I -P -r localhost:6060 -N staking -k 5aff3653958fdddefe04aaeb5e9c4a4fc7dda03538a04fd8dfd139c66d18ec31c7deb846cb67077fde48921ddb07a387.key # Check that it's earning ./hmy --node=\"https://api.s0.os.hmny.io\" blockchain validator information one1marnnvc8hywmfxhrc8mtpjkvvdt32x9kxtwkvv # Mark it active ./hmy -n https://api.s0.os.hmny.io staking edit-validator --validator-addr one1marnnvc8hywmfxhrc8mtpjkvvdt32x9kxtwkvv --active true # Check the node version ./node.sh -V # Look at the logs tail -f ./latest/*.log # Grab the logs cd /Users/johnwhitton/projects/staking/OSTN/logs/sentry3 scp -i ~/.ssh/keys/SentryOSTN.pem ec2-user@18.221.69.247:/home/ec2-user/latest/* . {% endtab %} {% tab title=\"STN\" %} ./node_ssh.sh 54.188.46.48 {% endtab %} {% endtabs %} Johns own validator - one1y5n7p8a845v96xyx2gh75wn5eyhtw5002lah27 {% tabs %} {% tab title=\"OSTN\" %} exec ssh -i ~/.ssh/keys/JOHN_OSTN_VALIDATOR_1.pem ec2-user@3.16.31.148 exec ssh -i ~/.ssh/keys/SentryOSTN.pem ec2-user@18.221.69.247 # Restart the node and CLEAN out blockchain curl -LO https://raw.githubusercontent.com/harmony-one/harmony/master/scripts/node.sh && chmod a+x node.sh rm -rf harmony_db* ./node.sh -S -c -z -I -P -r localhost:6060 -N staking -M # Check the node version ./node.sh -V # Check that it's earning ./hmy --node=\"https://api.s0.os.hmny.io\" blockchain validator information one1y5n7p8a845v96xyx2gh75wn5eyhtw5002lah27 # Register the Validator ./hmy --node=\"https://api.s0.os.hmny.io\" staking create-validator --validator-addr one1y5n7p8a845v96xyx2gh75wn5eyhtw5002lah27 --name JohnV1 --identity JohnV1 --website john@harmony.one --security-contact Sentry --details \"John Validator t3.small\" --rate 0.05 --max-rate 0.8 --max-change-rate 0.02 --min-self-delegation 10000 --max-total-delegation 10000000 --bls-pubkeys e65ce96e41d54d49243e2294fb306768862cccd5be80347f88bafe13aa4d3582c21c613fc26f6908ed1faa0dd0c27381,b3815c62affe89560ecabb2f30de46742c927e8a951f37f080264d0b394e16b55ea0786629798d0170c713a9779e4585,b9626bcf02210e8979b0e661bbdbf2e5a691105761fd8800bd1e96087a57c393285af91dcf3c3d6763a643d874f14599 --amount 10000 # Mark it active ./hmy -n https://api.s0.os.hmny.io staking edit-validator --validator-addr one1marnnvc8hywmfxhrc8mtpjkvvdt32x9kxtwkvv --active true ./hmy -n https://api.s0.os.hmny.io staking edit-validator --validator-addr one1y5n7p8a845v96xyx2gh75wn5eyhtw5002lah27 --active true # Look at the logs tail -f ./latest/*.log # Grab the logs cd /Users/johnwhitton/projects/staking/OSTN/logs/johnv1 scp -i ~/.ssh/keys/JOHN_OSTN_VALIDATOR_1.pem ec2-user@3.16.31.148:/home/ec2-user/latest/* . {% endtab %} {% tab title=\"STN\" %} mydesktop.sh tmux attach -t node Register the Validator ./hmy --node=\"https://api.s0.stn.hmny.io\" staking create-validator --validator-addr one1y5n7p8a845v96xyx2gh75wn5eyhtw5002lah27 --name JWValidator0 --identity JWValidator0 --website john@harmony.one --security-contact Sentry --details \"STN John Validator run from mydesktop c5a\" --rate 0.05 --max-rate 0.8 --max-change-rate 0.02 --min-self-delegation 10000 --max-total-delegation 10000000 --bls-pubkeys fce9a848df51e04e03db27de7b65bbaed950afee7b0b063d00849cc3500c2dbe0ad69639ed8c66210ab0b9ab752c9d0f --amount 10000 # Restart the node ./node.sh -S -z -I -P -R localhost:6060 -N stress -k fce9a848df51e04e03db27de7b65bbaed950afee7b0b063d00849cc3500c2dbe0ad69639ed8c66210ab0b9ab752c9d0f.key # Restart the node and CLEAN out blockchain curl -LO https://harmony.one/hmycli && mv hmycli hmy && chmod +x hmy curl -LO https://raw.githubusercontent.com/harmony-one/harmony/master/scripts/node.sh && chmod a+x node.sh rm -rf harmony_db* ./node.sh -S -c -z -I -P -R localhost:6060 -N stress -k fce9a848df51e04e03db27de7b65bbaed950afee7b0b063d00849cc3500c2dbe0ad69639ed8c66210ab0b9ab752c9d0f.key # Check that it's earning ./hmy --node=\"https://api.s0.stn.hmny.io\" blockchain validator information one1y5n7p8a845v96xyx2gh75wn5eyhtw5002lah27 # Mark it active ./hmy -n https://api.s0.stn.hmny.io staking edit-validator --validator-addr one1y5n7p8a845v96xyx2gh75wn5eyhtw5002lah27 --active true # Check the node version ./node.sh -V # Look at the logs tail -f ./latest/*.log {% endtab %} {% endtabs %} Multi BLS Key Setup # Create Multiple keys for the same shard ## Create the Keys ./hmy keys generate-bls-key ## Check the shard ./hmy --node=\"https://api.s0.os.hmny.io\" utility shard-for-bls b3815c62affe89560ecabb2f30de46742c927e8a951f37f080264d0b394e16b55ea0786629798d0170c713a9779e4585 # Stop the node ## Set up the BLS Key Folders mkdir -p .hmy/blskeys ## Move the BLS Keys into the folder cp *.key .hmy/blskeys ## Start the node ./node.sh -S -c -z -I -P -R localhost:6070 -N staking -M ## Update your Validator ./hmy -n https://api.s0.os.hmny.io staking edit-validator --validator-addr one1y5n7p8a845v96xyx2gh75wn5eyhtw5002lah27 --add-bls-key b3815c62affe89560ecabb2f30de46742c927e8a951f37f080264d0b394e16b55ea0786629798d0170c713a9779e4585 ./hmy -n https://api.s0.os.hmny.io staking edit-validator --validator-addr one1y5n7p8a845v96xyx2gh75wn5eyhtw5002lah27 --add-bls-key b9626bcf02210e8979b0e661bbdbf2e5a691105761fd8800bd1e96087a57c393285af91dcf3c3d6763a643d874f14599 # Check your validator ./hmy --node=\"https://api.s0.os.hmny.io\" blockchain validator information one1y5n7p8a845v96xyx2gh75wn5eyhtw5002lah27 Troubleshooting tail -f ./latest/*.log tail -f ./latest/*.log | grep Height tail -f ./latest/*.log | grep SYNC tail -f ./latest/*.log | grep OnAnnounce tail -f ./latest/*.log | grep OnPrepared ./hmy --node=\"https://api.s0.os.hmny.io\" blockchain validator information one1m6j80t6rhc3ypaumtsfmqwjwp0mrqk9ff50prh tac ./latest/*.log | grep invalid cat ./latest/*.log | grep invalid cat ./latest/*.log | grep \"error\" ./run_on_shard.sh -p os -T 2 \"tac ../tmp_log/*/zerolog-*.log | grep -m 1 myViewID\"","title":"Sentry Deployment"},{"location":"deploy/cicd/netdeploy/network-release/sentry-deployment/#sentry-deployment","text":"{% hint style=\"info\" %} For access to the Sentry node ask john@harmony.one {% endhint %} {% hint style=\"info\" %} To run in profiling mode use -R localhost:6070 and here are instructions on how to query it {% endhint %} {% hint style=\"success\" %} For docker autocreation of sentries see https://github.com/harmony-one/harmony-ops/tree/master/devops/auto_node {% endhint %} Overview Harmony runs a sentry node for each shard on OSTN. This is spun up using the same process as the validators to ensure that validates can earn rewards. These sentry nodes are critical for rolling upgrades and should be upgraded before the rolling upgrade begins. Also here is a sample script to register validators written by Edgar. The four sentries are listed below as well as a link to the pem key to connect to them. To copy a pem from your local machine to devops machine scp -i ~/.ssh/keys/oregon-key-benchmark.pem ~/.ssh/keys/JOHN_OSTN_VALIDATOR_1.pem ec2-user@35.160.64.190:/home/ec2-user/.ssh/keys/","title":"Sentry Deployment"},{"location":"deploy/cicd/netdeploy/network-release/sentry-deployment/#autonodes","text":"{% tabs %} {% tab title=\"OSTN\" %} # Sentry 0 - one1m6j80t6rhc3ypaumtsfmqwjwp0mrqk9ff50prh # afc4d81ab636323b04893c23d3404f38e95e9291b3d5299dade3d03822edd3a2b799bd6d64265a9a9cac025d5dbd600c.key exec ssh -i ~/.ssh/keys/harmony-testnet.pem ec2-user@13.59.156.175 # Sentry 1 - one10fjqteq6q75nm62cx8vejqsk7mc8t5hle8ewnl # 552f8aa65835f04e4bc3a04a4bd1f5c67dcd562513b6728c5b9fd258d9fdb054c10008b14a739818d0c234d37b8f1301.key exec ssh -i ~/.ssh/keys/harmony-testnet.pem ec2-user@18.188.241.110 # Sentry 2 - one1vzsj3julf0ljcj3hhxuqpu6zvadu488zfrtttz # a2232487bbf16dd01c5743700712819984d036bf3e39960c85045920784ba0d24149c93591dd4017ada3155e8105d402.key exec ssh -i ~/.ssh/keys/harmony-testnet.pem ec2-user@13.59.11.174 # Sentry 3 - Sentry 3 one1marnnvc8hywmfxhrc8mtpjkvvdt32x9kxt # 5aff3653958fdddefe04aaeb5e9c4a4fc7dda03538a04fd8dfd139c66d18ec31c7deb846cb67077fde48921ddb07a387.key exec ssh -i ~/.ssh/keys/harmony-testnet.pem ec2-user@3.22.97.78 ./auto_node.sh node-version ./auto_node.sh attach {% endtab %} {% tab title=\"STN\" %} {% endtab %} {% endtabs %}","title":"Autonodes"},{"location":"deploy/cicd/netdeploy/network-release/sentry-deployment/#sentry-0-one1m6j80t6rhc3ypaumtsfmqwjwp0mrqk9ff50prh","text":"{% tabs %} {% tab title=\"OSTN\" %} # Log into the machine can do this from devops machine or your local exec ssh -i ~/.ssh/keys/SentryOSTN.pem ec2-user@3.21.53.63 # tmux attach tmux att Register the Validator ./hmy --node=\"https://api.s0.os.hmny.io\" staking create-validator --validator-addr one1m6j80t6rhc3ypaumtsfmqwjwp0mrqk9ff50prh --name OSTNSentry0 --identity OSTNSentry0 --website sentry@harmony.one --security-contact Sentry --details \"OSTN Sentry for Shard 0 t3.small\" --rate 0.05 --max-rate 0.8 --max-change-rate 0.02 --min-self-delegation 10000 --max-total-delegation 100000 --bls-pubkeys afc4d81ab636323b04893c23d3404f38e95e9291b3d5299dade3d03822edd3a2b799bd6d64265a9a9cac025d5dbd600c --amount 100000 # Restart the node ./node.sh -S -z -I -P -N staking -k afc4d81ab636323b04893c23d3404f38e95e9291b3d5299dade3d03822edd3a2b799bd6d64265a9a9cac025d5dbd600c.key # Restart the node and CLEAN out blockchain curl -LO https://raw.githubusercontent.com/harmony-one/harmony/master/scripts/node.sh && chmod a+x node.sh rm -rf harmony_db* ./node.sh -S -c -z -I -P -r localhost:6060 -N staking -k afc4d81ab636323b04893c23d3404f38e95e9291b3d5299dade3d03822edd3a2b799bd6d64265a9a9cac025d5dbd600c.key # Check that it's earning ./hmy --node=\"https://api.s0.os.hmny.io\" blockchain validator information one1m6j80t6rhc3ypaumtsfmqwjwp0mrqk9ff50prh # Mark it active ./hmy -n https://api.s0.os.hmny.io staking edit-validator --validator-addr one1m6j80t6rhc3ypaumtsfmqwjwp0mrqk9ff50prh --active true ./hmy -n https://api.s0.os.hmny.io staking edit-validator --validator-addr one1m6j80t6rhc3ypaumtsfmqwjwp0mrqk9ff50prh --name \"OSTN-SENTRY-0\" # Check the node version ./node.sh -V # Look at the logs tail -f ./latest/*.log # Grab the logs cd /Users/johnwhitton/projects/staking/OSTN/logs/sentry0 scp -i ~/.ssh/keys/SentryOSTN.pem ec2-user@3.21.53.63:/home/ec2-user/latest/* . {% endtab %} {% tab title=\"STN\" %} # https://gist.github.com/Daniel-VDM/fe15ccd0561ba23ef7e0007b33b08d8f # https://github.com/harmony-one/harmony-ops/tree/master/devops/auto_node ./node_ssh.sh 52.11.85.154 tmux att ./auto_node.sh run --shard 0 --auto-active --clean --network stress --beacon-endpoint https://api.s0.stn.hmny.io/ # Get validator information ./hmy --node=\"https://api.s0.stn.hmny.io\" blockchain validator information one1m6j80t6rhc3ypaumtsfmqwjwp0mrqk9ff50prh # Removing a bls key ./hmy staking --node=\"https://api.s0.stn.hmny.io\" edit-validator --validator-addr one1m6j80t6rhc3ypaumtsfmqwjwp0mrqk9ff50prh --remove-bls-key 605569a402ff52e703cd3d66f3bc0a08be4955c8d2700d1581740ffed8e545f73736de350183cd30e50b06e1b880d605 # Validator Config { \"validator-addr\": \"one1m6j80t6rhc3ypaumtsfmqwjwp0mrqk9ff50prh\", \"name\": \"STN-Sentry-0-autonode-t3.small\", \"website\": \"harmony.one\", \"security-contact\": \"john@harmony.one\", \"identity\": \"STN-Sentry-0-auto-node\", \"amount\": 10100, \"min-self-delegation\": 10000, \"rate\": 0.1, \"max-rate\": 0.75, \"max-change-rate\": 0.05, \"max-total-delegation\": 1000000.0, \"details\": \"None\" } {% endtab %} {% endtabs %}","title":"Sentry 0 - one1m6j80t6rhc3ypaumtsfmqwjwp0mrqk9ff50prh"},{"location":"deploy/cicd/netdeploy/network-release/sentry-deployment/#sentry-1-one10fjqteq6q75nm62cx8vejqsk7mc8t5hle8ewnl","text":"{% tabs %} {% tab title=\"OSTN\" %} ssh -i ~/.ssh/keys/SentryOSTN.pem ec2-user@18.218.200.47 # tmux attach tmux att # Fund the account ./hmy --node=\"\"https://api.s0.os.hmny.io/\"\" transfer --from one14hd35aj7xvuq3vg4grnv2umkxkazcmjq68hpwh --to one10fjqteq6q75nm62cx8vejqsk7mc8t5hle8ewnl --from-shard 0 --to-shard 0 --amount 110000 Register the Validator ./hmy --node=\"https://api.s0.os.hmny.io\" staking create-validator --validator-addr one10fjqteq6q75nm62cx8vejqsk7mc8t5hle8ewnl --name OSTNSentry1 --identity OSTNSentry1 --website sentry@harmony.one --security-contact Sentry --details \"OSTN Sentry for Shard 1 t3.small\" --rate 0.05 --max-rate 0.8 --max-change-rate 0.02 --min-self-delegation 10000 --max-total-delegation 1000000 --bls-pubkeys 552f8aa65835f04e4bc3a04a4bd1f5c67dcd562513b6728c5b9fd258d9fdb054c10008b14a739818d0c234d37b8f1301 --amount 10000 # Restart the node ./node.sh -S -z -I -P -N staking -k 552f8aa65835f04e4bc3a04a4bd1f5c67dcd562513b6728c5b9fd258d9fdb054c10008b14a739818d0c234d37b8f1301.key # Restart the node and CLEAN out blockchain curl -LO https://raw.githubusercontent.com/harmony-one/harmony/master/scripts/node.sh && chmod a+x node.sh rm -rf harmony_db* ./node.sh -S -c -z -I -P -r localhost:6060 -N staking -k 552f8aa65835f04e4bc3a04a4bd1f5c67dcd562513b6728c5b9fd258d9fdb054c10008b14a739818d0c234d37b8f1301.key # Check that it's earning ./hmy --node=\"https://api.s0.os.hmny.io\" blockchain validator information one10fjqteq6q75nm62cx8vejqsk7mc8t5hle8ewnl # Mark it active ./hmy -n https://api.s0.os.hmny.io staking edit-validator --validator-addr one10fjqteq6q75nm62cx8vejqsk7mc8t5hle8ewnl --active true # Check the node version ./node.sh -V # Look at the logs tail -f ./latest/*.log # Grab the logs cd /Users/johnwhitton/projects/staking/OSTN/logs/sentry1 scp -i ~/.ssh/keys/SentryOSTN.pem ec2-user@18.218.200.47:/home/ec2-user/latest/* . {% endtab %} {% tab title=\"STN\" %} # https://gist.github.com/Daniel-VDM/fe15ccd0561ba23ef7e0007b33b08d8f # https://github.com/harmony-one/harmony-ops/tree/master/devops/auto_node ./node_ssh.sh 54.202.197.141 curl -LO https://harmony.one/hmycli && mv hmycli hmy && chmod +x hmy && sudo yum update -y && sudo yum install -y docker && sudo usermod -aG docker ec2-user && sudo service docker start && sudo yum install -y tmux && exit curl -O https://raw.githubusercontent.com/harmony-one/harmony-ops/master/devops/auto_node/scripts/auto_node.sh && chmod +x ./auto_node.sh && ./auto_node.sh setup ./hmy keys list ./hmy keys import-private-key <<KEY>> STNSentry1 tmux att ./auto_node.sh run --shard 1 --auto-active --clean --network stress --beacon-endpoint https://api.s0.stn.hmny.io/ # Get validator information ./hmy --node=\"https://api.s0.stn.hmny.io\" blockchain validator information one10fjqteq6q75nm62cx8vejqsk7mc8t5hle8ewnl # Removing a bls key ./hmy staking --node=\"https://api.s0.stn.hmny.io\" edit-validator --validator-addr one10fjqteq6q75nm62cx8vejqsk7mc8t5hle8ewnl --remove-bls-key 567fb7398184c382d92bf6b568e79363c9d7c238b261b456d280882c6a0ad42e7367ec57596b366a86b454dd53a93215 # Validator Config { \"validator-addr\": \"one10fjqteq6q75nm62cx8vejqsk7mc8t5hle8ewnl\", \"name\": \"STN-Sentry-1-autonode-t3.small\", \"website\": \"harmony.one\", \"security-contact\": \"john@harmony.one\", \"identity\": \"STN-Sentry-1-auto-node\", \"amount\": 10100, \"min-self-delegation\": 10000, \"rate\": 0.1, \"max-rate\": 0.75, \"max-change-rate\": 0.05, \"max-total-delegation\": 1000000.0, \"details\": \"None\" } {% endtab %} {% endtabs %}","title":"Sentry 1 - one10fjqteq6q75nm62cx8vejqsk7mc8t5hle8ewnl"},{"location":"deploy/cicd/netdeploy/network-release/sentry-deployment/#sentry-2-one1vzsj3julf0ljcj3hhxuqpu6zvadu488zfrtttz","text":"{% tabs %} {% tab title=\"OSTN\" %} exec ssh -i ~/.ssh/keys/SentryOSTN.pem ec2-user@3.21.169.132 # tmux attach tmux att # Fund the account ./hmy --node=\"\"https://api.s0.os.hmny.io/\"\" transfer --from one14hd35aj7xvuq3vg4grnv2umkxkazcmjq68hpwh --to one1vzsj3julf0ljcj3hhxuqpu6zvadu488zfrtttz --from-shard 0 --to-shard 0 --amount 1000 Register the Validator ./hmy --node=\"https://api.s0.os.hmny.io\" staking create-validator --validator-addr one1vzsj3julf0ljcj3hhxuqpu6zvadu488zfrtttz --name OSTNSentry2 --identity OSTNSentry2 --website sentry@harmony.one --security-contact Sentry --details \"OSTN Sentry for Shard 2 t3.small\" --rate 0.05 --max-rate 0.8 --max-change-rate 0.02 --min-self-delegation 10000 --max-total-delegation 10000000 --bls-pubkeys a2232487bbf16dd01c5743700712819984d036bf3e39960c85045920784ba0d24149c93591dd4017ada3155e8105d402 --amount 10000 # Restart the node ./node.sh -S -z -I -P -r localhost:6060 -N staking -k a2232487bbf16dd01c5743700712819984d036bf3e39960c85045920784ba0d24149c93591dd4017ada3155e8105d402.key # Restart the node and CLEAN out blockchain curl -LO https://raw.githubusercontent.com/harmony-one/harmony/master/scripts/node.sh && chmod a+x node.sh rm -rf harmony_db* ./node.sh -S -c -z -I -P -r localhost:6060 -N staking -k a2232487bbf16dd01c5743700712819984d036bf3e39960c85045920784ba0d24149c93591dd4017ada3155e8105d402.key # Check that it's earning ./hmy --node=\"https://api.s0.os.hmny.io\" blockchain validator information one1vzsj3julf0ljcj3hhxuqpu6zvadu488zfrtttz # Mark it active ./hmy -n https://api.s0.os.hmny.io staking edit-validator --validator-addr one1vzsj3julf0ljcj3hhxuqpu6zvadu488zfrtttz --active true # Check the node version ./node.sh -V # Look at the logs tail -f ./latest/*.log # Grab the logs cd /Users/johnwhitton/projects/staking/OSTN/logs/sentry2 scp -i ~/.ssh/keys/SentryOSTN.pem ec2-user@3.21.169.132:/home/ec2-user/latest/* . {% endtab %} {% tab title=\"STN\" %} ./node_ssh.sh 52.42.43.150 tmux attach -t node Register the Validator ./hmy --node=\"https://api.s0.stn.hmny.io\" staking create-validator --validator-addr one1vzsj3julf0ljcj3hhxuqpu6zvadu488zfrtttz --name OSTNSentry0.1 --identity OSTNSentry2 --website sentry@harmony.one --security-contact Sentry --details \"OSTN Sentry for Shard 2 t3.small\" --rate 0.05 --max-rate 0.8 --max-change-rate 0.02 --min-self-delegation 10000 --max-total-delegation 10000000 --bls-pubkeys 463298d9357ddb336038a122b84549b0589597214e28f12b7816f09b554fd4c935437f25eb1720bae923fcb070b3e596 --amount 10000 # Restart the node ./node.sh -S -z -I -P -r localhost:6060 -N stress -k 463298d9357ddb336038a122b84549b0589597214e28f12b7816f09b554fd4c935437f25eb1720bae923fcb070b3e596.key # Restart the node and CLEAN out blockchain curl -LO https://harmony.one/hmycli && mv hmycli hmy && chmod +x hmy curl -LO https://raw.githubusercontent.com/harmony-one/harmony/master/scripts/node.sh && chmod a+x node.sh rm -rf harmony_db* ./node.sh -S -c -z -I -P -R localhost:6060 -N stress -k 463298d9357ddb336038a122b84549b0589597214e28f12b7816f09b554fd4c935437f25eb1720bae923fcb070b3e596.key # Check that it's earning ./hmy --node=\"https://api.s0.stn.hmny.io\" blockchain validator information one1vzsj3julf0ljcj3hhxuqpu6zvadu488zfrtttz # Mark it active ./hmy -n https://api.s0.stn.hmny.io staking edit-validator --validator-addr one1vzsj3julf0ljcj3hhxuqpu6zvadu488zfrtttz --active true # Check the node version ./node.sh -V # Look at the logs tail -f ./latest/*.log {% endtab %} {% endtabs %}","title":"Sentry 2 - one1vzsj3julf0ljcj3hhxuqpu6zvadu488zfrtttz"},{"location":"deploy/cicd/netdeploy/network-release/sentry-deployment/#sentry-3-one1marnnvc8hywmfxhrc8mtpjkvvdt32x9kxtwkvv","text":"{% tabs %} {% tab title=\"OSTN\" %} exec ssh -i ~/.ssh/keys/SentryOSTN.pem ec2-user@18.221.69.247 # tmux attach tmux att # Fund the account ./hmy --node=\"\"https://api.s0.os.hmny.io/\"\" transfer --from one14hd35aj7xvuq3vg4grnv2umkxkazcmjq68hpwh --to one1marnnvc8hywmfxhrc8mtpjkvvdt32x9kxtwkvv --from-shard 0 --to-shard 0 --amount 1000 Register the Validator ./hmy --node=\"https://api.s0.os.hmny.io\" staking create-validator --validator-addr one1marnnvc8hywmfxhrc8mtpjkvvdt32x9kxtwkvv --name OSTNSentry3 --identity OSTNSentry3 --website sentry@harmony.one --security-contact Sentry --details \"OSTN Sentry for Shard 3 t3.small\" --rate 0.05 --max-rate 0.8 --max-change-rate 0.02 --min-self-delegation 10000 --max-total-delegation 10000000 --bls-pubkeys 5aff3653958fdddefe04aaeb5e9c4a4fc7dda03538a04fd8dfd139c66d18ec31c7deb846cb67077fde48921ddb07a387 --amount 10000 # Restart the node ./node.sh -S -z -I -P -N staking -k 5aff3653958fdddefe04aaeb5e9c4a4fc7dda03538a04fd8dfd139c66d18ec31c7deb846cb67077fde48921ddb07a387.key # Restart the node and CLEAN out blockchain curl -LO https://raw.githubusercontent.com/harmony-one/harmony/master/scripts/node.sh && chmod a+x node.sh rm -rf harmony_db* ./node.sh -S -c -z -I -P -r localhost:6060 -N staking -k 5aff3653958fdddefe04aaeb5e9c4a4fc7dda03538a04fd8dfd139c66d18ec31c7deb846cb67077fde48921ddb07a387.key # Check that it's earning ./hmy --node=\"https://api.s0.os.hmny.io\" blockchain validator information one1marnnvc8hywmfxhrc8mtpjkvvdt32x9kxtwkvv # Mark it active ./hmy -n https://api.s0.os.hmny.io staking edit-validator --validator-addr one1marnnvc8hywmfxhrc8mtpjkvvdt32x9kxtwkvv --active true # Check the node version ./node.sh -V # Look at the logs tail -f ./latest/*.log # Grab the logs cd /Users/johnwhitton/projects/staking/OSTN/logs/sentry3 scp -i ~/.ssh/keys/SentryOSTN.pem ec2-user@18.221.69.247:/home/ec2-user/latest/* . {% endtab %} {% tab title=\"STN\" %} ./node_ssh.sh 54.188.46.48 {% endtab %} {% endtabs %}","title":"Sentry 3 one1marnnvc8hywmfxhrc8mtpjkvvdt32x9kxtwkvv"},{"location":"deploy/cicd/netdeploy/network-release/sentry-deployment/#johns-own-validator-one1y5n7p8a845v96xyx2gh75wn5eyhtw5002lah27","text":"{% tabs %} {% tab title=\"OSTN\" %} exec ssh -i ~/.ssh/keys/JOHN_OSTN_VALIDATOR_1.pem ec2-user@3.16.31.148 exec ssh -i ~/.ssh/keys/SentryOSTN.pem ec2-user@18.221.69.247 # Restart the node and CLEAN out blockchain curl -LO https://raw.githubusercontent.com/harmony-one/harmony/master/scripts/node.sh && chmod a+x node.sh rm -rf harmony_db* ./node.sh -S -c -z -I -P -r localhost:6060 -N staking -M # Check the node version ./node.sh -V # Check that it's earning ./hmy --node=\"https://api.s0.os.hmny.io\" blockchain validator information one1y5n7p8a845v96xyx2gh75wn5eyhtw5002lah27 # Register the Validator ./hmy --node=\"https://api.s0.os.hmny.io\" staking create-validator --validator-addr one1y5n7p8a845v96xyx2gh75wn5eyhtw5002lah27 --name JohnV1 --identity JohnV1 --website john@harmony.one --security-contact Sentry --details \"John Validator t3.small\" --rate 0.05 --max-rate 0.8 --max-change-rate 0.02 --min-self-delegation 10000 --max-total-delegation 10000000 --bls-pubkeys e65ce96e41d54d49243e2294fb306768862cccd5be80347f88bafe13aa4d3582c21c613fc26f6908ed1faa0dd0c27381,b3815c62affe89560ecabb2f30de46742c927e8a951f37f080264d0b394e16b55ea0786629798d0170c713a9779e4585,b9626bcf02210e8979b0e661bbdbf2e5a691105761fd8800bd1e96087a57c393285af91dcf3c3d6763a643d874f14599 --amount 10000 # Mark it active ./hmy -n https://api.s0.os.hmny.io staking edit-validator --validator-addr one1marnnvc8hywmfxhrc8mtpjkvvdt32x9kxtwkvv --active true ./hmy -n https://api.s0.os.hmny.io staking edit-validator --validator-addr one1y5n7p8a845v96xyx2gh75wn5eyhtw5002lah27 --active true # Look at the logs tail -f ./latest/*.log # Grab the logs cd /Users/johnwhitton/projects/staking/OSTN/logs/johnv1 scp -i ~/.ssh/keys/JOHN_OSTN_VALIDATOR_1.pem ec2-user@3.16.31.148:/home/ec2-user/latest/* . {% endtab %} {% tab title=\"STN\" %} mydesktop.sh tmux attach -t node Register the Validator ./hmy --node=\"https://api.s0.stn.hmny.io\" staking create-validator --validator-addr one1y5n7p8a845v96xyx2gh75wn5eyhtw5002lah27 --name JWValidator0 --identity JWValidator0 --website john@harmony.one --security-contact Sentry --details \"STN John Validator run from mydesktop c5a\" --rate 0.05 --max-rate 0.8 --max-change-rate 0.02 --min-self-delegation 10000 --max-total-delegation 10000000 --bls-pubkeys fce9a848df51e04e03db27de7b65bbaed950afee7b0b063d00849cc3500c2dbe0ad69639ed8c66210ab0b9ab752c9d0f --amount 10000 # Restart the node ./node.sh -S -z -I -P -R localhost:6060 -N stress -k fce9a848df51e04e03db27de7b65bbaed950afee7b0b063d00849cc3500c2dbe0ad69639ed8c66210ab0b9ab752c9d0f.key # Restart the node and CLEAN out blockchain curl -LO https://harmony.one/hmycli && mv hmycli hmy && chmod +x hmy curl -LO https://raw.githubusercontent.com/harmony-one/harmony/master/scripts/node.sh && chmod a+x node.sh rm -rf harmony_db* ./node.sh -S -c -z -I -P -R localhost:6060 -N stress -k fce9a848df51e04e03db27de7b65bbaed950afee7b0b063d00849cc3500c2dbe0ad69639ed8c66210ab0b9ab752c9d0f.key # Check that it's earning ./hmy --node=\"https://api.s0.stn.hmny.io\" blockchain validator information one1y5n7p8a845v96xyx2gh75wn5eyhtw5002lah27 # Mark it active ./hmy -n https://api.s0.stn.hmny.io staking edit-validator --validator-addr one1y5n7p8a845v96xyx2gh75wn5eyhtw5002lah27 --active true # Check the node version ./node.sh -V # Look at the logs tail -f ./latest/*.log {% endtab %} {% endtabs %}","title":"Johns own validator - one1y5n7p8a845v96xyx2gh75wn5eyhtw5002lah27"},{"location":"deploy/cicd/netdeploy/network-release/sentry-deployment/#multi-bls-key-setup","text":"# Create Multiple keys for the same shard ## Create the Keys ./hmy keys generate-bls-key ## Check the shard ./hmy --node=\"https://api.s0.os.hmny.io\" utility shard-for-bls b3815c62affe89560ecabb2f30de46742c927e8a951f37f080264d0b394e16b55ea0786629798d0170c713a9779e4585 # Stop the node ## Set up the BLS Key Folders mkdir -p .hmy/blskeys ## Move the BLS Keys into the folder cp *.key .hmy/blskeys ## Start the node ./node.sh -S -c -z -I -P -R localhost:6070 -N staking -M ## Update your Validator ./hmy -n https://api.s0.os.hmny.io staking edit-validator --validator-addr one1y5n7p8a845v96xyx2gh75wn5eyhtw5002lah27 --add-bls-key b3815c62affe89560ecabb2f30de46742c927e8a951f37f080264d0b394e16b55ea0786629798d0170c713a9779e4585 ./hmy -n https://api.s0.os.hmny.io staking edit-validator --validator-addr one1y5n7p8a845v96xyx2gh75wn5eyhtw5002lah27 --add-bls-key b9626bcf02210e8979b0e661bbdbf2e5a691105761fd8800bd1e96087a57c393285af91dcf3c3d6763a643d874f14599 # Check your validator ./hmy --node=\"https://api.s0.os.hmny.io\" blockchain validator information one1y5n7p8a845v96xyx2gh75wn5eyhtw5002lah27","title":"Multi BLS Key Setup"},{"location":"deploy/cicd/netdeploy/network-release/sentry-deployment/#troubleshooting","text":"tail -f ./latest/*.log tail -f ./latest/*.log | grep Height tail -f ./latest/*.log | grep SYNC tail -f ./latest/*.log | grep OnAnnounce tail -f ./latest/*.log | grep OnPrepared ./hmy --node=\"https://api.s0.os.hmny.io\" blockchain validator information one1m6j80t6rhc3ypaumtsfmqwjwp0mrqk9ff50prh tac ./latest/*.log | grep invalid cat ./latest/*.log | grep invalid cat ./latest/*.log | grep \"error\" ./run_on_shard.sh -p os -T 2 \"tac ../tmp_log/*/zerolog-*.log | grep -m 1 myViewID\"","title":"Troubleshooting"},{"location":"deploy/cicd/netdeploy/network-release/staking-dashboard-deployment/","text":"Staking Dashboard Deployment {% hint style=\"info\" %} When refreshing a network you can delete staking history via a web browser. For example for Stressnet click here and then press delete collection. Note you will still need to restart the appengine to flush the cache (see below) {% endhint %} Overview The staking explorer is provides the ability to stake validators on the Harmony Protocol. It supports multiple networks and is integrated with multiple wallets including the Harmony Chrome Extension. The code is open source and is stored in staking-dashboard . This document will give an overview of the key components, repositories and the deployment Process Components Persistance Layer The Persistence Layer uses firebase Backend Logic The staking dashboard backend is written using node.js and is deployed on Google App Engine . Frontend Logic The staking dashboard frontend is written in vue.js Deployment Environments All networks are supported by the one app engine project and one firebase project with configuration being held at the firebase level for the network information Google App Engine Project - staking explorer2 Firebase Project - staking explorer Network Configuration - Mainnet - Partner Testnet , OSTN Deployment Setup Administrative Credentials In order to deploy and administer staking explorer you will need to have your harmony google account authorized to the above Projects Gcloud SDK You will also need to install the gcloud SDK . Clone Staking Dashboard You will need to clone the staking dashboard git clone https://github.com/harmony-one/staking-dashboard.git Install Firebase CLI You will need to install the firebase CLI NPM Version and Node Version You will need to set the correct version for npm and node. NVM is useful for this. Currently we are running on npm 6.14 and node v10.17.0 Johns-MacBook-Pro:appengine johnwhitton$ npm -v 6.14.2 Johns-MacBook-Pro:appengine johnwhitton$ node -v v10.17.0 Johns-MacBook-Pro:appengine johnwhitton$ nvm list v0.10.48 v0.12.18 v10.15.1 -> v10.17.0 v12.10.0 system default -> v12.10.0 node -> stable (-> v12.10.0) (default) stable -> 12.10 (-> v12.10.0) (default) iojs -> N/A (default) unstable -> N/A (default) lts/* -> lts/erbium (-> N/A) lts/argon -> v4.9.1 (-> N/A) lts/boron -> v6.17.1 (-> N/A) lts/carbon -> v8.17.0 (-> N/A) lts/dubnium -> v10.19.0 (-> N/A) lts/erbium -> v12.16.1 (-> N/A) Johns-MacBook-Pro:appengine johnwhitton$ Deploying a new Staking Explorer Persistence Layer Update dns end-point in firebase Go to firebase project staking-explorer database Look at database/networks OSTN , Mainnet , PTN Need to update Chaintitle Rpc_url Explorer_url chain_id Backend Deployment Go to staking-dashboard/appengine project on your local machine and update the codebase Login into the project by gcloud auth login (make should that you are able to access staking-explorer2-268108) gcloud config set project staking-explorer2-268108 gcloud config list for checking Remove database npm run clear-db (carefull) Deploy Run `deploy1.sh` It will ask you to confirm if we will deploy to an url (for example https://staking-explorer2-268108.appspot.com ) Say yes That url will be the end point for the frontend It takes about 5min # Login to gcloud and ensure you're in the correct project gcloud auth login gcloud config set project staking-explorer2-268108 gcloud config list # Go to staking-dashboard and update to latest codebase cd /Users/johnwhitton/projects/staking-dashboard git status git log --pretty=oneline git stash git pull git log --pretty=oneline cd appengine/ npm install cd /Users/johnwhitton/projects/staking-dashboard/appengine/keys cp ~/Downloads/staking_explorer.json . cd /Users/johnwhitton/projects/staking-dashboard/appengine #Remove Database # npm run clear-db # see https://github.com/harmony-one/staking-dashboard/pull/334/files # Choose one of the following ./clear_openstaking.sh ./clear_partnernet.sh ./clear_stressnet.sh # Run Deploy.sh ./deploy1.sh FrontEnd Deployment Install firebase cli Login into the project firebase use staking-explorer Make sure the url above ( https://staking-explorer2-268108.appspot.com ) produced from the appengine deployment is used in frontend/.env.production `npm run build` for building Deploy to dev env ( https://staking-explorer.firebaseapp.com/ ) ./dev_deploy.sh Deploy to prod env ( https://staking.harmony.one ) ./prod_deploy.sh # Log in to firebase project firebase login # Check frontend URL cat .env.production # Build the release npm run build # Deploy to Development or Production ./dev_deploy.sh ./prod_deploy.sh Troubleshooting / FAQS","title":"Staking Dashboard  Deployment"},{"location":"deploy/cicd/netdeploy/network-release/staking-dashboard-deployment/#staking-dashboard-deployment","text":"{% hint style=\"info\" %} When refreshing a network you can delete staking history via a web browser. For example for Stressnet click here and then press delete collection. Note you will still need to restart the appengine to flush the cache (see below) {% endhint %}","title":"Staking Dashboard  Deployment"},{"location":"deploy/cicd/netdeploy/network-release/staking-dashboard-deployment/#overview","text":"The staking explorer is provides the ability to stake validators on the Harmony Protocol. It supports multiple networks and is integrated with multiple wallets including the Harmony Chrome Extension. The code is open source and is stored in staking-dashboard . This document will give an overview of the key components, repositories and the deployment Process","title":"Overview"},{"location":"deploy/cicd/netdeploy/network-release/staking-dashboard-deployment/#components","text":"","title":"Components"},{"location":"deploy/cicd/netdeploy/network-release/staking-dashboard-deployment/#persistance-layer","text":"The Persistence Layer uses firebase","title":"Persistance Layer"},{"location":"deploy/cicd/netdeploy/network-release/staking-dashboard-deployment/#backend-logic","text":"The staking dashboard backend is written using node.js and is deployed on Google App Engine .","title":"Backend Logic"},{"location":"deploy/cicd/netdeploy/network-release/staking-dashboard-deployment/#frontend-logic","text":"The staking dashboard frontend is written in vue.js","title":"Frontend Logic"},{"location":"deploy/cicd/netdeploy/network-release/staking-dashboard-deployment/#deployment-environments","text":"All networks are supported by the one app engine project and one firebase project with configuration being held at the firebase level for the network information Google App Engine Project - staking explorer2 Firebase Project - staking explorer Network Configuration - Mainnet - Partner Testnet , OSTN","title":"Deployment Environments"},{"location":"deploy/cicd/netdeploy/network-release/staking-dashboard-deployment/#deployment-setup","text":"","title":"Deployment Setup"},{"location":"deploy/cicd/netdeploy/network-release/staking-dashboard-deployment/#administrative-credentials","text":"In order to deploy and administer staking explorer you will need to have your harmony google account authorized to the above Projects","title":"Administrative Credentials"},{"location":"deploy/cicd/netdeploy/network-release/staking-dashboard-deployment/#gcloud-sdk","text":"You will also need to install the gcloud SDK .","title":"Gcloud SDK"},{"location":"deploy/cicd/netdeploy/network-release/staking-dashboard-deployment/#clone-staking-dashboard","text":"You will need to clone the staking dashboard git clone https://github.com/harmony-one/staking-dashboard.git","title":"Clone Staking Dashboard"},{"location":"deploy/cicd/netdeploy/network-release/staking-dashboard-deployment/#install-firebase-cli","text":"You will need to install the firebase CLI","title":"Install Firebase CLI"},{"location":"deploy/cicd/netdeploy/network-release/staking-dashboard-deployment/#npm-version-and-node-version","text":"You will need to set the correct version for npm and node. NVM is useful for this. Currently we are running on npm 6.14 and node v10.17.0 Johns-MacBook-Pro:appengine johnwhitton$ npm -v 6.14.2 Johns-MacBook-Pro:appengine johnwhitton$ node -v v10.17.0 Johns-MacBook-Pro:appengine johnwhitton$ nvm list v0.10.48 v0.12.18 v10.15.1 -> v10.17.0 v12.10.0 system default -> v12.10.0 node -> stable (-> v12.10.0) (default) stable -> 12.10 (-> v12.10.0) (default) iojs -> N/A (default) unstable -> N/A (default) lts/* -> lts/erbium (-> N/A) lts/argon -> v4.9.1 (-> N/A) lts/boron -> v6.17.1 (-> N/A) lts/carbon -> v8.17.0 (-> N/A) lts/dubnium -> v10.19.0 (-> N/A) lts/erbium -> v12.16.1 (-> N/A) Johns-MacBook-Pro:appengine johnwhitton$","title":"NPM Version and Node Version"},{"location":"deploy/cicd/netdeploy/network-release/staking-dashboard-deployment/#deploying-a-new-staking-explorer","text":"","title":"Deploying a new Staking Explorer"},{"location":"deploy/cicd/netdeploy/network-release/staking-dashboard-deployment/#persistence-layer","text":"Update dns end-point in firebase Go to firebase project staking-explorer database Look at database/networks OSTN , Mainnet , PTN Need to update Chaintitle Rpc_url Explorer_url chain_id","title":"Persistence Layer"},{"location":"deploy/cicd/netdeploy/network-release/staking-dashboard-deployment/#backend-deployment","text":"Go to staking-dashboard/appengine project on your local machine and update the codebase Login into the project by gcloud auth login (make should that you are able to access staking-explorer2-268108) gcloud config set project staking-explorer2-268108 gcloud config list for checking Remove database npm run clear-db (carefull) Deploy Run `deploy1.sh` It will ask you to confirm if we will deploy to an url (for example https://staking-explorer2-268108.appspot.com ) Say yes That url will be the end point for the frontend It takes about 5min # Login to gcloud and ensure you're in the correct project gcloud auth login gcloud config set project staking-explorer2-268108 gcloud config list # Go to staking-dashboard and update to latest codebase cd /Users/johnwhitton/projects/staking-dashboard git status git log --pretty=oneline git stash git pull git log --pretty=oneline cd appengine/ npm install cd /Users/johnwhitton/projects/staking-dashboard/appengine/keys cp ~/Downloads/staking_explorer.json . cd /Users/johnwhitton/projects/staking-dashboard/appengine #Remove Database # npm run clear-db # see https://github.com/harmony-one/staking-dashboard/pull/334/files # Choose one of the following ./clear_openstaking.sh ./clear_partnernet.sh ./clear_stressnet.sh # Run Deploy.sh ./deploy1.sh","title":"Backend Deployment"},{"location":"deploy/cicd/netdeploy/network-release/staking-dashboard-deployment/#frontend-deployment","text":"Install firebase cli Login into the project firebase use staking-explorer Make sure the url above ( https://staking-explorer2-268108.appspot.com ) produced from the appengine deployment is used in frontend/.env.production `npm run build` for building Deploy to dev env ( https://staking-explorer.firebaseapp.com/ ) ./dev_deploy.sh Deploy to prod env ( https://staking.harmony.one ) ./prod_deploy.sh # Log in to firebase project firebase login # Check frontend URL cat .env.production # Build the release npm run build # Deploy to Development or Production ./dev_deploy.sh ./prod_deploy.sh","title":"FrontEnd Deployment"},{"location":"deploy/cicd/netdeploy/network-release/staking-dashboard-deployment/#troubleshooting-faqs","text":"","title":"Troubleshooting / FAQS"},{"location":"deploy/cicd/netdeploy/network-release/watchdog-deployment/","text":"Watchdog Deployment Update the IP addresses in the nodedb repo & restart Watchdog {% tabs %} {% tab title=\"OSTN\" %} ./update_nodedb.sh -u -p -r -y {% endtab %} {% tab title=\"STN\" %} ./update_nodedb.sh -w STN -t stn -u -p -r -y {% endtab %} {% endtabs %} Copy the IP files & init files to the nodedb repo & restart Watchdog {% tabs %} {% tab title=\"OSTN\" %} ./update_nodedb.sh -c -p -r -y {% endtab %} {% tab title=\"STN\" %} ./update_nodedb.sh -w STN -t stn -c -p -r -y {% endtab %} {% endtabs %} Just restart Watchdog {% tabs %} {% tab title=\"OSTN\" %} ./restart_watchdog.sh -a restart -s ostn -u {% endtab %} {% tab title=\"STN\" %} ./restart_watchdog.sh -a restart -s stn -u {% endtab %} {% endtabs %} Troubleshooting Machine Login exec ssh -i ~/.ssh/keys/california-key-benchmark.pem ec2-user@watchdog.hmny.io Watchdog Environments Mainnet: http://watchdog.hmny.io/report-mainnet - mainnet LRTN: http://watchdog.hmny.io/report-lrtn - lrtn OSTN: http://watchdog.hmny.io/report-ostn - os PSTN: http://watchdog.hmny.io/report-pstn - pstn STN: http://watchdog.hmny.io/report-stn - stn","title":"Watchdog Deployment"},{"location":"deploy/cicd/netdeploy/network-release/watchdog-deployment/#watchdog-deployment","text":"","title":"Watchdog Deployment"},{"location":"deploy/cicd/netdeploy/network-release/watchdog-deployment/#update-the-ip-addresses-in-the-nodedb-repo-restart-watchdog","text":"{% tabs %} {% tab title=\"OSTN\" %} ./update_nodedb.sh -u -p -r -y {% endtab %} {% tab title=\"STN\" %} ./update_nodedb.sh -w STN -t stn -u -p -r -y {% endtab %} {% endtabs %}","title":"Update the IP addresses in the nodedb repo &amp; restart Watchdog"},{"location":"deploy/cicd/netdeploy/network-release/watchdog-deployment/#copy-the-ip-files-init-files-to-the-nodedb-repo-restart-watchdog","text":"{% tabs %} {% tab title=\"OSTN\" %} ./update_nodedb.sh -c -p -r -y {% endtab %} {% tab title=\"STN\" %} ./update_nodedb.sh -w STN -t stn -c -p -r -y {% endtab %} {% endtabs %}","title":"Copy the IP files &amp; init files to the nodedb repo &amp; restart Watchdog"},{"location":"deploy/cicd/netdeploy/network-release/watchdog-deployment/#just-restart-watchdog","text":"{% tabs %} {% tab title=\"OSTN\" %} ./restart_watchdog.sh -a restart -s ostn -u {% endtab %} {% tab title=\"STN\" %} ./restart_watchdog.sh -a restart -s stn -u {% endtab %} {% endtabs %}","title":"Just restart Watchdog"},{"location":"deploy/cicd/netdeploy/network-release/watchdog-deployment/#troubleshooting","text":"Machine Login exec ssh -i ~/.ssh/keys/california-key-benchmark.pem ec2-user@watchdog.hmny.io","title":"Troubleshooting"},{"location":"deploy/cicd/netdeploy/network-release/watchdog-deployment/#watchdog-environments","text":"Mainnet: http://watchdog.hmny.io/report-mainnet - mainnet LRTN: http://watchdog.hmny.io/report-lrtn - lrtn OSTN: http://watchdog.hmny.io/report-ostn - os PSTN: http://watchdog.hmny.io/report-pstn - pstn STN: http://watchdog.hmny.io/report-stn - stn","title":"Watchdog Environments"},{"location":"deploy/cicd/netdeploy/network-release/cheat-sheets/","text":"Network Deployment Cheat Sheets Overview Just want to get up and running and do a deploy follow the below cheat sheets. Pre-requisites The following cheat sheets assume that you have completed the Pre-build Steps The codebase to deploy has been Synched to t3 You are building from the latest t3 branch You are building from the devops machine Experiment Deploy has been updated to the latest version on the devops machine You are releasing to OSTN You have captured the Log and validator Information You are logging the upgrade https://harmony.one/checklist Cheat Sheets Rolling Upgrade Refresh Network Launch or Upgrade","title":"Network Deployment Cheat Sheets"},{"location":"deploy/cicd/netdeploy/network-release/cheat-sheets/#network-deployment-cheat-sheets","text":"","title":"Network Deployment Cheat Sheets"},{"location":"deploy/cicd/netdeploy/network-release/cheat-sheets/#overview","text":"Just want to get up and running and do a deploy follow the below cheat sheets.","title":"Overview"},{"location":"deploy/cicd/netdeploy/network-release/cheat-sheets/#pre-requisites","text":"The following cheat sheets assume that you have completed the Pre-build Steps The codebase to deploy has been Synched to t3 You are building from the latest t3 branch You are building from the devops machine Experiment Deploy has been updated to the latest version on the devops machine You are releasing to OSTN You have captured the Log and validator Information You are logging the upgrade https://harmony.one/checklist","title":"Pre-requisites"},{"location":"deploy/cicd/netdeploy/network-release/cheat-sheets/#cheat-sheets","text":"Rolling Upgrade Refresh Network Launch or Upgrade","title":"Cheat Sheets"},{"location":"deploy/cicd/netdeploy/network-release/cheat-sheets/network-launch-or-upgrade/","text":"Network Launch or Upgrade Overview A network upgrade is necessary when deploying a new network or changing configuration of a network (e.g. additional shards or validators per shard). It can also be used as a quicker way to bring up an existing network which has lost a number of nodes (usually AWS spot instances) and as such can no longer gain consensus. This has the same effect as a hard refresh but with additional actions required to update the other network applications with new IP's for the new nodes as well as additional work required for DNS Configuration for both synching and api endpoints.","title":"Network Launch or Upgrade"},{"location":"deploy/cicd/netdeploy/network-release/cheat-sheets/network-launch-or-upgrade/#network-launch-or-upgrade","text":"","title":"Network Launch or Upgrade"},{"location":"deploy/cicd/netdeploy/network-release/cheat-sheets/network-launch-or-upgrade/#overview","text":"A network upgrade is necessary when deploying a new network or changing configuration of a network (e.g. additional shards or validators per shard). It can also be used as a quicker way to bring up an existing network which has lost a number of nodes (usually AWS spot instances) and as such can no longer gain consensus. This has the same effect as a hard refresh but with additional actions required to update the other network applications with new IP's for the new nodes as well as additional work required for DNS Configuration for both synching and api endpoints.","title":"Overview"},{"location":"deploy/cicd/netdeploy/network-release/cheat-sheets/refresh/","text":"Refresh Overview A hard refresh is necessary when there are breaking changes usually data related in the new version of the protocol software being deployed. This involves the removal of all data at the protocol level and also many network components which have their own persistent storage and caching layers that require cleaning out the applications database and restarting their applications. Finally all transactional data is lost and all validators need to reset their nodes and register themselves again on the network. Automated Process {% hint style=\"info\" %} The below commands are in the process of being automated using hard_reset.sh For STN here is the gist to run the refresh. here is how to build from a pull request and this ticket for the jenkins job. {% endhint %} Pre-requisites The following cheat sheets assume that you have completed the Pre-build Steps The codebase to deploy has been Synched to t3 You are building from the latest t3 branch You are building from the devops machine Experiment Deploy has been updated to the latest version on the devops machine You are releasing to OSTN You have captured the Log and validator Information You are logging the upgrade https://harmony.one/checklist Refresh Phases Announce Refresh Protocol Release Protocol Validation Network Release Network Validation Announce completion of refresh Refresh Cheat Sheet The following documents the manual process which was being used and was the baseline for the automated process above. {% tabs %} {% tab title=\"OSTN\" %} # Announce Refresh ## Discord channels - team-staking, p-ops, testnet-nodes ## Telegram channels - [P-OPS] Pangaea OPS team & tech support, Open staking volunteers - Pangaea ### Message - OSTN Refresh starting now - will let you know when complete - changes are here https://gist.github.com/fxfactorial/981d1716ed623984946b52a46f39dc5d and https://github.com/harmony-one/harmony/commits/t3 # Protocol Release ## Log in to the devops Machine, set profile and go to experiment deploy exec ssh -i ~/.ssh/keys/oregon-key-benchmark.pem ec2-user@devop.hmny.io tmux ls tmux attach-session -t os profile_print export WHOAMI=OS; export HMY_PROFILE=os; profile_print ##cd ~/experiment-deploy/pipeline/ cd /home/ec2-user/experiment-deploy/pipeline ## Release the Protocol ### Remove Existing Network ./run_on_shard.sh -p os -T 0 'sudo killall -9 harmony; sudo rm -rf harmony_db_*; sudo rm -rf .dht*; sudo rm harmony.err;' ./run_on_shard.sh -p os -T 1 'sudo killall -9 harmony; sudo rm -rf harmony_db_*; sudo rm -rf .dht*; sudo rm harmony.err;' ./run_on_shard.sh -p os -T 2 'sudo killall -9 harmony; sudo rm -rf harmony_db_*; sudo rm -rf .dht*; sudo rm harmony.err;' ./run_on_shard.sh -p os -T 3 'sudo killall -9 harmony; sudo rm -rf harmony_db_*; sudo rm -rf .dht*; sudo rm harmony.err;' ### Reset bootnodes ./go.sh -p os bootnode ### Upgrade Harmony Nodes cat logs/os/shard0.txt | xargs -i{} -P50 bash -c './restart_node.sh -U -y -d logs/os -p os -t 0 -r 0 -R 0 {}' cat logs/os/shard1.txt | xargs -i{} -P50 bash -c './restart_node.sh -U -y -d logs/os -p os -t 0 -r 0 -R 0 {}' cat logs/os/shard2.txt | xargs -i{} -P50 bash -c './restart_node.sh -U -y -d logs/os -p os -t 0 -r 0 -R 0 {}' cat logs/os/shard3.txt | xargs -i{} -P50 bash -c './restart_node.sh -U -y -d logs/os -p os -t 0 -r 0 -R 0 {}' # Protocol Validation ## Check Consensus ./run_on_shard.sh -p os -T 0 'tac ../tmp_log/*/zerolog*.log | grep -m 1 HOORAY' ./run_on_shard.sh -p os -T 1 'tac ../tmp_log/*/zerolog*.log | grep -m 1 HOORAY' ./run_on_shard.sh -p os -T 2 'tac ../tmp_log/*/zerolog*.log | grep -m 1 HOORAY' ./run_on_shard.sh -p os -T 3 'tac ../tmp_log/*/zerolog*.log | grep -m 1 HOORAY' ## Check the correct version of the Code was deployed ./run_on_shard.sh -p os -T 0 \"./harmony -version\" ./run_on_shard.sh -p os -T 1 \"./harmony -version\" ./run_on_shard.sh -p os -T 2 \"./harmony -version\" ./run_on_shard.sh -p os -T 3 \"./harmony -version\" # Network Release ## Restart Watchdog ./update_nodedb.sh -c -p -r -y ## Release Validator Build ### Run Jenkins Harmony Release - https://jenkins.harmony.one/job/harmony-release/ ### Parameters #### Branch : t3 #### Branch Release : Check #### Build Type : release #### Network : pangaea #### STATIC_BINARY : Checked ### Run a second Jenkins Harmony release job with above paramaters but STATIC_BINARY unchecked ## Fund Accounts ./fund.sh -f -c ## Restart Faucet cd /home/ec2-user/CF ./faucet_deploy.sh os cd /home/ec2-user/experiment-deploy/pipeline ## Sentry Build ### No longer required now using autonode ### # Sentry 0 - one1m6j80t6rhc3ypaumtsfmqwjwp0mrqk9ff50prh # afc4d81ab636323b04893c23d3404f38e95e9291b3d5299dade3d03822edd3a2b799bd6d64265a9a9cac025d5dbd600c.key exec ssh -i ~/.ssh/keys/harmony-testnet.pem ec2-user@13.59.156.175 # Sentry 1 - one10fjqteq6q75nm62cx8vejqsk7mc8t5hle8ewnl # 552f8aa65835f04e4bc3a04a4bd1f5c67dcd562513b6728c5b9fd258d9fdb054c10008b14a739818d0c234d37b8f1301.key exec ssh -i ~/.ssh/keys/harmony-testnet.pem ec2-user@18.188.241.110 # Sentry 2 - one1vzsj3julf0ljcj3hhxuqpu6zvadu488zfrtttz # a2232487bbf16dd01c5743700712819984d036bf3e39960c85045920784ba0d24149c93591dd4017ada3155e8105d402.key exec ssh -i ~/.ssh/keys/harmony-testnet.pem ec2-user@13.59.11.174 # Sentry 3 - Sentry 3 one1marnnvc8hywmfxhrc8mtpjkvvdt32x9kxt # 5aff3653958fdddefe04aaeb5e9c4a4fc7dda03538a04fd8dfd139c66d18ec31c7deb846cb67077fde48921ddb07a387.key exec ssh -i ~/.ssh/keys/harmony-testnet.pem ec2-user@3.22.97.78 ## ===== OBSOLETE - NOW USING AUTONODE - REMOVE AFTER NEXT OSTN REFRESH ====== ## Build Sentries - Done on Sentry Machines ### Sentry - Shard 0 exec ssh -i ~/.ssh/keys/SentryOSTN.pem ec2-user@3.21.53.63 tmux att curl -LO https://raw.githubusercontent.com/harmony-one/harmony/master/scripts/node.sh && chmod a+x node.sh rm -rf harmony_db* ./node.sh -S -c -z -I -P -r localhost:6060 -N staking -k afc4d81ab636323b04893c23d3404f38e95e9291b3d5299dade3d03822edd3a2b799bd6d64265a9a9cac025d5dbd600c.key <CTRL>b d ./node.sh -V ./hmy --node=\"https://api.s0.os.hmny.io\" staking create-validator --validator-addr one1m6j80t6rhc3ypaumtsfmqwjwp0mrqk9ff50prh --name OSTNSentry0 --identity OSTNSentry0 --website sentry@harmony.one --security-contact Sentry --details \"OSTN Sentry for Shard 0 t3.small\" --rate 0.05 --max-rate 0.8 --max-change-rate 0.02 --min-self-delegation 10000 --max-total-delegation 100000 --bls-pubkeys afc4d81ab636323b04893c23d3404f38e95e9291b3d5299dade3d03822edd3a2b799bd6d64265a9a9cac025d5dbd600c --amount 100000 ### Sentry - Shard 1 ssh -i ~/.ssh/keys/SentryOSTN.pem ec2-user@18.218.200.47 tmux att curl -LO https://raw.githubusercontent.com/harmony-one/harmony/master/scripts/node.sh && chmod a+x node.s rm -rf harmony_db* ./node.sh -S -c -z -I -P -r localhost:6060 -N staking -k 552f8aa65835f04e4bc3a04a4bd1f5c67dcd562513b6728c5b9fd258d9fdb054c10008b14a739818d0c234d37b8f1301.key <CTRL>b d ./node.sh -V ./hmy --node=\"https://api.s0.os.hmny.io\" staking create-validator --validator-addr one10fjqteq6q75nm62cx8vejqsk7mc8t5hle8ewnl --name OSTNSentry1 --identity OSTNSentry1 --website sentry@harmony.one --security-contact Sentry --details \"OSTN Sentry for Shard 1 t3.small\" --rate 0.05 --max-rate 0.8 --max-change-rate 0.02 --min-self-delegation 10000 --max-total-delegation 1000000 --bls-pubkeys 552f8aa65835f04e4bc3a04a4bd1f5c67dcd562513b6728c5b9fd258d9fdb054c10008b14a739818d0c234d37b8f1301 --amount 10000 ### Sentry - Shard 2 exec ssh -i ~/.ssh/keys/SentryOSTN.pem ec2-user@3.21.169.132 tmux att curl -LO https://raw.githubusercontent.com/harmony-one/harmony/master/scripts/node.sh && chmod a+x node.s rm -rf harmony_db* ./node.sh -S -c -z -I -P -r localhost:6060 -N staking -k a2232487bbf16dd01c5743700712819984d036bf3e39960c85045920784ba0d24149c93591dd4017ada3155e8105d402.key <CTRL>b d ./node.sh -V ./hmy --node=\"https://api.s0.os.hmny.io\" staking create-validator --validator-addr one1vzsj3julf0ljcj3hhxuqpu6zvadu488zfrtttz --name OSTNSentry2 --identity OSTNSentry2 --website sentry@harmony.one --security-contact Sentry --details \"OSTN Sentry for Shard 2 t3.small\" --rate 0.05 --max-rate 0.8 --max-change-rate 0.02 --min-self-delegation 10000 --max-total-delegation 10000000 --bls-pubkeys a2232487bbf16dd01c5743700712819984d036bf3e39960c85045920784ba0d24149c93591dd4017ada3155e8105d402 --amount 10000 ### Sentry - Shard 3 exec ssh -i ~/.ssh/keys/SentryOSTN.pem ec2-user@18.221.69.247 tmux att curl -LO https://raw.githubusercontent.com/harmony-one/harmony/master/scripts/node.sh && chmod a+x node.s rm -rf harmony_db* ./node.sh -S -c -z -I -P -r localhost:6060 -N staking -k 5aff3653958fdddefe04aaeb5e9c4a4fc7dda03538a04fd8dfd139c66d18ec31c7deb846cb67077fde48921ddb07a387.key <CTRL>b d ./node.sh -V ./hmy --node=\"https://api.s0.os.hmny.io\" staking create-validator --validator-addr one1marnnvc8hywmfxhrc8mtpjkvvdt32x9kxtwkvv --name OSTNSentry3 --identity OSTNSentry3 --website sentry@harmony.one --security-contact Sentry --details \"OSTN Sentry for Shard 3 t3.small\" --rate 0.05 --max-rate 0.8 --max-change-rate 0.02 --min-self-delegation 10000 --max-total-delegation 10000000 --bls-pubkeys 5aff3653958fdddefe04aaeb5e9c4a4fc7dda03538a04fd8dfd139c66d18ec31c7deb846cb67077fde48921ddb07a387 --amount 10000 ### MultiKey - Shard 1 cd /Users/johnwhitton/projects/staking/OSTN ssh -i \"JOHN_OSTN_VALIDATOR_1.pem\" ec2-user@ec2-3-16-31-148.us-east-2.compute.amazonaws.com tmux att curl -LO https://raw.githubusercontent.com/harmony-one/harmony/master/scripts/node.sh && chmod a+x node.s rm -rf harmony_db* ./node.sh -S -c -z -I -P -4 localhost:6060 -N staking -M <CTRL>b d ./node.sh -V ./hmy --node=\"https://api.s0.os.hmny.io\" staking create-validator --validator-addr one1y5n7p8a845v96xyx2gh75wn5eyhtw5002lah27 --name JohnV1 --identity JohnV1 --website john@harmony.one --security-contact Sentry --details \"John Validator t3.small\" --rate 0.05 --max-rate 0.8 --max-change-rate 0.02 --min-self-delegation 10000 --max-total-delegation 10000000 --bls-pubkeys e65ce96e41d54d49243e2294fb306768862cccd5be80347f88bafe13aa4d3582c21c613fc26f6908ed1faa0dd0c27381,b3815c62affe89560ecabb2f30de46742c927e8a951f37f080264d0b394e16b55ea0786629798d0170c713a9779e4585,b9626bcf02210e8979b0e661bbdbf2e5a691105761fd8800bd1e96087a57c393285af91dcf3c3d6763a643d874f14599 --amount 10000 #### END OF OBSOLETE SENTRY BUILD ##### ## Refresh Block Explorer - Done on Block Explorer exec ssh -i ~/.ssh/keys/oregon-key-benchmark.pem ec2-user@44.232.43.231 tmux att ### Go to the be session and kill the running process ### Usually you can then up arrow twice to run the following two commands npm run db-reset npm run start ## Refresh Staking Dashbaord - Done on Local Machine ### If problems with this check Block explorer deplpoyment to set up local instance cd /Users/johnwhitton/projects/staking-dashboard/appengine ### Clean the db ./clear_openstaking.sh ### Launch the backend (optional) ./deploy1.sh ### Launch the frontend (optional) #### Log in to firebase project firebase login #### Check frontend URL cat .env.production #### Build the release npm run build #### Deploy Frontend to Production ./prod_deploy.sh # Network Validation ## Validate Watchdog - http://watchdog.hmny.io/report-ostn ## Validate Validator Build - e.g. https://jenkins.harmony.one/job/harmony-release/412/console ### Go to the console and check that the commit you are building is correct #### e.g https://jenkins.harmony.one/job/harmony-release/412/console and find the below text under [harmony] #### Checking out Revision 0c46e086734aea2140f306d28ca3aa10e73c2153 (refs/remotesorigin/t3) ## Validate Accounts Funded ### fund.sh has confirms balances so check the output when you run the command ### Check a balance on explorer one1m6j80t6rhc3ypaumtsfmqwjwp0mrqk9ff50prh ## Validate Faucet ### Fund an account on https://faucet.os.hmny.io/ e.g one1m6j80t6rhc3ypaumtsfmqwjwp0mrqk9ff50prh ## Validate Sentries ### Check they are elected on https://staking.harmony.one/validators #### Check they are earning ./hmy --node=\"https://api.s0.os.hmny.io\" blockchain validator information one1m6j80t6rhc3ypaumtsfmqwjwp0mrqk9ff50prh ./hmy --node=\"https://api.s0.os.hmny.io\" blockchain validator information one10fjqteq6q75nm62cx8vejqsk7mc8t5hle8ewnl ./hmy --node=\"https://api.s0.os.hmny.io\" blockchain validator information one1vzsj3julf0ljcj3hhxuqpu6zvadu488zfrtttz ./hmy --node=\"https://api.s0.os.hmny.io\" blockchain validator information one1marnnvc8hywmfxhrc8mtpjkvvdt32x9kxtwkvv ./hmy --node=\"https://api.s0.os.hmny.io\" blockchain validator information one1y5n7p8a845v96xyx2gh75wn5eyhtw5002lah27 ## Validate Block Explorer - https://explorer.os.hmny.io/#/ ### Check blocks are being update ## Validate Staking Explorer - https://staking.harmony.one/validators ### Check Validators ### Delegate to a validator # Announce completion of Refresh ## Discord channels - team-staking, p-ops, testnet-nodes ## Telegram channels - [P-OPS] Pangaea OPS team & tech support, Open staking volunteers - Pangaea ### Message - \"OSTN Refresh is now complete - please reset your validators\" {% endtab %} {% tab title=\"STN\" %} # Announce Refresh ## Discord channels - stressnet ### Message - STN Refresh starting now - will let you know when complete - changes are here https://gist.github.com/fxfactorial/981d1716ed623984946b52a46f39dc5d and https://github.com/harmony-one/harmony/commits/t3 # Protocol Release ## Log in to the devops Machine, set profile and go to experiment deploy exec ssh -i ~/.ssh/keys/oregon-key-benchmark.pem ec2-user@devop.hmny.io tmux ls tmux attach-session -t STN profile_print export WHOAMI=STN; export HMY_PROFILE=stn; profile_print cd /home/ec2-user/go/src/github.com/harmony-one/experiment-deploy/pipeline ## Release the Protocol ### Remove Existing Network ./run_on_shard.sh -p stn -T 0 'sudo killall -9 harmony; sudo rm -rf harmony_db_*; sudo rm -rf .dht*; sudo rm harmony.err; sudo rm -rf ../tmp_log/*/*' ./run_on_shard.sh -p stn -T 1 'sudo killall -9 harmony; sudo rm -rf harmony_db_*; sudo rm -rf .dht*; sudo rm harmony.err; sudo rm -rf ../tmp_log/*/*' ### Reset bootnodes ./go.sh -p stn bootnode ### Upgrade Harmony Nodes cat logs/stn/shard0.txt | xargs -i{} -P50 bash -c './restart_node.sh -U -y -d logs/stn -p stn -t 0 -r 0 -R 0 {}' cat logs/stn/shard1.txt | xargs -i{} -P50 bash -c './restart_node.sh -U -y -d logs/stn -p stn -t 1 -r 0 -R 0 {}' # Protocol Validation ## Check Consensus ./run_on_shard.sh -p stn -y -T 0 'tac ../tmp_log/*/zerolog*.log | grep -m 1 HOORAY' ./run_on_shard.sh -p stn -y -T 1 'tac ../tmp_log/*/zerolog*.log | grep -m 1 HOORAY' ## Check the correct version of the Code was deployed ./run_on_shard.sh -p stn -y -T 0 \"LD_LIBRARY_PATH=. ./harmony -version\" ./run_on_shard.sh -p stn -y -T 1 \"LD_LIBRARY_PATH=. ./harmony -version\" # Network Release ## Restart Watchdog ./update_nodedb.sh -w STN -t stn -c -p -r -y ## Release Validator Build ### Run Jenkins Harmony Release - https://jenkins.harmony.one/job/harmony-release/ ### Parameters #### Branch : t3 #### Branch Release : Check #### Build Type : release #### Network : pangaea #### STATIC_BINARY : Checked ### Run a second Jenkins Harmony release job with above paramaters but STATIC_BINARY unchecked ## Fund Accounts chmod a+x ./fund.sh ./fund.sh -f -c ## Restart Faucet - https://faucet.stn.hmny.io/ cd /home/ec2-user/CF ./faucet_deploy.sh stn cd /home/ec2-user/go/src/github.com/harmony-one/experiment-deploy/pipeline ## Stressnet nodes are using autonode so whould restart autmotically ### Sentry0 ./node_ssh.sh 52.11.85.154 ### Sentry1 ./node_ssh.sh 54.202.197.141 ## Monitoring setry optional ./node_ssh.sh 52.42.43.150 tmux attach - t node <CTL> c curl -LO https://harmony.one/hmycli && mv hmycli hmy && chmod +x hmy curl -LO https://raw.githubusercontent.com/harmony-one/harmony/master/scripts/node.sh && chmod a+x node.sh rm -rf harmony_db* ./node.sh -S -c -z -I -P -R localhost:6060 -N stress -k 463298d9357ddb336038a122b84549b0589597214e28f12b7816f09b554fd4c935437f25eb1720bae923fcb070b3e596.key <CTL> b ./node.sh -V ./hmy --node=\"https://api.s0.stn.hmny.io\" staking create-validator --validator-addr one1vzsj3julf0ljcj3hhxuqpu6zvadu488zfrtttz --name OSTNSentry0.1 --identity OSTNSentry2 --website sentry@harmony.one --security-contact Sentry --details \"OSTN Sentry for Shard 2 t3.small\" --rate 0.05 --max-rate 0.8 --max-change-rate 0.02 --min-self-delegation 10000 --max-total-delegation 10000000 --bls-pubkeys 463298d9357ddb336038a122b84549b0589597214e28f12b7816f09b554fd4c935437f25eb1720bae923fcb070b3e596 --amount 10000 ./hmy --node=\"https://api.s0.stn.hmny.io\" blockchain validator information one1vzsj3julf0ljcj3hhxuqpu6zvadu488zfrtttz ### Sentries not yet configured ./node_ssh.sh 54.188.46.48 ### Refresh Staking Explorer ./clear_stressnet.sh ## Refresh Block Explorer - Done on Block Explorer - Have to connect from Devops exec ssh -i ~/.ssh/keys/oregon-key-benchmark.pem ec2-user@35.164.26.115 tmux att ### Go to the be session and kill the running process ### Usually you can then up arrow twice to run the following two commands npm run db-reset npm run rebuild; npm run start # Network Validation ## Validate Watchdog - http://watchdog.hmny.io/report-ostn ## Validate Validator Build - e.g. https://jenkins.harmony.one/job/harmony-release/412/console ### Go to the console and check that the commit you are building is correct #### e.g https://jenkins.harmony.one/job/harmony-release/412/console and find the below text under [harmony] #### Checking out Revision 0c46e086734aea2140f306d28ca3aa10e73c2153 (refs/remotesorigin/t3) ## Validate Accounts Funded ### fund.sh has confirms balances so check the output when you run the command ### Check a balance on explorer one1m6j80t6rhc3ypaumtsfmqwjwp0mrqk9ff50prh ## Validate Faucet ### Fund an account on https://faucet.stn.hmny.io/ e.g one1m6j80t6rhc3ypaumtsfmqwjwp0mrqk9ff50prh ## Validate Sentries ### Check they are elected on https://staking.harmony.one/validators #### Check they are earning ./hmy --node=\"https://api.s0.os.hmny.io\" blockchain validator information one1m6j80t6rhc3ypaumtsfmqwjwp0mrqk9ff50prh ./hmy --node=\"https://api.s0.os.hmny.io\" blockchain validator information one10fjqteq6q75nm62cx8vejqsk7mc8t5hle8ewnl ./hmy --node=\"https://api.s0.os.hmny.io\" blockchain validator information one1vzsj3julf0ljcj3hhxuqpu6zvadu488zfrtttz ./hmy --node=\"https://api.s0.os.hmny.io\" blockchain validator information one1marnnvc8hywmfxhrc8mtpjkvvdt32x9kxtwkvv ./hmy --node=\"https://api.s0.os.hmny.io\" blockchain validator information one1y5n7p8a845v96xyx2gh75wn5eyhtw5002lah27 ## Validate Block Explorer - https://explorer.os.hmny.io/#/ ### Check blocks are being update ## Validate Staking Explorer - https://staking.harmony.one/validators ### Check Validators ### Delegate to a validator # Announce completion of Refresh ## Discord channels - team-staking, p-ops, testnet-nodes ## Telegram channels - [P-OPS] Pangaea OPS team & tech support, Open staking volunteers - Pangaea ### Message - \"OSTN Refresh is now complete - please reset your validators\" {% endtab %} {% endtabs %} Reference Material p2 state of emergency on dev & ops Fixit Edgars Deployment Proposal OSTN Checklist - OSTN Release Log Post Mortem Post-Mortem: Mar-31-2020 Mainnet Shards Down Post-Mortem: Apr 3-4-2020 OSTN Refresh issues","title":"Refresh"},{"location":"deploy/cicd/netdeploy/network-release/cheat-sheets/refresh/#refresh","text":"","title":"Refresh"},{"location":"deploy/cicd/netdeploy/network-release/cheat-sheets/refresh/#overview","text":"A hard refresh is necessary when there are breaking changes usually data related in the new version of the protocol software being deployed. This involves the removal of all data at the protocol level and also many network components which have their own persistent storage and caching layers that require cleaning out the applications database and restarting their applications. Finally all transactional data is lost and all validators need to reset their nodes and register themselves again on the network.","title":"Overview"},{"location":"deploy/cicd/netdeploy/network-release/cheat-sheets/refresh/#automated-process","text":"{% hint style=\"info\" %} The below commands are in the process of being automated using hard_reset.sh For STN here is the gist to run the refresh. here is how to build from a pull request and this ticket for the jenkins job. {% endhint %}","title":"Automated Process"},{"location":"deploy/cicd/netdeploy/network-release/cheat-sheets/refresh/#pre-requisites","text":"The following cheat sheets assume that you have completed the Pre-build Steps The codebase to deploy has been Synched to t3 You are building from the latest t3 branch You are building from the devops machine Experiment Deploy has been updated to the latest version on the devops machine You are releasing to OSTN You have captured the Log and validator Information You are logging the upgrade https://harmony.one/checklist","title":"Pre-requisites"},{"location":"deploy/cicd/netdeploy/network-release/cheat-sheets/refresh/#refresh-phases","text":"Announce Refresh Protocol Release Protocol Validation Network Release Network Validation Announce completion of refresh","title":"Refresh Phases"},{"location":"deploy/cicd/netdeploy/network-release/cheat-sheets/refresh/#refresh-cheat-sheet","text":"The following documents the manual process which was being used and was the baseline for the automated process above. {% tabs %} {% tab title=\"OSTN\" %} # Announce Refresh ## Discord channels - team-staking, p-ops, testnet-nodes ## Telegram channels - [P-OPS] Pangaea OPS team & tech support, Open staking volunteers - Pangaea ### Message - OSTN Refresh starting now - will let you know when complete - changes are here https://gist.github.com/fxfactorial/981d1716ed623984946b52a46f39dc5d and https://github.com/harmony-one/harmony/commits/t3 # Protocol Release ## Log in to the devops Machine, set profile and go to experiment deploy exec ssh -i ~/.ssh/keys/oregon-key-benchmark.pem ec2-user@devop.hmny.io tmux ls tmux attach-session -t os profile_print export WHOAMI=OS; export HMY_PROFILE=os; profile_print ##cd ~/experiment-deploy/pipeline/ cd /home/ec2-user/experiment-deploy/pipeline ## Release the Protocol ### Remove Existing Network ./run_on_shard.sh -p os -T 0 'sudo killall -9 harmony; sudo rm -rf harmony_db_*; sudo rm -rf .dht*; sudo rm harmony.err;' ./run_on_shard.sh -p os -T 1 'sudo killall -9 harmony; sudo rm -rf harmony_db_*; sudo rm -rf .dht*; sudo rm harmony.err;' ./run_on_shard.sh -p os -T 2 'sudo killall -9 harmony; sudo rm -rf harmony_db_*; sudo rm -rf .dht*; sudo rm harmony.err;' ./run_on_shard.sh -p os -T 3 'sudo killall -9 harmony; sudo rm -rf harmony_db_*; sudo rm -rf .dht*; sudo rm harmony.err;' ### Reset bootnodes ./go.sh -p os bootnode ### Upgrade Harmony Nodes cat logs/os/shard0.txt | xargs -i{} -P50 bash -c './restart_node.sh -U -y -d logs/os -p os -t 0 -r 0 -R 0 {}' cat logs/os/shard1.txt | xargs -i{} -P50 bash -c './restart_node.sh -U -y -d logs/os -p os -t 0 -r 0 -R 0 {}' cat logs/os/shard2.txt | xargs -i{} -P50 bash -c './restart_node.sh -U -y -d logs/os -p os -t 0 -r 0 -R 0 {}' cat logs/os/shard3.txt | xargs -i{} -P50 bash -c './restart_node.sh -U -y -d logs/os -p os -t 0 -r 0 -R 0 {}' # Protocol Validation ## Check Consensus ./run_on_shard.sh -p os -T 0 'tac ../tmp_log/*/zerolog*.log | grep -m 1 HOORAY' ./run_on_shard.sh -p os -T 1 'tac ../tmp_log/*/zerolog*.log | grep -m 1 HOORAY' ./run_on_shard.sh -p os -T 2 'tac ../tmp_log/*/zerolog*.log | grep -m 1 HOORAY' ./run_on_shard.sh -p os -T 3 'tac ../tmp_log/*/zerolog*.log | grep -m 1 HOORAY' ## Check the correct version of the Code was deployed ./run_on_shard.sh -p os -T 0 \"./harmony -version\" ./run_on_shard.sh -p os -T 1 \"./harmony -version\" ./run_on_shard.sh -p os -T 2 \"./harmony -version\" ./run_on_shard.sh -p os -T 3 \"./harmony -version\" # Network Release ## Restart Watchdog ./update_nodedb.sh -c -p -r -y ## Release Validator Build ### Run Jenkins Harmony Release - https://jenkins.harmony.one/job/harmony-release/ ### Parameters #### Branch : t3 #### Branch Release : Check #### Build Type : release #### Network : pangaea #### STATIC_BINARY : Checked ### Run a second Jenkins Harmony release job with above paramaters but STATIC_BINARY unchecked ## Fund Accounts ./fund.sh -f -c ## Restart Faucet cd /home/ec2-user/CF ./faucet_deploy.sh os cd /home/ec2-user/experiment-deploy/pipeline ## Sentry Build ### No longer required now using autonode ### # Sentry 0 - one1m6j80t6rhc3ypaumtsfmqwjwp0mrqk9ff50prh # afc4d81ab636323b04893c23d3404f38e95e9291b3d5299dade3d03822edd3a2b799bd6d64265a9a9cac025d5dbd600c.key exec ssh -i ~/.ssh/keys/harmony-testnet.pem ec2-user@13.59.156.175 # Sentry 1 - one10fjqteq6q75nm62cx8vejqsk7mc8t5hle8ewnl # 552f8aa65835f04e4bc3a04a4bd1f5c67dcd562513b6728c5b9fd258d9fdb054c10008b14a739818d0c234d37b8f1301.key exec ssh -i ~/.ssh/keys/harmony-testnet.pem ec2-user@18.188.241.110 # Sentry 2 - one1vzsj3julf0ljcj3hhxuqpu6zvadu488zfrtttz # a2232487bbf16dd01c5743700712819984d036bf3e39960c85045920784ba0d24149c93591dd4017ada3155e8105d402.key exec ssh -i ~/.ssh/keys/harmony-testnet.pem ec2-user@13.59.11.174 # Sentry 3 - Sentry 3 one1marnnvc8hywmfxhrc8mtpjkvvdt32x9kxt # 5aff3653958fdddefe04aaeb5e9c4a4fc7dda03538a04fd8dfd139c66d18ec31c7deb846cb67077fde48921ddb07a387.key exec ssh -i ~/.ssh/keys/harmony-testnet.pem ec2-user@3.22.97.78 ## ===== OBSOLETE - NOW USING AUTONODE - REMOVE AFTER NEXT OSTN REFRESH ====== ## Build Sentries - Done on Sentry Machines ### Sentry - Shard 0 exec ssh -i ~/.ssh/keys/SentryOSTN.pem ec2-user@3.21.53.63 tmux att curl -LO https://raw.githubusercontent.com/harmony-one/harmony/master/scripts/node.sh && chmod a+x node.sh rm -rf harmony_db* ./node.sh -S -c -z -I -P -r localhost:6060 -N staking -k afc4d81ab636323b04893c23d3404f38e95e9291b3d5299dade3d03822edd3a2b799bd6d64265a9a9cac025d5dbd600c.key <CTRL>b d ./node.sh -V ./hmy --node=\"https://api.s0.os.hmny.io\" staking create-validator --validator-addr one1m6j80t6rhc3ypaumtsfmqwjwp0mrqk9ff50prh --name OSTNSentry0 --identity OSTNSentry0 --website sentry@harmony.one --security-contact Sentry --details \"OSTN Sentry for Shard 0 t3.small\" --rate 0.05 --max-rate 0.8 --max-change-rate 0.02 --min-self-delegation 10000 --max-total-delegation 100000 --bls-pubkeys afc4d81ab636323b04893c23d3404f38e95e9291b3d5299dade3d03822edd3a2b799bd6d64265a9a9cac025d5dbd600c --amount 100000 ### Sentry - Shard 1 ssh -i ~/.ssh/keys/SentryOSTN.pem ec2-user@18.218.200.47 tmux att curl -LO https://raw.githubusercontent.com/harmony-one/harmony/master/scripts/node.sh && chmod a+x node.s rm -rf harmony_db* ./node.sh -S -c -z -I -P -r localhost:6060 -N staking -k 552f8aa65835f04e4bc3a04a4bd1f5c67dcd562513b6728c5b9fd258d9fdb054c10008b14a739818d0c234d37b8f1301.key <CTRL>b d ./node.sh -V ./hmy --node=\"https://api.s0.os.hmny.io\" staking create-validator --validator-addr one10fjqteq6q75nm62cx8vejqsk7mc8t5hle8ewnl --name OSTNSentry1 --identity OSTNSentry1 --website sentry@harmony.one --security-contact Sentry --details \"OSTN Sentry for Shard 1 t3.small\" --rate 0.05 --max-rate 0.8 --max-change-rate 0.02 --min-self-delegation 10000 --max-total-delegation 1000000 --bls-pubkeys 552f8aa65835f04e4bc3a04a4bd1f5c67dcd562513b6728c5b9fd258d9fdb054c10008b14a739818d0c234d37b8f1301 --amount 10000 ### Sentry - Shard 2 exec ssh -i ~/.ssh/keys/SentryOSTN.pem ec2-user@3.21.169.132 tmux att curl -LO https://raw.githubusercontent.com/harmony-one/harmony/master/scripts/node.sh && chmod a+x node.s rm -rf harmony_db* ./node.sh -S -c -z -I -P -r localhost:6060 -N staking -k a2232487bbf16dd01c5743700712819984d036bf3e39960c85045920784ba0d24149c93591dd4017ada3155e8105d402.key <CTRL>b d ./node.sh -V ./hmy --node=\"https://api.s0.os.hmny.io\" staking create-validator --validator-addr one1vzsj3julf0ljcj3hhxuqpu6zvadu488zfrtttz --name OSTNSentry2 --identity OSTNSentry2 --website sentry@harmony.one --security-contact Sentry --details \"OSTN Sentry for Shard 2 t3.small\" --rate 0.05 --max-rate 0.8 --max-change-rate 0.02 --min-self-delegation 10000 --max-total-delegation 10000000 --bls-pubkeys a2232487bbf16dd01c5743700712819984d036bf3e39960c85045920784ba0d24149c93591dd4017ada3155e8105d402 --amount 10000 ### Sentry - Shard 3 exec ssh -i ~/.ssh/keys/SentryOSTN.pem ec2-user@18.221.69.247 tmux att curl -LO https://raw.githubusercontent.com/harmony-one/harmony/master/scripts/node.sh && chmod a+x node.s rm -rf harmony_db* ./node.sh -S -c -z -I -P -r localhost:6060 -N staking -k 5aff3653958fdddefe04aaeb5e9c4a4fc7dda03538a04fd8dfd139c66d18ec31c7deb846cb67077fde48921ddb07a387.key <CTRL>b d ./node.sh -V ./hmy --node=\"https://api.s0.os.hmny.io\" staking create-validator --validator-addr one1marnnvc8hywmfxhrc8mtpjkvvdt32x9kxtwkvv --name OSTNSentry3 --identity OSTNSentry3 --website sentry@harmony.one --security-contact Sentry --details \"OSTN Sentry for Shard 3 t3.small\" --rate 0.05 --max-rate 0.8 --max-change-rate 0.02 --min-self-delegation 10000 --max-total-delegation 10000000 --bls-pubkeys 5aff3653958fdddefe04aaeb5e9c4a4fc7dda03538a04fd8dfd139c66d18ec31c7deb846cb67077fde48921ddb07a387 --amount 10000 ### MultiKey - Shard 1 cd /Users/johnwhitton/projects/staking/OSTN ssh -i \"JOHN_OSTN_VALIDATOR_1.pem\" ec2-user@ec2-3-16-31-148.us-east-2.compute.amazonaws.com tmux att curl -LO https://raw.githubusercontent.com/harmony-one/harmony/master/scripts/node.sh && chmod a+x node.s rm -rf harmony_db* ./node.sh -S -c -z -I -P -4 localhost:6060 -N staking -M <CTRL>b d ./node.sh -V ./hmy --node=\"https://api.s0.os.hmny.io\" staking create-validator --validator-addr one1y5n7p8a845v96xyx2gh75wn5eyhtw5002lah27 --name JohnV1 --identity JohnV1 --website john@harmony.one --security-contact Sentry --details \"John Validator t3.small\" --rate 0.05 --max-rate 0.8 --max-change-rate 0.02 --min-self-delegation 10000 --max-total-delegation 10000000 --bls-pubkeys e65ce96e41d54d49243e2294fb306768862cccd5be80347f88bafe13aa4d3582c21c613fc26f6908ed1faa0dd0c27381,b3815c62affe89560ecabb2f30de46742c927e8a951f37f080264d0b394e16b55ea0786629798d0170c713a9779e4585,b9626bcf02210e8979b0e661bbdbf2e5a691105761fd8800bd1e96087a57c393285af91dcf3c3d6763a643d874f14599 --amount 10000 #### END OF OBSOLETE SENTRY BUILD ##### ## Refresh Block Explorer - Done on Block Explorer exec ssh -i ~/.ssh/keys/oregon-key-benchmark.pem ec2-user@44.232.43.231 tmux att ### Go to the be session and kill the running process ### Usually you can then up arrow twice to run the following two commands npm run db-reset npm run start ## Refresh Staking Dashbaord - Done on Local Machine ### If problems with this check Block explorer deplpoyment to set up local instance cd /Users/johnwhitton/projects/staking-dashboard/appengine ### Clean the db ./clear_openstaking.sh ### Launch the backend (optional) ./deploy1.sh ### Launch the frontend (optional) #### Log in to firebase project firebase login #### Check frontend URL cat .env.production #### Build the release npm run build #### Deploy Frontend to Production ./prod_deploy.sh # Network Validation ## Validate Watchdog - http://watchdog.hmny.io/report-ostn ## Validate Validator Build - e.g. https://jenkins.harmony.one/job/harmony-release/412/console ### Go to the console and check that the commit you are building is correct #### e.g https://jenkins.harmony.one/job/harmony-release/412/console and find the below text under [harmony] #### Checking out Revision 0c46e086734aea2140f306d28ca3aa10e73c2153 (refs/remotesorigin/t3) ## Validate Accounts Funded ### fund.sh has confirms balances so check the output when you run the command ### Check a balance on explorer one1m6j80t6rhc3ypaumtsfmqwjwp0mrqk9ff50prh ## Validate Faucet ### Fund an account on https://faucet.os.hmny.io/ e.g one1m6j80t6rhc3ypaumtsfmqwjwp0mrqk9ff50prh ## Validate Sentries ### Check they are elected on https://staking.harmony.one/validators #### Check they are earning ./hmy --node=\"https://api.s0.os.hmny.io\" blockchain validator information one1m6j80t6rhc3ypaumtsfmqwjwp0mrqk9ff50prh ./hmy --node=\"https://api.s0.os.hmny.io\" blockchain validator information one10fjqteq6q75nm62cx8vejqsk7mc8t5hle8ewnl ./hmy --node=\"https://api.s0.os.hmny.io\" blockchain validator information one1vzsj3julf0ljcj3hhxuqpu6zvadu488zfrtttz ./hmy --node=\"https://api.s0.os.hmny.io\" blockchain validator information one1marnnvc8hywmfxhrc8mtpjkvvdt32x9kxtwkvv ./hmy --node=\"https://api.s0.os.hmny.io\" blockchain validator information one1y5n7p8a845v96xyx2gh75wn5eyhtw5002lah27 ## Validate Block Explorer - https://explorer.os.hmny.io/#/ ### Check blocks are being update ## Validate Staking Explorer - https://staking.harmony.one/validators ### Check Validators ### Delegate to a validator # Announce completion of Refresh ## Discord channels - team-staking, p-ops, testnet-nodes ## Telegram channels - [P-OPS] Pangaea OPS team & tech support, Open staking volunteers - Pangaea ### Message - \"OSTN Refresh is now complete - please reset your validators\" {% endtab %} {% tab title=\"STN\" %} # Announce Refresh ## Discord channels - stressnet ### Message - STN Refresh starting now - will let you know when complete - changes are here https://gist.github.com/fxfactorial/981d1716ed623984946b52a46f39dc5d and https://github.com/harmony-one/harmony/commits/t3 # Protocol Release ## Log in to the devops Machine, set profile and go to experiment deploy exec ssh -i ~/.ssh/keys/oregon-key-benchmark.pem ec2-user@devop.hmny.io tmux ls tmux attach-session -t STN profile_print export WHOAMI=STN; export HMY_PROFILE=stn; profile_print cd /home/ec2-user/go/src/github.com/harmony-one/experiment-deploy/pipeline ## Release the Protocol ### Remove Existing Network ./run_on_shard.sh -p stn -T 0 'sudo killall -9 harmony; sudo rm -rf harmony_db_*; sudo rm -rf .dht*; sudo rm harmony.err; sudo rm -rf ../tmp_log/*/*' ./run_on_shard.sh -p stn -T 1 'sudo killall -9 harmony; sudo rm -rf harmony_db_*; sudo rm -rf .dht*; sudo rm harmony.err; sudo rm -rf ../tmp_log/*/*' ### Reset bootnodes ./go.sh -p stn bootnode ### Upgrade Harmony Nodes cat logs/stn/shard0.txt | xargs -i{} -P50 bash -c './restart_node.sh -U -y -d logs/stn -p stn -t 0 -r 0 -R 0 {}' cat logs/stn/shard1.txt | xargs -i{} -P50 bash -c './restart_node.sh -U -y -d logs/stn -p stn -t 1 -r 0 -R 0 {}' # Protocol Validation ## Check Consensus ./run_on_shard.sh -p stn -y -T 0 'tac ../tmp_log/*/zerolog*.log | grep -m 1 HOORAY' ./run_on_shard.sh -p stn -y -T 1 'tac ../tmp_log/*/zerolog*.log | grep -m 1 HOORAY' ## Check the correct version of the Code was deployed ./run_on_shard.sh -p stn -y -T 0 \"LD_LIBRARY_PATH=. ./harmony -version\" ./run_on_shard.sh -p stn -y -T 1 \"LD_LIBRARY_PATH=. ./harmony -version\" # Network Release ## Restart Watchdog ./update_nodedb.sh -w STN -t stn -c -p -r -y ## Release Validator Build ### Run Jenkins Harmony Release - https://jenkins.harmony.one/job/harmony-release/ ### Parameters #### Branch : t3 #### Branch Release : Check #### Build Type : release #### Network : pangaea #### STATIC_BINARY : Checked ### Run a second Jenkins Harmony release job with above paramaters but STATIC_BINARY unchecked ## Fund Accounts chmod a+x ./fund.sh ./fund.sh -f -c ## Restart Faucet - https://faucet.stn.hmny.io/ cd /home/ec2-user/CF ./faucet_deploy.sh stn cd /home/ec2-user/go/src/github.com/harmony-one/experiment-deploy/pipeline ## Stressnet nodes are using autonode so whould restart autmotically ### Sentry0 ./node_ssh.sh 52.11.85.154 ### Sentry1 ./node_ssh.sh 54.202.197.141 ## Monitoring setry optional ./node_ssh.sh 52.42.43.150 tmux attach - t node <CTL> c curl -LO https://harmony.one/hmycli && mv hmycli hmy && chmod +x hmy curl -LO https://raw.githubusercontent.com/harmony-one/harmony/master/scripts/node.sh && chmod a+x node.sh rm -rf harmony_db* ./node.sh -S -c -z -I -P -R localhost:6060 -N stress -k 463298d9357ddb336038a122b84549b0589597214e28f12b7816f09b554fd4c935437f25eb1720bae923fcb070b3e596.key <CTL> b ./node.sh -V ./hmy --node=\"https://api.s0.stn.hmny.io\" staking create-validator --validator-addr one1vzsj3julf0ljcj3hhxuqpu6zvadu488zfrtttz --name OSTNSentry0.1 --identity OSTNSentry2 --website sentry@harmony.one --security-contact Sentry --details \"OSTN Sentry for Shard 2 t3.small\" --rate 0.05 --max-rate 0.8 --max-change-rate 0.02 --min-self-delegation 10000 --max-total-delegation 10000000 --bls-pubkeys 463298d9357ddb336038a122b84549b0589597214e28f12b7816f09b554fd4c935437f25eb1720bae923fcb070b3e596 --amount 10000 ./hmy --node=\"https://api.s0.stn.hmny.io\" blockchain validator information one1vzsj3julf0ljcj3hhxuqpu6zvadu488zfrtttz ### Sentries not yet configured ./node_ssh.sh 54.188.46.48 ### Refresh Staking Explorer ./clear_stressnet.sh ## Refresh Block Explorer - Done on Block Explorer - Have to connect from Devops exec ssh -i ~/.ssh/keys/oregon-key-benchmark.pem ec2-user@35.164.26.115 tmux att ### Go to the be session and kill the running process ### Usually you can then up arrow twice to run the following two commands npm run db-reset npm run rebuild; npm run start # Network Validation ## Validate Watchdog - http://watchdog.hmny.io/report-ostn ## Validate Validator Build - e.g. https://jenkins.harmony.one/job/harmony-release/412/console ### Go to the console and check that the commit you are building is correct #### e.g https://jenkins.harmony.one/job/harmony-release/412/console and find the below text under [harmony] #### Checking out Revision 0c46e086734aea2140f306d28ca3aa10e73c2153 (refs/remotesorigin/t3) ## Validate Accounts Funded ### fund.sh has confirms balances so check the output when you run the command ### Check a balance on explorer one1m6j80t6rhc3ypaumtsfmqwjwp0mrqk9ff50prh ## Validate Faucet ### Fund an account on https://faucet.stn.hmny.io/ e.g one1m6j80t6rhc3ypaumtsfmqwjwp0mrqk9ff50prh ## Validate Sentries ### Check they are elected on https://staking.harmony.one/validators #### Check they are earning ./hmy --node=\"https://api.s0.os.hmny.io\" blockchain validator information one1m6j80t6rhc3ypaumtsfmqwjwp0mrqk9ff50prh ./hmy --node=\"https://api.s0.os.hmny.io\" blockchain validator information one10fjqteq6q75nm62cx8vejqsk7mc8t5hle8ewnl ./hmy --node=\"https://api.s0.os.hmny.io\" blockchain validator information one1vzsj3julf0ljcj3hhxuqpu6zvadu488zfrtttz ./hmy --node=\"https://api.s0.os.hmny.io\" blockchain validator information one1marnnvc8hywmfxhrc8mtpjkvvdt32x9kxtwkvv ./hmy --node=\"https://api.s0.os.hmny.io\" blockchain validator information one1y5n7p8a845v96xyx2gh75wn5eyhtw5002lah27 ## Validate Block Explorer - https://explorer.os.hmny.io/#/ ### Check blocks are being update ## Validate Staking Explorer - https://staking.harmony.one/validators ### Check Validators ### Delegate to a validator # Announce completion of Refresh ## Discord channels - team-staking, p-ops, testnet-nodes ## Telegram channels - [P-OPS] Pangaea OPS team & tech support, Open staking volunteers - Pangaea ### Message - \"OSTN Refresh is now complete - please reset your validators\" {% endtab %} {% endtabs %}","title":"Refresh Cheat Sheet"},{"location":"deploy/cicd/netdeploy/network-release/cheat-sheets/refresh/#reference-material","text":"p2 state of emergency on dev & ops Fixit Edgars Deployment Proposal OSTN Checklist - OSTN Release Log Post Mortem Post-Mortem: Mar-31-2020 Mainnet Shards Down Post-Mortem: Apr 3-4-2020 OSTN Refresh issues","title":"Reference Material"},{"location":"deploy/cicd/netdeploy/network-release/cheat-sheets/rolling-upgrade/","text":"Rolling Upgrade Overview A rolling upgrade is the simplest form of Network upgrade. It is at the protocol level only and no other network components need to be restarted. Before doing a rolling upgrade a review of the code changes should be done to ensure no other network components are effected. If there are other components effected then changes to those components need to be coordinated. Finally a rolling upgrade can only be performed if the code changes are non breaking to the existing network (i.e. there are no backward incompatible data or protocol changes). {% hint style=\"danger\" %} Pre-requisites Verification the changes are backward compatible Ensure code change is compatible with other network components Protocol Build Preparation has been completed. {% endhint %} Perform Rolling Upgrade - ROLLING UPGRADE ONLY Check your profile {% tabs %} {% tab title=\"OSTN\" %} profile_print export WHOAMI=OS; export HMY_PROFILE=os; profile_print {% endtab %} {% tab title=\"PTN\" %} profile_print export WHOAMI=STN; export HMY_PROFILE=stn; profile_print {% endtab %} {% endtabs %} Perform Rolling Upgrade {% tabs %} {% tab title=\"OSTN\" %} cd ~/experiment-deploy/pipeline/ ./rolling_restart_shard.sh -s 1 -d logs/os -p os -t 90 -r 1 -R 1 3 ./rolling_restart_shard.sh -s 1 -d logs/os -p os -t 90 -r 1 -R 1 2 ./rolling_restart_shard.sh -s 1 -d logs/os -p os -t 90 -r 1 -R 1 1 ./rolling_restart_shard.sh -s 1 -d logs/os -p os -t 90 -r 1 -R 1 0 {% endtab %} {% tab title=\"STN\" %} cd /home/ec2-user/JL/experiment-deploy/pipeline # Rolling Upgrade ./rolling_restart_shard.sh -s 1 -d logs/stn -p stn -t 90 -r 1 -R 1 1 ./rolling_restart_shard.sh -s 1 -d logs/stn -p stn -t 90 -r 1 -R 1 0 # Quick Shard Restart cat logs/stn/shard0.txt | xargs -i{} -P50 bash -c './restart_node.sh -U -y -t -c -d logs/stn -p stn -t 0 -r 0 -R 0 {}' cat logs/stn/shard1.txt | xargs -i{} -P50 bash -c './restart_node.sh -U -y -t -c -d logs/stn -p stn -t 0 -r 0 -R 0 {}' {% endtab %} {% endtabs %}","title":"Rolling Upgrade"},{"location":"deploy/cicd/netdeploy/network-release/cheat-sheets/rolling-upgrade/#rolling-upgrade","text":"","title":"Rolling Upgrade"},{"location":"deploy/cicd/netdeploy/network-release/cheat-sheets/rolling-upgrade/#overview","text":"A rolling upgrade is the simplest form of Network upgrade. It is at the protocol level only and no other network components need to be restarted. Before doing a rolling upgrade a review of the code changes should be done to ensure no other network components are effected. If there are other components effected then changes to those components need to be coordinated. Finally a rolling upgrade can only be performed if the code changes are non breaking to the existing network (i.e. there are no backward incompatible data or protocol changes). {% hint style=\"danger\" %} Pre-requisites Verification the changes are backward compatible Ensure code change is compatible with other network components Protocol Build Preparation has been completed. {% endhint %}","title":"Overview"},{"location":"deploy/cicd/netdeploy/network-release/cheat-sheets/rolling-upgrade/#perform-rolling-upgrade-rolling-upgrade-only","text":"Check your profile {% tabs %} {% tab title=\"OSTN\" %} profile_print export WHOAMI=OS; export HMY_PROFILE=os; profile_print {% endtab %} {% tab title=\"PTN\" %} profile_print export WHOAMI=STN; export HMY_PROFILE=stn; profile_print {% endtab %} {% endtabs %} Perform Rolling Upgrade {% tabs %} {% tab title=\"OSTN\" %} cd ~/experiment-deploy/pipeline/ ./rolling_restart_shard.sh -s 1 -d logs/os -p os -t 90 -r 1 -R 1 3 ./rolling_restart_shard.sh -s 1 -d logs/os -p os -t 90 -r 1 -R 1 2 ./rolling_restart_shard.sh -s 1 -d logs/os -p os -t 90 -r 1 -R 1 1 ./rolling_restart_shard.sh -s 1 -d logs/os -p os -t 90 -r 1 -R 1 0 {% endtab %} {% tab title=\"STN\" %} cd /home/ec2-user/JL/experiment-deploy/pipeline # Rolling Upgrade ./rolling_restart_shard.sh -s 1 -d logs/stn -p stn -t 90 -r 1 -R 1 1 ./rolling_restart_shard.sh -s 1 -d logs/stn -p stn -t 90 -r 1 -R 1 0 # Quick Shard Restart cat logs/stn/shard0.txt | xargs -i{} -P50 bash -c './restart_node.sh -U -y -t -c -d logs/stn -p stn -t 0 -r 0 -R 0 {}' cat logs/stn/shard1.txt | xargs -i{} -P50 bash -c './restart_node.sh -U -y -t -c -d logs/stn -p stn -t 0 -r 0 -R 0 {}' {% endtab %} {% endtabs %}","title":"Perform Rolling Upgrade - ROLLING UPGRADE ONLY"},{"location":"deploy/cicd/netdeploy/network-release/faucet-deployment/","text":"Faucet Deployment {% hint style=\"info\" %} Quick restart on deploy of a new network # Connect to the devops Machine /cd home/ec2-user/CF ./faucet_deploy.sh os OSTN refund faucet from master faucet ho transfer --from one1zksj3evekayy90xt4psrz8h6j2v3hla4qwz4ur --to one1r6jrm6uh8aeysu0jwgrcafrs9mqlglp45sytxx --from-shard 0 --to-shard 0 --amount 10000000 {% endhint %} {% hint style=\"info\" %} Work around for nonce issue Create a new faucet account Fund the account Export the private key Edit ./faucet_deploy.sh to replace the existing key with correct one Relaunch faucet Transfer old faucet account funds back to master faucet {% endhint %} Faucet Overview The faucet is used to allow developers, validators and delegators to fund their account on Harmony's test networks so that they can participate in Harmony testing and development. It consists of a smart contract layer, a backend and a simple front end hosted by Harmony. Economics Funding is 30M ONE at each hard refresh Issuance is 10,000 ONE per wallet address every 450 blocks This enables 3000 faucet transactions of 10,000 each Top up is 30M ONE using the same mechanism as above e.g https://faucet.os.hmny.io/exposeAddress get the address and then fund the account from any account Components Smart Contract Layer - Code can be found in node-faucet with faucet.sol containing the key functionality Backend - Also found in node-faucet with app.js being the entry point Frontend - Also found in node-faucet with index.html being the entry point Deployment Environments OSTN - website PSTN - website Deployment Setup Clone the HRC REPOSITORY git clone https://github.com/harmony-one/HRC.git Spin up a new instance for the faucet This will be an AWS instance t3.small 8GB with ports 80, 443 22 open see here for an example from STN deployed in Oregon List of Instances # STN - 18.237.99.236 (harmony-testnet.pem) ./node_ssh.sh 18.237.99.236 # OSTN ./node_ssh.sh 3.133.82.52 # PTN Host faucet IdentityFile ~/.ssh/harmony-keys/cem_harmony_key2.pem User ubuntu HostName ec2-3-133-82-52.us-east-2.compute.amazonaws.com Host p-faucet IdentityFile ~/.ssh/harmony-keys/cem_harmony_key2.pem User ubuntu HostName ec2-3-134-93-91.us-east-2.compute.amazonaws.com Host t-faucet IdentityFile ~/.ssh/harmony-keys/cem_harmony_key2.pem User ubuntu HostName ec2-18-221-19-29.us-east-2.compute.amazonaws.com Faucet Machine Setup {% tabs %} {% tab title=\"OSTN\" %} ho {% endtab %} {% tab title=\"STN\" %} # Log into devops machine devops.sh # Log into STN tmux tmux att -t STN profile_print cd /home/ec2-user/JL/experiment-deploy/pipeline ./node_ssh.sh 54.200.244.64 # {% endtab %} {% endtabs %} Deployment Process # For a restart cd /Users/johnwhitton/projects/HRC/examples/node-faucet-no-contract # run a deployment script npm run clean-start Overview of funding process: run the deploy script (included separately) in the examples/node-faucet directory of the up to date HRC repo OSTN: OSTN_deploy.sh PSTN: PSTN_deploy.sh LRTN: LRTN_deploy.sh run the output command in the respective faucet instance kill the current running faucet first ( tmux attach ) either reuse the same tmux instance or start a new one in the faucet directory: ~/HRC2/examples/node-faucet copy the last command from the output [OSTN | PSTN]_cmd_log.txt and run it in the tmux window detach the tmux window with <ctrl-b>, d fund the contract account OSTN: https://faucet.os.hmny.io/exposeAddress PSTN: https://faucet.ps.hmny.io/exposeAddress funding process can be automated by grabbing the hex faucet address from the deploy script and converting it to bech32. can check that the faucet is successfully deployed by checking that amount in shard 0 is the initial funded amount (currently 0.01 ONE) Areas for Improvement Funding increase amount of funds by 10x Timeouts - analyze whether we can send multiple transactions per block - nonce issue Deploy multiple(5) faucets with different end points and tree structure Modify process to remove smart contract and sign transactions directly (if this enables multi transactions per block) Enhance further to send from multiple accounts.","title":"Faucet Deployment"},{"location":"deploy/cicd/netdeploy/network-release/faucet-deployment/#faucet-deployment","text":"{% hint style=\"info\" %} Quick restart on deploy of a new network # Connect to the devops Machine /cd home/ec2-user/CF ./faucet_deploy.sh os OSTN refund faucet from master faucet ho transfer --from one1zksj3evekayy90xt4psrz8h6j2v3hla4qwz4ur --to one1r6jrm6uh8aeysu0jwgrcafrs9mqlglp45sytxx --from-shard 0 --to-shard 0 --amount 10000000 {% endhint %} {% hint style=\"info\" %} Work around for nonce issue Create a new faucet account Fund the account Export the private key Edit ./faucet_deploy.sh to replace the existing key with correct one Relaunch faucet Transfer old faucet account funds back to master faucet {% endhint %}","title":"Faucet Deployment"},{"location":"deploy/cicd/netdeploy/network-release/faucet-deployment/#faucet-overview","text":"The faucet is used to allow developers, validators and delegators to fund their account on Harmony's test networks so that they can participate in Harmony testing and development. It consists of a smart contract layer, a backend and a simple front end hosted by Harmony.","title":"Faucet Overview"},{"location":"deploy/cicd/netdeploy/network-release/faucet-deployment/#economics","text":"Funding is 30M ONE at each hard refresh Issuance is 10,000 ONE per wallet address every 450 blocks This enables 3000 faucet transactions of 10,000 each Top up is 30M ONE using the same mechanism as above e.g https://faucet.os.hmny.io/exposeAddress get the address and then fund the account from any account","title":"Economics"},{"location":"deploy/cicd/netdeploy/network-release/faucet-deployment/#components","text":"Smart Contract Layer - Code can be found in node-faucet with faucet.sol containing the key functionality Backend - Also found in node-faucet with app.js being the entry point Frontend - Also found in node-faucet with index.html being the entry point","title":"Components"},{"location":"deploy/cicd/netdeploy/network-release/faucet-deployment/#deployment-environments","text":"OSTN - website PSTN - website","title":"Deployment Environments"},{"location":"deploy/cicd/netdeploy/network-release/faucet-deployment/#deployment-setup","text":"Clone the HRC REPOSITORY git clone https://github.com/harmony-one/HRC.git Spin up a new instance for the faucet This will be an AWS instance t3.small 8GB with ports 80, 443 22 open see here for an example from STN deployed in Oregon","title":"Deployment Setup"},{"location":"deploy/cicd/netdeploy/network-release/faucet-deployment/#list-of-instances","text":"# STN - 18.237.99.236 (harmony-testnet.pem) ./node_ssh.sh 18.237.99.236 # OSTN ./node_ssh.sh 3.133.82.52 # PTN Host faucet IdentityFile ~/.ssh/harmony-keys/cem_harmony_key2.pem User ubuntu HostName ec2-3-133-82-52.us-east-2.compute.amazonaws.com Host p-faucet IdentityFile ~/.ssh/harmony-keys/cem_harmony_key2.pem User ubuntu HostName ec2-3-134-93-91.us-east-2.compute.amazonaws.com Host t-faucet IdentityFile ~/.ssh/harmony-keys/cem_harmony_key2.pem User ubuntu HostName ec2-18-221-19-29.us-east-2.compute.amazonaws.com","title":"List of Instances"},{"location":"deploy/cicd/netdeploy/network-release/faucet-deployment/#faucet-machine-setup","text":"{% tabs %} {% tab title=\"OSTN\" %} ho {% endtab %} {% tab title=\"STN\" %} # Log into devops machine devops.sh # Log into STN tmux tmux att -t STN profile_print cd /home/ec2-user/JL/experiment-deploy/pipeline ./node_ssh.sh 54.200.244.64 # {% endtab %} {% endtabs %}","title":"Faucet Machine Setup"},{"location":"deploy/cicd/netdeploy/network-release/faucet-deployment/#deployment-process","text":"# For a restart cd /Users/johnwhitton/projects/HRC/examples/node-faucet-no-contract # run a deployment script npm run clean-start","title":"Deployment Process"},{"location":"deploy/cicd/netdeploy/network-release/faucet-deployment/#overview-of-funding-process","text":"run the deploy script (included separately) in the examples/node-faucet directory of the up to date HRC repo OSTN: OSTN_deploy.sh PSTN: PSTN_deploy.sh LRTN: LRTN_deploy.sh run the output command in the respective faucet instance kill the current running faucet first ( tmux attach ) either reuse the same tmux instance or start a new one in the faucet directory: ~/HRC2/examples/node-faucet copy the last command from the output [OSTN | PSTN]_cmd_log.txt and run it in the tmux window detach the tmux window with <ctrl-b>, d fund the contract account OSTN: https://faucet.os.hmny.io/exposeAddress PSTN: https://faucet.ps.hmny.io/exposeAddress funding process can be automated by grabbing the hex faucet address from the deploy script and converting it to bech32. can check that the faucet is successfully deployed by checking that amount in shard 0 is the initial funded amount (currently 0.01 ONE)","title":"Overview of funding process:"},{"location":"deploy/cicd/netdeploy/network-release/faucet-deployment/#areas-for-improvement","text":"Funding increase amount of funds by 10x Timeouts - analyze whether we can send multiple transactions per block - nonce issue Deploy multiple(5) faucets with different end points and tree structure Modify process to remove smart contract and sign transactions directly (if this enables multi transactions per block) Enhance further to send from multiple accounts.","title":"Areas for Improvement"},{"location":"deploy/cicd/netdeploy/network-release/faucet-deployment/faucet-install-notes/","text":"Faucet Install Notes ENV setup AWS instance ubuntu 18.04 t3.small Open SSH for your ip/devop machine, http/https ports for anywhere keep track of PEM key SSH into your new instance bash $ chmod 400 <path-to-pem-key> $ ssh -i <path-to-pem-key> ubuntu@<your-host-name> 2. Install dependencies ```bash $ sudo apt update && sudo apt install g++ make nginx tmux -y ## AWS Linux notes 1 sudo yum update 2 sudo yum install g++ make nginx tmux -y 3 sudo yum install nginx1 4 sudo amazon-linux-extras install nginx1.12 5 sudo amazon-linux-extras install g++ 6 sudo yum install gcc-c++ ``` Setup node environment bash $ curl -o- https://raw.githubusercontent.com/creationix/nvm/v0.32.1/install.sh | bash $ source ~/.bashrc $ nvm install 13 Setup nginx bash $ sudo apt update && sudo apt install nginx -y $ sudo rm /etc/nginx/sites-enabled/default $ sudo echo \"server { listen 80; server_name faucet; location / { proxy_set_header X-Real-IP \\$remote_addr; proxy_set_header X-Forwarded-For \\$remote_addr; proxy_set_header Host \\$http_host; proxy_pass http://127.0.0.1:3000; } }\" | sudo tee /etc/nginx/sites-available/faucet $ sudo ln -s /etc/nginx/sites-available/faucet /etc/nginx/sites-enabled/faucet $ sudo service nginx restart Clone and initialize node-faucet directory bash $ git clone https://github.com/harmony-one/HRC.git $ cd HRC/examples/node-faucet-no-contract $ npm i open tmux bash $ tmux new -s faucet $ cd ~/HRC/examples/node-faucet-no-contract As of this point, the faucet environment is set up and ready to be deployed. Notes Domain name Ask Leo to set up a domain name with Route 53 for easier access You'll need to provide the host-name and the public IP of the faucet machine You can access this information from the AWS EC2 instance page (OPTIONAL) TLS for security You can follow this guide to setup https with certbot: https://certbot.eff.org/lets-encrypt/ubuntubionic-nginx","title":"Faucet Install Notes"},{"location":"deploy/cicd/netdeploy/network-release/faucet-deployment/faucet-install-notes/#faucet-install-notes","text":"","title":"Faucet Install Notes"},{"location":"deploy/cicd/netdeploy/network-release/faucet-deployment/faucet-install-notes/#env-setup","text":"AWS instance ubuntu 18.04 t3.small Open SSH for your ip/devop machine, http/https ports for anywhere keep track of PEM key SSH into your new instance bash $ chmod 400 <path-to-pem-key> $ ssh -i <path-to-pem-key> ubuntu@<your-host-name> 2. Install dependencies ```bash $ sudo apt update && sudo apt install g++ make nginx tmux -y ## AWS Linux notes 1 sudo yum update 2 sudo yum install g++ make nginx tmux -y 3 sudo yum install nginx1 4 sudo amazon-linux-extras install nginx1.12 5 sudo amazon-linux-extras install g++ 6 sudo yum install gcc-c++ ``` Setup node environment bash $ curl -o- https://raw.githubusercontent.com/creationix/nvm/v0.32.1/install.sh | bash $ source ~/.bashrc $ nvm install 13 Setup nginx bash $ sudo apt update && sudo apt install nginx -y $ sudo rm /etc/nginx/sites-enabled/default $ sudo echo \"server { listen 80; server_name faucet; location / { proxy_set_header X-Real-IP \\$remote_addr; proxy_set_header X-Forwarded-For \\$remote_addr; proxy_set_header Host \\$http_host; proxy_pass http://127.0.0.1:3000; } }\" | sudo tee /etc/nginx/sites-available/faucet $ sudo ln -s /etc/nginx/sites-available/faucet /etc/nginx/sites-enabled/faucet $ sudo service nginx restart Clone and initialize node-faucet directory bash $ git clone https://github.com/harmony-one/HRC.git $ cd HRC/examples/node-faucet-no-contract $ npm i open tmux bash $ tmux new -s faucet $ cd ~/HRC/examples/node-faucet-no-contract As of this point, the faucet environment is set up and ready to be deployed.","title":"ENV setup"},{"location":"deploy/cicd/netdeploy/network-release/faucet-deployment/faucet-install-notes/#notes","text":"Domain name Ask Leo to set up a domain name with Route 53 for easier access You'll need to provide the host-name and the public IP of the faucet machine You can access this information from the AWS EC2 instance page (OPTIONAL) TLS for security You can follow this guide to setup https with certbot: https://certbot.eff.org/lets-encrypt/ubuntubionic-nginx","title":"Notes"},{"location":"deploy/cicd/netdeploy/network-release/harmony-protocol-deployment/","text":"Harmony Protocol Deployment Deployment Process Overview This document describes the build process for a complete Harmony Network it includes the following key steps and components Preparation Deploys are done from devops machine and are highly dependent on WHOAMI and HMY_PROFILE environment variables Harmony Protocol Building Harmony Binary Deleting existing network REFRESH ONLY Deploying Binaries to Network SDK and CLI Build and deploy latest CLI Block Explorer Update Block Explorer Endpoints Watchdog Update Watch Explorer Endpoints Faucet Deploy Deploy Faucet Staking Explorer Deploy Staking Explorer Harmony Chrome Extension Updating to latest version of Harmony Chrome Extension Old documentation is here","title":"Harmony Protocol Deployment"},{"location":"deploy/cicd/netdeploy/network-release/harmony-protocol-deployment/#harmony-protocol-deployment","text":"","title":"Harmony Protocol Deployment"},{"location":"deploy/cicd/netdeploy/network-release/harmony-protocol-deployment/#deployment-process-overview","text":"This document describes the build process for a complete Harmony Network it includes the following key steps and components Preparation Deploys are done from devops machine and are highly dependent on WHOAMI and HMY_PROFILE environment variables Harmony Protocol Building Harmony Binary Deleting existing network REFRESH ONLY Deploying Binaries to Network SDK and CLI Build and deploy latest CLI Block Explorer Update Block Explorer Endpoints Watchdog Update Watch Explorer Endpoints Faucet Deploy Deploy Faucet Staking Explorer Deploy Staking Explorer Harmony Chrome Extension Updating to latest version of Harmony Chrome Extension Old documentation is here","title":"Deployment Process Overview"},{"location":"deploy/cicd/netdeploy/network-release/harmony-protocol-deployment/release-validator-build/","text":"Release Validator Build {% hint style=\"info\" %} Note must build twice one for static_binary and one for normal release {% endhint %} Use Jenkins Harmony Release with the following Parameters {% tabs %} {% tab title=\"OSTN Static\" %} BRANCH - T3 BRANCH RELEASE - Check this box BUILD TYPE - RELEASE NETWORK - pangaea STATIC BINARY - Check this box {% endtab %} {% tab title=\"OSTN Normal\" %} BRANCH - T3 BRANCH RELEASE - Check this box BUILD TYPE - RELEASE NETWORK - pangaea STATIC BINARY - DO NOT Check this box {% endtab %} {% tab title=\"STN Static\" %} BRANCH - Master BRANCH RELEASE - Check this box BUILD TYPE - RELEASE NETWORK - stressnet STATIC BINARY - Check this box {% endtab %} {% tab title=\"STN Normal\" %} BRANCH - Master BRANCH RELEASE - Check this box BUILD TYPE - RELEASE NETWORK - stressnet STATIC BINARY - DO NOT Check this box {% endtab %} {% endtabs %} {% hint style=\"info\" %} If we have to build manually review this ticket for the script as a starting point. Also read the AWS CLI S3 instructions and go_executable_build.sh {% endhint %} Manual Validator Release {% tabs %} {% tab title=\"OSTN\" %} export WHOAMI=OS; export HMY_PROFILE=os; profile_print aws s3 ls s3:// aws s3 ls s3://pub.harmony.one/ {% endtab %} {% endtabs %}","title":"Release Validator Build"},{"location":"deploy/cicd/netdeploy/network-release/harmony-protocol-deployment/release-validator-build/#release-validator-build","text":"{% hint style=\"info\" %} Note must build twice one for static_binary and one for normal release {% endhint %} Use Jenkins Harmony Release with the following Parameters {% tabs %} {% tab title=\"OSTN Static\" %} BRANCH - T3 BRANCH RELEASE - Check this box BUILD TYPE - RELEASE NETWORK - pangaea STATIC BINARY - Check this box {% endtab %} {% tab title=\"OSTN Normal\" %} BRANCH - T3 BRANCH RELEASE - Check this box BUILD TYPE - RELEASE NETWORK - pangaea STATIC BINARY - DO NOT Check this box {% endtab %} {% tab title=\"STN Static\" %} BRANCH - Master BRANCH RELEASE - Check this box BUILD TYPE - RELEASE NETWORK - stressnet STATIC BINARY - Check this box {% endtab %} {% tab title=\"STN Normal\" %} BRANCH - Master BRANCH RELEASE - Check this box BUILD TYPE - RELEASE NETWORK - stressnet STATIC BINARY - DO NOT Check this box {% endtab %} {% endtabs %} {% hint style=\"info\" %} If we have to build manually review this ticket for the script as a starting point. Also read the AWS CLI S3 instructions and go_executable_build.sh {% endhint %}","title":"Release Validator Build"},{"location":"deploy/cicd/netdeploy/network-release/harmony-protocol-deployment/release-validator-build/#manual-validator-release","text":"{% tabs %} {% tab title=\"OSTN\" %} export WHOAMI=OS; export HMY_PROFILE=os; profile_print aws s3 ls s3:// aws s3 ls s3://pub.harmony.one/ {% endtab %} {% endtabs %}","title":"Manual Validator Release"},{"location":"deploy/cicd/netdeploy/network-release/harmony-protocol-deployment/validate-build/","text":"Validate Consensus Checks for consensus {% tabs %} {% tab title=\"OSTN\" %} ./run_on_shard.sh -p os -T 0 'tac ../tmp_log/*/zerolog*.log | grep -m 1 HOORAY' ./run_on_shard.sh -p os -T 1 'tac ../tmp_log/*/zerolog*.log | grep -m 1 HOORAY' ./run_on_shard.sh -p os -T 2 'tac ../tmp_log/*/zerolog*.log | grep -m 1 HOORAY' ./run_on_shard.sh -p os -T 3 'tac ../tmp_log/*/zerolog*.log | grep -m 1 HOORAY' {% endtab %} {% tab title=\"STN\" %} ./run_on_shard.sh -p stn -y -T 0 'tac ../tmp_log/*/zerolog*.log | grep -m 1 HOORAY' ./run_on_shard.sh -p stn -y -T 1 'tac ../tmp_log/*/zerolog*.log | grep -m 1 HOORAY' {% endtab %} {% endtabs %} {% hint style=\"info\" %} If consensus fails you can restart a shard using the following command cat logs/os/shard0.txt | xargs -i{} -P50 bash -c './restart_node.sh -y -d logs/os -p os -t 0 -r 0 -R 0 {}' {% endhint %}","title":"Validate Consensus"},{"location":"deploy/cicd/netdeploy/network-release/harmony-protocol-deployment/validate-build/#validate-consensus","text":"","title":"Validate Consensus"},{"location":"deploy/cicd/netdeploy/network-release/harmony-protocol-deployment/validate-build/#checks-for-consensus","text":"{% tabs %} {% tab title=\"OSTN\" %} ./run_on_shard.sh -p os -T 0 'tac ../tmp_log/*/zerolog*.log | grep -m 1 HOORAY' ./run_on_shard.sh -p os -T 1 'tac ../tmp_log/*/zerolog*.log | grep -m 1 HOORAY' ./run_on_shard.sh -p os -T 2 'tac ../tmp_log/*/zerolog*.log | grep -m 1 HOORAY' ./run_on_shard.sh -p os -T 3 'tac ../tmp_log/*/zerolog*.log | grep -m 1 HOORAY' {% endtab %} {% tab title=\"STN\" %} ./run_on_shard.sh -p stn -y -T 0 'tac ../tmp_log/*/zerolog*.log | grep -m 1 HOORAY' ./run_on_shard.sh -p stn -y -T 1 'tac ../tmp_log/*/zerolog*.log | grep -m 1 HOORAY' {% endtab %} {% endtabs %} {% hint style=\"info\" %} If consensus fails you can restart a shard using the following command cat logs/os/shard0.txt | xargs -i{} -P50 bash -c './restart_node.sh -y -d logs/os -p os -t 0 -r 0 -R 0 {}' {% endhint %}","title":"Checks for consensus"},{"location":"deploy/cicd/netdeploy/network-release/harmony-protocol-deployment/build/","text":"Build Updating T3 Branch {% hint style=\"info\" %} Note if ever a force push is done then all downstream repos can no longer just do a pull they instead need to git remote -v git fetch origin git log --pretty=oneline git branch -a git reset --hard origin/t3 git log --pretty=oneline {% endhint %} Build Preparation We will connect to the devops machine, set our profile and check which branch we are on Connect to devops machine exec ssh -i ~/.ssh/keys/oregon-key-benchmark.pem ec2-user@devop.hmny.io # or exec ssh -i ~/.ssh/keys/oregon-key-benchmark.pem ec2-user@35.160.64.190 # or exec ssh -i ~/.ssh/id_rsa jw@devop.hmny.io Connect to tmux session {% tabs %} {% tab title=\"OSTN\" %} tmux ls tmux attach-session -t os {% endtab %} {% tab title=\"STN\" %} tmux ls tmux attach-session -t STN {% endtab %} {% endtabs %} Set Harmony Profile {% tabs %} {% tab title=\"OSTN\" %} export WHOAMI=OS; export HMY_PROFILE=os; profile_print {% endtab %} {% tab title=\"STN\" %} export WHOAMI=STN; export HMY_PROFILE=stn; profile_print {% endtab %} {% endtabs %} Merge the latest changes from Master to t3 {% hint style=\"info\" %} This is optional if you are building of t3 branch, see here for details. {% endhint %} Harmony Build We will pull the latest code, build and deploy latest binaries Ensure our profile is set correctly profile_print Build our binary - ensure you use the correct branch (master for OSTN currently) {% tabs %} {% tab title=\"OSTN\" %} cd $(go env GOPATH)/src/github.com/harmony-one/harmony # This goes somewhere like here # /home/ec2-user/go/src/github.com/harmony-one/harmony git status git checkout t3 git pull ## If there has been a forced update you also need to git remote -v git fetch origin git log --pretty=oneline git branch -a git reset --hard origin/t3 ## Check the version aligins with what you want to build git log --pretty=oneline ## Tag the release (only used when building from master) git tag -a v1.0-20200316.0 git push origin v1.0-20200316.0 # Build and upload Static Binary # Should only need to do this once make linux_static # Check whether the build is static or not file bin/harmony ldd bin/harmony ./scripts/go_executable_build.sh -s file bin/harmony ./scripts/go_executable_build.sh -s upload # Build and upload Dynamic Binary ./scripts/go_executable_build.sh file bin/harmony ldd bin/harmony ./scripts/go_executable_build.sh upload {% endtab %} {% tab title=\"STN\" %} cd ~/JL/harmony git status git clean -fdx git checkout master git pull ## If there has been a forced update you also need to git remote -v git fetch origin git log --pretty=oneline git branch -a git reset --hard origin/t3 ## Check the version aligins with what you want to build git log --pretty=oneline ## Tag the release (only used when building from master) git tag -a v1.0-20200316.0 git push origin v1.0-20200316.0 # Build and upload Static Binary # Should only need to do this once make linux_static # Check whether the build is static or not file bin/harmony # Upload the static binary ./scripts/go_executable_build.sh -s upload # Build and upload Dynamic Binary ./scripts/go_executable_build.sh file bin/harmony ldd bin/harmony ./scripts/go_executable_build.sh upload {% endtab %} {% endtabs %} Update Experiment-deploy ready for upgrade process {% tabs %} {% tab title=\"OSTN\" %} cd ~/experiment-deploy/ git status git pull git log --pretty=oneline cd ~/experiment-deploy/pipeline/ git diff {% endtab %} {% tab title=\"STN\" %} cd ~/JL/experiment-deploy/ git status git pull git log --pretty=oneline cd ~/JL/experiment-deploy/pipeline/ git diff {% endtab %} {% endtabs %}","title":"Build"},{"location":"deploy/cicd/netdeploy/network-release/harmony-protocol-deployment/build/#build","text":"","title":"Build"},{"location":"deploy/cicd/netdeploy/network-release/harmony-protocol-deployment/build/#updating-t3-branch","text":"{% hint style=\"info\" %} Note if ever a force push is done then all downstream repos can no longer just do a pull they instead need to git remote -v git fetch origin git log --pretty=oneline git branch -a git reset --hard origin/t3 git log --pretty=oneline {% endhint %}","title":"Updating T3 Branch"},{"location":"deploy/cicd/netdeploy/network-release/harmony-protocol-deployment/build/#build_1","text":"","title":"Build"},{"location":"deploy/cicd/netdeploy/network-release/harmony-protocol-deployment/build/#preparation","text":"We will connect to the devops machine, set our profile and check which branch we are on Connect to devops machine exec ssh -i ~/.ssh/keys/oregon-key-benchmark.pem ec2-user@devop.hmny.io # or exec ssh -i ~/.ssh/keys/oregon-key-benchmark.pem ec2-user@35.160.64.190 # or exec ssh -i ~/.ssh/id_rsa jw@devop.hmny.io Connect to tmux session {% tabs %} {% tab title=\"OSTN\" %} tmux ls tmux attach-session -t os {% endtab %} {% tab title=\"STN\" %} tmux ls tmux attach-session -t STN {% endtab %} {% endtabs %} Set Harmony Profile {% tabs %} {% tab title=\"OSTN\" %} export WHOAMI=OS; export HMY_PROFILE=os; profile_print {% endtab %} {% tab title=\"STN\" %} export WHOAMI=STN; export HMY_PROFILE=stn; profile_print {% endtab %} {% endtabs %}","title":"Preparation"},{"location":"deploy/cicd/netdeploy/network-release/harmony-protocol-deployment/build/#merge-the-latest-changes-from-master-to-t3","text":"{% hint style=\"info\" %} This is optional if you are building of t3 branch, see here for details. {% endhint %}","title":"Merge the latest changes from Master to t3"},{"location":"deploy/cicd/netdeploy/network-release/harmony-protocol-deployment/build/#harmony-build","text":"We will pull the latest code, build and deploy latest binaries Ensure our profile is set correctly profile_print Build our binary - ensure you use the correct branch (master for OSTN currently) {% tabs %} {% tab title=\"OSTN\" %} cd $(go env GOPATH)/src/github.com/harmony-one/harmony # This goes somewhere like here # /home/ec2-user/go/src/github.com/harmony-one/harmony git status git checkout t3 git pull ## If there has been a forced update you also need to git remote -v git fetch origin git log --pretty=oneline git branch -a git reset --hard origin/t3 ## Check the version aligins with what you want to build git log --pretty=oneline ## Tag the release (only used when building from master) git tag -a v1.0-20200316.0 git push origin v1.0-20200316.0 # Build and upload Static Binary # Should only need to do this once make linux_static # Check whether the build is static or not file bin/harmony ldd bin/harmony ./scripts/go_executable_build.sh -s file bin/harmony ./scripts/go_executable_build.sh -s upload # Build and upload Dynamic Binary ./scripts/go_executable_build.sh file bin/harmony ldd bin/harmony ./scripts/go_executable_build.sh upload {% endtab %} {% tab title=\"STN\" %} cd ~/JL/harmony git status git clean -fdx git checkout master git pull ## If there has been a forced update you also need to git remote -v git fetch origin git log --pretty=oneline git branch -a git reset --hard origin/t3 ## Check the version aligins with what you want to build git log --pretty=oneline ## Tag the release (only used when building from master) git tag -a v1.0-20200316.0 git push origin v1.0-20200316.0 # Build and upload Static Binary # Should only need to do this once make linux_static # Check whether the build is static or not file bin/harmony # Upload the static binary ./scripts/go_executable_build.sh -s upload # Build and upload Dynamic Binary ./scripts/go_executable_build.sh file bin/harmony ldd bin/harmony ./scripts/go_executable_build.sh upload {% endtab %} {% endtabs %}","title":"Harmony Build"},{"location":"deploy/cicd/netdeploy/network-release/harmony-protocol-deployment/build/#update-experiment-deploy-ready-for-upgrade-process","text":"{% tabs %} {% tab title=\"OSTN\" %} cd ~/experiment-deploy/ git status git pull git log --pretty=oneline cd ~/experiment-deploy/pipeline/ git diff {% endtab %} {% tab title=\"STN\" %} cd ~/JL/experiment-deploy/ git status git pull git log --pretty=oneline cd ~/JL/experiment-deploy/pipeline/ git diff {% endtab %} {% endtabs %}","title":"Update Experiment-deploy ready for upgrade process"},{"location":"deploy/cicd/netdeploy/network-release/harmony-protocol-deployment/build/funding-acounts/","text":"Funding acounts From the pipeline directory run funds.sh {% tabs %} {% tab title=\"OSTN\" %} cd /home/ec2-user/experiment-deploy/pipeline chmod a+x fund.sh ./fund.sh # Or to force funding ./fund.sh -c -f {% endtab %} {% tab title=\"STN\" %} cd /home/ec2-user/JL/experiment-deploy/pipeline chmod a+x fund.sh ./fund.sh # Or to force funding ./fund.sh -c -f {% endtab %} {% endtabs %}","title":"Funding acounts"},{"location":"deploy/cicd/netdeploy/network-release/harmony-protocol-deployment/build/funding-acounts/#funding-acounts","text":"From the pipeline directory run funds.sh {% tabs %} {% tab title=\"OSTN\" %} cd /home/ec2-user/experiment-deploy/pipeline chmod a+x fund.sh ./fund.sh # Or to force funding ./fund.sh -c -f {% endtab %} {% tab title=\"STN\" %} cd /home/ec2-user/JL/experiment-deploy/pipeline chmod a+x fund.sh ./fund.sh # Or to force funding ./fund.sh -c -f {% endtab %} {% endtabs %}","title":"Funding acounts"},{"location":"deploy/cicd/netdeploy/network-release/harmony-protocol-deployment/build/hard-refresh/","text":"Hard Refresh Remove existing network - REFRESH ONLY {% hint style=\"info\" %} Place PAGER DUTY IN MAINTENANCE MODE {% endhint %} Check your profile {% tabs %} {% tab title=\"OSTN\" %} profile_print export WHOAMI=OS; export HMY_PROFILE=os; profile_print {% endtab %} {% tab title=\"STN\" %} export WHOAMI=STN; export HMY_PROFILE=stn; profile_print cd ~/JL/experiment-deploy/pipeline {% endtab %} {% endtabs %} Remove existing network {% tabs %} {% tab title=\"OSTN\" %} ./run_on_shard.sh -p os -T 0 'sudo killall -9 harmony; sudo rm -rf harmony_db_*; sudo rm -rf .dht*; sudo rm harmony.err; sudo rm -rf ../tmp_log/*/*' ./run_on_shard.sh -p os -T 1 'sudo killall -9 harmony; sudo rm -rf harmony_db_*; sudo rm -rf .dht*; sudo rm harmony.err; sudo rm -rf ../tmp_log/*/*' ./run_on_shard.sh -p os -T 2 'sudo killall -9 harmony; sudo rm -rf harmony_db_*; sudo rm -rf .dht*; sudo rm harmony.err; sudo rm -rf ../tmp_log/*/*' ./run_on_shard.sh -p os -T 3 'sudo killall -9 harmony; sudo rm -rf harmony_db_*; sudo rm -rf .dht*; sudo rm harmony.err; sudo rm -rf ../tmp_log/*/*' {% endtab %} {% tab title=\"STN\" %} ./run_on_shard.sh -p stn -T 0 'sudo killall -9 harmony; sudo rm -rf harmony_db_*; sudo rm -rf .dht*; sudo rm harmony.err; sudo rm -rf ../tmp_log/*/*' ./run_on_shard.sh -p stn -T 1 'sudo killall -9 harmony; sudo rm -rf harmony_db_*; sudo rm -rf .dht*; sudo rm harmony.err; sudo rm -rf ../tmp_log/*/*' {% endtab %} {% endtabs %} Reset bootnodes {% tabs %} {% tab title=\"OSTN\" %} ./go.sh -p os bootnode {% endtab %} {% tab title=\"STN\" %} ./go.sh -p stn bootnode {% endtab %} {% endtabs %} Upgrade nodes {% tabs %} {% tab title=\"OSTN\" %} cat logs/os/shard0.txt | xargs -i{} -P50 bash -c './restart_node.sh -U -y -d logs/os -p os -t 0 -r 0 -R 0 {}' cat logs/os/shard1.txt | xargs -i{} -P50 bash -c './restart_node.sh -U -y -d logs/os -p os -t 0 -r 0 -R 0 {}' cat logs/os/shard2.txt | xargs -i{} -P50 bash -c './restart_node.sh -U -y -d logs/os -p os -t 0 -r 0 -R 0 {}' cat logs/os/shard3.txt | xargs -i{} -P50 bash -c './restart_node.sh -U -y -d logs/os -p os -t 0 -r 0 -R 0 {}' {% endtab %} {% tab title=\"STN\" %} cat logs/stn/shard0.txt | xargs -i{} -P50 bash -c './restart_node.sh -U -y -d logs/stn -p stn -t 0 -r 0 -R 0 {}' cat logs/stn/shard1.txt | xargs -i{} -P50 bash -c './restart_node.sh -U -y -d logs/stn -p stn -t 1 -r 0 -R 0 {}' {% endtab %} {% endtabs %} {% hint style=\"info\" %} Turn PagerDuty on again {% endhint %}","title":"Hard Refresh"},{"location":"deploy/cicd/netdeploy/network-release/harmony-protocol-deployment/build/hard-refresh/#hard-refresh","text":"","title":"Hard Refresh"},{"location":"deploy/cicd/netdeploy/network-release/harmony-protocol-deployment/build/hard-refresh/#remove-existing-network-refresh-only","text":"{% hint style=\"info\" %} Place PAGER DUTY IN MAINTENANCE MODE {% endhint %} Check your profile {% tabs %} {% tab title=\"OSTN\" %} profile_print export WHOAMI=OS; export HMY_PROFILE=os; profile_print {% endtab %} {% tab title=\"STN\" %} export WHOAMI=STN; export HMY_PROFILE=stn; profile_print cd ~/JL/experiment-deploy/pipeline {% endtab %} {% endtabs %} Remove existing network {% tabs %} {% tab title=\"OSTN\" %} ./run_on_shard.sh -p os -T 0 'sudo killall -9 harmony; sudo rm -rf harmony_db_*; sudo rm -rf .dht*; sudo rm harmony.err; sudo rm -rf ../tmp_log/*/*' ./run_on_shard.sh -p os -T 1 'sudo killall -9 harmony; sudo rm -rf harmony_db_*; sudo rm -rf .dht*; sudo rm harmony.err; sudo rm -rf ../tmp_log/*/*' ./run_on_shard.sh -p os -T 2 'sudo killall -9 harmony; sudo rm -rf harmony_db_*; sudo rm -rf .dht*; sudo rm harmony.err; sudo rm -rf ../tmp_log/*/*' ./run_on_shard.sh -p os -T 3 'sudo killall -9 harmony; sudo rm -rf harmony_db_*; sudo rm -rf .dht*; sudo rm harmony.err; sudo rm -rf ../tmp_log/*/*' {% endtab %} {% tab title=\"STN\" %} ./run_on_shard.sh -p stn -T 0 'sudo killall -9 harmony; sudo rm -rf harmony_db_*; sudo rm -rf .dht*; sudo rm harmony.err; sudo rm -rf ../tmp_log/*/*' ./run_on_shard.sh -p stn -T 1 'sudo killall -9 harmony; sudo rm -rf harmony_db_*; sudo rm -rf .dht*; sudo rm harmony.err; sudo rm -rf ../tmp_log/*/*' {% endtab %} {% endtabs %}","title":"Remove existing network - REFRESH ONLY"},{"location":"deploy/cicd/netdeploy/network-release/harmony-protocol-deployment/build/hard-refresh/#reset-bootnodes","text":"{% tabs %} {% tab title=\"OSTN\" %} ./go.sh -p os bootnode {% endtab %} {% tab title=\"STN\" %} ./go.sh -p stn bootnode {% endtab %} {% endtabs %}","title":"Reset bootnodes"},{"location":"deploy/cicd/netdeploy/network-release/harmony-protocol-deployment/build/hard-refresh/#upgrade-nodes","text":"{% tabs %} {% tab title=\"OSTN\" %} cat logs/os/shard0.txt | xargs -i{} -P50 bash -c './restart_node.sh -U -y -d logs/os -p os -t 0 -r 0 -R 0 {}' cat logs/os/shard1.txt | xargs -i{} -P50 bash -c './restart_node.sh -U -y -d logs/os -p os -t 0 -r 0 -R 0 {}' cat logs/os/shard2.txt | xargs -i{} -P50 bash -c './restart_node.sh -U -y -d logs/os -p os -t 0 -r 0 -R 0 {}' cat logs/os/shard3.txt | xargs -i{} -P50 bash -c './restart_node.sh -U -y -d logs/os -p os -t 0 -r 0 -R 0 {}' {% endtab %} {% tab title=\"STN\" %} cat logs/stn/shard0.txt | xargs -i{} -P50 bash -c './restart_node.sh -U -y -d logs/stn -p stn -t 0 -r 0 -R 0 {}' cat logs/stn/shard1.txt | xargs -i{} -P50 bash -c './restart_node.sh -U -y -d logs/stn -p stn -t 1 -r 0 -R 0 {}' {% endtab %} {% endtabs %} {% hint style=\"info\" %} Turn PagerDuty on again {% endhint %}","title":"Upgrade nodes"},{"location":"deploy/cicd/netdeploy/network-release/harmony-protocol-deployment/build/rolling-upgrade/","text":"Rolling Upgrade Perform Rolling Upgrade - ROLLING UPGRADE ONLY Check your profile {% tabs %} {% tab title=\"OSTN\" %} profile_print export WHOAMI=OS; export HMY_PROFILE=os; profile_print {% endtab %} {% tab title=\"PTN\" %} profile_print export WHOAMI=STN; export HMY_PROFILE=stn; profile_print {% endtab %} {% endtabs %} Perform Rolling Upgrade {% tabs %} {% tab title=\"OSTN\" %} cd ~/experiment-deploy/pipeline/ ./rolling_restart_shard.sh -s 1 -d logs/os -p os -t 90 -r 1 -R 1 3 ./rolling_restart_shard.sh -s 1 -d logs/os -p os -t 90 -r 1 -R 1 2 ./rolling_restart_shard.sh -s 1 -d logs/os -p os -t 90 -r 1 -R 1 1 ./rolling_restart_shard.sh -s 1 -d logs/os -p os -t 90 -r 1 -R 1 0 {% endtab %} {% tab title=\"STN\" %} cd /home/ec2-user/JL/experiment-deploy/pipeline # Rolling Upgrade ./rolling_restart_shard.sh -s 1 -d logs/stn -p stn -t 90 -r 1 -R 1 1 ./rolling_restart_shard.sh -s 1 -d logs/stn -p stn -t 90 -r 1 -R 1 0 # Quick Shard Restart cat logs/stn/shard0.txt | xargs -i{} -P50 bash -c './restart_node.sh -U -y -t -c -d logs/stn -p stn -t 0 -r 0 -R 0 {}' cat logs/stn/shard1.txt | xargs -i{} -P50 bash -c './restart_node.sh -U -y -t -c -d logs/stn -p stn -t 0 -r 0 -R 0 {}' {% endtab %} {% endtabs %}","title":"Rolling Upgrade"},{"location":"deploy/cicd/netdeploy/network-release/harmony-protocol-deployment/build/rolling-upgrade/#rolling-upgrade","text":"","title":"Rolling Upgrade"},{"location":"deploy/cicd/netdeploy/network-release/harmony-protocol-deployment/build/rolling-upgrade/#perform-rolling-upgrade-rolling-upgrade-only","text":"Check your profile {% tabs %} {% tab title=\"OSTN\" %} profile_print export WHOAMI=OS; export HMY_PROFILE=os; profile_print {% endtab %} {% tab title=\"PTN\" %} profile_print export WHOAMI=STN; export HMY_PROFILE=stn; profile_print {% endtab %} {% endtabs %} Perform Rolling Upgrade {% tabs %} {% tab title=\"OSTN\" %} cd ~/experiment-deploy/pipeline/ ./rolling_restart_shard.sh -s 1 -d logs/os -p os -t 90 -r 1 -R 1 3 ./rolling_restart_shard.sh -s 1 -d logs/os -p os -t 90 -r 1 -R 1 2 ./rolling_restart_shard.sh -s 1 -d logs/os -p os -t 90 -r 1 -R 1 1 ./rolling_restart_shard.sh -s 1 -d logs/os -p os -t 90 -r 1 -R 1 0 {% endtab %} {% tab title=\"STN\" %} cd /home/ec2-user/JL/experiment-deploy/pipeline # Rolling Upgrade ./rolling_restart_shard.sh -s 1 -d logs/stn -p stn -t 90 -r 1 -R 1 1 ./rolling_restart_shard.sh -s 1 -d logs/stn -p stn -t 90 -r 1 -R 1 0 # Quick Shard Restart cat logs/stn/shard0.txt | xargs -i{} -P50 bash -c './restart_node.sh -U -y -t -c -d logs/stn -p stn -t 0 -r 0 -R 0 {}' cat logs/stn/shard1.txt | xargs -i{} -P50 bash -c './restart_node.sh -U -y -t -c -d logs/stn -p stn -t 0 -r 0 -R 0 {}' {% endtab %} {% endtabs %}","title":"Perform Rolling Upgrade - ROLLING UPGRADE ONLY"},{"location":"deploy/cicd/netdeploy/network-release/harmony-protocol-deployment/build/network-upgrade/","text":"Network Upgrade Changing the network configuration We need to update https://github.com/harmony-one/experiment-deploy/blob/master/configs/benchmark-os.json and https://github.com/harmony-one/experiment-deploy/blob/master/configs/launch-os.json {% hint style=\"info\" %} Place Pager Duty in maintenance mode {% endhint %} Set Harmony Profile {% tabs %} {% tab title=\"OSTN\" %} export WHOAMI=OS; export HMY_PROFILE=os; profile_print {% endtab %} {% tab title=\"STN\" %} export WHOAMI=STN; export HMY_PROFILE=stn; profile_print cd ~/JL/experiment-deploy/ {% endtab %} {% endtabs %} Removing Existing Network - For Fresh Network - ONLY {% tabs %} {% tab title=\"OSTN\" %} cd ~/experiment-deploy/pipeline/ # Scan through all nodes with OS profile tag ./aws-instances.sh -g OS # Terminates all the nodes created in the list ./go.sh -p os deinit {% endtab %} {% tab title=\"STN\" %} cd ~/JL/experiment-deploy/pipeline/ # Scan through all nodes with STN profile tag ./aws-instances.sh -g STN # Terminates all the nodes created in the list ./go.sh -p stn deinit {% endtab %} {% endtabs %} Launch New Network For Fresh Network - ONLY {% tabs %} {% tab title=\"OSTN\" %} # Launches new instances ./go.sh -p os -k # Create the bls key list ./run_on_shard.sh -p os -y -T 0 'ip=$(curl http://169.254.169.254/latest/meta-data/public-ipv4); for k in $(ls ./.hmy/blskeys/); do echo $k, $ip; done' > ostn-s0-actual.txt ./run_on_shard.sh -p os -y -T 1 'ip=$(curl http://169.254.169.254/latest/meta-data/public-ipv4); for k in $(ls ./.hmy/blskeys/); do echo $k, $ip; done' > ostn-s1-actual.txt ./run_on_shard.sh -p os -y -T 2 'ip=$(curl http://169.254.169.254/latest/meta-data/public-ipv4); for k in $(ls ./.hmy/blskeys/); do echo $k, $ip; done' > ostn-s2-actual.txt ./run_on_shard.sh -p os -y -T 3 'ip=$(curl http://169.254.169.254/latest/meta-data/public-ipv4); for k in $(ls ./.hmy/blskeys/); do echo $k, $ip; done' > ostn-s3-actual.txt cat ostn*actual* ## To get the date time stamp for the log directory on the devops machine more /home/ec2-user/experiment-deploy/pipeline/logs/os/profile-os.json { \"bucket\": \"unique-bucket-bin\", \"folder\": \"OS\", \"sessionID\": \"20200326.180455\" } ## Manually create the temp logs with sessionID from above - NOT NEEDED USUALLY ## ls -ltr logs/os/ ## cd logs/os/ ## cd .. ## ./run_on_shard.sh -p os -T 0 'sudo mkdir -p ../tmp_log/log-20200318.173735;' ## ./run_on_shard.sh -p os -T 1 'sudo mkdir -p ../tmp_log/log-20200318.173735;' ## ./run_on_shard.sh -p os -T 2 'sudo mkdir -p ../tmp_log/log-20200318.173735;' ## ./run_on_shard.sh -p os -T 3 'sudo mkdir -p ../tmp_log/log-20200318.173735;' # Restart all the shards - NOT NEEDED USUALLY cat logs/os/shard0.txt | xargs -i{} -P50 bash -c './restart_node.sh -y -d logs/os -p os -t 0 -r 0 -R 0 {}' cat logs/os/shard1.txt | xargs -i{} -P50 bash -c './restart_node.sh -y -d logs/os -p os -t 0 -r 0 -R 0 {}' cat logs/os/shard2.txt | xargs -i{} -P50 bash -c './restart_node.sh -y -d logs/os -p os -t 0 -r 0 -R 0 {}' cat logs/os/shard3.txt | xargs -i{} -P50 bash -c './restart_node.sh -y -d logs/os -p os -t 0 -r 0 -R 0 {}' {% endtab %} {% tab title=\"STN\" %} # Launches new instances ./go.sh -p stn -k # Create the bls key list ./run_on_shard.sh -p stn -y -T 0 'ip=$(curl http://169.254.169.254/latest/meta-data/public-ipv4); for k in $(ls ./.hmy/blskeys/); do echo $k, $ip; done' > stn-s0-actual.txt ./run_on_shard.sh -p stn -y -T 1 'ip=$(curl http://169.254.169.254/latest/meta-data/public-ipv4); for k in $(ls ./.hmy/blskeys/); do echo $k, $ip; done' > stn-s1-actual.txt cat stn*actual* python3 bls.py ref ## To get the date time stamp for the log directory on the devops machine more /home/ec2-user/experiment-deploy/pipeline/logs/os/profile-os.json { \"bucket\": \"unique-bucket-bin\", \"folder\": \"OS\", \"sessionID\": \"20200326.180455\" } ## Manually create the temp logs with sessionID from above - NOT NEEDED USUALLY ## ls -ltr logs/os/ ## cd logs/os/ ## cd .. ## ./run_on_shard.sh -p os -T 0 'sudo mkdir -p ../tmp_log/log-20200318.173735;' ## ./run_on_shard.sh -p os -T 1 'sudo mkdir -p ../tmp_log/log-20200318.173735;' ## ./run_on_shard.sh -p os -T 2 'sudo mkdir -p ../tmp_log/log-20200318.173735;' ## ./run_on_shard.sh -p os -T 3 'sudo mkdir -p ../tmp_log/log-20200318.173735;' # Restart all the shards - NOT NEEDED USUALLY cat logs/stn/shard0.txt | xargs -i{} -P50 bash -c './restart_node.sh -y -d -c logs/stn -p stn -t 0 -r 0 -R 0 {}' cat logs/stn/shard1.txt | xargs -i{} -P50 bash -c './restart_node.sh -y -d -c logs/stn -p stn -t 0 -r 0 -R 0 {}' {% endtab %} {% endtabs %} Share the new network IP addresses with watchdog See here Update DNS Entries See here {% hint style=\"info\" %} Turn Pager duty on again {% endhint %} scp /home/ec2-user/experiment-deploy/pipeline/logs/os/shard?.txt watchdog:/home/ec2-user/staking ssh watchdog -- sudo systemctl restart harmony-watchdogd@staking.service Update the explorer information see this pull request { \"domain_name\": \"os.hmny.io\", \"num_of_shards\": 4, \"explorers_0\" : [\"54.184.36.85\"], \"explorers_1\" : [\"54.183.185.205\"], \"explorers_2\" : [\"18.189.185.176\"], \"explorers_3\" : [\"34.230.46.2\"], \"hosted_zone_id\" : \"Z1UEV9ND4IWBVM\", \"subnet_us-east-1\": [\"subnet-14da445e\", \"subnet-2c957212\", \"subnet-2f00cb73\", \"subnet-7b65f774\", \"subnet-7da3751a\", \"subnet-7e5c8950\"], \"subnet_us-east-2\": [\"subnet-45031908\", \"subnet-b38df5db\", \"subnet-c071c0ba\"], \"subnet_us-west-1\": [\"subnet-551f560e\", \"subnet-5be2df3c\"], \"subnet_us-west-2\": [\"subnet-1953d052\", \"subnet-6a6c1230\", \"subnet-c33554ba\", \"subnet-d73bdcfc\"], \"sg_us-east-1\": [\"sg-0a9f239987978e0eb\"], \"sg_us-east-2\": [\"sg-05c8f480d9a17574c\"], \"sg_us-west-1\": [\"sg-0fc2b150b51b313ec\"], \"sg_us-west-2\": [\"sg-03de0eb6b8f247581\"] } Notes hosted_zone_id -> comes from aws route53 -> hosted zones subnet -> comes from vpc -> subnets in aws sg are the security groups","title":"Network Upgrade"},{"location":"deploy/cicd/netdeploy/network-release/harmony-protocol-deployment/build/network-upgrade/#network-upgrade","text":"","title":"Network Upgrade"},{"location":"deploy/cicd/netdeploy/network-release/harmony-protocol-deployment/build/network-upgrade/#changing-the-network-configuration","text":"We need to update https://github.com/harmony-one/experiment-deploy/blob/master/configs/benchmark-os.json and https://github.com/harmony-one/experiment-deploy/blob/master/configs/launch-os.json {% hint style=\"info\" %} Place Pager Duty in maintenance mode {% endhint %} Set Harmony Profile {% tabs %} {% tab title=\"OSTN\" %} export WHOAMI=OS; export HMY_PROFILE=os; profile_print {% endtab %} {% tab title=\"STN\" %} export WHOAMI=STN; export HMY_PROFILE=stn; profile_print cd ~/JL/experiment-deploy/ {% endtab %} {% endtabs %}","title":"Changing the network configuration"},{"location":"deploy/cicd/netdeploy/network-release/harmony-protocol-deployment/build/network-upgrade/#removing-existing-network-for-fresh-network-only","text":"{% tabs %} {% tab title=\"OSTN\" %} cd ~/experiment-deploy/pipeline/ # Scan through all nodes with OS profile tag ./aws-instances.sh -g OS # Terminates all the nodes created in the list ./go.sh -p os deinit {% endtab %} {% tab title=\"STN\" %} cd ~/JL/experiment-deploy/pipeline/ # Scan through all nodes with STN profile tag ./aws-instances.sh -g STN # Terminates all the nodes created in the list ./go.sh -p stn deinit {% endtab %} {% endtabs %}","title":"Removing Existing Network - For Fresh Network - ONLY"},{"location":"deploy/cicd/netdeploy/network-release/harmony-protocol-deployment/build/network-upgrade/#launch-new-network-for-fresh-network-only","text":"{% tabs %} {% tab title=\"OSTN\" %} # Launches new instances ./go.sh -p os -k # Create the bls key list ./run_on_shard.sh -p os -y -T 0 'ip=$(curl http://169.254.169.254/latest/meta-data/public-ipv4); for k in $(ls ./.hmy/blskeys/); do echo $k, $ip; done' > ostn-s0-actual.txt ./run_on_shard.sh -p os -y -T 1 'ip=$(curl http://169.254.169.254/latest/meta-data/public-ipv4); for k in $(ls ./.hmy/blskeys/); do echo $k, $ip; done' > ostn-s1-actual.txt ./run_on_shard.sh -p os -y -T 2 'ip=$(curl http://169.254.169.254/latest/meta-data/public-ipv4); for k in $(ls ./.hmy/blskeys/); do echo $k, $ip; done' > ostn-s2-actual.txt ./run_on_shard.sh -p os -y -T 3 'ip=$(curl http://169.254.169.254/latest/meta-data/public-ipv4); for k in $(ls ./.hmy/blskeys/); do echo $k, $ip; done' > ostn-s3-actual.txt cat ostn*actual* ## To get the date time stamp for the log directory on the devops machine more /home/ec2-user/experiment-deploy/pipeline/logs/os/profile-os.json { \"bucket\": \"unique-bucket-bin\", \"folder\": \"OS\", \"sessionID\": \"20200326.180455\" } ## Manually create the temp logs with sessionID from above - NOT NEEDED USUALLY ## ls -ltr logs/os/ ## cd logs/os/ ## cd .. ## ./run_on_shard.sh -p os -T 0 'sudo mkdir -p ../tmp_log/log-20200318.173735;' ## ./run_on_shard.sh -p os -T 1 'sudo mkdir -p ../tmp_log/log-20200318.173735;' ## ./run_on_shard.sh -p os -T 2 'sudo mkdir -p ../tmp_log/log-20200318.173735;' ## ./run_on_shard.sh -p os -T 3 'sudo mkdir -p ../tmp_log/log-20200318.173735;' # Restart all the shards - NOT NEEDED USUALLY cat logs/os/shard0.txt | xargs -i{} -P50 bash -c './restart_node.sh -y -d logs/os -p os -t 0 -r 0 -R 0 {}' cat logs/os/shard1.txt | xargs -i{} -P50 bash -c './restart_node.sh -y -d logs/os -p os -t 0 -r 0 -R 0 {}' cat logs/os/shard2.txt | xargs -i{} -P50 bash -c './restart_node.sh -y -d logs/os -p os -t 0 -r 0 -R 0 {}' cat logs/os/shard3.txt | xargs -i{} -P50 bash -c './restart_node.sh -y -d logs/os -p os -t 0 -r 0 -R 0 {}' {% endtab %} {% tab title=\"STN\" %} # Launches new instances ./go.sh -p stn -k # Create the bls key list ./run_on_shard.sh -p stn -y -T 0 'ip=$(curl http://169.254.169.254/latest/meta-data/public-ipv4); for k in $(ls ./.hmy/blskeys/); do echo $k, $ip; done' > stn-s0-actual.txt ./run_on_shard.sh -p stn -y -T 1 'ip=$(curl http://169.254.169.254/latest/meta-data/public-ipv4); for k in $(ls ./.hmy/blskeys/); do echo $k, $ip; done' > stn-s1-actual.txt cat stn*actual* python3 bls.py ref ## To get the date time stamp for the log directory on the devops machine more /home/ec2-user/experiment-deploy/pipeline/logs/os/profile-os.json { \"bucket\": \"unique-bucket-bin\", \"folder\": \"OS\", \"sessionID\": \"20200326.180455\" } ## Manually create the temp logs with sessionID from above - NOT NEEDED USUALLY ## ls -ltr logs/os/ ## cd logs/os/ ## cd .. ## ./run_on_shard.sh -p os -T 0 'sudo mkdir -p ../tmp_log/log-20200318.173735;' ## ./run_on_shard.sh -p os -T 1 'sudo mkdir -p ../tmp_log/log-20200318.173735;' ## ./run_on_shard.sh -p os -T 2 'sudo mkdir -p ../tmp_log/log-20200318.173735;' ## ./run_on_shard.sh -p os -T 3 'sudo mkdir -p ../tmp_log/log-20200318.173735;' # Restart all the shards - NOT NEEDED USUALLY cat logs/stn/shard0.txt | xargs -i{} -P50 bash -c './restart_node.sh -y -d -c logs/stn -p stn -t 0 -r 0 -R 0 {}' cat logs/stn/shard1.txt | xargs -i{} -P50 bash -c './restart_node.sh -y -d -c logs/stn -p stn -t 0 -r 0 -R 0 {}' {% endtab %} {% endtabs %}","title":"Launch New Network For Fresh Network - ONLY"},{"location":"deploy/cicd/netdeploy/network-release/harmony-protocol-deployment/build/network-upgrade/#share-the-new-network-ip-addresses-with-watchdog","text":"See here","title":"Share the new network IP addresses with watchdog"},{"location":"deploy/cicd/netdeploy/network-release/harmony-protocol-deployment/build/network-upgrade/#update-dns-entries","text":"See here {% hint style=\"info\" %} Turn Pager duty on again {% endhint %} scp /home/ec2-user/experiment-deploy/pipeline/logs/os/shard?.txt watchdog:/home/ec2-user/staking ssh watchdog -- sudo systemctl restart harmony-watchdogd@staking.service","title":"Update DNS Entries"},{"location":"deploy/cicd/netdeploy/network-release/harmony-protocol-deployment/build/network-upgrade/#update-the-explorer-information-see-this-pull-request","text":"{ \"domain_name\": \"os.hmny.io\", \"num_of_shards\": 4, \"explorers_0\" : [\"54.184.36.85\"], \"explorers_1\" : [\"54.183.185.205\"], \"explorers_2\" : [\"18.189.185.176\"], \"explorers_3\" : [\"34.230.46.2\"], \"hosted_zone_id\" : \"Z1UEV9ND4IWBVM\", \"subnet_us-east-1\": [\"subnet-14da445e\", \"subnet-2c957212\", \"subnet-2f00cb73\", \"subnet-7b65f774\", \"subnet-7da3751a\", \"subnet-7e5c8950\"], \"subnet_us-east-2\": [\"subnet-45031908\", \"subnet-b38df5db\", \"subnet-c071c0ba\"], \"subnet_us-west-1\": [\"subnet-551f560e\", \"subnet-5be2df3c\"], \"subnet_us-west-2\": [\"subnet-1953d052\", \"subnet-6a6c1230\", \"subnet-c33554ba\", \"subnet-d73bdcfc\"], \"sg_us-east-1\": [\"sg-0a9f239987978e0eb\"], \"sg_us-east-2\": [\"sg-05c8f480d9a17574c\"], \"sg_us-west-1\": [\"sg-0fc2b150b51b313ec\"], \"sg_us-west-2\": [\"sg-03de0eb6b8f247581\"] } Notes hosted_zone_id -> comes from aws route53 -> hosted zones subnet -> comes from vpc -> subnets in aws sg are the security groups","title":"Update the explorer information see this pull request"},{"location":"deploy/cicd/netdeploy/network-release/harmony-protocol-deployment/build/network-upgrade/updating-dns-entries/","text":"Updating DNS Entries and Endpoints Overview This page gives an overview of key dns and network configuration that is needed for the network to work. Here is an overview of Peer discovery in Harmony Network . Key Concepts and components Component Sample Endpoint or topic Description Booting Booting and Peer Discover Synching s0.stn.hmny.io Typically contains six or more nodes per shard Transactions api.so.hmny.io Must point to explorer nodes, currently only one explorer node per shard in stress and open staking networks. Beacon Chain Cross Shard Messaging Booting and Peer Discovery Syncing When a node starts up it must get a copy of the blockchain to this point in order to do this it needs to synch with other nodes. The list of nodes which it can synch with are controlled by a dns endpoint for that network shard e.g. s0.stn.hmny.io refers to the nodes which are used for synching on shard 0 in the stress network in harmony. To update these endpoints you call r53update.py from the experimental deploy pipeline the easiest way to do this is to create a script called updater53.sh containing the nodes you with to use for synching in each shard e.g. python3 r53update.py os 0 18.237.78.103 35.160.74.239 18.188.43.135 13.57.48.226 54.187.159.66 3.21.170.73 Initial (fast state syncing) may also be provided using rclone, this will automatically bring the node to the current state by using a db copy of the latest state backed up for the shard. Making RPC Calls RPC calls go through api.stn.hmy.io which must point to one or more explorer nodes. At the time of writing this for stress and open staking networks there is only one explorer node per shard. Cross Shard Transactions Troubleshooting Manual Steps To see which ips are set up dig s0.stn.hmny.io {% tabs %} {% tab title=\"OSTN\" %} ec2-user@ip-172-31-37-52 pipeline (master) $ vim ./logs/os/updater53.sh \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 ec2-user@ip-172-31-37-52 pipeline (master) $ ./logs/os/updater53.sh {% endtab %} {% tab title=\"STN\" %} tmux ls tmux attach-session -t STN export WHOAMI=STN; export HMY_PROFILE=stn; profile_print # Replace the IP's with valid IP's from shard?.txt or http://watchdog.hmny.io/report-stn cd ~/JL/experiment-deploy/pipeline/ vim ./logs/stn/updater53.sh \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 ./logs/stn/updater53.sh {% endtab %} {% endtabs %} Updating endpoints {% hint style=\"info\" %} You may need to pull harmony-ops repo if you have problems {% endhint %} {% tabs %} {% tab title=\"OSTN\" %} # Make sure you've pulled the latest version of devops # Go to the endpoint creation folder cd /home/ec2-user/harmony-ops/devops/create_https_wss_endpoints_aws ## Get the explorer endpoints cat ../../../experiment-deploy/pipeline/logs/stn/distribution_config.txt # You will see 52.36.135.220 9000 explorer_node 0 4-STN-explorer_node-od-2020-04-02_03_40_15 18.144.35.250 9000 explorer_node 1 3-STN-explorer_node-od-2020-04-02_03_40_15 # update the explorer endpoints vim staking.json # Run the update job python3 main.py -n staking -u # If any error check with andy {% endtab %} {% tab title=\"STN\" %} # Make sure you've pulled the latest version of devops # Go to the endpoint creation folder cd /home/ec2-user/JL/harmony-ops/devops/create_https_wss_endpoints_aws ## Get the explorer endpoints cat ../../../experiment-deploy/pipeline/logs/stn/distribution_config.txt # You will see 52.36.135.220 9000 explorer_node 0 4-STN-explorer_node-od-2020-04-02_03_40_15 18.144.35.250 9000 explorer_node 1 3-STN-explorer_node-od-2020-04-02_03_40_15 # update the explorer endpoints vim stress.json # Run the update job python3 main.py -n stress -u # If any error check with andy {% endtab %} {% endtabs %} Sample staking.json file { \"domain_name\": \"os.hmny.io\", \"num_of_shards\": 4, \"explorers_0\" : [\"54.242.77.34\"], \"explorers_1\" : [\"34.219.198.58\"], \"explorers_2\" : [\"3.15.151.190\"], \"explorers_3\" : [\"52.53.237.192\"], \"hosted_zone_id\" : \"Z3KY18NSN0TRRC\", \"subnet_us-east-1\": [\"subnet-14da445e\", \"subnet-2c957212\", \"subnet-2f00cb73\", \"subnet-7b65f774\", \"subnet-7da3751a\", \"subnet-7e5c8950\"], \"subnet_us-east-2\": [\"subnet-45031908\", \"subnet-b38df5db\", \"subnet-c071c0ba\"], \"subnet_us-west-1\": [\"subnet-551f560e\", \"subnet-5be2df3c\"], \"subnet_us-west-2\": [\"subnet-1953d052\", \"subnet-6a6c1230\", \"subnet-c33554ba\", \"subnet-d73bdcfc\"], \"sg_us-east-1\": [\"sg-0a9f239987978e0eb\"], \"sg_us-east-2\": [\"sg-05c8f480d9a17574c\"], \"sg_us-west-1\": [\"sg-0fc2b150b51b313ec\"], \"sg_us-west-2\": [\"sg-03de0eb6b8f247581\"] }","title":"Updating DNS Entries and Endpoints"},{"location":"deploy/cicd/netdeploy/network-release/harmony-protocol-deployment/build/network-upgrade/updating-dns-entries/#updating-dns-entries-and-endpoints","text":"","title":"Updating DNS Entries and Endpoints"},{"location":"deploy/cicd/netdeploy/network-release/harmony-protocol-deployment/build/network-upgrade/updating-dns-entries/#overview","text":"This page gives an overview of key dns and network configuration that is needed for the network to work. Here is an overview of Peer discovery in Harmony Network .","title":"Overview"},{"location":"deploy/cicd/netdeploy/network-release/harmony-protocol-deployment/build/network-upgrade/updating-dns-entries/#key-concepts-and-components","text":"Component Sample Endpoint or topic Description Booting Booting and Peer Discover Synching s0.stn.hmny.io Typically contains six or more nodes per shard Transactions api.so.hmny.io Must point to explorer nodes, currently only one explorer node per shard in stress and open staking networks. Beacon Chain Cross Shard Messaging","title":"Key Concepts and components"},{"location":"deploy/cicd/netdeploy/network-release/harmony-protocol-deployment/build/network-upgrade/updating-dns-entries/#booting-and-peer-discovery","text":"","title":"Booting and Peer Discovery"},{"location":"deploy/cicd/netdeploy/network-release/harmony-protocol-deployment/build/network-upgrade/updating-dns-entries/#syncing","text":"When a node starts up it must get a copy of the blockchain to this point in order to do this it needs to synch with other nodes. The list of nodes which it can synch with are controlled by a dns endpoint for that network shard e.g. s0.stn.hmny.io refers to the nodes which are used for synching on shard 0 in the stress network in harmony. To update these endpoints you call r53update.py from the experimental deploy pipeline the easiest way to do this is to create a script called updater53.sh containing the nodes you with to use for synching in each shard e.g. python3 r53update.py os 0 18.237.78.103 35.160.74.239 18.188.43.135 13.57.48.226 54.187.159.66 3.21.170.73 Initial (fast state syncing) may also be provided using rclone, this will automatically bring the node to the current state by using a db copy of the latest state backed up for the shard.","title":"Syncing"},{"location":"deploy/cicd/netdeploy/network-release/harmony-protocol-deployment/build/network-upgrade/updating-dns-entries/#making-rpc-calls","text":"RPC calls go through api.stn.hmy.io which must point to one or more explorer nodes. At the time of writing this for stress and open staking networks there is only one explorer node per shard.","title":"Making RPC Calls"},{"location":"deploy/cicd/netdeploy/network-release/harmony-protocol-deployment/build/network-upgrade/updating-dns-entries/#cross-shard-transactions","text":"","title":"Cross Shard Transactions"},{"location":"deploy/cicd/netdeploy/network-release/harmony-protocol-deployment/build/network-upgrade/updating-dns-entries/#troubleshooting-manual-steps","text":"To see which ips are set up dig s0.stn.hmny.io {% tabs %} {% tab title=\"OSTN\" %} ec2-user@ip-172-31-37-52 pipeline (master) $ vim ./logs/os/updater53.sh \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 ec2-user@ip-172-31-37-52 pipeline (master) $ ./logs/os/updater53.sh {% endtab %} {% tab title=\"STN\" %} tmux ls tmux attach-session -t STN export WHOAMI=STN; export HMY_PROFILE=stn; profile_print # Replace the IP's with valid IP's from shard?.txt or http://watchdog.hmny.io/report-stn cd ~/JL/experiment-deploy/pipeline/ vim ./logs/stn/updater53.sh \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 ./logs/stn/updater53.sh {% endtab %} {% endtabs %}","title":"Troubleshooting Manual Steps"},{"location":"deploy/cicd/netdeploy/network-release/harmony-protocol-deployment/build/network-upgrade/updating-dns-entries/#updating-endpoints","text":"{% hint style=\"info\" %} You may need to pull harmony-ops repo if you have problems {% endhint %} {% tabs %} {% tab title=\"OSTN\" %} # Make sure you've pulled the latest version of devops # Go to the endpoint creation folder cd /home/ec2-user/harmony-ops/devops/create_https_wss_endpoints_aws ## Get the explorer endpoints cat ../../../experiment-deploy/pipeline/logs/stn/distribution_config.txt # You will see 52.36.135.220 9000 explorer_node 0 4-STN-explorer_node-od-2020-04-02_03_40_15 18.144.35.250 9000 explorer_node 1 3-STN-explorer_node-od-2020-04-02_03_40_15 # update the explorer endpoints vim staking.json # Run the update job python3 main.py -n staking -u # If any error check with andy {% endtab %} {% tab title=\"STN\" %} # Make sure you've pulled the latest version of devops # Go to the endpoint creation folder cd /home/ec2-user/JL/harmony-ops/devops/create_https_wss_endpoints_aws ## Get the explorer endpoints cat ../../../experiment-deploy/pipeline/logs/stn/distribution_config.txt # You will see 52.36.135.220 9000 explorer_node 0 4-STN-explorer_node-od-2020-04-02_03_40_15 18.144.35.250 9000 explorer_node 1 3-STN-explorer_node-od-2020-04-02_03_40_15 # update the explorer endpoints vim stress.json # Run the update job python3 main.py -n stress -u # If any error check with andy {% endtab %} {% endtabs %}","title":"Updating endpoints"},{"location":"deploy/cicd/netdeploy/network-release/harmony-protocol-deployment/build/network-upgrade/updating-dns-entries/#sample-stakingjson-file","text":"{ \"domain_name\": \"os.hmny.io\", \"num_of_shards\": 4, \"explorers_0\" : [\"54.242.77.34\"], \"explorers_1\" : [\"34.219.198.58\"], \"explorers_2\" : [\"3.15.151.190\"], \"explorers_3\" : [\"52.53.237.192\"], \"hosted_zone_id\" : \"Z3KY18NSN0TRRC\", \"subnet_us-east-1\": [\"subnet-14da445e\", \"subnet-2c957212\", \"subnet-2f00cb73\", \"subnet-7b65f774\", \"subnet-7da3751a\", \"subnet-7e5c8950\"], \"subnet_us-east-2\": [\"subnet-45031908\", \"subnet-b38df5db\", \"subnet-c071c0ba\"], \"subnet_us-west-1\": [\"subnet-551f560e\", \"subnet-5be2df3c\"], \"subnet_us-west-2\": [\"subnet-1953d052\", \"subnet-6a6c1230\", \"subnet-c33554ba\", \"subnet-d73bdcfc\"], \"sg_us-east-1\": [\"sg-0a9f239987978e0eb\"], \"sg_us-east-2\": [\"sg-05c8f480d9a17574c\"], \"sg_us-west-1\": [\"sg-0fc2b150b51b313ec\"], \"sg_us-west-2\": [\"sg-03de0eb6b8f247581\"] }","title":"Sample staking.json file"},{"location":"deploy/cicd/netdeploy/network-validation/","text":"Network Validation Overview Following are a list of tools and approaches for validating a network once upgraded or refreshed. CLI Validation After a refresh you can validate that consensus has been formed via the CLI by looking for HOORAY in the log files for all the shards as follows, this will also identify the leader shard as it will be the IP that has the latest HOORAY. {% tabs %} {% tab title=\"OSTN\" %} ./run_on_shard.sh -p os -T 0 'tac ../tmp_log/*/zerolog*.log | grep -m 1 HOORAY' ./run_on_shard.sh -p os -T 1 'tac ../tmp_log/*/zerolog*.log | grep -m 1 HOORAY' ./run_on_shard.sh -p os -T 2 'tac ../tmp_log/*/zerolog*.log | grep -m 1 HOORAY' ./run_on_shard.sh -p os -T 3 'tac ../tmp_log/*/zerolog*.log | grep -m 1 HOORAY' {% endtab %} {% tab title=\"STN\" %} ./run_on_shard.sh -p stn -y -T 0 'tac ../tmp_log/*/zerolog*.log | grep -m 1 HOORAY' ./run_on_shard.sh -p stn -y -T 1 'tac ../tmp_log/*/zerolog*.log | grep -m 1 HOORAY' {% endtab %} {% endtabs %} Watchdog Validation After a refresh (or at any time) watchdog provides detailed information about Harmony Nodes including consensus, number of nodes, software version and any down nodes. Note : Watchdog is password protected. The userid and password for watchdog are pinned to the devops discord channel. All Environments - http://monitor.hmny.io/status Mainnet: http://watchdog.hmny.io/report-mainnet - mainnet LRTN: http://watchdog.hmny.io/report-lrtn - lrtn OSTN: http://watchdog.hmny.io/report-ostn - os PSTN: http://watchdog.hmny.io/report-pstn - pstn STN: http://watchdog.hmny.io/report-stn - stn Regression Testing When launching a network with a new version of the software it is important to run regression tests. Today this is typically done on stressnet and harmony tests repository is used. Sample commands mydesktop.sh tmux attach -t tests cd /home/ec2-user/harmony-tests hs transfer --from one1zksj3evekayy90xt4psrz8h6j2v3hla4qwz4ur --to one1y5n7p8a845v96xyx2gh75wn5eyhtw5002lah27 --from-shard 0 --to-shard 0 --amount 10000 hs transfer --from one1zksj3evekayy90xt4psrz8h6j2v3hla4qwz4ur --to one1y5n7p8a845v96xyx2gh75wn5eyhtw5002lah27 --from-shard 1 --to-shard 1 --amount 10000 ./tests --network stress --address one1y5n7p8a845v96xyx2gh75wn5eyhtw5002lah27 --export csv # download the file locally cd /Users/johnwhitton/projects/staking/STN/tests scp -i ~/.ssh/keys/california-key-benchmark.pem ec2-user@54.67.5.59:/home/ec2-user/harmony-tests/export/* . Stress Testing When launching a network with a new version of the software it is important to run stress tests. Today this is typically done on stressnet and harmony stress repository is used. Notes from Seb And if you're wondering why there seems to be such a massive discrepancy between how fast the stress tool appear to send txs and how few txs actually end up on the explorer - that usually comes down to either a) your ip address getting rate limited by the endpoint rules (AWS network setting I presume), or b) your sender address being marked for spam by the receiving node(s) To fully max out tx stress testing you need to run a modified binary that disables some of the tx pool validation checks and route your requests via that node. So when I try to maximize the tx load I typically do this: Download the custom node binary: bash <(curl -sSL https://raw.githubusercontent.com/SebastianJ/harmony-tools/master/install/install.sh) --node --disable-tx-validation Generate a bls key for a given shard (e.g. shard 0): bash <(curl -sSL https://raw.githubusercontent.com/SebastianJ/harmony-tools/master/keys/generate.sh) --shard 0 --count 1 Start the node: ./node.sh -k *.key -N stress -S -I -z -D -P Run the spammer using the node: ./stress txs --network stress --infinite --concurrency 100 --from YOUR_ADDRESS --node http://localhost:9500 If the node's not on the same machine as the spammer, check the external ip, e.g. curl ifconfig.me and use --node http://EXTERNAL_IP:9500 Caveat with that setup is that my custom branch of harmony-one/harmony has to stay updated with master and that I have to cut a new release whenever that happens - so it's not ideal for e.g. automated stress-testing. It's not a requirement to stress test tho - it's just a way to try to maximize the throughput using a hacked/modified binary","title":"Network Validation"},{"location":"deploy/cicd/netdeploy/network-validation/#network-validation","text":"","title":"Network Validation"},{"location":"deploy/cicd/netdeploy/network-validation/#overview","text":"Following are a list of tools and approaches for validating a network once upgraded or refreshed.","title":"Overview"},{"location":"deploy/cicd/netdeploy/network-validation/#cli-validation","text":"After a refresh you can validate that consensus has been formed via the CLI by looking for HOORAY in the log files for all the shards as follows, this will also identify the leader shard as it will be the IP that has the latest HOORAY. {% tabs %} {% tab title=\"OSTN\" %} ./run_on_shard.sh -p os -T 0 'tac ../tmp_log/*/zerolog*.log | grep -m 1 HOORAY' ./run_on_shard.sh -p os -T 1 'tac ../tmp_log/*/zerolog*.log | grep -m 1 HOORAY' ./run_on_shard.sh -p os -T 2 'tac ../tmp_log/*/zerolog*.log | grep -m 1 HOORAY' ./run_on_shard.sh -p os -T 3 'tac ../tmp_log/*/zerolog*.log | grep -m 1 HOORAY' {% endtab %} {% tab title=\"STN\" %} ./run_on_shard.sh -p stn -y -T 0 'tac ../tmp_log/*/zerolog*.log | grep -m 1 HOORAY' ./run_on_shard.sh -p stn -y -T 1 'tac ../tmp_log/*/zerolog*.log | grep -m 1 HOORAY' {% endtab %} {% endtabs %}","title":"CLI Validation"},{"location":"deploy/cicd/netdeploy/network-validation/#watchdog-validation","text":"After a refresh (or at any time) watchdog provides detailed information about Harmony Nodes including consensus, number of nodes, software version and any down nodes. Note : Watchdog is password protected. The userid and password for watchdog are pinned to the devops discord channel. All Environments - http://monitor.hmny.io/status Mainnet: http://watchdog.hmny.io/report-mainnet - mainnet LRTN: http://watchdog.hmny.io/report-lrtn - lrtn OSTN: http://watchdog.hmny.io/report-ostn - os PSTN: http://watchdog.hmny.io/report-pstn - pstn STN: http://watchdog.hmny.io/report-stn - stn","title":"Watchdog Validation"},{"location":"deploy/cicd/netdeploy/network-validation/#regression-testing","text":"When launching a network with a new version of the software it is important to run regression tests. Today this is typically done on stressnet and harmony tests repository is used. Sample commands mydesktop.sh tmux attach -t tests cd /home/ec2-user/harmony-tests hs transfer --from one1zksj3evekayy90xt4psrz8h6j2v3hla4qwz4ur --to one1y5n7p8a845v96xyx2gh75wn5eyhtw5002lah27 --from-shard 0 --to-shard 0 --amount 10000 hs transfer --from one1zksj3evekayy90xt4psrz8h6j2v3hla4qwz4ur --to one1y5n7p8a845v96xyx2gh75wn5eyhtw5002lah27 --from-shard 1 --to-shard 1 --amount 10000 ./tests --network stress --address one1y5n7p8a845v96xyx2gh75wn5eyhtw5002lah27 --export csv # download the file locally cd /Users/johnwhitton/projects/staking/STN/tests scp -i ~/.ssh/keys/california-key-benchmark.pem ec2-user@54.67.5.59:/home/ec2-user/harmony-tests/export/* .","title":"Regression Testing"},{"location":"deploy/cicd/netdeploy/network-validation/#stress-testing","text":"When launching a network with a new version of the software it is important to run stress tests. Today this is typically done on stressnet and harmony stress repository is used. Notes from Seb And if you're wondering why there seems to be such a massive discrepancy between how fast the stress tool appear to send txs and how few txs actually end up on the explorer - that usually comes down to either a) your ip address getting rate limited by the endpoint rules (AWS network setting I presume), or b) your sender address being marked for spam by the receiving node(s) To fully max out tx stress testing you need to run a modified binary that disables some of the tx pool validation checks and route your requests via that node. So when I try to maximize the tx load I typically do this: Download the custom node binary: bash <(curl -sSL https://raw.githubusercontent.com/SebastianJ/harmony-tools/master/install/install.sh) --node --disable-tx-validation Generate a bls key for a given shard (e.g. shard 0): bash <(curl -sSL https://raw.githubusercontent.com/SebastianJ/harmony-tools/master/keys/generate.sh) --shard 0 --count 1 Start the node: ./node.sh -k *.key -N stress -S -I -z -D -P Run the spammer using the node: ./stress txs --network stress --infinite --concurrency 100 --from YOUR_ADDRESS --node http://localhost:9500 If the node's not on the same machine as the spammer, check the external ip, e.g. curl ifconfig.me and use --node http://EXTERNAL_IP:9500 Caveat with that setup is that my custom branch of harmony-one/harmony has to stay updated with master and that I have to cut a new release whenever that happens - so it's not ideal for e.g. automated stress-testing. It's not a requirement to stress test tho - it's just a way to try to maximize the throughput using a hacked/modified binary","title":"Stress Testing"},{"location":"deploy/cicd/netdeploy/network-validation/developer-profiling-and-testing/","text":"Developer Profiling and Testing Overview This is an overview of how all the network validation components can be used in conjunction for running stress tests and capturing profiling information. It goes through configuration currently using johns developer desktop as well as a number of hosted aws instances. {% hint style=\"warning\" %} This document is a work in progress and moving forward many of the manual steps can be automated and the current nodes can be replaced with spot instances and scripted moving forward. {% endhint %} Component Overview Endpoints Explorer Profiling Information shows the pprof info on the explorer node Interactive Allocation (alloc) - from explorer Node Interactive Heap (heap) - from explorer node Interactive GoRoutine (goroutine) - from explorer node Hosting Component Hosted Description Explorer Node STN 0 52.42.43.150 Full explorer node with pprof enabled (t3.small) Validator Node STN 0 52.11.85.154 Validator Node with pprof enabled (t3.small) Validator Node STN 1 54.202.197.141 Validator node with pprof enabled (t3.small) Profiler 54.188.46.48 Web server which produces profiling info from the above nodes (t3.small) Regression Tests 54.67.5.59 Runs the complete regression tests (t3.large - johns dev desktop) Stress Tests 54.67.5.59 Runs stress tests (t3.large - johns dev desktop) Grafana monitor.harmony.one Shows cpu usage and memory utilization Analytics analytics.hmny.io Used to pull analytics data Running Tests Comprehensive instructions on how to run stress tests documented in the harmony-stress repository . Whilst the stress tests are running you can then capture the profiling information using the Capture Profiling Information section below. Below is the command used to run stress tests pointed to the Validator with profiling capabilities. ./stress txs --from one1y5n7p8a845v96xyx2gh75wn5eyhtw5002 # with your own custom node ./stress txs --from one1y5n7p8a845v96xyx2gh75wn5eyhtw5002lah27 --network stress --node=http://52.42.43.150:9500 --count 100 --concurrency 10 Component Setup Explorer Node The explorer node is needed to test rpc calls. It also has pprof setup and needs port 6060 exposed. You can then view the profiling information from the explorer at http://52.42.43.150:6060/debug/pprof/ devops.sh cdp pos ./node_ssh tmux attach -t explorer ./node.sh -S -c -z -I -P -T explorer -i 0 -r 0.0.0.0:6060 -N stress -k 463298d9357ddb336038a122b84549b0589597214e28f12b7816f09b554fd4c935437f25eb1720bae923fcb070b3e596.key Profiler The profiler connects to nodes via port 6060. It then enables viewing of these profiling info via a web interface. Setup #### Profiling Machine setup ### devops.sh cdp pstn ./node_ssh.sh 54.188.46.48 sudo yum install -y golang sudo yum install git sudo yum install tmux go get -u github.com/google/pprof sudo yum install graphviz mkdir pprof cd pprof tmux new-session -s pprof bash <(curl -sSL https://raw.githubusercontent.com/SebastianJ/harmony-tools/master/pprof/report.sh) --address localhost:6060 --interval 5m http://52.42.43.150:6060/debug/pprof/profile?seconds=60 curl http://52.42.43.150:6060/debug/pprof/allocs > allocs sudo go tool pprof -http=0.0.0.0:80 pprof.harmony.samples.cpu.086.pb.gz Capturing Profiling Information The following commands should be run to capture profiling information from the explorer whilst running stress tests. After capturing the information the servers need to be restarted. curl http://54.201.207.240:6060/debug/pprof/allocs?seconds=60 > allocs curl http://54.201.207.240:6060/debug/pprof/heap?seconds=60 > heap curl http://54.201.207.240:6060/debug/pprof/goroutine?seconds=60 > goroutine Displaying Various profiles tmux attach -t allocs sudo go tool pprof -http=0.0.0.0:80 allocs allocs tmux attach -t heap sudo go tool pprof -http=0.0.0.0:8080 heap tmux attach -t goroutine sudo go tool pprof -http=0.0.0.0:8081 goroutine","title":"Developer Profiling and Testing"},{"location":"deploy/cicd/netdeploy/network-validation/developer-profiling-and-testing/#developer-profiling-and-testing","text":"","title":"Developer Profiling and Testing"},{"location":"deploy/cicd/netdeploy/network-validation/developer-profiling-and-testing/#overview","text":"This is an overview of how all the network validation components can be used in conjunction for running stress tests and capturing profiling information. It goes through configuration currently using johns developer desktop as well as a number of hosted aws instances. {% hint style=\"warning\" %} This document is a work in progress and moving forward many of the manual steps can be automated and the current nodes can be replaced with spot instances and scripted moving forward. {% endhint %}","title":"Overview"},{"location":"deploy/cicd/netdeploy/network-validation/developer-profiling-and-testing/#component-overview","text":"","title":"Component Overview"},{"location":"deploy/cicd/netdeploy/network-validation/developer-profiling-and-testing/#endpoints","text":"Explorer Profiling Information shows the pprof info on the explorer node Interactive Allocation (alloc) - from explorer Node Interactive Heap (heap) - from explorer node Interactive GoRoutine (goroutine) - from explorer node","title":"Endpoints"},{"location":"deploy/cicd/netdeploy/network-validation/developer-profiling-and-testing/#hosting","text":"Component Hosted Description Explorer Node STN 0 52.42.43.150 Full explorer node with pprof enabled (t3.small) Validator Node STN 0 52.11.85.154 Validator Node with pprof enabled (t3.small) Validator Node STN 1 54.202.197.141 Validator node with pprof enabled (t3.small) Profiler 54.188.46.48 Web server which produces profiling info from the above nodes (t3.small) Regression Tests 54.67.5.59 Runs the complete regression tests (t3.large - johns dev desktop) Stress Tests 54.67.5.59 Runs stress tests (t3.large - johns dev desktop) Grafana monitor.harmony.one Shows cpu usage and memory utilization Analytics analytics.hmny.io Used to pull analytics data","title":"Hosting"},{"location":"deploy/cicd/netdeploy/network-validation/developer-profiling-and-testing/#running-tests","text":"Comprehensive instructions on how to run stress tests documented in the harmony-stress repository . Whilst the stress tests are running you can then capture the profiling information using the Capture Profiling Information section below. Below is the command used to run stress tests pointed to the Validator with profiling capabilities. ./stress txs --from one1y5n7p8a845v96xyx2gh75wn5eyhtw5002 # with your own custom node ./stress txs --from one1y5n7p8a845v96xyx2gh75wn5eyhtw5002lah27 --network stress --node=http://52.42.43.150:9500 --count 100 --concurrency 10","title":"Running Tests"},{"location":"deploy/cicd/netdeploy/network-validation/developer-profiling-and-testing/#component-setup","text":"","title":"Component Setup"},{"location":"deploy/cicd/netdeploy/network-validation/developer-profiling-and-testing/#explorer-node","text":"The explorer node is needed to test rpc calls. It also has pprof setup and needs port 6060 exposed. You can then view the profiling information from the explorer at http://52.42.43.150:6060/debug/pprof/ devops.sh cdp pos ./node_ssh tmux attach -t explorer ./node.sh -S -c -z -I -P -T explorer -i 0 -r 0.0.0.0:6060 -N stress -k 463298d9357ddb336038a122b84549b0589597214e28f12b7816f09b554fd4c935437f25eb1720bae923fcb070b3e596.key","title":"Explorer Node"},{"location":"deploy/cicd/netdeploy/network-validation/developer-profiling-and-testing/#profiler","text":"The profiler connects to nodes via port 6060. It then enables viewing of these profiling info via a web interface.","title":"Profiler"},{"location":"deploy/cicd/netdeploy/network-validation/developer-profiling-and-testing/#setup","text":"#### Profiling Machine setup ### devops.sh cdp pstn ./node_ssh.sh 54.188.46.48 sudo yum install -y golang sudo yum install git sudo yum install tmux go get -u github.com/google/pprof sudo yum install graphviz mkdir pprof cd pprof tmux new-session -s pprof bash <(curl -sSL https://raw.githubusercontent.com/SebastianJ/harmony-tools/master/pprof/report.sh) --address localhost:6060 --interval 5m http://52.42.43.150:6060/debug/pprof/profile?seconds=60 curl http://52.42.43.150:6060/debug/pprof/allocs > allocs sudo go tool pprof -http=0.0.0.0:80 pprof.harmony.samples.cpu.086.pb.gz Capturing Profiling Information The following commands should be run to capture profiling information from the explorer whilst running stress tests. After capturing the information the servers need to be restarted. curl http://54.201.207.240:6060/debug/pprof/allocs?seconds=60 > allocs curl http://54.201.207.240:6060/debug/pprof/heap?seconds=60 > heap curl http://54.201.207.240:6060/debug/pprof/goroutine?seconds=60 > goroutine","title":"Setup"},{"location":"deploy/cicd/netdeploy/network-validation/developer-profiling-and-testing/#displaying-various-profiles","text":"tmux attach -t allocs sudo go tool pprof -http=0.0.0.0:80 allocs allocs tmux attach -t heap sudo go tool pprof -http=0.0.0.0:8080 heap tmux attach -t goroutine sudo go tool pprof -http=0.0.0.0:8081 goroutine","title":"Displaying Various profiles"},{"location":"deploy/cicd/netdeploy/network-validation/jenkins-and-postman/","text":"Build Tests - Jenkins and Postman Overview","title":"Build Tests - Jenkins and Postman"},{"location":"deploy/cicd/netdeploy/network-validation/jenkins-and-postman/#build-tests-jenkins-and-postman","text":"","title":"Build Tests - Jenkins and Postman"},{"location":"deploy/cicd/netdeploy/network-validation/jenkins-and-postman/#overview","text":"","title":"Overview"},{"location":"deploy/cicd/netdeploy/network-validation/regression-tests/","text":"Regression Tests Regression Testing When launching a network with a new version of the software it is important to run regression tests. Today this is typically done on stressnet and harmony tests repository is used. Sample commands mydesktop.sh tmux attach -t tests cd /home/ec2-user/harmony-tests hs transfer --from one1zksj3evekayy90xt4psrz8h6j2v3hla4qwz4ur --to one1y5n7p8a845v96xyx2gh75wn5eyhtw5002lah27 --from-shard 0 --to-shard 0 --amount 10000 hs transfer --from one1zksj3evekayy90xt4psrz8h6j2v3hla4qwz4ur --to one1y5n7p8a845v96xyx2gh75wn5eyhtw5002lah27 --from-shard 1 --to-shard 1 --amount 10000 ./tests --network stress --address one1y5n7p8a845v96xyx2gh75wn5eyhtw5002lah27 --export csv # download the file locally cd /Users/johnwhitton/projects/staking/STN/tests scp -i ~/.ssh/keys/california-key-benchmark.pem ec2-user@54.67.5.59:/home/ec2-user/harmony-tests/export/* .","title":"Regression Tests"},{"location":"deploy/cicd/netdeploy/network-validation/regression-tests/#regression-tests","text":"","title":"Regression Tests"},{"location":"deploy/cicd/netdeploy/network-validation/regression-tests/#regression-testing","text":"When launching a network with a new version of the software it is important to run regression tests. Today this is typically done on stressnet and harmony tests repository is used. Sample commands mydesktop.sh tmux attach -t tests cd /home/ec2-user/harmony-tests hs transfer --from one1zksj3evekayy90xt4psrz8h6j2v3hla4qwz4ur --to one1y5n7p8a845v96xyx2gh75wn5eyhtw5002lah27 --from-shard 0 --to-shard 0 --amount 10000 hs transfer --from one1zksj3evekayy90xt4psrz8h6j2v3hla4qwz4ur --to one1y5n7p8a845v96xyx2gh75wn5eyhtw5002lah27 --from-shard 1 --to-shard 1 --amount 10000 ./tests --network stress --address one1y5n7p8a845v96xyx2gh75wn5eyhtw5002lah27 --export csv # download the file locally cd /Users/johnwhitton/projects/staking/STN/tests scp -i ~/.ssh/keys/california-key-benchmark.pem ec2-user@54.67.5.59:/home/ec2-user/harmony-tests/export/* .","title":"Regression Testing"},{"location":"deploy/cicd/netdeploy/network-validation/stress-tests/","text":"Stress Tests Stress Testing When launching a network with a new version of the software it is important to run stress tests. Today this is typically done on stressnet and harmony stress repository is used. Notes from Seb And if you're wondering why there seems to be such a massive discrepancy between how fast the stress tool appear to send txs and how few txs actually end up on the explorer - that usually comes down to either a) your ip address getting rate limited by the endpoint rules (AWS network setting I presume), or b) your sender address being marked for spam by the receiving node(s) To fully max out tx stress testing you need to run a modified binary that disables some of the tx pool validation checks and route your requests via that node. So when I try to maximize the tx load I typically do this: Download the custom node binary: bash <(curl -sSL https://raw.githubusercontent.com/SebastianJ/harmony-tools/master/install/install.sh) --node --disable-tx-validation Generate a bls key for a given shard (e.g. shard 0): bash <(curl -sSL https://raw.githubusercontent.com/SebastianJ/harmony-tools/master/keys/generate.sh) --shard 0 --count 1 Start the node: ./node.sh -k *.key -N stress -S -I -z -D -P Run the spammer using the node: ./stress txs --network stress --infinite --concurrency 100 --from YOUR_ADDRESS --node http://localhost:9500 If the node's not on the same machine as the spammer, check the external ip, e.g. curl ifconfig.me and use --node http://EXTERNAL_IP:9500 Caveat with that setup is that my custom branch of harmony-one/harmony has to stay updated with master and that I have to cut a new release whenever that happens - so it's not ideal for e.g. automated stress-testing. It's not a requirement to stress test tho - it's just a way to try to maximize the throughput using a hacked/modified binary","title":"Stress Tests"},{"location":"deploy/cicd/netdeploy/network-validation/stress-tests/#stress-tests","text":"","title":"Stress Tests"},{"location":"deploy/cicd/netdeploy/network-validation/stress-tests/#stress-testing","text":"When launching a network with a new version of the software it is important to run stress tests. Today this is typically done on stressnet and harmony stress repository is used. Notes from Seb And if you're wondering why there seems to be such a massive discrepancy between how fast the stress tool appear to send txs and how few txs actually end up on the explorer - that usually comes down to either a) your ip address getting rate limited by the endpoint rules (AWS network setting I presume), or b) your sender address being marked for spam by the receiving node(s) To fully max out tx stress testing you need to run a modified binary that disables some of the tx pool validation checks and route your requests via that node. So when I try to maximize the tx load I typically do this: Download the custom node binary: bash <(curl -sSL https://raw.githubusercontent.com/SebastianJ/harmony-tools/master/install/install.sh) --node --disable-tx-validation Generate a bls key for a given shard (e.g. shard 0): bash <(curl -sSL https://raw.githubusercontent.com/SebastianJ/harmony-tools/master/keys/generate.sh) --shard 0 --count 1 Start the node: ./node.sh -k *.key -N stress -S -I -z -D -P Run the spammer using the node: ./stress txs --network stress --infinite --concurrency 100 --from YOUR_ADDRESS --node http://localhost:9500 If the node's not on the same machine as the spammer, check the external ip, e.g. curl ifconfig.me and use --node http://EXTERNAL_IP:9500 Caveat with that setup is that my custom branch of harmony-one/harmony has to stay updated with master and that I have to cut a new release whenever that happens - so it's not ideal for e.g. automated stress-testing. It's not a requirement to stress test tho - it's just a way to try to maximize the throughput using a hacked/modified binary","title":"Stress Testing"},{"location":"deploy/cicd/netdeploy/network-validation/stressnet-stn-cheatsheat/","text":"Runtime Profiling (pprof) Overview Deeper analysis on node and validator is often required to provide insights as to inefficient code causing issues with memory utilization, cpu usage or networking performance. This document runs through how to run a node and enable it to capture profiling information via pprof. It goes through how to download those files to your local machine and conduct further analysis on them. Profiling Information - instructions # Copy files from Stressnet Monitor cd /Users/johnwhitton/projects/staking/STN scp -i ~/.ssh/keys/harmony-testnet.pem ec2-user@52.42.43.150:/home/ec2-user/pprof/* . pprof -http=localhost:8003 pprof.harmony.samples.cpu.007.pb.gz Local Machine setup ### Local Machine setup ### go get -u github.com/google/pprof brew install Graphviz Running a sentry ### Node Management commands #### Register the Validator ./hmy --node=\"https://api.s0.stn.hmny.io\" staking create-validator --validator-addr one1vzsj3julf0ljcj3hhxuqpu6zvadu488zfrtttz --name OSTNSentry0.1 --identity OSTNSentry2 --website sentry@harmony.one --security-contact Sentry --details \"OSTN Sentry for Shard 2 t3.small\" --rate 0.05 --max-rate 0.8 --max-change-rate 0.02 --min-self-delegation 10000 --max-total-delegation 10000000 --bls-pubkeys 463298d9357ddb336038a122b84549b0589597214e28f12b7816f09b554fd4c935437f25eb1720bae923fcb070b3e596 --amount 10000 # Restart the node ./node.sh -S -z -I -P -r localhost:6060 -N stress -k 463298d9357ddb336038a122b84549b0589597214e28f12b7816f09b554fd4c935437f25eb1720bae923fcb070b3e596.key # Restart the node and CLEAN out blockchain curl -LO https://harmony.one/hmycli && mv hmycli hmy && chmod +x hmy curl -LO https://raw.githubusercontent.com/harmony-one/harmony/master/scripts/node.sh && chmod a+x node.sh ./node.sh -S -c -z -I -P -r localhost:6060 -N stress -k 463298d9357ddb336038a122b84549b0589597214e28f12b7816f09b554fd4c935437f25eb1720bae923fcb070b3e596.key # If running an explorer node ./node.sh -S -c -z -I -P -T explorer -i 0 -r localhost:6060 -N stress -k 463298d9357ddb336038a122b84549b0589597214e28f12b7816f09b554fd4c935437f25eb1720bae923fcb070b3e596.key # Check that it's earning ./hmy --node=\"https://api.s0.os.hmny.io\" blockchain validator information one1vzsj3julf0ljcj3hhxuqpu6zvadu488zfrtttz # Mark it active ./hmy -n https://api.s0.os.hmny.io staking edit-validator --validator-addr one1vzsj3julf0ljcj3hhxuqpu6zvadu488zfrtttz --active true # Check the node version ./node.sh -V # Look at the logs tail -f ./latest/*.log Monitoring machine setup #### Stressnet Machine setup ### devops.sh export WHOAMI=STN; export HMY_PROFILE=stn; profile_print cd ~/john/experiment-deploy/pipeline ./node_ssh.sh 52.42.43.150 sudo yum install -y golang sudo yum install git go get -u github.com/google/pprof sudo yum install graphviz tmux new-session -s stress-node-s0-pprof bash <(curl -sSL https://raw.githubusercontent.com/SebastianJ/harmony-tools/master/pprof/report.sh) --address localhost:6060 --interval 5m go tool pprof --pdf http://localhost:6060/debug/pprof/profile?seconds=60 > cpu.pdf Capturing Data # http://localhost:6060/debug/pprof/allocs # A sampling of all past memory allocations go tool pprof --pdf http://localhost:6060/debug/pprof/allocs?seconds=600 > allocs.pdf # Stack traces of all current goroutines go tool pprof --pdf http://localhost:6060/debug/pprof/goroutine?seconds=600 > goroutine.pdf # A sampling of memory allocations of live objects. You can specify the gc GET parameter to run GC before taking the heap sample. go tool pprof --pdf http://localhost:6060/debug/pprof/heap?seconds=600 > heap.pdf # Stack traces that led to blocking on synchronization primitives go tool pprof --pdf http://localhost:6060/debug/pprof/block?seconds=600 > block.pdf # The command line invocation of the current program go tool pprof --pdf http://localhost:6060/debug/pprof/cmdline?seconds=60 > cmdline.pdf # Stack traces of holders of contended mutexes go tool pprof --pdf http://localhost:6060/debug/pprof/mutex?seconds=600 > mutex.pdf # Stack traces that led to the creation of new OS threads go tool pprof --pdf http://localhost:6060/debug/pprof/threadcreate?seconds=600 > threadcreate.pdf #scp files down from sentries scp -i ~/.ssh/keys/SentryOSTN.pem ec2-user@3.21.169.132:/home/ec2-user/*.pdf . exec ssh -i ~/.ssh/keys/SentryOSTN.pem ec2-user@3.21.169.132 Interactive mode scp -i ~/.ssh/keys/SentryOSTN.pem ec2-user@3.21.169.132:/home/ec2-user/pprof/* . go tool pprof -http=localhost:6060 pprof.harmony.alloc_objects.alloc_space.inuse_objects.inuse_space.010.pb.gz # On AWS instance go tool pprof -http=localhost:6070 pprof.harmony.contentions.delay.007.pb.gz Running Stress Tests - instructions # Log into the stress net machine ./node_ssh.sh 52.42.43.150 #Log into my desktop mydesktop.sh #See sentries for running nodes Additional Material Sebs Testing Instructions Double Signing Issue text bash <(curl -sSL https://raw.githubusercontent.com/SebastianJ/harmony-tools/master/double-signing/setup.sh) --network stress --shard 1 --address one1y5n7p8a845v96xyx2gh75wn5eyhtw5002lah27 Sebs Harmony tests repo Pangaea testing Sebs original ticket Sebs stress repo Sebs testing spreadsheet Daniels Autonode - instruction gist","title":"Runtime Profiling \\(pprof\\)"},{"location":"deploy/cicd/netdeploy/network-validation/stressnet-stn-cheatsheat/#runtime-profiling-pprof","text":"","title":"Runtime Profiling (pprof)"},{"location":"deploy/cicd/netdeploy/network-validation/stressnet-stn-cheatsheat/#overview","text":"Deeper analysis on node and validator is often required to provide insights as to inefficient code causing issues with memory utilization, cpu usage or networking performance. This document runs through how to run a node and enable it to capture profiling information via pprof. It goes through how to download those files to your local machine and conduct further analysis on them.","title":"Overview"},{"location":"deploy/cicd/netdeploy/network-validation/stressnet-stn-cheatsheat/#profiling-information-instructions","text":"# Copy files from Stressnet Monitor cd /Users/johnwhitton/projects/staking/STN scp -i ~/.ssh/keys/harmony-testnet.pem ec2-user@52.42.43.150:/home/ec2-user/pprof/* . pprof -http=localhost:8003 pprof.harmony.samples.cpu.007.pb.gz","title":"Profiling Information - instructions"},{"location":"deploy/cicd/netdeploy/network-validation/stressnet-stn-cheatsheat/#local-machine-setup","text":"### Local Machine setup ### go get -u github.com/google/pprof brew install Graphviz","title":"Local Machine setup"},{"location":"deploy/cicd/netdeploy/network-validation/stressnet-stn-cheatsheat/#running-a-sentry","text":"### Node Management commands #### Register the Validator ./hmy --node=\"https://api.s0.stn.hmny.io\" staking create-validator --validator-addr one1vzsj3julf0ljcj3hhxuqpu6zvadu488zfrtttz --name OSTNSentry0.1 --identity OSTNSentry2 --website sentry@harmony.one --security-contact Sentry --details \"OSTN Sentry for Shard 2 t3.small\" --rate 0.05 --max-rate 0.8 --max-change-rate 0.02 --min-self-delegation 10000 --max-total-delegation 10000000 --bls-pubkeys 463298d9357ddb336038a122b84549b0589597214e28f12b7816f09b554fd4c935437f25eb1720bae923fcb070b3e596 --amount 10000 # Restart the node ./node.sh -S -z -I -P -r localhost:6060 -N stress -k 463298d9357ddb336038a122b84549b0589597214e28f12b7816f09b554fd4c935437f25eb1720bae923fcb070b3e596.key # Restart the node and CLEAN out blockchain curl -LO https://harmony.one/hmycli && mv hmycli hmy && chmod +x hmy curl -LO https://raw.githubusercontent.com/harmony-one/harmony/master/scripts/node.sh && chmod a+x node.sh ./node.sh -S -c -z -I -P -r localhost:6060 -N stress -k 463298d9357ddb336038a122b84549b0589597214e28f12b7816f09b554fd4c935437f25eb1720bae923fcb070b3e596.key # If running an explorer node ./node.sh -S -c -z -I -P -T explorer -i 0 -r localhost:6060 -N stress -k 463298d9357ddb336038a122b84549b0589597214e28f12b7816f09b554fd4c935437f25eb1720bae923fcb070b3e596.key # Check that it's earning ./hmy --node=\"https://api.s0.os.hmny.io\" blockchain validator information one1vzsj3julf0ljcj3hhxuqpu6zvadu488zfrtttz # Mark it active ./hmy -n https://api.s0.os.hmny.io staking edit-validator --validator-addr one1vzsj3julf0ljcj3hhxuqpu6zvadu488zfrtttz --active true # Check the node version ./node.sh -V # Look at the logs tail -f ./latest/*.log","title":"Running a sentry"},{"location":"deploy/cicd/netdeploy/network-validation/stressnet-stn-cheatsheat/#monitoring-machine-setup","text":"#### Stressnet Machine setup ### devops.sh export WHOAMI=STN; export HMY_PROFILE=stn; profile_print cd ~/john/experiment-deploy/pipeline ./node_ssh.sh 52.42.43.150 sudo yum install -y golang sudo yum install git go get -u github.com/google/pprof sudo yum install graphviz tmux new-session -s stress-node-s0-pprof bash <(curl -sSL https://raw.githubusercontent.com/SebastianJ/harmony-tools/master/pprof/report.sh) --address localhost:6060 --interval 5m go tool pprof --pdf http://localhost:6060/debug/pprof/profile?seconds=60 > cpu.pdf","title":"Monitoring machine setup"},{"location":"deploy/cicd/netdeploy/network-validation/stressnet-stn-cheatsheat/#capturing-data","text":"# http://localhost:6060/debug/pprof/allocs # A sampling of all past memory allocations go tool pprof --pdf http://localhost:6060/debug/pprof/allocs?seconds=600 > allocs.pdf # Stack traces of all current goroutines go tool pprof --pdf http://localhost:6060/debug/pprof/goroutine?seconds=600 > goroutine.pdf # A sampling of memory allocations of live objects. You can specify the gc GET parameter to run GC before taking the heap sample. go tool pprof --pdf http://localhost:6060/debug/pprof/heap?seconds=600 > heap.pdf # Stack traces that led to blocking on synchronization primitives go tool pprof --pdf http://localhost:6060/debug/pprof/block?seconds=600 > block.pdf # The command line invocation of the current program go tool pprof --pdf http://localhost:6060/debug/pprof/cmdline?seconds=60 > cmdline.pdf # Stack traces of holders of contended mutexes go tool pprof --pdf http://localhost:6060/debug/pprof/mutex?seconds=600 > mutex.pdf # Stack traces that led to the creation of new OS threads go tool pprof --pdf http://localhost:6060/debug/pprof/threadcreate?seconds=600 > threadcreate.pdf #scp files down from sentries scp -i ~/.ssh/keys/SentryOSTN.pem ec2-user@3.21.169.132:/home/ec2-user/*.pdf . exec ssh -i ~/.ssh/keys/SentryOSTN.pem ec2-user@3.21.169.132 Interactive mode scp -i ~/.ssh/keys/SentryOSTN.pem ec2-user@3.21.169.132:/home/ec2-user/pprof/* . go tool pprof -http=localhost:6060 pprof.harmony.alloc_objects.alloc_space.inuse_objects.inuse_space.010.pb.gz # On AWS instance go tool pprof -http=localhost:6070 pprof.harmony.contentions.delay.007.pb.gz","title":"Capturing Data"},{"location":"deploy/cicd/netdeploy/network-validation/stressnet-stn-cheatsheat/#running-stress-tests-instructions","text":"# Log into the stress net machine ./node_ssh.sh 52.42.43.150 #Log into my desktop mydesktop.sh #See sentries for running nodes","title":"Running Stress Tests - instructions"},{"location":"deploy/cicd/netdeploy/network-validation/stressnet-stn-cheatsheat/#additional-material","text":"Sebs Testing Instructions Double Signing Issue text bash <(curl -sSL https://raw.githubusercontent.com/SebastianJ/harmony-tools/master/double-signing/setup.sh) --network stress --shard 1 --address one1y5n7p8a845v96xyx2gh75wn5eyhtw5002lah27 Sebs Harmony tests repo Pangaea testing Sebs original ticket Sebs stress repo Sebs testing spreadsheet Daniels Autonode - instruction gist","title":"Additional Material"},{"location":"deploy/cicd/netdeploy/outages/","text":"Outages","title":"Outages"},{"location":"deploy/cicd/netdeploy/outages/#outages","text":"","title":"Outages"},{"location":"deploy/cicd/netdeploy/outages/apr-9th-ostn-shard-2-out-of-memory/","text":"Apr 9th - OSTN Shard 2 - Out of Memory Overview Supporting Information Logs - s3://harmony-benchmark/logs/os/20/04/09/22:20:42 Profiling from Sentry 2 - 3.21.169.132 Link to Google Drive","title":"Apr 9th - OSTN Shard 2 - Out of Memory"},{"location":"deploy/cicd/netdeploy/outages/apr-9th-ostn-shard-2-out-of-memory/#apr-9th-ostn-shard-2-out-of-memory","text":"","title":"Apr 9th - OSTN Shard 2 - Out of Memory"},{"location":"deploy/cicd/netdeploy/outages/apr-9th-ostn-shard-2-out-of-memory/#overview","text":"","title":"Overview"},{"location":"deploy/cicd/netdeploy/outages/apr-9th-ostn-shard-2-out-of-memory/#supporting-information","text":"Logs - s3://harmony-benchmark/logs/os/20/04/09/22:20:42","title":"Supporting Information"},{"location":"deploy/cicd/netdeploy/outages/apr-9th-ostn-shard-2-out-of-memory/#profiling-from-sentry-2-321169132","text":"Link to Google Drive","title":"Profiling from Sentry 2 - 3.21.169.132"},{"location":"deploy/cicd/netdeploy/outages/april-4th-2020/","text":"April 4th 2020 Sebs analysis out of memory - https://gist.github.com/SebastianJ/95c20ff8b781035115533cd77c690106 s3://harmony-benchmark/logs/os/20/04/04/13:13:43 s3://harmony-benchmark/logs/os/20/04/04/13:43:05 9 NODES DOWN 18.220.13.70 18.234.87.124 34.222.111.126 35.172.221.7 35.172.229.66 52.14.136.4 54.176.115.167 54.188.74.132 54.221.20.6 6:45 Manual node restart ## Apr 4th 9 nodes down didn't work ./restart_node.sh -d logs/os -M -p os -t 0 -r 0 -R 0 18.220.13.70 ./restart_node.sh -d logs/os -U -p os -t 0 -r 0 -R 0 18.234.87.124 ./restart_node.sh -d logs/os -U -p os -t 0 -r 0 -R 0 34.222.111.126 ./restart_node.sh -d logs/os -U -p os -t 0 -r 0 -R 0 35.172.221.7 ./restart_node.sh -d logs/os -U -p os -t 0 -r 0 -R 0 35.172.229.66 ./restart_node.sh -d logs/os -U -p os -t 0 -r 0 -R 0 52.14.136.4 ./restart_node.sh -d logs/os -U -p os -t 0 -r 0 -R 0 54.176.115.167 ./restart_node.sh -d logs/os -U -p os -t 0 -r 0 -R 0 54.188.74.132 ./restart_node.sh -d logs/os -U -p os -t 0 -r 0 -R 0 54.221.20.6 # Restarted Shard brought 6 nodes back up ./run_on_shard.sh -p os -T 0 \"sudo rm -r .dht*\" cat logs/os/shard0.txt | xargs -i{} -P50 bash -c './restart_node.sh -y -d logs/os -p os -t 0 -r 0 -R 0 {}' ## Remaining 3 18.234.87.124 18.220.13.70 35.172.221.7 ## Check the view id run_on_shard.sh: using outdir logs/os/run_on_shard/2020-04-04T14:02:13Z.2f8Suf {\"level\":\"debug\",\"port\":\"9000\",\"ip\":\"34.222.111.126\",\"myEpoch\":137,\"myBlock\":5206,\"myViewID\":5206,\"phase\":1,\"mode\":\"Normal\",\"caller\":\"/home/ec2-user/harmony/consensus/consensus_v2.go:341\",\"time\":\"2020-04-04T14:02:11.016825931Z\",\"message\":\"[ConsensusMainLoop] Ticker\"} {\"level\":\"debug\",\"port\":\"9000\",\"ip\":\"54.242.77.34\",\"myEpoch\":137,\"myBlock\":5206,\"myViewID\":5206,\"phase\":0,\"mode\":\"Listening\",\"Phase\":\"Announce\",\"caller\":\"/home/ec2-user/harmony/consensus/view_change.go:94\",\"time\":\"2020-04-04T13:58:26.16919027Z\",\"message\":\"[ResetViewChangeState] Resetting view change state\"} {\"level\":\"debug\",\"port\":\"9000\",\"ip\":\"3.19.143.176\",\"myEpoch\":137,\"myBlock\":5206,\"myViewID\":5206,\"phase\":1,\"mode\":\"Normal\",\"caller\":\"/home/ec2-user/harmony/consensus/consensus_v2.go:341\",\"time\":\"2020-04-04T14:02:13.697762805Z\",\"message\":\"[ConsensusMainLoop] Ticker\"} {\"level\":\"debug\",\"port\":\"9000\",\"ip\":\"54.176.115.167\",\"myEpoch\":137,\"myBlock\":5206,\"myViewID\":5206,\"phase\":1,\"mode\":\"Normal\",\"caller\":\"/home/ec2-user/harmony/consensus/consensus_v2.go:341\",\"time\":\"2020-04-04T14:02:12.663571848Z\",\"message\":\"[ConsensusMainLoop] Ticker\"} {\"level\":\"debug\",\"port\":\"9000\",\"ip\":\"54.221.20.6\",\"myEpoch\":137,\"myBlock\":5206,\"myViewID\":5206,\"phase\":1,\"mode\":\"Normal\",\"caller\":\"/home/ec2-user/harmony/consensus/consensus_v2.go:341\",\"time\":\"2020-04-04T14:02:14.497625882Z\",\"message\":\"[ConsensusMainLoop] Ticker\"} {\"level\":\"debug\",\"port\":\"9000\",\"ip\":\"52.14.136.4\",\"myEpoch\":137,\"myBlock\":5206,\"myViewID\":5206,\"phase\":1,\"mode\":\"Normal\",\"caller\":\"/home/ec2-user/harmony/consensus/consensus_v2.go:341\",\"time\":\"2020-04-04T14:02:13.656551917Z\",\"message\":\"[ConsensusMainLoop] Ticker\"} {\"level\":\"debug\",\"port\":\"9000\",\"ip\":\"54.188.74.132\",\"myEpoch\":137,\"myBlock\":5206,\"myViewID\":5206,\"phase\":1,\"mode\":\"Normal\",\"caller\":\"/home/ec2-user/harmony/consensus/consensus_v2.go:341\",\"time\":\"2020-04-04T14:02:11.196847434Z\",\"message\":\"[ConsensusMainLoop] Ticker\"} {\"level\":\"debug\",\"port\":\"9000\",\"ip\":\"18.234.87.124\",\"myEpoch\":137,\"myBlock\":5206,\"myViewID\":5212,\"phase\":0,\"mode\":\"Normal\",\"caller\":\"/home/ec2-user/harmony/consensus/consensus_v2.go:341\",\"time\":\"2020-04-04T12:59:51.13887406Z\",\"message\":\"[ConsensusMainLoop] Ticker\"} {\"level\":\"debug\",\"port\":\"9000\",\"ip\":\"18.220.13.70\",\"myEpoch\":137,\"myBlock\":5206,\"myViewID\":5213,\"phase\":0,\"mode\":\"Normal\",\"myKey\":\"42c100b423e14387862fa419d81b430c9c6068d665e8a21737e293f49e41739795567176ab18070066a216eadb808808ba27796a04c1e4d2cb2d946ac520c2b41589517cb9ae22e64718086c1b13bec1c3d1d78c274d4ffafd78e1b66705e496f6dcead63386972fb00c26c7aefda614b8c58bc33c05d488df9bfef361c1dcced0088b245acb411b52a36ed287051215\",\"viewID\":5213,\"block\":5206,\"caller\":\"/home/ec2-user/harmony/consensus/view_change.go:409\",\"time\":\"2020-04-04T13:00:53.925142119Z\",\"message\":\"[onViewChange] I am the New Leader\"} {\"level\":\"debug\",\"port\":\"9000\",\"ip\":\"35.172.229.66\",\"myEpoch\":137,\"myBlock\":5206,\"myViewID\":5206,\"phase\":1,\"mode\":\"Normal\",\"caller\":\"/home/ec2-user/harmony/consensus/consensus_v2.go:341\",\"time\":\"2020-04-04T14:02:14.312296644Z\",\"message\":\"[ConsensusMainLoop] Ticker\"} {\"level\":\"debug\",\"port\":\"9000\",\"ip\":\"35.172.221.7\",\"myEpoch\":137,\"myBlock\":5206,\"myViewID\":5215,\"phase\":0,\"mode\":\"Normal\",\"myKey\":\"0f4a33e3b0babad97efea55b7c10991ebdf08ef8a41bbd95c9bca4b79c92d771d8606a3763a1d6ebf349ec5cb87f818fe6c33ada02e808fa7c2dd98734648cbb03c30d39e5c5deb5baae89c4b89e3b2356aff11cb94c35d7d955e14e131b4a18f3a65597fefc025493b00dbff904182b4e1da1c88f2743eb0690bc9db7bbabc3cf283cf7e98f4695e967d5418fd1ce94\",\"viewID\":5215,\"block\":5206,\"caller\":\"/home/ec2-user/harmony/consensus/view_change.go:409\",\"time\":\"2020-04-04T13:03:00.071816578Z\",\"message\":\"[onViewChange] I am the New Leader\"} {\"level\":\"debug\",\"port\":\"9000\",\"ip\":\"3.80.120.170\",\"myEpoch\":137,\"myBlock\":5206,\"myViewID\":5206,\"phase\":1,\"mode\":\"Normal\",\"caller\":\"/home/ec2-user/harmony/consensus/consensus_v2.go:341\",\"time\":\"2020-04-04T14:02:14.623056381Z\",\"message\":\"[ConsensusMainLoop] Ticker\"} {\"level\":\"debug\",\"port\":\"9000\",\"ip\":\"54.241.83.130\",\"myEpoch\":137,\"myBlock\":5206,\"myViewID\":5206,\"phase\":1,\"mode\":\"Normal\",\"caller\":\"/home/ec2-user/harmony/consensus/consensus_v2.go:341\",\"time\":\"2020-04-04T14:02:12.595807369Z\",\"message\":\"[ConsensusMainLoop] Ticker\"} {\"level\":\"debug\",\"port\":\"9000\",\"ip\":\"54.219.145.146\",\"myEpoch\":137,\"myBlock\":5206,\"myViewID\":5206,\"phase\":1,\"mode\":\"Normal\",\"caller\":\"/home/ec2-user/harmony/consensus/consensus_v2.go:341\",\"time\":\"2020-04-04T14:02:12.583594671Z\",\"message\":\"[ConsensusMainLoop] Ticker\"} {\"level\":\"debug\",\"port\":\"9000\",\"ip\":\"35.166.149.247\",\"myEpoch\":137,\"myBlock\":5206,\"myViewID\":5206,\"phase\":1,\"mode\":\"Normal\",\"caller\":\"/home/ec2-user/harmony/consensus/consensus_v2.go:341\",\"time\":\"2020-04-04T14:02:10.994572753Z\",\"message\":\"[ConsensusMainLoop] Ticker\"} {\"level\":\"debug\",\"port\":\"9000\",\"ip\":\"34.222.135.72\",\"myEpoch\":137,\"myBlock\":5206,\"myViewID\":5206,\"phase\":1,\"mode\":\"Normal\",\"caller\":\"/home/ec2-user/harmony/consensus/consensus_v2.go:341\",\"time\":\"2020-04-04T14:02:11.048995312Z\",\"message\":\"[ConsensusMainLoop] Ticker\"} {\"level\":\"debug\",\"port\":\"9000\",\"ip\":\"54.224.85.122\",\"myEpoch\":137,\"myBlock\":5206,\"myViewID\":5206,\"phase\":1,\"mode\":\"Normal\",\"caller\":\"/home/ec2-user/harmony/consensus/consensus_v2.go:341\",\"time\":\"2020-04-04T14:02:14.60496646Z\",\"message\":\"[ConsensusMainLoop] Ticker\"} {\"level\":\"debug\",\"port\":\"9000\",\"ip\":\"34.217.126.210\",\"myEpoch\":137,\"myBlock\":5206,\"myViewID\":5206,\"phase\":1,\"mode\":\"Normal\",\"caller\":\"/home/ec2-user/harmony/consensus/consensus_v2.go:341\",\"time\":\"2020-04-04T14:02:11.09705862Z\",\"message\":\"[ConsensusMainLoop] Ticker\"} {\"level\":\"debug\",\"port\":\"9000\",\"ip\":\"34.220.116.129\",\"myEpoch\":137,\"myBlock\":5206,\"myViewID\":5206,\"phase\":1,\"mode\":\"Normal\",\"caller\":\"/home/ec2-user/harmony/consensus/consensus_v2.go:341\",\"time\":\"2020-04-04T14:02:11.785156818Z\",\"message\":\"[ConsensusMainLoop] Ticker\"} {\"level\":\"debug\",\"port\":\"9000\",\"ip\":\"54.183.179.150\",\"myEpoch\":137,\"myBlock\":5206,\"myViewID\":5206,\"phase\":1,\"mode\":\"Normal\",\"caller\":\"/home/ec2-user/harmony/consensus/consensus_v2.go:341\",\"time\":\"2020-04-04T14:02:12.92316511Z\",\"message\":\"[ConsensusMainLoop] Ticker\"} {\"level\":\"debug\",\"port\":\"9000\",\"ip\":\"54.221.3.34\",\"myEpoch\":137,\"myBlock\":5206,\"myViewID\":5206,\"phase\":1,\"mode\":\"Normal\",\"caller\":\"/home/ec2-user/harmony/consensus/consensus_v2.go:341\",\"time\":\"2020-04-04T14:02:14.70864152Z\",\"message\":\"[ConsensusMainLoop] Ticker\"} run_on_shard.sh: results are in logs/os/run_on_shard/2020-04-04T14:02:13Z.2f8Suf ## Check the DNS entry ec2-user@ip-172-31-37-52 pipeline (master) $ cat ./logs/os/updater53.sh python3 r53update.py os 0 54.176.115.167 54.221.20.6 52.14.136.4 54.188.74.132 18.234.87.124 18.220.13.70 python3 r53update.py os 1 18.188.29.61 13.57.12.245 52.42.160.90 18.220.177.109 34.219.155.88 35.167.175.89 python3 r53update.py os 2 54.151.12.210 13.56.76.188 3.133.59.235 54.89.187.90 52.25.105.47 13.56.59.152 python3 r53update.py os 3 54.183.213.61 13.58.243.90 18.221.77.180 34.221.231.89 3.134.100.110 54.241.134.52 ## Update the DNS Entry vim ./logs/os/updater53.sh python3 r53update.py os 0 54.176.115.167 54.221.20.6 52.14.136.4 54.188.74.132 3.80.120.170 3.19.143.176 python3 r53update.py os 1 18.188.29.61 13.57.12.245 52.42.160.90 18.220.177.109 34.219.155.88 35.167.175.89 python3 r53update.py os 2 54.151.12.210 13.56.76.188 3.133.59.235 54.89.187.90 52.25.105.47 13.56.59.152 python3 r53update.py os 3 54.183.213.61 13.58.243.90 18.221.77.180 34.221.231.89 3.134.100.110 54.241.134.52 ## Update DNS ./logs/os/updater53.sh ## Kill these 3 nodes and resynch - did not help - just tried for 1 ./node_ssh.sh 18.234.87.124 sudo killall -9 harmony; sudo rm -rf harmony_db_*; sudo rm -rf .dht*; sudo rm harmony.err; sudo rm -rf ../tmp_log/*/* ./restart_node.sh -d logs/os -M -p os -t 0 -r 0 -R 0 18.234.87.124 # Restarted Shard still 3 down ./run_on_shard.sh -p os -T 0 \"sudo rm -r .dht*\" cat logs/os/shard0.txt | xargs -i{} -P50 bash -c './restart_node.sh -y -d logs/os -p os -t 0 -r 0 -R 0 {}' # Try rebooting the machine via aws # 18.234.87.124 - North Virgnia # 35.172.221.7 - North Virginia # 18.220.13.70 - Ohio ./restart_node.sh -d logs/os -M -p os -t 0 -r 0 -R 0 18.234.87.124 /restart_node.sh -t 0 -r 0 -R 0 18.234.87.124 18.220.13.70 35.172.221.7 # Launch a new instance with the same keys [ec2-user@ip-172-31-17-118 blskeys]$ ll total 12 -rw-rw-r-- 1 ec2-user ec2-user 184 Jul 9 2019 45b7a484e7a5c91bbbe881e4422c288e61deeb58e3dab1729dfbe921d150b9083947ba84a2a07b89866777d47f8d7d06.key -rw-rw-r-- 1 ec2-user ec2-user 184 Jul 9 2019 eeab83dfea9753a4c00cec1d2a08722c544fb7cae7914fc09e84d6fef1e6a4c5fd8a1f1dcb9a028f509776423f074801.key -rw-rw-r-- 1 ec2-user ec2-user 184 Jul 9 2019 f248bd21d67f0b2cd0dd2c06446c557fc35737873857c000698ae391b607ca8ed8df00a79d9dcace1b0ce05492fc9789.key Cloning new machines Finding the keys # Find the key files ./node_ssh.sh 18.234.87.124 [ec2-user@ip-172-31-17-118 ~]$ ll .hmy/blskeys/* -rw-rw-r-- 1 ec2-user ec2-user 184 Jul 9 2019 .hmy/blskeys/45b7a484e7a5c91bbbe881e4422c288e61deeb58e3dab1729dfbe921d150b9083947ba84a2a07b89866777d47f8d7d06.key -rw-rw-r-- 1 ec2-user ec2-user 184 Jul 9 2019 .hmy/blskeys/eeab83dfea9753a4c00cec1d2a08722c544fb7cae7914fc09e84d6fef1e6a4c5fd8a1f1dcb9a028f509776423f074801.key -rw-rw-r-- 1 ec2-user ec2-user 184 Jul 9 2019 .hmy/blskeys/f248bd21d67f0b2cd0dd2c06446c557fc35737873857c000698ae391b607ca8ed8df00a79d9dcace1b0ce05492fc9789.key ./node_ssh.sh 18.220.13.70 ll .hmy/blskeys/* -rw-rw-r-- 1 ec2-user ec2-user 184 Jul 9 2019 .hmy/blskeys/42c100b423e14387862fa419d81b430c9c6068d665e8a21737e293f49e41739795567176ab18070066a216eadb808808.key -rw-rw-r-- 1 ec2-user ec2-user 184 Jul 9 2019 .hmy/blskeys/ba27796a04c1e4d2cb2d946ac520c2b41589517cb9ae22e64718086c1b13bec1c3d1d78c274d4ffafd78e1b66705e496.key -rw-rw-r-- 1 ec2-user ec2-user 184 Jul 9 2019 .hmy/blskeys/f6dcead63386972fb00c26c7aefda614b8c58bc33c05d488df9bfef361c1dcced0088b245acb411b52a36ed287051215.key ./node_ssh.sh 35.172.221.7 ll .hmy/blskeys/* -rw-rw-r-- 1 ec2-user ec2-user 184 Jul 9 2019 .hmy/blskeys/0f4a33e3b0babad97efea55b7c10991ebdf08ef8a41bbd95c9bca4b79c92d771d8606a3763a1d6ebf349ec5cb87f818f.key -rw-rw-r-- 1 ec2-user ec2-user 184 Jul 9 2019 .hmy/blskeys/e6c33ada02e808fa7c2dd98734648cbb03c30d39e5c5deb5baae89c4b89e3b2356aff11cb94c35d7d955e14e131b4a18.key -rw-rw-r-- 1 ec2-user ec2-user 184 Jul 9 2019 .hmy/blskeys/f3a65597fefc025493b00dbff904182b4e1da1c88f2743eb0690bc9db7bbabc3cf283cf7e98f4695e967d5418fd1ce94.key Try restart initially work with 18.220.13.70 in Ohio -> 18.220.155.46 Update the machine ## Machine 18.220.155.46 ~/experiment-deploy/pipeline/node_ssh.sh 18.220.155.46 sudo yum update curl -LO https://harmony.one/hmycli && mv hmycli hmy && chmod +x hmy sudo rm -rf harmony_db* sudo rm -rf .dht* # mkdir ../tmp_log/log-20200404.010428 cd .. sudo mkdir tmp_log cd tmp_log sudo mkdir log-20200404.010428 ll ../tmp_log/log-20200404.010428 mkdir -p /home/ec2-user/.hmy/blskeys mkdir .hmy cd .hmy mkdir blskeys mkdir .hmy/blskeys cd /home/ec2-user/.hmy/blskeys ll aws s3 cp s3://harmony-secret-keys/bls-test/42c100b423e14387862fa419d81b430c9c6068d665e8a21737e293f49e41739795567176ab18070066a216eadb808808.key . aws s3 cp s3://harmony-secret-keys/bls-test/ba27796a04c1e4d2cb2d946ac520c2b41589517cb9ae22e64718086c1b13bec1c3d1d78c274d4ffafd78e1b66705e496.key . aws s3 cp s3://harmony-secret-keys/bls-test/f6dcead63386972fb00c26c7aefda614b8c58bc33c05d488df9bfef361c1dcced0088b245acb411b52a36ed287051215.key . ll exit # Create the init files cd ./logs/os/init/ cp init-18.220.13.70.json init-18.220.155.46.json cd /home/ec2-user/experiment-deploy/pipeline/ # Restart the nodes ./restart_node.sh -t 0 -r 0 -R 0 18.220.155.46 # Update the Shard Entries cd ./logs/os vim shard0.txt cd /home/ec2-user/experiment-deploy/pipeline/ # Update the DNS Entries vim ./logs/os/updater53.sh ./logs/os/updater53.sh # Restart watchdog scp /home/ec2-user/experiment-deploy/pipeline/logs/os/shard0.txt watchdog:/home/ec2-user/staking ssh watchdog -- sudo systemctl restart harmony-watchdogd@staking.service ./update_watchdog.sh -u -p -r -y ./restart_node.sh -d logs/os -M -p os -t 0 -r 0 -R 0 18.220.13.70 ./restart_node.sh -t 0 -r 0 -R 0 18.220.13.70 /tmp_log/log-20200404.010428/ ./run_on_shard.sh -p os -T 3 `LD_LIBRARY_PATH=. ./harmony -version`","title":"April 4th 2020"},{"location":"deploy/cicd/netdeploy/outages/april-4th-2020/#april-4th-2020","text":"Sebs analysis out of memory - https://gist.github.com/SebastianJ/95c20ff8b781035115533cd77c690106 s3://harmony-benchmark/logs/os/20/04/04/13:13:43 s3://harmony-benchmark/logs/os/20/04/04/13:43:05 9 NODES DOWN 18.220.13.70 18.234.87.124 34.222.111.126 35.172.221.7 35.172.229.66 52.14.136.4 54.176.115.167 54.188.74.132 54.221.20.6 6:45 Manual node restart ## Apr 4th 9 nodes down didn't work ./restart_node.sh -d logs/os -M -p os -t 0 -r 0 -R 0 18.220.13.70 ./restart_node.sh -d logs/os -U -p os -t 0 -r 0 -R 0 18.234.87.124 ./restart_node.sh -d logs/os -U -p os -t 0 -r 0 -R 0 34.222.111.126 ./restart_node.sh -d logs/os -U -p os -t 0 -r 0 -R 0 35.172.221.7 ./restart_node.sh -d logs/os -U -p os -t 0 -r 0 -R 0 35.172.229.66 ./restart_node.sh -d logs/os -U -p os -t 0 -r 0 -R 0 52.14.136.4 ./restart_node.sh -d logs/os -U -p os -t 0 -r 0 -R 0 54.176.115.167 ./restart_node.sh -d logs/os -U -p os -t 0 -r 0 -R 0 54.188.74.132 ./restart_node.sh -d logs/os -U -p os -t 0 -r 0 -R 0 54.221.20.6 # Restarted Shard brought 6 nodes back up ./run_on_shard.sh -p os -T 0 \"sudo rm -r .dht*\" cat logs/os/shard0.txt | xargs -i{} -P50 bash -c './restart_node.sh -y -d logs/os -p os -t 0 -r 0 -R 0 {}' ## Remaining 3 18.234.87.124 18.220.13.70 35.172.221.7 ## Check the view id run_on_shard.sh: using outdir logs/os/run_on_shard/2020-04-04T14:02:13Z.2f8Suf {\"level\":\"debug\",\"port\":\"9000\",\"ip\":\"34.222.111.126\",\"myEpoch\":137,\"myBlock\":5206,\"myViewID\":5206,\"phase\":1,\"mode\":\"Normal\",\"caller\":\"/home/ec2-user/harmony/consensus/consensus_v2.go:341\",\"time\":\"2020-04-04T14:02:11.016825931Z\",\"message\":\"[ConsensusMainLoop] Ticker\"} {\"level\":\"debug\",\"port\":\"9000\",\"ip\":\"54.242.77.34\",\"myEpoch\":137,\"myBlock\":5206,\"myViewID\":5206,\"phase\":0,\"mode\":\"Listening\",\"Phase\":\"Announce\",\"caller\":\"/home/ec2-user/harmony/consensus/view_change.go:94\",\"time\":\"2020-04-04T13:58:26.16919027Z\",\"message\":\"[ResetViewChangeState] Resetting view change state\"} {\"level\":\"debug\",\"port\":\"9000\",\"ip\":\"3.19.143.176\",\"myEpoch\":137,\"myBlock\":5206,\"myViewID\":5206,\"phase\":1,\"mode\":\"Normal\",\"caller\":\"/home/ec2-user/harmony/consensus/consensus_v2.go:341\",\"time\":\"2020-04-04T14:02:13.697762805Z\",\"message\":\"[ConsensusMainLoop] Ticker\"} {\"level\":\"debug\",\"port\":\"9000\",\"ip\":\"54.176.115.167\",\"myEpoch\":137,\"myBlock\":5206,\"myViewID\":5206,\"phase\":1,\"mode\":\"Normal\",\"caller\":\"/home/ec2-user/harmony/consensus/consensus_v2.go:341\",\"time\":\"2020-04-04T14:02:12.663571848Z\",\"message\":\"[ConsensusMainLoop] Ticker\"} {\"level\":\"debug\",\"port\":\"9000\",\"ip\":\"54.221.20.6\",\"myEpoch\":137,\"myBlock\":5206,\"myViewID\":5206,\"phase\":1,\"mode\":\"Normal\",\"caller\":\"/home/ec2-user/harmony/consensus/consensus_v2.go:341\",\"time\":\"2020-04-04T14:02:14.497625882Z\",\"message\":\"[ConsensusMainLoop] Ticker\"} {\"level\":\"debug\",\"port\":\"9000\",\"ip\":\"52.14.136.4\",\"myEpoch\":137,\"myBlock\":5206,\"myViewID\":5206,\"phase\":1,\"mode\":\"Normal\",\"caller\":\"/home/ec2-user/harmony/consensus/consensus_v2.go:341\",\"time\":\"2020-04-04T14:02:13.656551917Z\",\"message\":\"[ConsensusMainLoop] Ticker\"} {\"level\":\"debug\",\"port\":\"9000\",\"ip\":\"54.188.74.132\",\"myEpoch\":137,\"myBlock\":5206,\"myViewID\":5206,\"phase\":1,\"mode\":\"Normal\",\"caller\":\"/home/ec2-user/harmony/consensus/consensus_v2.go:341\",\"time\":\"2020-04-04T14:02:11.196847434Z\",\"message\":\"[ConsensusMainLoop] Ticker\"} {\"level\":\"debug\",\"port\":\"9000\",\"ip\":\"18.234.87.124\",\"myEpoch\":137,\"myBlock\":5206,\"myViewID\":5212,\"phase\":0,\"mode\":\"Normal\",\"caller\":\"/home/ec2-user/harmony/consensus/consensus_v2.go:341\",\"time\":\"2020-04-04T12:59:51.13887406Z\",\"message\":\"[ConsensusMainLoop] Ticker\"} {\"level\":\"debug\",\"port\":\"9000\",\"ip\":\"18.220.13.70\",\"myEpoch\":137,\"myBlock\":5206,\"myViewID\":5213,\"phase\":0,\"mode\":\"Normal\",\"myKey\":\"42c100b423e14387862fa419d81b430c9c6068d665e8a21737e293f49e41739795567176ab18070066a216eadb808808ba27796a04c1e4d2cb2d946ac520c2b41589517cb9ae22e64718086c1b13bec1c3d1d78c274d4ffafd78e1b66705e496f6dcead63386972fb00c26c7aefda614b8c58bc33c05d488df9bfef361c1dcced0088b245acb411b52a36ed287051215\",\"viewID\":5213,\"block\":5206,\"caller\":\"/home/ec2-user/harmony/consensus/view_change.go:409\",\"time\":\"2020-04-04T13:00:53.925142119Z\",\"message\":\"[onViewChange] I am the New Leader\"} {\"level\":\"debug\",\"port\":\"9000\",\"ip\":\"35.172.229.66\",\"myEpoch\":137,\"myBlock\":5206,\"myViewID\":5206,\"phase\":1,\"mode\":\"Normal\",\"caller\":\"/home/ec2-user/harmony/consensus/consensus_v2.go:341\",\"time\":\"2020-04-04T14:02:14.312296644Z\",\"message\":\"[ConsensusMainLoop] Ticker\"} {\"level\":\"debug\",\"port\":\"9000\",\"ip\":\"35.172.221.7\",\"myEpoch\":137,\"myBlock\":5206,\"myViewID\":5215,\"phase\":0,\"mode\":\"Normal\",\"myKey\":\"0f4a33e3b0babad97efea55b7c10991ebdf08ef8a41bbd95c9bca4b79c92d771d8606a3763a1d6ebf349ec5cb87f818fe6c33ada02e808fa7c2dd98734648cbb03c30d39e5c5deb5baae89c4b89e3b2356aff11cb94c35d7d955e14e131b4a18f3a65597fefc025493b00dbff904182b4e1da1c88f2743eb0690bc9db7bbabc3cf283cf7e98f4695e967d5418fd1ce94\",\"viewID\":5215,\"block\":5206,\"caller\":\"/home/ec2-user/harmony/consensus/view_change.go:409\",\"time\":\"2020-04-04T13:03:00.071816578Z\",\"message\":\"[onViewChange] I am the New Leader\"} {\"level\":\"debug\",\"port\":\"9000\",\"ip\":\"3.80.120.170\",\"myEpoch\":137,\"myBlock\":5206,\"myViewID\":5206,\"phase\":1,\"mode\":\"Normal\",\"caller\":\"/home/ec2-user/harmony/consensus/consensus_v2.go:341\",\"time\":\"2020-04-04T14:02:14.623056381Z\",\"message\":\"[ConsensusMainLoop] Ticker\"} {\"level\":\"debug\",\"port\":\"9000\",\"ip\":\"54.241.83.130\",\"myEpoch\":137,\"myBlock\":5206,\"myViewID\":5206,\"phase\":1,\"mode\":\"Normal\",\"caller\":\"/home/ec2-user/harmony/consensus/consensus_v2.go:341\",\"time\":\"2020-04-04T14:02:12.595807369Z\",\"message\":\"[ConsensusMainLoop] Ticker\"} {\"level\":\"debug\",\"port\":\"9000\",\"ip\":\"54.219.145.146\",\"myEpoch\":137,\"myBlock\":5206,\"myViewID\":5206,\"phase\":1,\"mode\":\"Normal\",\"caller\":\"/home/ec2-user/harmony/consensus/consensus_v2.go:341\",\"time\":\"2020-04-04T14:02:12.583594671Z\",\"message\":\"[ConsensusMainLoop] Ticker\"} {\"level\":\"debug\",\"port\":\"9000\",\"ip\":\"35.166.149.247\",\"myEpoch\":137,\"myBlock\":5206,\"myViewID\":5206,\"phase\":1,\"mode\":\"Normal\",\"caller\":\"/home/ec2-user/harmony/consensus/consensus_v2.go:341\",\"time\":\"2020-04-04T14:02:10.994572753Z\",\"message\":\"[ConsensusMainLoop] Ticker\"} {\"level\":\"debug\",\"port\":\"9000\",\"ip\":\"34.222.135.72\",\"myEpoch\":137,\"myBlock\":5206,\"myViewID\":5206,\"phase\":1,\"mode\":\"Normal\",\"caller\":\"/home/ec2-user/harmony/consensus/consensus_v2.go:341\",\"time\":\"2020-04-04T14:02:11.048995312Z\",\"message\":\"[ConsensusMainLoop] Ticker\"} {\"level\":\"debug\",\"port\":\"9000\",\"ip\":\"54.224.85.122\",\"myEpoch\":137,\"myBlock\":5206,\"myViewID\":5206,\"phase\":1,\"mode\":\"Normal\",\"caller\":\"/home/ec2-user/harmony/consensus/consensus_v2.go:341\",\"time\":\"2020-04-04T14:02:14.60496646Z\",\"message\":\"[ConsensusMainLoop] Ticker\"} {\"level\":\"debug\",\"port\":\"9000\",\"ip\":\"34.217.126.210\",\"myEpoch\":137,\"myBlock\":5206,\"myViewID\":5206,\"phase\":1,\"mode\":\"Normal\",\"caller\":\"/home/ec2-user/harmony/consensus/consensus_v2.go:341\",\"time\":\"2020-04-04T14:02:11.09705862Z\",\"message\":\"[ConsensusMainLoop] Ticker\"} {\"level\":\"debug\",\"port\":\"9000\",\"ip\":\"34.220.116.129\",\"myEpoch\":137,\"myBlock\":5206,\"myViewID\":5206,\"phase\":1,\"mode\":\"Normal\",\"caller\":\"/home/ec2-user/harmony/consensus/consensus_v2.go:341\",\"time\":\"2020-04-04T14:02:11.785156818Z\",\"message\":\"[ConsensusMainLoop] Ticker\"} {\"level\":\"debug\",\"port\":\"9000\",\"ip\":\"54.183.179.150\",\"myEpoch\":137,\"myBlock\":5206,\"myViewID\":5206,\"phase\":1,\"mode\":\"Normal\",\"caller\":\"/home/ec2-user/harmony/consensus/consensus_v2.go:341\",\"time\":\"2020-04-04T14:02:12.92316511Z\",\"message\":\"[ConsensusMainLoop] Ticker\"} {\"level\":\"debug\",\"port\":\"9000\",\"ip\":\"54.221.3.34\",\"myEpoch\":137,\"myBlock\":5206,\"myViewID\":5206,\"phase\":1,\"mode\":\"Normal\",\"caller\":\"/home/ec2-user/harmony/consensus/consensus_v2.go:341\",\"time\":\"2020-04-04T14:02:14.70864152Z\",\"message\":\"[ConsensusMainLoop] Ticker\"} run_on_shard.sh: results are in logs/os/run_on_shard/2020-04-04T14:02:13Z.2f8Suf ## Check the DNS entry ec2-user@ip-172-31-37-52 pipeline (master) $ cat ./logs/os/updater53.sh python3 r53update.py os 0 54.176.115.167 54.221.20.6 52.14.136.4 54.188.74.132 18.234.87.124 18.220.13.70 python3 r53update.py os 1 18.188.29.61 13.57.12.245 52.42.160.90 18.220.177.109 34.219.155.88 35.167.175.89 python3 r53update.py os 2 54.151.12.210 13.56.76.188 3.133.59.235 54.89.187.90 52.25.105.47 13.56.59.152 python3 r53update.py os 3 54.183.213.61 13.58.243.90 18.221.77.180 34.221.231.89 3.134.100.110 54.241.134.52 ## Update the DNS Entry vim ./logs/os/updater53.sh python3 r53update.py os 0 54.176.115.167 54.221.20.6 52.14.136.4 54.188.74.132 3.80.120.170 3.19.143.176 python3 r53update.py os 1 18.188.29.61 13.57.12.245 52.42.160.90 18.220.177.109 34.219.155.88 35.167.175.89 python3 r53update.py os 2 54.151.12.210 13.56.76.188 3.133.59.235 54.89.187.90 52.25.105.47 13.56.59.152 python3 r53update.py os 3 54.183.213.61 13.58.243.90 18.221.77.180 34.221.231.89 3.134.100.110 54.241.134.52 ## Update DNS ./logs/os/updater53.sh ## Kill these 3 nodes and resynch - did not help - just tried for 1 ./node_ssh.sh 18.234.87.124 sudo killall -9 harmony; sudo rm -rf harmony_db_*; sudo rm -rf .dht*; sudo rm harmony.err; sudo rm -rf ../tmp_log/*/* ./restart_node.sh -d logs/os -M -p os -t 0 -r 0 -R 0 18.234.87.124 # Restarted Shard still 3 down ./run_on_shard.sh -p os -T 0 \"sudo rm -r .dht*\" cat logs/os/shard0.txt | xargs -i{} -P50 bash -c './restart_node.sh -y -d logs/os -p os -t 0 -r 0 -R 0 {}' # Try rebooting the machine via aws # 18.234.87.124 - North Virgnia # 35.172.221.7 - North Virginia # 18.220.13.70 - Ohio ./restart_node.sh -d logs/os -M -p os -t 0 -r 0 -R 0 18.234.87.124 /restart_node.sh -t 0 -r 0 -R 0 18.234.87.124 18.220.13.70 35.172.221.7 # Launch a new instance with the same keys [ec2-user@ip-172-31-17-118 blskeys]$ ll total 12 -rw-rw-r-- 1 ec2-user ec2-user 184 Jul 9 2019 45b7a484e7a5c91bbbe881e4422c288e61deeb58e3dab1729dfbe921d150b9083947ba84a2a07b89866777d47f8d7d06.key -rw-rw-r-- 1 ec2-user ec2-user 184 Jul 9 2019 eeab83dfea9753a4c00cec1d2a08722c544fb7cae7914fc09e84d6fef1e6a4c5fd8a1f1dcb9a028f509776423f074801.key -rw-rw-r-- 1 ec2-user ec2-user 184 Jul 9 2019 f248bd21d67f0b2cd0dd2c06446c557fc35737873857c000698ae391b607ca8ed8df00a79d9dcace1b0ce05492fc9789.key","title":"April 4th 2020"},{"location":"deploy/cicd/netdeploy/outages/april-4th-2020/#cloning-new-machines","text":"Finding the keys # Find the key files ./node_ssh.sh 18.234.87.124 [ec2-user@ip-172-31-17-118 ~]$ ll .hmy/blskeys/* -rw-rw-r-- 1 ec2-user ec2-user 184 Jul 9 2019 .hmy/blskeys/45b7a484e7a5c91bbbe881e4422c288e61deeb58e3dab1729dfbe921d150b9083947ba84a2a07b89866777d47f8d7d06.key -rw-rw-r-- 1 ec2-user ec2-user 184 Jul 9 2019 .hmy/blskeys/eeab83dfea9753a4c00cec1d2a08722c544fb7cae7914fc09e84d6fef1e6a4c5fd8a1f1dcb9a028f509776423f074801.key -rw-rw-r-- 1 ec2-user ec2-user 184 Jul 9 2019 .hmy/blskeys/f248bd21d67f0b2cd0dd2c06446c557fc35737873857c000698ae391b607ca8ed8df00a79d9dcace1b0ce05492fc9789.key ./node_ssh.sh 18.220.13.70 ll .hmy/blskeys/* -rw-rw-r-- 1 ec2-user ec2-user 184 Jul 9 2019 .hmy/blskeys/42c100b423e14387862fa419d81b430c9c6068d665e8a21737e293f49e41739795567176ab18070066a216eadb808808.key -rw-rw-r-- 1 ec2-user ec2-user 184 Jul 9 2019 .hmy/blskeys/ba27796a04c1e4d2cb2d946ac520c2b41589517cb9ae22e64718086c1b13bec1c3d1d78c274d4ffafd78e1b66705e496.key -rw-rw-r-- 1 ec2-user ec2-user 184 Jul 9 2019 .hmy/blskeys/f6dcead63386972fb00c26c7aefda614b8c58bc33c05d488df9bfef361c1dcced0088b245acb411b52a36ed287051215.key ./node_ssh.sh 35.172.221.7 ll .hmy/blskeys/* -rw-rw-r-- 1 ec2-user ec2-user 184 Jul 9 2019 .hmy/blskeys/0f4a33e3b0babad97efea55b7c10991ebdf08ef8a41bbd95c9bca4b79c92d771d8606a3763a1d6ebf349ec5cb87f818f.key -rw-rw-r-- 1 ec2-user ec2-user 184 Jul 9 2019 .hmy/blskeys/e6c33ada02e808fa7c2dd98734648cbb03c30d39e5c5deb5baae89c4b89e3b2356aff11cb94c35d7d955e14e131b4a18.key -rw-rw-r-- 1 ec2-user ec2-user 184 Jul 9 2019 .hmy/blskeys/f3a65597fefc025493b00dbff904182b4e1da1c88f2743eb0690bc9db7bbabc3cf283cf7e98f4695e967d5418fd1ce94.key Try restart initially work with 18.220.13.70 in Ohio -> 18.220.155.46 Update the machine ## Machine 18.220.155.46 ~/experiment-deploy/pipeline/node_ssh.sh 18.220.155.46 sudo yum update curl -LO https://harmony.one/hmycli && mv hmycli hmy && chmod +x hmy sudo rm -rf harmony_db* sudo rm -rf .dht* # mkdir ../tmp_log/log-20200404.010428 cd .. sudo mkdir tmp_log cd tmp_log sudo mkdir log-20200404.010428 ll ../tmp_log/log-20200404.010428 mkdir -p /home/ec2-user/.hmy/blskeys mkdir .hmy cd .hmy mkdir blskeys mkdir .hmy/blskeys cd /home/ec2-user/.hmy/blskeys ll aws s3 cp s3://harmony-secret-keys/bls-test/42c100b423e14387862fa419d81b430c9c6068d665e8a21737e293f49e41739795567176ab18070066a216eadb808808.key . aws s3 cp s3://harmony-secret-keys/bls-test/ba27796a04c1e4d2cb2d946ac520c2b41589517cb9ae22e64718086c1b13bec1c3d1d78c274d4ffafd78e1b66705e496.key . aws s3 cp s3://harmony-secret-keys/bls-test/f6dcead63386972fb00c26c7aefda614b8c58bc33c05d488df9bfef361c1dcced0088b245acb411b52a36ed287051215.key . ll exit # Create the init files cd ./logs/os/init/ cp init-18.220.13.70.json init-18.220.155.46.json cd /home/ec2-user/experiment-deploy/pipeline/ # Restart the nodes ./restart_node.sh -t 0 -r 0 -R 0 18.220.155.46 # Update the Shard Entries cd ./logs/os vim shard0.txt cd /home/ec2-user/experiment-deploy/pipeline/ # Update the DNS Entries vim ./logs/os/updater53.sh ./logs/os/updater53.sh # Restart watchdog scp /home/ec2-user/experiment-deploy/pipeline/logs/os/shard0.txt watchdog:/home/ec2-user/staking ssh watchdog -- sudo systemctl restart harmony-watchdogd@staking.service ./update_watchdog.sh -u -p -r -y ./restart_node.sh -d logs/os -M -p os -t 0 -r 0 -R 0 18.220.13.70 ./restart_node.sh -t 0 -r 0 -R 0 18.220.13.70 /tmp_log/log-20200404.010428/ ./run_on_shard.sh -p os -T 3 `LD_LIBRARY_PATH=. ./harmony -version`","title":"Cloning new machines"},{"location":"deploy/cicd/netdeploy/prepare-build/","text":"Network Release Preparation","title":"Network Release Preparation"},{"location":"deploy/cicd/netdeploy/prepare-build/#network-release-preparation","text":"","title":"Network Release Preparation"},{"location":"deploy/cicd/netdeploy/prepare-build/backups-and-snapshots-and-analysis/","text":"Backups and Snapshots and Analysis Overview This page list handy commands and mandatory data capture points before refreshing OSTN or restarting a shard. Backup Logs {% tabs %} {% tab title=\"OSTN\" %} cd experiment-deploy/pipeline/ ./go.sh -p os log # Wait for it to finish, then record the s3:// path {% endtab %} {% tab title=\"STN\" %} ./go.sh -p stn log # Wait for it to finish, then record the s3:// path {% endtab %} {% endtabs %} Capture Validator Information {% hint style=\"info\" %} From Janet In harmony-ops/devops/validator_stats I wrote a script to get validator stats for the network for the biz team you can run that instead of Stephens's shell scripting before restart to get stats if you want python3 validator_stats.py cd /Users/johnwhitton/projects/staking/OSTN source_harmony for x in `hmy --node=https://api.s0.os.hmny.io blockchain validator all | grep one1 | tr -d '\",'`; do hmy --node=https://api.s0.os.hmny.io blockchain validator information $x | python -c 'import sys, json; print json.dumps(json.load(sys.stdin))'; done > info_ostn_20200414.json # Copy and paste the text into this gist # https://gist.github.com/john-harmony/3de1a5a264bc5f99dbc97347eca903a5 {% endhint %} {% tabs %} {% tab title=\"OSTN\" %} cd /Users/johnwhitton/projects/staking/OSTN/ source /Users/johnwhitton/go/src/github.com/harmony-one/harmony/scripts/setup_bls_build_flags.sh for x in `$(go env GOPATH)/src/github.com/harmony-one/go-sdk/hmy --node=https://api.s0.os.hmny.io blockchain validator all | grep one1 | tr -d '\",'`; do $(go env GOPATH)/src/github.com/harmony-one/go-sdk/hmy --node=https://api.s0.os.hmny.io blockchain validator information $x | python -c 'import sys, json; print json.dumps(json.load(sys.stdin))'; done > info_ostn_20200406_0715.json # Copy and paste the text into this gist # https://gist.github.com/john-harmony/3de1a5a264bc5f99dbc97347eca903a5 {% endtab %} {% tab title=\"STN\" %} cd /Users/johnwhitton/projects/staking/STN source /Users/johnwhitton/go/src/github.com/harmony-one/harmony/scripts/setup_bls_build_flags.sh for x in `$(go env GOPATH)/src/github.com/harmony-one/go-sdk/hmy --node=https://api.s0.stn.hmny.io blockchain validator all | grep one1 | tr -d '\",'`; do $(go env GOPATH)/src/github.com/harmony-one/go-sdk/hmy --node=https://api.s0.stn.hmny.io blockchain validator information $x | python -c 'import sys, json; print json.dumps(json.load(sys.stdin))'; done > info_stn_20200406.json # Copy and paste the text into this gist # https://gist.github.com/john-harmony/3de1a5a264bc5f99dbc97347eca903a5 # Downloading to to a local machine cd /Users/johnwhitton/projects/staking/OSTN scp -i ~/.ssh/keys/JOHN_OSTN_VALIDATOR_1.pem ec2-user@ec2-3-16-31-148.us-east-2.compute.amazonaws.com:/home/ec2-user/info_20200330.json . {% endtab %} {% endtabs %} Update Pager Duty to maintenance mode Go to service and select immediate maintenance mode Announce Build discord team-staking p-ops testnet-nodes telegram p-ops open staking volunteers Update Pager Duty Go to service and enable service Other Handy Gists CheckEarning.sh Realtime Economics Testing Validator and Watchdog utilities","title":"Backups and Snapshots and Analysis"},{"location":"deploy/cicd/netdeploy/prepare-build/backups-and-snapshots-and-analysis/#backups-and-snapshots-and-analysis","text":"","title":"Backups and Snapshots and Analysis"},{"location":"deploy/cicd/netdeploy/prepare-build/backups-and-snapshots-and-analysis/#overview","text":"This page list handy commands and mandatory data capture points before refreshing OSTN or restarting a shard.","title":"Overview"},{"location":"deploy/cicd/netdeploy/prepare-build/backups-and-snapshots-and-analysis/#backup-logs","text":"{% tabs %} {% tab title=\"OSTN\" %} cd experiment-deploy/pipeline/ ./go.sh -p os log # Wait for it to finish, then record the s3:// path {% endtab %} {% tab title=\"STN\" %} ./go.sh -p stn log # Wait for it to finish, then record the s3:// path {% endtab %} {% endtabs %}","title":"Backup Logs"},{"location":"deploy/cicd/netdeploy/prepare-build/backups-and-snapshots-and-analysis/#capture-validator-information","text":"{% hint style=\"info\" %} From Janet In harmony-ops/devops/validator_stats I wrote a script to get validator stats for the network for the biz team you can run that instead of Stephens's shell scripting before restart to get stats if you want python3 validator_stats.py cd /Users/johnwhitton/projects/staking/OSTN source_harmony for x in `hmy --node=https://api.s0.os.hmny.io blockchain validator all | grep one1 | tr -d '\",'`; do hmy --node=https://api.s0.os.hmny.io blockchain validator information $x | python -c 'import sys, json; print json.dumps(json.load(sys.stdin))'; done > info_ostn_20200414.json # Copy and paste the text into this gist # https://gist.github.com/john-harmony/3de1a5a264bc5f99dbc97347eca903a5 {% endhint %} {% tabs %} {% tab title=\"OSTN\" %} cd /Users/johnwhitton/projects/staking/OSTN/ source /Users/johnwhitton/go/src/github.com/harmony-one/harmony/scripts/setup_bls_build_flags.sh for x in `$(go env GOPATH)/src/github.com/harmony-one/go-sdk/hmy --node=https://api.s0.os.hmny.io blockchain validator all | grep one1 | tr -d '\",'`; do $(go env GOPATH)/src/github.com/harmony-one/go-sdk/hmy --node=https://api.s0.os.hmny.io blockchain validator information $x | python -c 'import sys, json; print json.dumps(json.load(sys.stdin))'; done > info_ostn_20200406_0715.json # Copy and paste the text into this gist # https://gist.github.com/john-harmony/3de1a5a264bc5f99dbc97347eca903a5 {% endtab %} {% tab title=\"STN\" %} cd /Users/johnwhitton/projects/staking/STN source /Users/johnwhitton/go/src/github.com/harmony-one/harmony/scripts/setup_bls_build_flags.sh for x in `$(go env GOPATH)/src/github.com/harmony-one/go-sdk/hmy --node=https://api.s0.stn.hmny.io blockchain validator all | grep one1 | tr -d '\",'`; do $(go env GOPATH)/src/github.com/harmony-one/go-sdk/hmy --node=https://api.s0.stn.hmny.io blockchain validator information $x | python -c 'import sys, json; print json.dumps(json.load(sys.stdin))'; done > info_stn_20200406.json # Copy and paste the text into this gist # https://gist.github.com/john-harmony/3de1a5a264bc5f99dbc97347eca903a5 # Downloading to to a local machine cd /Users/johnwhitton/projects/staking/OSTN scp -i ~/.ssh/keys/JOHN_OSTN_VALIDATOR_1.pem ec2-user@ec2-3-16-31-148.us-east-2.compute.amazonaws.com:/home/ec2-user/info_20200330.json . {% endtab %} {% endtabs %}","title":"Capture Validator Information"},{"location":"deploy/cicd/netdeploy/prepare-build/backups-and-snapshots-and-analysis/#update-pager-duty-to-maintenance-mode","text":"Go to service and select immediate maintenance mode","title":"Update Pager Duty to maintenance mode"},{"location":"deploy/cicd/netdeploy/prepare-build/backups-and-snapshots-and-analysis/#announce-build","text":"discord team-staking p-ops testnet-nodes telegram p-ops open staking volunteers","title":"Announce Build"},{"location":"deploy/cicd/netdeploy/prepare-build/backups-and-snapshots-and-analysis/#update-pager-duty","text":"Go to service and enable service","title":"Update Pager Duty"},{"location":"deploy/cicd/netdeploy/prepare-build/backups-and-snapshots-and-analysis/#other-handy-gists","text":"CheckEarning.sh Realtime Economics Testing Validator and Watchdog utilities","title":"Other Handy Gists"},{"location":"deploy/cicd/netdeploy/prepare-build/synch-t3-branch-with-master/","text":"Protocol Build Preparation Overview Before beginning a network release. It is important to build a valid release candidate. This document goes over the build process. {% hint style=\"info\" %} Note if ever a force push is done then all downstream repos can no longer just do a pull they instead need to git remote -v git fetch origin git log --pretty=oneline git branch -a git reset --hard origin/t3 {% endhint %} Synching Master Branch # Make sure you delete the old branch first from the prior pull request cdh git status git checkout t3 git log --pretty=oneline git clean -fdx git pull git log --pretty=oneline git checkout master git pull git log --pretty=oneline git fetch origin #==== Choose one or more of the following ====* ## To merge from master git merge origin/master ## To merge to a specific commit git merge 1fe41df8ab70381ae2a2ef2ab418270fdc49674d ## To cherry pick a commit git checkout merge-master-t3-0403 git cherry-pick 1fe41df8ab70381ae2a2ef2ab418270fdc49674d git push #========== End Choice ==============================* git log --pretty=oneline git tag -a v1.0-20200420.0 git push jw HEAD:merge-master-t3-0404 # Create PR # Merger the PR (do not squash merge) # Delete the branch {% hint style=\"info\" %} For more information including cherry-pick read the git documentation {% endhint %} Additional Ideas from Edgar git clean -fdx git fetch origin git checkout t3 git merge --squash origin/master git push ... so you want to add --squash for the merge for origin/master, the rest is the same right? Edgar | HarmonyToday at 11:49 AM and the clean -fdx in beginning just in case. If there is a situation when can't blindly merge from origin/master, do an individual git cherry-pick for the commits from master to bring into t3. If have situation like this 'just one more commit' , then don't need any git merge at all, just git cherry-pick at step right before git push , also have something git tag I think if we do deploys to ostn in this kind of way, it will be easier to conclusively know where a bad commit/bug was introduced and what to fall back to because more advanced features of git will more easily work, like git bisect Additional Ideas from Edgar April 5th some git knowledge. Because of the urgency of the deploy to get a fix out on t3, I went on devsops machine. Here is the flow I had and some special things happened that others have run into and I want to show ways around it. git clean -fdx git fetch origin git checkout t3 git reset --hard origin/t3 git merge --squash origin/master -X theirs git commit --no-edit ./scripts/go_executable_build.sh Doing a merge from master (regardless if squash or plain) would have done merge conflicts. But because we know that master is right and t3 is master code, its fine to accept the master version of code automatically instead of t3. Then i did a --no-edit commit to accept the default commit message made when you do a squash merge. After the deploy was done, then I opened PR to t3 because no reason to wait for jenkins when we know code already past master jenkins job.","title":"Protocol Build Preparation"},{"location":"deploy/cicd/netdeploy/prepare-build/synch-t3-branch-with-master/#protocol-build-preparation","text":"","title":"Protocol Build Preparation"},{"location":"deploy/cicd/netdeploy/prepare-build/synch-t3-branch-with-master/#overview","text":"Before beginning a network release. It is important to build a valid release candidate. This document goes over the build process. {% hint style=\"info\" %} Note if ever a force push is done then all downstream repos can no longer just do a pull they instead need to git remote -v git fetch origin git log --pretty=oneline git branch -a git reset --hard origin/t3 {% endhint %}","title":"Overview"},{"location":"deploy/cicd/netdeploy/prepare-build/synch-t3-branch-with-master/#synching-master-branch","text":"# Make sure you delete the old branch first from the prior pull request cdh git status git checkout t3 git log --pretty=oneline git clean -fdx git pull git log --pretty=oneline git checkout master git pull git log --pretty=oneline git fetch origin #==== Choose one or more of the following ====* ## To merge from master git merge origin/master ## To merge to a specific commit git merge 1fe41df8ab70381ae2a2ef2ab418270fdc49674d ## To cherry pick a commit git checkout merge-master-t3-0403 git cherry-pick 1fe41df8ab70381ae2a2ef2ab418270fdc49674d git push #========== End Choice ==============================* git log --pretty=oneline git tag -a v1.0-20200420.0 git push jw HEAD:merge-master-t3-0404 # Create PR # Merger the PR (do not squash merge) # Delete the branch {% hint style=\"info\" %} For more information including cherry-pick read the git documentation {% endhint %}","title":"Synching Master Branch"},{"location":"deploy/cicd/netdeploy/prepare-build/synch-t3-branch-with-master/#additional-ideas-from-edgar","text":"git clean -fdx git fetch origin git checkout t3 git merge --squash origin/master git push ... so you want to add --squash for the merge for origin/master, the rest is the same right? Edgar | HarmonyToday at 11:49 AM and the clean -fdx in beginning just in case. If there is a situation when can't blindly merge from origin/master, do an individual git cherry-pick for the commits from master to bring into t3. If have situation like this 'just one more commit' , then don't need any git merge at all, just git cherry-pick at step right before git push , also have something git tag I think if we do deploys to ostn in this kind of way, it will be easier to conclusively know where a bad commit/bug was introduced and what to fall back to because more advanced features of git will more easily work, like git bisect","title":"Additional Ideas from Edgar"},{"location":"deploy/cicd/netdeploy/prepare-build/synch-t3-branch-with-master/#additional-ideas-from-edgar-april-5th","text":"some git knowledge. Because of the urgency of the deploy to get a fix out on t3, I went on devsops machine. Here is the flow I had and some special things happened that others have run into and I want to show ways around it. git clean -fdx git fetch origin git checkout t3 git reset --hard origin/t3 git merge --squash origin/master -X theirs git commit --no-edit ./scripts/go_executable_build.sh Doing a merge from master (regardless if squash or plain) would have done merge conflicts. But because we know that master is right and t3 is master code, its fine to accept the master version of code automatically instead of t3. Then i did a --no-edit commit to accept the default commit message made when you do a squash merge. After the deploy was done, then I opened PR to t3 because no reason to wait for jenkins when we know code already past master jenkins job.","title":"Additional Ideas from Edgar April 5th"},{"location":"deploy/cicd/netdeploy/troubleshooting/","text":"Troubleshooting Restarting a shard ./run_on_shard.sh -p os -T 1 \"sudo rm -r .dht*\" cat logs/os/shard1.txt | xargs -i{} -P50 bash -c './restart_node.sh -y -U -d logs/os -p os -t 0 -r 0 -R 0 {}' Never remove temp logs as they are needed for configuration of the network below command was a onetime fix that Daniel had to do text ./run_on_shard.sh -p os -T 3 'sudo mkdir -p ../tmp_log/log-20200228.034942;' Restart a single node ```text ./restart_node.sh -d logs/os -U -p os -t 0 -r 0 -R 0 34.228.217.167 ./restart_node.sh -d logs/stn -U -p stn -t 0 -r 0 -R 0 52.53.217.219 ./restart_node.sh -d logs/os -U -p os -t 0 -r 0 -R 0 54.244.20.65 ./restart_node.sh -d logs/stn -U -p stn -t 0 -r 0 -R 0 52.53.161.58 ./restart_node.sh -d logs/stn -U -p stn -t 0 -r 0 -R 0 52.53.161.58 ./restart_node.sh -d logs/stn -U -p stn -t 0 -r 0 -R 0 54.245.77.197 ./restart_node.sh -d logs/stn -U -p stn -t 0 -r 0 -R 0 52.53.198.40 ``` Run a node text sudo ./node.sh -N staking -z -D -k ../../go-sdk/426739d753d36fbe34f8782c01faf0c224e6fbb764fb08339010195b8e657893b8ae4f9bcdad451060518e07a87b418e.key Dig to check DNS, only needed today since we had DNS issue last night text dig s0.os.hmny.io dig s1.os.hmny.io dig s2.os.hmny.io dig s3.os.hmny.io Mkeys check if all the keys have been deployed... text ./run_on_shard.sh -p os -T 0 'ls -al .hmy/blskeys' Clean up an existing node ready for an upgrade ./run_on_shard.sh -p ps -T 0 'sudo killall -9 harmony; sudo rm -rf harmony_db; sudo rm -rf .dht_; sudo rm harmony.err' Clean up an esiting node and upgrade it text ./run_on_shard.sh -p os -T 2 'sudo killall harmony; sudo rm -rf .dht*' cat logs/os/shard2.txt | xargs -i{} -P50 bash -c './restart_node.sh -y -d logs/os -p os -t 0 -r 0 -R 0 {}' peer_per_shard = keys for mkeys ./aws-instances.sh -g OS ./go.sh -p os deinit ./go.sh -p os -k","title":"Troubleshooting"},{"location":"deploy/cicd/netdeploy/troubleshooting/#troubleshooting","text":"Restarting a shard ./run_on_shard.sh -p os -T 1 \"sudo rm -r .dht*\" cat logs/os/shard1.txt | xargs -i{} -P50 bash -c './restart_node.sh -y -U -d logs/os -p os -t 0 -r 0 -R 0 {}' Never remove temp logs as they are needed for configuration of the network below command was a onetime fix that Daniel had to do text ./run_on_shard.sh -p os -T 3 'sudo mkdir -p ../tmp_log/log-20200228.034942;' Restart a single node ```text ./restart_node.sh -d logs/os -U -p os -t 0 -r 0 -R 0 34.228.217.167 ./restart_node.sh -d logs/stn -U -p stn -t 0 -r 0 -R 0 52.53.217.219 ./restart_node.sh -d logs/os -U -p os -t 0 -r 0 -R 0 54.244.20.65 ./restart_node.sh -d logs/stn -U -p stn -t 0 -r 0 -R 0 52.53.161.58 ./restart_node.sh -d logs/stn -U -p stn -t 0 -r 0 -R 0 52.53.161.58 ./restart_node.sh -d logs/stn -U -p stn -t 0 -r 0 -R 0 54.245.77.197 ./restart_node.sh -d logs/stn -U -p stn -t 0 -r 0 -R 0 52.53.198.40 ``` Run a node text sudo ./node.sh -N staking -z -D -k ../../go-sdk/426739d753d36fbe34f8782c01faf0c224e6fbb764fb08339010195b8e657893b8ae4f9bcdad451060518e07a87b418e.key Dig to check DNS, only needed today since we had DNS issue last night text dig s0.os.hmny.io dig s1.os.hmny.io dig s2.os.hmny.io dig s3.os.hmny.io Mkeys check if all the keys have been deployed... text ./run_on_shard.sh -p os -T 0 'ls -al .hmy/blskeys' Clean up an existing node ready for an upgrade ./run_on_shard.sh -p ps -T 0 'sudo killall -9 harmony; sudo rm -rf harmony_db; sudo rm -rf .dht_; sudo rm harmony.err' Clean up an esiting node and upgrade it text ./run_on_shard.sh -p os -T 2 'sudo killall harmony; sudo rm -rf .dht*' cat logs/os/shard2.txt | xargs -i{} -P50 bash -c './restart_node.sh -y -d logs/os -p os -t 0 -r 0 -R 0 {}' peer_per_shard = keys for mkeys ./aws-instances.sh -g OS ./go.sh -p os deinit ./go.sh -p os -k","title":"Troubleshooting"},{"location":"deploy/cicd/netdeploy/troubleshooting/aws-information/","text":"AWS Information Ensure you are logged in to the correct role (item at the top)","title":"AWS Information"},{"location":"deploy/cicd/netdeploy/troubleshooting/aws-information/#aws-information","text":"","title":"AWS Information"},{"location":"deploy/cicd/netdeploy/troubleshooting/aws-information/#ensure-you-are-logged-in-to-the-correct-role-item-at-the-top","text":"","title":"Ensure you are logged in to the correct role (item at the top)"},{"location":"deploy/cicd/netdeploy/troubleshooting/capturing-command-history/","text":"Capturing command history Creating History file exec ssh -i ~/.ssh/keys/oregon-key-benchmark.pem ec2-user@devop.hmny.io tmux ls tmux attach-session -t os history 10000 > jw20200325_upgrade_issue.txt history 10000 > jw20200326_new_network.txt history 10000 > jw20200326_new_network2.txt Downloading it to your local machine scp -i ~/.ssh/keys/oregon-key-benchmark.pem ec2-user@devop.hmny.io:/home/ec2-user/experiment-deploy/pipeline/jw20200325_upgrade_issue.txt . Loading it into a gist See this example from 2020-03-22","title":"Capturing command history"},{"location":"deploy/cicd/netdeploy/troubleshooting/capturing-command-history/#capturing-command-history","text":"","title":"Capturing command history"},{"location":"deploy/cicd/netdeploy/troubleshooting/capturing-command-history/#creating-history-file","text":"exec ssh -i ~/.ssh/keys/oregon-key-benchmark.pem ec2-user@devop.hmny.io tmux ls tmux attach-session -t os history 10000 > jw20200325_upgrade_issue.txt history 10000 > jw20200326_new_network.txt history 10000 > jw20200326_new_network2.txt","title":"Creating History file"},{"location":"deploy/cicd/netdeploy/troubleshooting/capturing-command-history/#downloading-it-to-your-local-machine","text":"scp -i ~/.ssh/keys/oregon-key-benchmark.pem ec2-user@devop.hmny.io:/home/ec2-user/experiment-deploy/pipeline/jw20200325_upgrade_issue.txt .","title":"Downloading it to your local machine"},{"location":"deploy/cicd/netdeploy/troubleshooting/capturing-command-history/#loading-it-into-a-gist","text":"See this example from 2020-03-22","title":"Loading it into a gist"},{"location":"deploy/cicd/netdeploy/troubleshooting/changing-signing-time-of-node/","text":"Changing signing time of node Uses init.json ec2-user@ip-172-31-37-52 init (master) $ pwd \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 /home/ec2-user/experiment-deploy/pipeline/logs/os/init ec2-user@ip-172-31-37-52 init (master) $ more init.json \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 { \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 \"ip\":\"127.0.0.1\", \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 \"port\":\"9000\", \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 \"sessionID\":\"20200318.173735\", \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 \"benchmarkArgs\":\"-bootnodes /ip4/52.40.84.2/tcp/9867/p2p/QmbPVwrqWsTYXq1RxGWcxx9SWaTUCfoo1wA6wmdbduWe29,/ip4/54.86.126.90/tcp/9867/p2p/Qmdfjtk6hPoyrH1zVD9PEH4zfWLo38dP2mDvvKXfh3tnEv \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 -min_peers 12 -blspass file:blsnopass.txt -blsfolder=.hmy/blskeys -delay_commit=3s -network_type=pangaea -dns_zone=os.hmny.io -public_rpc\", \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 \"txgenArgs\":\"-duration -1 -cross_shard_ratio 30 -bootnodes /ip4/52.40.84.2/tcp/9867/p2p/QmbPVwrqWsTYXq1RxGWcxx9SWaTUCfoo1wA6wmdbduWe29,/ip4/54.86.126.90/tcp/9867/p2p/Qmdfjtk6hPoyrH1z\u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 VD9PEH4zfWLo38dP2mDvvKXfh3tnEv\" \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 } \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 ec2-user@ip-172-31-37-52 init (master) $ pwd \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 /home/ec2-user/experiment-deploy/pipeline/logs/os/init \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 ec2-user@ip-172-31-37-52 init (master) $ more init-54.87.129.121.json \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 { \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 \"ip\":\"127.0.0.1\", \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 \"port\":\"9000\", \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 \"sessionID\":\"20200318.173735\", \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 \"benchmarkArgs\":\"-bootnodes /ip4/52.40.84.2/tcp/9867/p2p/QmbPVwrqWsTYXq1RxGWcxx9SWaTUCfoo1wA6wmdbduWe29,/ip4/54.86.126.90/tcp/9867/p2p/Qmdfjtk6hPoyrH1zVD9PEH4zfWLo38dP2mDvvKXfh3tnEv \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 -min_peers 12 -blspass file:blsnopass.txt -blsfolder=.hmy/blskeys -delay_commit=3s -network_type=pangaea -dns_zone=os.hmny.io -public_rpc\", \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 \"txgenArgs\":\"-duration -1 -cross_shard_ratio 30 -bootnodes /ip4/52.40.84.2/tcp/9867/p2p/QmbPVwrqWsTYXq1RxGWcxx9SWaTUCfoo1wA6wmdbduWe29,/ip4/54.86.126.90/tcp/9867/p2p/Qmdfjtk6hPoyrH1z\u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 VD9PEH4zfWLo38dP2mDvvKXfh3tnEv\" \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 } \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 ec2-user@ip-172-31-37-52 init (master) $ diff init-54.87.129.121.json init-54.87.129.121.jsonorig \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 5c5 \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 < \"benchmarkArgs\":\"-bootnodes /ip4/52.40.84.2/tcp/9867/p2p/QmbPVwrqWsTYXq1RxGWcxx9SWaTUCfoo1wA6wmdbduWe29,/ip4/54.86.126.90/tcp/9867/p2p/Qmdfjtk6hPoyrH1zVD9PEH4zfWLo38dP2mDvvKXfh3tnE\u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 v -min_peers 12 -blspass file:blsnopass.txt -blsfolder=.hmy/blskeys -delay_commit=3s -network_type=pangaea -dns_zone=os.hmny.io -public_rpc\", \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 --- \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 > \"benchmarkArgs\":\"-bootnodes /ip4/52.40.84.2/tcp/9867/p2p/QmbPVwrqWsTYXq1RxGWcxx9SWaTUCfoo1wA6wmdbduWe29,/ip4/54.86.126.90/tcp/9867/p2p/Qmdfjtk6hPoyrH1zVD9PEH4zfWLo38dP2mDvvKXfh3tnE\u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 v -min_peers 12 -blspass file:blsnopass.txt -blsfolder=.hmy/blskeys -delay_commit=2s -network_type=pangaea -dns_zone=os.hmny.io -public_rpc\", \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 ec2-user@ip-172-31-37-52 init (master) $","title":"Changing signing time of node"},{"location":"deploy/cicd/netdeploy/troubleshooting/changing-signing-time-of-node/#changing-signing-time-of-node","text":"Uses init.json ec2-user@ip-172-31-37-52 init (master) $ pwd \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 /home/ec2-user/experiment-deploy/pipeline/logs/os/init ec2-user@ip-172-31-37-52 init (master) $ more init.json \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 { \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 \"ip\":\"127.0.0.1\", \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 \"port\":\"9000\", \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 \"sessionID\":\"20200318.173735\", \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 \"benchmarkArgs\":\"-bootnodes /ip4/52.40.84.2/tcp/9867/p2p/QmbPVwrqWsTYXq1RxGWcxx9SWaTUCfoo1wA6wmdbduWe29,/ip4/54.86.126.90/tcp/9867/p2p/Qmdfjtk6hPoyrH1zVD9PEH4zfWLo38dP2mDvvKXfh3tnEv \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 -min_peers 12 -blspass file:blsnopass.txt -blsfolder=.hmy/blskeys -delay_commit=3s -network_type=pangaea -dns_zone=os.hmny.io -public_rpc\", \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 \"txgenArgs\":\"-duration -1 -cross_shard_ratio 30 -bootnodes /ip4/52.40.84.2/tcp/9867/p2p/QmbPVwrqWsTYXq1RxGWcxx9SWaTUCfoo1wA6wmdbduWe29,/ip4/54.86.126.90/tcp/9867/p2p/Qmdfjtk6hPoyrH1z\u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 VD9PEH4zfWLo38dP2mDvvKXfh3tnEv\" \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 } \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 ec2-user@ip-172-31-37-52 init (master) $ pwd \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 /home/ec2-user/experiment-deploy/pipeline/logs/os/init \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 ec2-user@ip-172-31-37-52 init (master) $ more init-54.87.129.121.json \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 { \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 \"ip\":\"127.0.0.1\", \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 \"port\":\"9000\", \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 \"sessionID\":\"20200318.173735\", \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 \"benchmarkArgs\":\"-bootnodes /ip4/52.40.84.2/tcp/9867/p2p/QmbPVwrqWsTYXq1RxGWcxx9SWaTUCfoo1wA6wmdbduWe29,/ip4/54.86.126.90/tcp/9867/p2p/Qmdfjtk6hPoyrH1zVD9PEH4zfWLo38dP2mDvvKXfh3tnEv \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 -min_peers 12 -blspass file:blsnopass.txt -blsfolder=.hmy/blskeys -delay_commit=3s -network_type=pangaea -dns_zone=os.hmny.io -public_rpc\", \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 \"txgenArgs\":\"-duration -1 -cross_shard_ratio 30 -bootnodes /ip4/52.40.84.2/tcp/9867/p2p/QmbPVwrqWsTYXq1RxGWcxx9SWaTUCfoo1wA6wmdbduWe29,/ip4/54.86.126.90/tcp/9867/p2p/Qmdfjtk6hPoyrH1z\u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 VD9PEH4zfWLo38dP2mDvvKXfh3tnEv\" \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 } \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 ec2-user@ip-172-31-37-52 init (master) $ diff init-54.87.129.121.json init-54.87.129.121.jsonorig \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 5c5 \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 < \"benchmarkArgs\":\"-bootnodes /ip4/52.40.84.2/tcp/9867/p2p/QmbPVwrqWsTYXq1RxGWcxx9SWaTUCfoo1wA6wmdbduWe29,/ip4/54.86.126.90/tcp/9867/p2p/Qmdfjtk6hPoyrH1zVD9PEH4zfWLo38dP2mDvvKXfh3tnE\u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 v -min_peers 12 -blspass file:blsnopass.txt -blsfolder=.hmy/blskeys -delay_commit=3s -network_type=pangaea -dns_zone=os.hmny.io -public_rpc\", \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 --- \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 > \"benchmarkArgs\":\"-bootnodes /ip4/52.40.84.2/tcp/9867/p2p/QmbPVwrqWsTYXq1RxGWcxx9SWaTUCfoo1wA6wmdbduWe29,/ip4/54.86.126.90/tcp/9867/p2p/Qmdfjtk6hPoyrH1zVD9PEH4zfWLo38dP2mDvvKXfh3tnE\u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 v -min_peers 12 -blspass file:blsnopass.txt -blsfolder=.hmy/blskeys -delay_commit=2s -network_type=pangaea -dns_zone=os.hmny.io -public_rpc\", \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 ec2-user@ip-172-31-37-52 init (master) $","title":"Changing signing time of node"},{"location":"deploy/cicd/netdeploy/troubleshooting/cloning-and-copying-a-db/","text":"Cloning and copying a db ssh into machine pgrep harmony kil -9 pid scp 54.158.239.171:harmony_db_0.tar.gz . ## Log into a machine kill harmony and zip up the db host 54.158.239.171 scp 54.158.239.171:harmony_db_0.tar.gz . ssh 3.84.74.78 pgrep harmony sudo pkill harmony logout ## Create a list of machines we want to copy the db to echo 3.84.74.78 3.84.119.155 54.234.169.74 54.163.11.184 3.84.119.155 > logs/os/shard0down.txt echo 3.84.74.78 3.84.119.155 54.234.169.74 54.163.11.184 3.84.119.155 | tr \" \" \"\\n\" > logs/os/shard0down.txt ./run_on_shard.sh -p os 0down 'pgrep harmony' \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 profile: os \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 execute: pgrep harmony \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 [Y]/n > Y \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 run_on_shard.sh: using timestamp 20200318.212437 (from logs/os -> /home/ec2-user/experiment-deploy/pipeline/logs/20200318.212437) \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 run_on_shard.sh: using outdir logs/os/run_on_shard/2020-03-21T20:43:02Z.Hqhd07 \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 run_on_shard.sh: collecting SSH host keys \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 # 54.163.11.184:22 SSH-2.0-OpenSSH_7.4 \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 # 3.84.74.78:22 SSH-2.0-OpenSSH_7.4 \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 # 3.84.74.78:22 SSH-2.0-OpenSSH_7.4 \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 # 3.84.74.78:22 SSH-2.0-OpenSSH_7.4 \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 # 3.84.119.155:22 SSH-2.0-OpenSSH_7.4 \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 # 3.84.119.155:22 SSH-2.0-OpenSSH_7.4 \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 # 3.84.119.155:22 SSH-2.0-OpenSSH_7.4 \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 # 54.234.169.74:22 SSH-2.0-OpenSSH_7.4 \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 # 54.234.169.74:22 SSH-2.0-OpenSSH_7.4 \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 # 54.234.169.74:22 SSH-2.0-OpenSSH_7.4 \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 # 54.163.11.184:22 SSH-2.0-OpenSSH_7.4 \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 # 54.163.11.184:22 SSH-2.0-OpenSSH_7.4 \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 # 3.84.119.155:22 SSH-2.0-OpenSSH_7.4 \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 # 3.84.119.155:22 SSH-2.0-OpenSSH_7.4 \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 # 3.84.119.155:22 SSH-2.0-OpenSSH_7.4 \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 3.84.74.78 returned status 1 \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 --- BEGIN 3.84.119.155 stdout --- \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 21424 \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 --- END 3.84.119.155 stdout --- \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 --- BEGIN 54.234.169.74 stdout --- \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 8775 \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 --- END 54.234.169.74 stdout --- \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 --- BEGIN 54.163.11.184 stdout --- \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 3620 \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 --- END 54.163.11.184 stdout --- \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 --- BEGIN 3.84.119.155 stdout --- \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 21424 \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 --- END 3.84.119.155 stdout --- \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 run_on_shard.sh: results are in logs/os/run_on_shard/2020-03-21T20:43:02Z.Hqhd07 ec2-user@ip-172-31-37-52 pipeline (master) $ ./run_on_shard.sh -p os 0down 'sudo rm -rf harmony_db_0' \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 profile: os \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 execute: sudo rm -rf harmony_db_0 \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 [Y]/n > Y \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 run_on_shard.sh: using timestamp 20200318.212437 (from logs/os -> /home/ec2-user/experiment-deploy/pipeline/logs/20200318.212437) \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 run_on_shard.sh: using outdir logs/os/run_on_shard/2020-03-21T20:43:57Z.jOHGIv \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 run_on_shard.sh: results are in logs/os/run_on_shard/2020-03-21T20:43:57Z.jOHGIv ## Copy the dbs The authenticity of host '3.84.119.155 (3.84.119.155)' can't be established. \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 ECDSA key fingerprint is SHA256:b3V7K53Oe+KDxw2pm8w3qwWcEbHRK3PK0G5/fZOB9Ss. \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 ECDSA key fingerprint is MD5:5c:60:92:c3:7a:52:4f:de:c5:85:87:cf:85:03:99:8f. \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 Are you sure you want to continue connecting (yes/no)? yes \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 Warning: Permanently added '3.84.119.155' (ECDSA) to the list of known hosts. \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 harmony_db_0.tar.gz 100% 41MB 19.4MB/s 00:02 \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 harmony_db_0.tar.gz 100% 41MB 18.8MB/s 00:02 \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 harmony_db_0.tar.gz 100% 41MB 18.3MB/s 00:02 \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 harmony_db_0.tar.gz 100% 41MB 17.7MB/s 00:02 \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 ec2-user@ip-172-31-37-52 pipeline (mast ./run_on_shard.sh -p os 0down 'du -h' ## Unzip the files scp harmony_db_0.tar.gz 35.171.157.97: ssh 35.171.157.97 'tar xfz harmony_db_0.tar.gz' ./restart_node.sh -y -d logs/os -p os -t 0 -r 0 -R 0 35.171.157.97 ## Restart the entire shard","title":"Cloning and copying a db"},{"location":"deploy/cicd/netdeploy/troubleshooting/cloning-and-copying-a-db/#cloning-and-copying-a-db","text":"ssh into machine pgrep harmony kil -9 pid scp 54.158.239.171:harmony_db_0.tar.gz . ## Log into a machine kill harmony and zip up the db host 54.158.239.171 scp 54.158.239.171:harmony_db_0.tar.gz . ssh 3.84.74.78 pgrep harmony sudo pkill harmony logout ## Create a list of machines we want to copy the db to echo 3.84.74.78 3.84.119.155 54.234.169.74 54.163.11.184 3.84.119.155 > logs/os/shard0down.txt echo 3.84.74.78 3.84.119.155 54.234.169.74 54.163.11.184 3.84.119.155 | tr \" \" \"\\n\" > logs/os/shard0down.txt ./run_on_shard.sh -p os 0down 'pgrep harmony' \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 profile: os \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 execute: pgrep harmony \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 [Y]/n > Y \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 run_on_shard.sh: using timestamp 20200318.212437 (from logs/os -> /home/ec2-user/experiment-deploy/pipeline/logs/20200318.212437) \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 run_on_shard.sh: using outdir logs/os/run_on_shard/2020-03-21T20:43:02Z.Hqhd07 \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 run_on_shard.sh: collecting SSH host keys \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 # 54.163.11.184:22 SSH-2.0-OpenSSH_7.4 \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 # 3.84.74.78:22 SSH-2.0-OpenSSH_7.4 \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 # 3.84.74.78:22 SSH-2.0-OpenSSH_7.4 \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 # 3.84.74.78:22 SSH-2.0-OpenSSH_7.4 \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 # 3.84.119.155:22 SSH-2.0-OpenSSH_7.4 \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 # 3.84.119.155:22 SSH-2.0-OpenSSH_7.4 \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 # 3.84.119.155:22 SSH-2.0-OpenSSH_7.4 \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 # 54.234.169.74:22 SSH-2.0-OpenSSH_7.4 \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 # 54.234.169.74:22 SSH-2.0-OpenSSH_7.4 \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 # 54.234.169.74:22 SSH-2.0-OpenSSH_7.4 \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 # 54.163.11.184:22 SSH-2.0-OpenSSH_7.4 \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 # 54.163.11.184:22 SSH-2.0-OpenSSH_7.4 \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 # 3.84.119.155:22 SSH-2.0-OpenSSH_7.4 \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 # 3.84.119.155:22 SSH-2.0-OpenSSH_7.4 \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 # 3.84.119.155:22 SSH-2.0-OpenSSH_7.4 \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 3.84.74.78 returned status 1 \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 --- BEGIN 3.84.119.155 stdout --- \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 21424 \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 --- END 3.84.119.155 stdout --- \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 --- BEGIN 54.234.169.74 stdout --- \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 8775 \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 --- END 54.234.169.74 stdout --- \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 --- BEGIN 54.163.11.184 stdout --- \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 3620 \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 --- END 54.163.11.184 stdout --- \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 --- BEGIN 3.84.119.155 stdout --- \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 21424 \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 --- END 3.84.119.155 stdout --- \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 run_on_shard.sh: results are in logs/os/run_on_shard/2020-03-21T20:43:02Z.Hqhd07 ec2-user@ip-172-31-37-52 pipeline (master) $ ./run_on_shard.sh -p os 0down 'sudo rm -rf harmony_db_0' \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 profile: os \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 execute: sudo rm -rf harmony_db_0 \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 [Y]/n > Y \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 run_on_shard.sh: using timestamp 20200318.212437 (from logs/os -> /home/ec2-user/experiment-deploy/pipeline/logs/20200318.212437) \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 run_on_shard.sh: using outdir logs/os/run_on_shard/2020-03-21T20:43:57Z.jOHGIv \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 run_on_shard.sh: results are in logs/os/run_on_shard/2020-03-21T20:43:57Z.jOHGIv ## Copy the dbs The authenticity of host '3.84.119.155 (3.84.119.155)' can't be established. \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 ECDSA key fingerprint is SHA256:b3V7K53Oe+KDxw2pm8w3qwWcEbHRK3PK0G5/fZOB9Ss. \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 ECDSA key fingerprint is MD5:5c:60:92:c3:7a:52:4f:de:c5:85:87:cf:85:03:99:8f. \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 Are you sure you want to continue connecting (yes/no)? yes \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 Warning: Permanently added '3.84.119.155' (ECDSA) to the list of known hosts. \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 harmony_db_0.tar.gz 100% 41MB 19.4MB/s 00:02 \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 harmony_db_0.tar.gz 100% 41MB 18.8MB/s 00:02 \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 harmony_db_0.tar.gz 100% 41MB 18.3MB/s 00:02 \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 harmony_db_0.tar.gz 100% 41MB 17.7MB/s 00:02 \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 ec2-user@ip-172-31-37-52 pipeline (mast ./run_on_shard.sh -p os 0down 'du -h' ## Unzip the files scp harmony_db_0.tar.gz 35.171.157.97: ssh 35.171.157.97 'tar xfz harmony_db_0.tar.gz' ./restart_node.sh -y -d logs/os -p os -t 0 -r 0 -R 0 35.171.157.97 ## Restart the entire shard","title":"Cloning and copying a db"},{"location":"deploy/cicd/netdeploy/troubleshooting/systemd-changes-and-handy-commands/","text":"systemd changes and handy commands Overview Harmony recently enhanced node restart capabilities using systemd At the time of writing this has been deployed to all OSTN nodes and explorer nodes for STN. See enable-systemd-service.sh to look at the configuration used for restarts and see harmony.service.template below. Troubleshooting To troubleshoot why a node is being restarted to the following # Log into the node from the devops machine (assume checking STN node) devops.sh export WHOAMI=STN; export HMY_PROFILE=stn; cd /home/ec2-user/go/src/github.com/harmony-one/experiment-deploy/pipeline ./node_ssh.sh 54.245.77.197 # Check how long harmony service has been running sudo systemctl status harmony ## This will give output like this /* [ec2-user@ip-172-31-45-4 latest]$ sudo systemctl status harmony \u25cf harmony.service - harmony service Loaded: loaded (/usr/lib/systemd/system/harmony.service; enabled; vendor preset: disabled) Active: active (running) since Mon 2020-04-20 21:29:52 UTC; 1s ago Main PID: 4802 (bash) CGroup: /system.slice/harmony.service \u251c\u25004802 bash /home/ec2-user/node.sh -1 -S -P -M -D -N stress -p /home/ec2-user/bls.pass -T explorer -i 0 \u251c\u25004813 bash /home/ec2-user/node.sh -1 -S -P -M -D -N stress -p /home/ec2-user/bls.pass -T explorer -i 0 \u251c\u25004815 sleep 30 \u2514\u25004816 ./harmony -bootnodes /ip4/52.40.84.2/tcp/9842/p2p/QmbPVwrqWsTYXq1RxGWcxx9SWaTUCfoo1wA6wmdbduWe29 -ip 54.245.77.197 -port 9000 -network_type=stressnet -dns_zone=... */ # Check the log files to see the errors cd /home/ec2-user/latest tail -f zerolog-validator-54.245.77.197-9000.log | grep error #You will see something like this /* [ec2-user@ip-172-31-45-4 latest]$ tail -f zerolog-validator-54.245.77.197-9000.log | grep error {\"level\":\"info\",\"port\":\"9000\",\"ip\":\"54.245.77.197\",\"error\":\"leveldb: not found\",\"caller\":\"/home/leochen/go/src/github.com/harmony-one/harmony/core/offchain.go:186\",\"time\":\"2020-04-20T21:31:17.375871749Z\",\"message\":\"Could not roll up last continuous crosslink\"} {\"level\":\"error\",\"port\":\"9000\",\"ip\":\"54.245.77.197\",\"error\":\"staking message does not match directive message\",\"txHash\":\"0x2d3751b43f1a498aca2d3d470cc85210fcbccd5ab62f2dc5cb9d31ecc77f8c83\",\"caller\":\"/home/leochen/go/src/github.com/harmony-one/harmony/api/service/explorer/storage.go:109\",\"time\":\"2020-04-20T21:31:17.771977291Z\",\"message\":\"Failed to get explorer StakingTransaction mapping\"} {\"level\":\"warn\",\"port\":\"9000\",\"ip\":\"54.245.77.197\",\"caller\":\"/home/leochen/go/src/github.com/harmony-one/harmony/cmd/harmony/main.go:456\",\"time\":\"2020-04-20T21:31:18.907295295Z\",\"message\":\"Blacklist setup error: open ./.hmy/blacklist.txt: no such file or directory\"} {\"level\":\"error\",\"port\":\"9000\",\"ip\":\"54.245.77.197\",\"error\":\"EOF\",\"caller\":\"/home/leochen/go/src/github.com/harmony-one/harmony/core/blockchain.go:1963\",\"time\":\"2020-04-20T21:31:20.303429495Z\",\"message\":\"Invalid pending crosslink RLP decoding\"} {\"level\":\"error\",\"port\":\"9000\",\"ip\":\"54.245.77.197\",\"error\":\"EOF\",\"caller\":\"/home/leochen/go/src/github.com/harmony-one/harmony/core/blockchain.go:1963\",\"time\":\"2020-04-20T21:31:20.316708794Z\",\"message\":\"Invalid pending crosslink RLP decoding\"} */ # You can also use journalctl to see the logs - however this did not work on the STN exploreer journalctl -r -l # Or look at dmesg to to examine the kernel ring buffer ## For example to see if Out Of Memory occured dmesg | grep oom-killer harmony.service.template curl -g https://haochen-harmony-pub.s3.amazonaws.com/pub/systemd/harmony.service.template [Unit] Description=harmony service After=network.target StartLimitIntervalSec=0 [Service] Type=simple Restart=always RestartSec=1 User=%%USER%% WorkingDirectory=%%HOME%% ExecStart=%%HOME%%/node.sh -1 -S -P -M -D -N %%NETWORK%% -p %%HOME%%/%%BLSPASS%% -T %%NODETYPE%% %%EXTRA%% [Install] WantedBy=multi-user.target","title":"systemd changes and handy commands"},{"location":"deploy/cicd/netdeploy/troubleshooting/systemd-changes-and-handy-commands/#systemd-changes-and-handy-commands","text":"","title":"systemd changes and handy commands"},{"location":"deploy/cicd/netdeploy/troubleshooting/systemd-changes-and-handy-commands/#overview","text":"Harmony recently enhanced node restart capabilities using systemd At the time of writing this has been deployed to all OSTN nodes and explorer nodes for STN. See enable-systemd-service.sh to look at the configuration used for restarts and see harmony.service.template below.","title":"Overview"},{"location":"deploy/cicd/netdeploy/troubleshooting/systemd-changes-and-handy-commands/#troubleshooting","text":"To troubleshoot why a node is being restarted to the following # Log into the node from the devops machine (assume checking STN node) devops.sh export WHOAMI=STN; export HMY_PROFILE=stn; cd /home/ec2-user/go/src/github.com/harmony-one/experiment-deploy/pipeline ./node_ssh.sh 54.245.77.197 # Check how long harmony service has been running sudo systemctl status harmony ## This will give output like this /* [ec2-user@ip-172-31-45-4 latest]$ sudo systemctl status harmony \u25cf harmony.service - harmony service Loaded: loaded (/usr/lib/systemd/system/harmony.service; enabled; vendor preset: disabled) Active: active (running) since Mon 2020-04-20 21:29:52 UTC; 1s ago Main PID: 4802 (bash) CGroup: /system.slice/harmony.service \u251c\u25004802 bash /home/ec2-user/node.sh -1 -S -P -M -D -N stress -p /home/ec2-user/bls.pass -T explorer -i 0 \u251c\u25004813 bash /home/ec2-user/node.sh -1 -S -P -M -D -N stress -p /home/ec2-user/bls.pass -T explorer -i 0 \u251c\u25004815 sleep 30 \u2514\u25004816 ./harmony -bootnodes /ip4/52.40.84.2/tcp/9842/p2p/QmbPVwrqWsTYXq1RxGWcxx9SWaTUCfoo1wA6wmdbduWe29 -ip 54.245.77.197 -port 9000 -network_type=stressnet -dns_zone=... */ # Check the log files to see the errors cd /home/ec2-user/latest tail -f zerolog-validator-54.245.77.197-9000.log | grep error #You will see something like this /* [ec2-user@ip-172-31-45-4 latest]$ tail -f zerolog-validator-54.245.77.197-9000.log | grep error {\"level\":\"info\",\"port\":\"9000\",\"ip\":\"54.245.77.197\",\"error\":\"leveldb: not found\",\"caller\":\"/home/leochen/go/src/github.com/harmony-one/harmony/core/offchain.go:186\",\"time\":\"2020-04-20T21:31:17.375871749Z\",\"message\":\"Could not roll up last continuous crosslink\"} {\"level\":\"error\",\"port\":\"9000\",\"ip\":\"54.245.77.197\",\"error\":\"staking message does not match directive message\",\"txHash\":\"0x2d3751b43f1a498aca2d3d470cc85210fcbccd5ab62f2dc5cb9d31ecc77f8c83\",\"caller\":\"/home/leochen/go/src/github.com/harmony-one/harmony/api/service/explorer/storage.go:109\",\"time\":\"2020-04-20T21:31:17.771977291Z\",\"message\":\"Failed to get explorer StakingTransaction mapping\"} {\"level\":\"warn\",\"port\":\"9000\",\"ip\":\"54.245.77.197\",\"caller\":\"/home/leochen/go/src/github.com/harmony-one/harmony/cmd/harmony/main.go:456\",\"time\":\"2020-04-20T21:31:18.907295295Z\",\"message\":\"Blacklist setup error: open ./.hmy/blacklist.txt: no such file or directory\"} {\"level\":\"error\",\"port\":\"9000\",\"ip\":\"54.245.77.197\",\"error\":\"EOF\",\"caller\":\"/home/leochen/go/src/github.com/harmony-one/harmony/core/blockchain.go:1963\",\"time\":\"2020-04-20T21:31:20.303429495Z\",\"message\":\"Invalid pending crosslink RLP decoding\"} {\"level\":\"error\",\"port\":\"9000\",\"ip\":\"54.245.77.197\",\"error\":\"EOF\",\"caller\":\"/home/leochen/go/src/github.com/harmony-one/harmony/core/blockchain.go:1963\",\"time\":\"2020-04-20T21:31:20.316708794Z\",\"message\":\"Invalid pending crosslink RLP decoding\"} */ # You can also use journalctl to see the logs - however this did not work on the STN exploreer journalctl -r -l # Or look at dmesg to to examine the kernel ring buffer ## For example to see if Out Of Memory occured dmesg | grep oom-killer","title":"Troubleshooting"},{"location":"deploy/cicd/netdeploy/troubleshooting/systemd-changes-and-handy-commands/#harmonyservicetemplate","text":"curl -g https://haochen-harmony-pub.s3.amazonaws.com/pub/systemd/harmony.service.template [Unit] Description=harmony service After=network.target StartLimitIntervalSec=0 [Service] Type=simple Restart=always RestartSec=1 User=%%USER%% WorkingDirectory=%%HOME%% ExecStart=%%HOME%%/node.sh -1 -S -P -M -D -N %%NETWORK%% -p %%HOME%%/%%BLSPASS%% -T %%NODETYPE%% %%EXTRA%% [Install] WantedBy=multi-user.target","title":"harmony.service.template"},{"location":"deploy/cicd/netdeploy/troubleshooting/protocol-codebase-and-log-analysis/","text":"Protocol Codebase and Log Analysis (Work In Progress) Overview This document is a work in progress. The goal is to give a high level overview of how key functionality works. the code which delivers that functionality and how to review log messages to determine the cause of issues such as losing consensus or nodes not synching. It will walk through the various functional stages in Launching a network, epoch change, view change, peer discovery, etc and give practical tips on how to resolve the issue. Network Launch Code Node Configuration Protocol Code Peer Discovery service_setup networkinfo findpeer Best way to do cpu profiling (see sebs script) Debugging Steps # Check the network configuration # Check the Signing Delay # Check that Node is Discovered # Check the Status of All Shards # Check who the leader is # Check the current committee # Synchronization Code Syncing .go - syncLoop Node_syncing.go - DoSync Peer Discovery Epoch Change Choosing Validators Committee Assignment - Elects validators View Change Leader Election Proposing Blocks Receiving Blocks Checking Signatures Checking Consensus (enough signatures) Broadcasting Signed Blocks Lost Consensus consensus_v2.go - routes consensus messages and runs consensus loop leader.go - handles leader consensus messages validator.go - handles validator consensus messages checks.go - validates consensus messages Broadcasting Transactions","title":"Protocol Codebase and Log Analysis \\(Work In Progress\\)"},{"location":"deploy/cicd/netdeploy/troubleshooting/protocol-codebase-and-log-analysis/#protocol-codebase-and-log-analysis-work-in-progress","text":"","title":"Protocol Codebase and Log Analysis (Work In Progress)"},{"location":"deploy/cicd/netdeploy/troubleshooting/protocol-codebase-and-log-analysis/#overview","text":"This document is a work in progress. The goal is to give a high level overview of how key functionality works. the code which delivers that functionality and how to review log messages to determine the cause of issues such as losing consensus or nodes not synching. It will walk through the various functional stages in Launching a network, epoch change, view change, peer discovery, etc and give practical tips on how to resolve the issue.","title":"Overview"},{"location":"deploy/cicd/netdeploy/troubleshooting/protocol-codebase-and-log-analysis/#network-launch","text":"Code Node Configuration Protocol Code Peer Discovery service_setup networkinfo findpeer Best way to do cpu profiling (see sebs script)","title":"Network Launch"},{"location":"deploy/cicd/netdeploy/troubleshooting/protocol-codebase-and-log-analysis/#debugging-steps","text":"# Check the network configuration # Check the Signing Delay # Check that Node is Discovered # Check the Status of All Shards # Check who the leader is # Check the current committee #","title":"Debugging Steps"},{"location":"deploy/cicd/netdeploy/troubleshooting/protocol-codebase-and-log-analysis/#synchronization","text":"Code Syncing .go - syncLoop Node_syncing.go - DoSync","title":"Synchronization"},{"location":"deploy/cicd/netdeploy/troubleshooting/protocol-codebase-and-log-analysis/#peer-discovery","text":"","title":"Peer Discovery"},{"location":"deploy/cicd/netdeploy/troubleshooting/protocol-codebase-and-log-analysis/#epoch-change","text":"Choosing Validators Committee Assignment - Elects validators","title":"Epoch Change"},{"location":"deploy/cicd/netdeploy/troubleshooting/protocol-codebase-and-log-analysis/#view-change","text":"Leader Election","title":"View Change"},{"location":"deploy/cicd/netdeploy/troubleshooting/protocol-codebase-and-log-analysis/#proposing-blocks","text":"","title":"Proposing Blocks"},{"location":"deploy/cicd/netdeploy/troubleshooting/protocol-codebase-and-log-analysis/#receiving-blocks","text":"Checking Signatures Checking Consensus (enough signatures) Broadcasting Signed Blocks","title":"Receiving Blocks"},{"location":"deploy/cicd/netdeploy/troubleshooting/protocol-codebase-and-log-analysis/#lost-consensus","text":"consensus_v2.go - routes consensus messages and runs consensus loop leader.go - handles leader consensus messages validator.go - handles validator consensus messages checks.go - validates consensus messages","title":"Lost Consensus"},{"location":"deploy/cicd/netdeploy/troubleshooting/protocol-codebase-and-log-analysis/#broadcasting-transactions","text":"","title":"Broadcasting Transactions"},{"location":"deploy/cicd/netdeploy/troubleshooting/protocol-codebase-and-log-analysis/protocol-debugging/","text":"Protocol Debugging Connecting to devops machine {% tabs %} {% tab title=\"OSTN\" %} exec ssh -i ~/.ssh/keys/oregon-key-benchmark.pem ec2-user@devop.hmny.io profile_print export WHOAMI=OS; export HMY_PROFILE=os; profile_print {% endtab %} {% tab title=\"STN\" %} exec ssh -i ~/.ssh/keys/oregon-key-benchmark.pem ec2-user@devop.hmny.io profile_print export WHOAMI=STN; export HMY_PROFILE=stn; profile_print {% endtab %} {% endtabs %} Running commands on all nodes in a shard cd ~/experiment-deploy/pipeline ./run_on_shard.sh -p os -T 2 \"tac ../tmp_log/*/zerolog-*.log | grep -m 1 myViewID\" Finding the leader Look at watchdog Connecting to a running validator Leader # Replace with the IP of the machine you wish to connect to ~/experiment-deploy/pipeline/node_ssh.sh 34.227.152.66 Handy Commands to view logs tail -f ../tmp_log/log-20200326.034158/zerolog-validator-34.227.152.66-9000.log # Sentry logs are in ./latest # Harmony nodes logs are in ../tmp_log/DATETIME/ # e.g. tail -f ../tmp_log/log-20200326.034158/zerolog-validator-3.84.241.74-9000.log tail -f ./latest/*.log tail -f ./latest/*.log | grep Height tail -f ./latest/*.log | grep SYNC tail -f ./latest/*.log | grep OnAnnounce tail -f ./latest/*.log | grep OnPrepared ./hmy --node=\"https://api.s0.os.hmny.io\" blockchain validator information one1m6j80t6rhc3ypaumtsfmqwjwp0mrqk9ff50prh tac ./latest/*.log | grep invalid cat ./latest/*.log | grep invalid cat ./latest/*.log | grep \"error\" Reference Code Synchronizing Peer Discovery Epoch Change Choosing the Validators View Change Leader Election Proposing Blocks Receiving Blocks Proposing Signed Blocks Checking Signatures Checking Consensus Broadcasting Signed Block Broadcasting Transactions","title":"Protocol Debugging"},{"location":"deploy/cicd/netdeploy/troubleshooting/protocol-codebase-and-log-analysis/protocol-debugging/#protocol-debugging","text":"","title":"Protocol Debugging"},{"location":"deploy/cicd/netdeploy/troubleshooting/protocol-codebase-and-log-analysis/protocol-debugging/#connecting-to-devops-machine","text":"{% tabs %} {% tab title=\"OSTN\" %} exec ssh -i ~/.ssh/keys/oregon-key-benchmark.pem ec2-user@devop.hmny.io profile_print export WHOAMI=OS; export HMY_PROFILE=os; profile_print {% endtab %} {% tab title=\"STN\" %} exec ssh -i ~/.ssh/keys/oregon-key-benchmark.pem ec2-user@devop.hmny.io profile_print export WHOAMI=STN; export HMY_PROFILE=stn; profile_print {% endtab %} {% endtabs %}","title":"Connecting to devops machine"},{"location":"deploy/cicd/netdeploy/troubleshooting/protocol-codebase-and-log-analysis/protocol-debugging/#running-commands-on-all-nodes-in-a-shard","text":"cd ~/experiment-deploy/pipeline ./run_on_shard.sh -p os -T 2 \"tac ../tmp_log/*/zerolog-*.log | grep -m 1 myViewID\"","title":"Running commands on all nodes in a shard"},{"location":"deploy/cicd/netdeploy/troubleshooting/protocol-codebase-and-log-analysis/protocol-debugging/#finding-the-leader","text":"Look at watchdog","title":"Finding the leader"},{"location":"deploy/cicd/netdeploy/troubleshooting/protocol-codebase-and-log-analysis/protocol-debugging/#connecting-to-a-running-validator-leader","text":"# Replace with the IP of the machine you wish to connect to ~/experiment-deploy/pipeline/node_ssh.sh 34.227.152.66","title":"Connecting to a running validator Leader"},{"location":"deploy/cicd/netdeploy/troubleshooting/protocol-codebase-and-log-analysis/protocol-debugging/#handy-commands-to-view-logs","text":"tail -f ../tmp_log/log-20200326.034158/zerolog-validator-34.227.152.66-9000.log # Sentry logs are in ./latest # Harmony nodes logs are in ../tmp_log/DATETIME/ # e.g. tail -f ../tmp_log/log-20200326.034158/zerolog-validator-3.84.241.74-9000.log tail -f ./latest/*.log tail -f ./latest/*.log | grep Height tail -f ./latest/*.log | grep SYNC tail -f ./latest/*.log | grep OnAnnounce tail -f ./latest/*.log | grep OnPrepared ./hmy --node=\"https://api.s0.os.hmny.io\" blockchain validator information one1m6j80t6rhc3ypaumtsfmqwjwp0mrqk9ff50prh tac ./latest/*.log | grep invalid cat ./latest/*.log | grep invalid cat ./latest/*.log | grep \"error\"","title":"Handy Commands to view logs"},{"location":"deploy/cicd/netdeploy/troubleshooting/protocol-codebase-and-log-analysis/protocol-debugging/#reference-code","text":"Synchronizing Peer Discovery Epoch Change Choosing the Validators View Change Leader Election Proposing Blocks Receiving Blocks Proposing Signed Blocks Checking Signatures Checking Consensus Broadcasting Signed Block Broadcasting Transactions","title":"Reference Code"},{"location":"deploy/cicd/netdeploy/troubleshooting/recovering-nodes-killed-as-spot-instances/","text":"Recovering nodes killed as spot Instances Overview OSTN uses spot instances which means nodes will occasionally get killed. This page gives an overview of how to recover these nodes. Previous documentation here Identify the nodes which have been killed A list of down machines can be found on watchdog Check whether the machine is up # Log into deveops machine exec ssh -i ~/.ssh/keys/oregon-key-benchmark.pem ec2-user@devop.hmny.io # Log into tmux and set your profile tmux ls tmux attach-session -t os profile_print export WHOAMI=OS; export HMY_PROFILE=os; profile_print # SSH into the machines ~/experiment-deploy/pipeline/node_ssh.sh 35.175.137.77 # If instance is gone you will see # ssh: connect to host 35.175.137.77 port 22: Connection timed out Spin up new instances Log into the AWS CONSOLE and search for EC2 instances with the name os Select one and choose Launch more like this - you can launch multiple instances at once set up on demand instances use 15GB storage set IAM role to harmony_node Add the BLS keys and synch the DB'S BLS keys are under .hmy We use three keys per node and they are assigned round robin from the top i.e. a node may have keys from line 52, 132 and 212 of blskeys-test.txt Get the actual keys still existing Log into each machine and grab the bls keys ./run_on_shard.sh -p os -y -T 0 'ip=$(curl http://169.254.169.254/latest/meta-data/public-ipv4); for k in $(ls ./.hmy/blskeys/); do echo $k, $ip; done' > ostn-s0-actual.txt ./run_on_shard.sh -p os -y -T 1 'ip=$(curl http://169.254.169.254/latest/meta-data/public-ipv4); for k in $(ls ./.hmy/blskeys/); do echo $k, $ip; done' > ostn-s1-actual.txt ./run_on_shard.sh -p os -y -T 2 'ip=$(curl http://169.254.169.254/latest/meta-data/public-ipv4); for k in $(ls ./.hmy/blskeys/); do echo $k, $ip; done' > ostn-s2-actual.txt ./run_on_shard.sh -p os -y -T 3 'ip=$(curl http://169.254.169.254/latest/meta-data/public-ipv4); for k in $(ls ./.hmy/blskeys/); do echo $k, $ip; done' > ostn-s3-actual.txt Some Python magic to print the 20 missing keys for Shard 1 from blskeys-test.txt Need to do this four times changing line 7 from (0,1,2,3) to get all shards and then place them in a file os-s0-20.txt with open('../configs/blskey-test.txt') as f: content = f.readlines() content = [x.strip() for x in content] count = 0 for i, x in enumerate(content): if i % 4 == 0: count += 1 print(i+3, x) if count >= 20: break Some Python magic to find the keys for the node Find the missing keys in bls_keys-test.txt and then find the keys for the node by adding 80 to the index twice (each node has 3 keys) In [63]: for x in s0_absent: ...: i = ref.index(x) ...: for j in range(i, i+(80*2)+1, 80): ...: print(j, ref[j]) ...: ...: 52 d69c70aa8e43853487760533ad1cbeb9f8e91d409ede23f5db9e0038528bd9914ecd8710afe187bb303cc345a52f0b93.key 132 d2756594a894175bcffa03ce8a945e8c73f8149e3a4acf0695a206b70a9a4c5782a16199f590ee1cdafb50a45488e518.key 212 f4354e218f74d3d629586cb361d28025b4d8d2387eb173c49c86912f7f8e20f13c214f3351466a6140a4ee0071efdb8a.key 76 03406acec541e0e0d7cbcb7c0502b4901d09b4f563fe0db4cf3e3d18038373f71eb3f720d9d9c66244364bfd7ef09217.key 156 069e433b4112cda534bf4171d33c13a832dbcbf8222afacb701b2e00bd2303ff107d2bc75ba02185e48958aeba7a7697.key 236 e53407496e6c807be3e583c45b49b5a00c8c0550ced7fdadab9139109002625107035a5885f9d097a68791db48ecc803.key In [64]: for x in s1_absent: ...: i = ref.index(x) ...: for j in range(i, i+(80*2)+1, 80): ...: print(j, ref[j]) ...: ...: 41 90404f04db155afc0444210b83a1f6acb29e0c479a31222afe7827b643067754817af06fbda99600d5afcc0dfd510c89.key 121 ba17088f82e461ace61eec13b48463b8bebef8046a2362fd9c0e302a0331228233c7ad6811d151f63e01db36c1093a83.key 201 a7a3fef9449204c26de34129d30793c5adcc9ddb5aa1e02bad8bbe5662db336ab5538ee3e1156785486c4a75ca68b211.key 73 867ae6f88a5edecd6d89df05d94e08785971b4611ccda62944a7773f5cdcd6f2d86af8364fc7670d38a18109b2416413.key 153 3664120aa99f98a215819b4a4adffc59450f5ad73da7a7594dd9cc2633fad63ad9692b580326575a99250700a77d7717.key 233 5eb082f818ea3c5a3b49079d8d86d8d43cec0863e4226d1c7facdf9537e17c5ebdcb53450cafd47d6c4ed0c51b7c2214.key In [65]: for x in s2_absent: ...: i = ref.index(x) ...: for j in range(i, i+(80*2)+1, 80): ...: print(j, ref[j]) ...: ...: 18 1bf1ca37df49190578391d3c34cdb62cc9b2c88ebf5bbbe72a41db8da5236576fdb4513973045f23633a6ddd5a52488a.key 98 9fd7463748f72c1a219ccd8e0e3388e7c5f8c426260d78baabd8c5ca172950661410d7a84ed25669edf9419ffa657618.key 178 8e85ca728c071af97586b178d906dd27a652b426b8bd2c5e15149700741ee605310a3981232c9f6aca1a37274539948e.key 46 351f04e4329c8e3a49ea956b8d85307a8eaf56849f20c0006e7b59346922c3e038a1fee4bd7cbf1b34551a0270b40710.key 126 7c880b17c5cec63bebc634ad4530ea32e4632b7b73085f5d9948c333ae3963cf4e448d29b194a2e304b68736c2b3a903.key 206 a77967462bea74b9eb96608ee0e4e4ba444da7a3708da2f8f60f8ff53878adcb0cf25a38d8caddeb3be3b4a35e35fe0d.key 58 a4a75bfc607dd1bee6d60454309bb5fb4c9a48805bc514f29e56c5766e391545bc8d750011c6d1f4b12218adc7c15e95.key 138 929d436cccbb46229f3405e57ebd44cb9b2987e1d8cfe48455738a9f2f8f77438771f53478a71dc247a857686c28b60a.key 218 4af2bd9f1e91b9c7db1f6d239a0c76006e8d8d1219468a49d4c06893f15cc6844d5826083bb0f06d4f9af80e38e0b002.key 62 2d24f086b9cf9a7f3e934a9bf4bd9355a0aaf3b21c03d74725fe8253d01888bfa839eaafe5a99a41678d1d4750f2eb92.key 142 50c3565ad3275e660a97ef29dae9d335f77871cfd5c09ee5c5f61306781c0478988ed1ca45e5c151a0fa5d483346de92.key 222 49f9c2b3d90aa7dd1ead32ce40cf90864cc6420f5f11b136f35d58753838756f991561fc1350b5b7facdcc4c1d88ba88.key 78 6d8faf3a0ff828bfc59702755c8e84d1e4dbd434d798c56bfa4772aa22254ae4643d6b4a9d385941780b848e1aed6007.key 158 60aae7000932b498084255484f94c394159650817095a2ca097f2031d63b04decfa24d659655241792276f14f64fa294.key 238 6963a4a6283d8f7150aef2b2ca05cd15bf43c77a9e42dd544caf869ece8292510ca2e255d675407e14429bfb00335a92.key In [66]: for x in s3_absent: ...: i = ref.index(x) ...: for j in range(i, i+(80*2)+1, 80): ...: print(j, ref[j]) ...: ...: 47 8f657775630e2f58fe7fc679fd5827705eb19ad1ea47c78d3d5ac544ddc8d2fa0aa542bafd350d4eb7e9c822a89e3006.key 127 fcacc28fdc2bacd2ea3f6b3bda853553522ed5cf1a335f67930ea7c7d981ec3f33ce00d1b4b30438287a77ec043b478f.key 207 acb484265281f4f956f4b73221d1fb3df8f78adecfd59e693f961d0de46b1790c4d2d12856c35bdc733ebdf0da134d85.key Load them onto the new instances see Copying Keys Update the IPs sudo mkdir -p ../tmp_log/log-20200318.173735; Start the node Update Watchdogs IP's and restart Additional commands cd /home/ec2-user/experiment-deploy/configs cat blskey-test.txt # Get all the keys from the online nodes ./node_ssh.sh 54.234.169.74 cd .hmy/blskeys/ ls # Also held in cd ~/ \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 ls ./.hmy/blskeys/ # Use run on shard to get all the keys ./run_on_shard.sh -p os -y -T 0 'ls ./.hmy/blskeys/' > ostn-s0-actual.txt cat ostn-s0-actual.txt | sort > ostn-s0-actual-sort.txt # Grab the top 20 keys (these are the keys for the 20 nodes on shard 0 head -n20 blskey-test.txt > ostn-s0.txt \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 cat ostn-s0.txt ./run_on_shard.sh -p os -T 0 'ls ./.hmy/blskeys/' | sort > ostn-s0-actual.txt Add them to the configuration for OSTN # Compare the differences in the files grep -vxf ../pipeline/ostn-s0-actual-sort.txt ostn-s0.txt Validation Check watchdog Check the nodes have synched beacon chain grep SYNC ../tmp_log/log-20200318.212437/*.log | grep \"isBeacon: true\"","title":"Recovering nodes killed as spot Instances"},{"location":"deploy/cicd/netdeploy/troubleshooting/recovering-nodes-killed-as-spot-instances/#recovering-nodes-killed-as-spot-instances","text":"","title":"Recovering nodes killed as spot Instances"},{"location":"deploy/cicd/netdeploy/troubleshooting/recovering-nodes-killed-as-spot-instances/#overview","text":"OSTN uses spot instances which means nodes will occasionally get killed. This page gives an overview of how to recover these nodes. Previous documentation here","title":"Overview"},{"location":"deploy/cicd/netdeploy/troubleshooting/recovering-nodes-killed-as-spot-instances/#identify-the-nodes-which-have-been-killed","text":"A list of down machines can be found on watchdog","title":"Identify the nodes which have been killed"},{"location":"deploy/cicd/netdeploy/troubleshooting/recovering-nodes-killed-as-spot-instances/#check-whether-the-machine-is-up","text":"# Log into deveops machine exec ssh -i ~/.ssh/keys/oregon-key-benchmark.pem ec2-user@devop.hmny.io # Log into tmux and set your profile tmux ls tmux attach-session -t os profile_print export WHOAMI=OS; export HMY_PROFILE=os; profile_print # SSH into the machines ~/experiment-deploy/pipeline/node_ssh.sh 35.175.137.77 # If instance is gone you will see # ssh: connect to host 35.175.137.77 port 22: Connection timed out","title":"Check whether the machine is up"},{"location":"deploy/cicd/netdeploy/troubleshooting/recovering-nodes-killed-as-spot-instances/#spin-up-new-instances","text":"Log into the AWS CONSOLE and search for EC2 instances with the name os Select one and choose Launch more like this - you can launch multiple instances at once set up on demand instances use 15GB storage set IAM role to harmony_node","title":"Spin up new instances"},{"location":"deploy/cicd/netdeploy/troubleshooting/recovering-nodes-killed-as-spot-instances/#add-the-bls-keys-and-synch-the-dbs","text":"BLS keys are under .hmy We use three keys per node and they are assigned round robin from the top i.e. a node may have keys from line 52, 132 and 212 of blskeys-test.txt","title":"Add the BLS keys and synch the DB'S"},{"location":"deploy/cicd/netdeploy/troubleshooting/recovering-nodes-killed-as-spot-instances/#get-the-actual-keys-still-existing","text":"Log into each machine and grab the bls keys ./run_on_shard.sh -p os -y -T 0 'ip=$(curl http://169.254.169.254/latest/meta-data/public-ipv4); for k in $(ls ./.hmy/blskeys/); do echo $k, $ip; done' > ostn-s0-actual.txt ./run_on_shard.sh -p os -y -T 1 'ip=$(curl http://169.254.169.254/latest/meta-data/public-ipv4); for k in $(ls ./.hmy/blskeys/); do echo $k, $ip; done' > ostn-s1-actual.txt ./run_on_shard.sh -p os -y -T 2 'ip=$(curl http://169.254.169.254/latest/meta-data/public-ipv4); for k in $(ls ./.hmy/blskeys/); do echo $k, $ip; done' > ostn-s2-actual.txt ./run_on_shard.sh -p os -y -T 3 'ip=$(curl http://169.254.169.254/latest/meta-data/public-ipv4); for k in $(ls ./.hmy/blskeys/); do echo $k, $ip; done' > ostn-s3-actual.txt","title":"Get the actual keys still existing"},{"location":"deploy/cicd/netdeploy/troubleshooting/recovering-nodes-killed-as-spot-instances/#some-python-magic-to-print-the-20-missing-keys-for-shard-1-from-blskeys-testtxt","text":"Need to do this four times changing line 7 from (0,1,2,3) to get all shards and then place them in a file os-s0-20.txt with open('../configs/blskey-test.txt') as f: content = f.readlines() content = [x.strip() for x in content] count = 0 for i, x in enumerate(content): if i % 4 == 0: count += 1 print(i+3, x) if count >= 20: break","title":"Some Python magic to print the 20 missing keys for Shard 1 from blskeys-test.txt"},{"location":"deploy/cicd/netdeploy/troubleshooting/recovering-nodes-killed-as-spot-instances/#some-python-magic-to-find-the-keys-for-the-node","text":"Find the missing keys in bls_keys-test.txt and then find the keys for the node by adding 80 to the index twice (each node has 3 keys) In [63]: for x in s0_absent: ...: i = ref.index(x) ...: for j in range(i, i+(80*2)+1, 80): ...: print(j, ref[j]) ...: ...: 52 d69c70aa8e43853487760533ad1cbeb9f8e91d409ede23f5db9e0038528bd9914ecd8710afe187bb303cc345a52f0b93.key 132 d2756594a894175bcffa03ce8a945e8c73f8149e3a4acf0695a206b70a9a4c5782a16199f590ee1cdafb50a45488e518.key 212 f4354e218f74d3d629586cb361d28025b4d8d2387eb173c49c86912f7f8e20f13c214f3351466a6140a4ee0071efdb8a.key 76 03406acec541e0e0d7cbcb7c0502b4901d09b4f563fe0db4cf3e3d18038373f71eb3f720d9d9c66244364bfd7ef09217.key 156 069e433b4112cda534bf4171d33c13a832dbcbf8222afacb701b2e00bd2303ff107d2bc75ba02185e48958aeba7a7697.key 236 e53407496e6c807be3e583c45b49b5a00c8c0550ced7fdadab9139109002625107035a5885f9d097a68791db48ecc803.key In [64]: for x in s1_absent: ...: i = ref.index(x) ...: for j in range(i, i+(80*2)+1, 80): ...: print(j, ref[j]) ...: ...: 41 90404f04db155afc0444210b83a1f6acb29e0c479a31222afe7827b643067754817af06fbda99600d5afcc0dfd510c89.key 121 ba17088f82e461ace61eec13b48463b8bebef8046a2362fd9c0e302a0331228233c7ad6811d151f63e01db36c1093a83.key 201 a7a3fef9449204c26de34129d30793c5adcc9ddb5aa1e02bad8bbe5662db336ab5538ee3e1156785486c4a75ca68b211.key 73 867ae6f88a5edecd6d89df05d94e08785971b4611ccda62944a7773f5cdcd6f2d86af8364fc7670d38a18109b2416413.key 153 3664120aa99f98a215819b4a4adffc59450f5ad73da7a7594dd9cc2633fad63ad9692b580326575a99250700a77d7717.key 233 5eb082f818ea3c5a3b49079d8d86d8d43cec0863e4226d1c7facdf9537e17c5ebdcb53450cafd47d6c4ed0c51b7c2214.key In [65]: for x in s2_absent: ...: i = ref.index(x) ...: for j in range(i, i+(80*2)+1, 80): ...: print(j, ref[j]) ...: ...: 18 1bf1ca37df49190578391d3c34cdb62cc9b2c88ebf5bbbe72a41db8da5236576fdb4513973045f23633a6ddd5a52488a.key 98 9fd7463748f72c1a219ccd8e0e3388e7c5f8c426260d78baabd8c5ca172950661410d7a84ed25669edf9419ffa657618.key 178 8e85ca728c071af97586b178d906dd27a652b426b8bd2c5e15149700741ee605310a3981232c9f6aca1a37274539948e.key 46 351f04e4329c8e3a49ea956b8d85307a8eaf56849f20c0006e7b59346922c3e038a1fee4bd7cbf1b34551a0270b40710.key 126 7c880b17c5cec63bebc634ad4530ea32e4632b7b73085f5d9948c333ae3963cf4e448d29b194a2e304b68736c2b3a903.key 206 a77967462bea74b9eb96608ee0e4e4ba444da7a3708da2f8f60f8ff53878adcb0cf25a38d8caddeb3be3b4a35e35fe0d.key 58 a4a75bfc607dd1bee6d60454309bb5fb4c9a48805bc514f29e56c5766e391545bc8d750011c6d1f4b12218adc7c15e95.key 138 929d436cccbb46229f3405e57ebd44cb9b2987e1d8cfe48455738a9f2f8f77438771f53478a71dc247a857686c28b60a.key 218 4af2bd9f1e91b9c7db1f6d239a0c76006e8d8d1219468a49d4c06893f15cc6844d5826083bb0f06d4f9af80e38e0b002.key 62 2d24f086b9cf9a7f3e934a9bf4bd9355a0aaf3b21c03d74725fe8253d01888bfa839eaafe5a99a41678d1d4750f2eb92.key 142 50c3565ad3275e660a97ef29dae9d335f77871cfd5c09ee5c5f61306781c0478988ed1ca45e5c151a0fa5d483346de92.key 222 49f9c2b3d90aa7dd1ead32ce40cf90864cc6420f5f11b136f35d58753838756f991561fc1350b5b7facdcc4c1d88ba88.key 78 6d8faf3a0ff828bfc59702755c8e84d1e4dbd434d798c56bfa4772aa22254ae4643d6b4a9d385941780b848e1aed6007.key 158 60aae7000932b498084255484f94c394159650817095a2ca097f2031d63b04decfa24d659655241792276f14f64fa294.key 238 6963a4a6283d8f7150aef2b2ca05cd15bf43c77a9e42dd544caf869ece8292510ca2e255d675407e14429bfb00335a92.key In [66]: for x in s3_absent: ...: i = ref.index(x) ...: for j in range(i, i+(80*2)+1, 80): ...: print(j, ref[j]) ...: ...: 47 8f657775630e2f58fe7fc679fd5827705eb19ad1ea47c78d3d5ac544ddc8d2fa0aa542bafd350d4eb7e9c822a89e3006.key 127 fcacc28fdc2bacd2ea3f6b3bda853553522ed5cf1a335f67930ea7c7d981ec3f33ce00d1b4b30438287a77ec043b478f.key 207 acb484265281f4f956f4b73221d1fb3df8f78adecfd59e693f961d0de46b1790c4d2d12856c35bdc733ebdf0da134d85.key","title":"Some Python magic to find the keys for the node"},{"location":"deploy/cicd/netdeploy/troubleshooting/recovering-nodes-killed-as-spot-instances/#load-them-onto-the-new-instances","text":"see Copying Keys","title":"Load them onto the new instances"},{"location":"deploy/cicd/netdeploy/troubleshooting/recovering-nodes-killed-as-spot-instances/#update-the-ips","text":"sudo mkdir -p ../tmp_log/log-20200318.173735;","title":"Update the IPs"},{"location":"deploy/cicd/netdeploy/troubleshooting/recovering-nodes-killed-as-spot-instances/#start-the-node","text":"","title":"Start the node"},{"location":"deploy/cicd/netdeploy/troubleshooting/recovering-nodes-killed-as-spot-instances/#update-watchdogs-ips-and-restart","text":"","title":"Update Watchdogs IP's and restart"},{"location":"deploy/cicd/netdeploy/troubleshooting/recovering-nodes-killed-as-spot-instances/#additional-commands","text":"cd /home/ec2-user/experiment-deploy/configs cat blskey-test.txt # Get all the keys from the online nodes ./node_ssh.sh 54.234.169.74 cd .hmy/blskeys/ ls # Also held in cd ~/ \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 ls ./.hmy/blskeys/ # Use run on shard to get all the keys ./run_on_shard.sh -p os -y -T 0 'ls ./.hmy/blskeys/' > ostn-s0-actual.txt cat ostn-s0-actual.txt | sort > ostn-s0-actual-sort.txt # Grab the top 20 keys (these are the keys for the 20 nodes on shard 0 head -n20 blskey-test.txt > ostn-s0.txt \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 cat ostn-s0.txt ./run_on_shard.sh -p os -T 0 'ls ./.hmy/blskeys/' | sort > ostn-s0-actual.txt Add them to the configuration for OSTN # Compare the differences in the files grep -vxf ../pipeline/ostn-s0-actual-sort.txt ostn-s0.txt","title":"Additional commands"},{"location":"deploy/cicd/netdeploy/troubleshooting/recovering-nodes-killed-as-spot-instances/#validation","text":"Check watchdog Check the nodes have synched beacon chain grep SYNC ../tmp_log/log-20200318.212437/*.log | grep \"isBeacon: true\"","title":"Validation"},{"location":"deploy/cicd/netdeploy/troubleshooting/recovering-nodes-killed-as-spot-instances/copying-keys-and-restarting-nodes/","text":"Copying Keys and restarting nodes OSTN Offline Nodes Recovery **** April 4th 2020 Finding the Keys Date Mar 26,2020 - 6:10 a.m. Note when recovering made the instances on demand t3 instances Copying from 3.95.248.189 ======= 0 - 54.88.123.11 -> 34.239.247.106 0 - 18.209.51.64 -> 54.236.19.179 0 - 3.89.180.137 -> 3.90.29.120 1 - 3.88.107.86 -> 54.86.57.51 1 - 54.242.8.180 -> 34.201.50.140 1 - 34.224.25.234 -> 3.80.155.110 1 - 3.91.21.142 -> 3.85.184.167 3 - 54.88.117.227-> 34.226.208.122 3 - 3.89.55.66-> 3.90.108.3 3 - 52.70.34.203 -> 34.204.13.21 From Devops Machine Finding the Keys ## Shard 0 ec2-user@ip-172-31-37-52 pipeline (master) $ cat ostn-s0-actual.txt | grep 54.88.123.11 8c95e04a4826d4d80ef16183f13aa5d14eb3c96d2755407e15c440bb4edd6e4636a82e47975385c6223ba24759561103.key, 54.88.123.11 e215ebfefc9b1746990adec617b4094f25512f5f16d3cd715d67da7cb6a7aabb7df1f8f1134b0a8d85608d5144cc188c.key, 54.88.123.11 e27e4452d716fac92c46c4e0636ab05e1389a79c17555e2ba4e896ee9696be5e213b3b1ae9e2980eafd4425af3730d8f.key, 54.88.123.11 ec2-user@ip-172-31-37-52 pipeline (master) $ cat ostn-s0-actual.txt | grep 18.209.51.64 1e2b98c8eaac6624d64eff5c54d3dba9e7ad05b272df59deafbc8d8263ccc0beb0cfd3564d47c40300411a894a090398.key, 18.209.51.64 24044191bcc50e6f43dc21d052c88885aadc0c693675d9a418d00d1afd98286658812f17b612658fc433e8eb619b5c00.key, 18.209.51.64 f9a0be6a719e2c5ba86029f912fdcfbbbcfc7ff3c400e1e6e681e7ec01da214b597a03bfd0ed0d3f351c7036282aea97.key, 18.209.51.64 ec2-user@ip-172-31-37-52 pipeline (master) $ cat ostn-s0-actual.txt | grep 3.89.180.137 20b6f747fdf027718fccb8c48fb92b499c88d1b49e9dcfebb53107c2aec6b9de2bbe1b965e22a725b137462756bf2a84.key, 3.89.180.137 2d5edcee1cd1d4d921a31443b1872b333dc2293f543dd299f9061e6d0fe0731f814ba0b1c01f1fd41067ae6c3b79ee8c.key, 3.89.180.137 8e8b42296aef2ba1aed7e6a64b8734a0bd12a55c2c32d1a893129d0b3c0d04b2c2d778d5929cd8b460bc987141080a83.key, 3.89.180.137 ## Shard 1 ec2-user@ip-172-31-37-52 pipeline (master) $ cat ostn-s1-actual.txt | grep 3.88.107.86 4cf88358365733859717ccabc63c73a6ec01a03f07fef266342bfec2f1d57c14b543b9995c3a66b8a737db3a9b60920a.key, 3.88.107.86 8f95764298fa08f6624b7acc9731899778158d6264e42341ba55ac2918ed5d05cba452ebafead2a04100e2bf24a69216.key, 3.88.107.86 fb5c286f0ad78e1c029b874d96ee251c6761facf4279e95fe566af08221a1d05e1da580b9babe4f8a2f38ff0c5543c8f.key, 3.88.107.86 ec2-user@ip-172-31-37-52 pipeline (master) $ cat ostn-s1-actual.txt | grep 54.242.8.180 6ed606f323da02b0e18d64a87a1b42641d847c15e9e11596e77d87d34f26679785fb4e76d270dc9d14bb539f02157501.key, 54.242.8.180 6f064aaaf557ef56495ee6efa175ef050144d619fec89fb06893634c02773704d673712ca15c1b54806379405f31bb18.key, 54.242.8.180 851194219e2df66dc33203dcb3344b88ab6ff248236bf67422b5c9b5478e5c2f0a424050b4c5901d6bcb72ee03219c05.key, 54.242.8.180 ec2-user@ip-172-31-37-52 pipeline (master) $ cat ostn-s1-actual.txt | grep 34.224.25.234 174c95f97ff6b98e4f840bd84d05f735cc195d5d1caffc79a1335c9deaf85bee3b01184b0f741c32f22daa004c140401.key, 34.224.25.234 3a3d6481bb95279254ad74649e65e31a18818c56da38c3623af86e5527cc7bce62f84187f10c9b6c30fd485196501518.key, 34.224.25.234 f1136f1223d144c6a5fe164899b0e917359483dd407ad490bbcc9480881e12c27071e3c1342a2d636fde0ea30117c980.key, 34.224.25.234 ec2-user@ip-172-31-37-52 pipeline (master) $ cat ostn-s1-actual.txt | grep 3.91.21.142 021926136495a0adcdda5af0602cb4b4ce6d6529cfd451b844728a0e4e424f2a78879a8b5d5e4b3e42127f95f2e2858b.key, 3.91.21.142 b08bc8548a1f59646d9b610d7cffeaa97c1d441721b2f0079cafd60a39437b2fbe2bda27b295fa03d3a2a72265e4da12.key, 3.91.21.142 e99c10f7969f3845cb467e23f0a5095d372198c834bb2efa1c0bb220d67bacc85d2637486e52f8acd5dccff36580de0f.key, 3.91.21.142 ## Shard 3 ec2-user@ip-172-31-37-52 pipeline (master) $ cat ostn-s3-actual.txt | grep 54.88.117.227 3943095fcd433157cbc609e5293462f4ecd22fbb7b9a961c4075b3fa93471b59611a1bb05c0323c46201badef5aaf20e.key, 54.88.117.227 425240abe5de3d1878bed335d91e2ffc4e41606c45fb5a6edd4ede1b3f255fc4cf23f530a7160ac027ad42fb0f200e89.key, 54.88.117.227 7edc5e823ab766382c0d517cf914f5cd5b5297697fdfdc329de8e7b1c5da0fba121eb9c51cc2089cf9494986e02f0596.key, 54.88.117.227 ec2-user@ip-172-31-37-52 pipeline (master) $ cat ostn-s3-actual.txt | grep 3.89.55.66 3166f4502e3a7b1a1ccf24a56044d2ac4f1ae42b01b807fcb7583c9d0c56b46b3516cf5d3bcacdcb063da72a24c0d392.key, 3.89.55.66 546794217d78eb628fcc90b567c4e18eb9a7b110838d640412fb2f0f52c934b90cf33f698357c27088d741401a1f6d95.key, 3.89.55.66 6aec97cccb934f6c50c60737be830c92f480f2fd1106c0f9c910dfee0cfa458dded98e6618a500bc4f9b833c1ab20e95.key, 3.89.55.66 ec2-user@ip-172-31-37-52 pipeline (master) $ cat ostn-s3-actual.txt | grep 52.70.34.203 02b7698e95e30a87dee5e579926da604de094569c88f443e9ad0aae0be380b400ce26d50b983b6ea5730277f51fb1e10.key, 52.70.34.203 15e5b5b1b455d8814d8986f9fd00bd64e897506c8e958bbbfd6f43e2302837ab625096f19f05b751fceac5caf387f483.key, 52.70.34.203 e92333fd7866a3802e902b18b72f97df92627869a8222d3dde533e07948e43ea3d9bd969ee7967b872bf6c0327e6ba80.key, 52.70.34.203 Update the machines ## Machine 34.239.247.106 ~/experiment-deploy/pipeline/node_ssh.sh 34.239.247.106 sudo yum update curl -LO https://harmony.one/hmycli && mv hmycli hmy && chmod +x hmy sudo rm -rf harmony_db* sudo rm -rf .dht* mkdir -p /home/ec2-user/.hmy/blskeys mkdir .hmy cd .hmy mkdir blskeys mkdir .hmy/blskeys cd /home/ec2-user/.hmy/blskeys ll aws s3 cp s3://harmony-secret-keys/bls-test/8c95e04a4826d4d80ef16183f13aa5d14eb3c96d2755407e15c440bb4edd6e4636a82e47975385c6223ba24759561103.key . aws s3 cp s3://harmony-secret-keys/bls-test/e215ebfefc9b1746990adec617b4094f25512f5f16d3cd715d67da7cb6a7aabb7df1f8f1134b0a8d85608d5144cc188c.key . aws s3 cp s3://harmony-secret-keys/bls-test/e27e4452d716fac92c46c4e0636ab05e1389a79c17555e2ba4e896ee9696be5e213b3b1ae9e2980eafd4425af3730d8f.key . ll # Clean up log files rm -rf exit ./restart_node.sh -t 0 -r 0 -R 0 34.239.247.106 Update the IPS and config # Create the init files cd /home/ec2-user/experiment-deploy/pipeline/logs/os/init cp init-54.91.206.0.json init-34.239.247.106.json cp init-54.91.206.0.json init-54.236.19.179.json cp init-54.91.206.0.json init-3.90.29.120.json cp init-54.91.206.0.json init-54.86.57.51.json cp init-54.91.206.0.json init-34.201.50.140.json cp init-54.91.206.0.json init-3.80.155.110.json cp init-54.91.206.0.json init-3.85.184.167.json cp init-54.91.206.0.json init-34.226.208.122.json cp init-54.91.206.0.json init-3.90.108.3.json cp init-54.91.206.0.json init-34.204.13.21.json /home/ec2-user/experiment-deploy/pipeline/ Date: Mar 25, 2020 Firefighter: JW AW ==== SHARD 2 ==== SHARD 2 34.221.66.228 -> 52.89.13.173 SHARD 1 54.69.211.255 -> 54.214.173.40 SHARD 1 35.161.237.184 -> 52.26.48.137 To get the keys # Find the key files cat ostn-s2-actual.txt | grep 34.221.66.228 cat ostn-s1-actual.txt | grep 54.69.211.255 cat ostn-s1-actual.txt | grep 35.161.237.184 ## NOW LOAD THE KEYS ON THE MACHINES THEN COME BACK # Create the init files cd ./logs/os/init/ cp init-52.90.110.183.json init-52.89.13.173.json cp init-52.90.110.183.json init-54.214.173.40.json cp init-52.90.110.183.json init-52.26.48.137.json cd /home/ec2-user/experiment-deploy/pipeline/ # Restart the nodes ./restart_node.sh -t 0 -r 0 -R 0 52.89.13.173 ./restart_node.sh -t 0 -r 0 -R 0 54.214.173.40 ./restart_node.sh -t 0 -r 0 -R 0 52.26.48.137 # Update the Shard Entries cd ./logs/os vim shard1.txt vim shard2.txt cd /home/ec2-user/experiment-deploy/pipeline/ # Update the DNS Entries vim ./logs/os/updater53.sh ./logs/os/updater53.sh # Restart watchdog scp /home/ec2-user/experiment-deploy/pipeline/logs/os/shard?.txt watchdog:/home/ec2-user/staking ssh watchdog -- sudo systemctl restart harmony-watchdogd@staking.service # Update the ostn-s?-actual.txt with the correct ips mkdir ostn-20200325 || mv ostn-s?-actual.txt ./ostn-20200325/. ll ./ostn-20200325/* ./run_on_shard.sh -p os -y -T 0 'ip=$(curl http://169.254.169.254/latest/meta-data/public-ipv4); for k in $(ls ./.hmy/blskeys/); do echo $k, $ip; done' > ostn-s0-actual.txt ./run_on_shard.sh -p os -y -T 1 'ip=$(curl http://169.254.169.254/latest/meta-data/public-ipv4); for k in $(ls ./.hmy/blskeys/); do echo $k, $ip; done' > ostn-s1-actual.txt ./run_on_shard.sh -p os -y -T 2 'ip=$(curl http://169.254.169.254/latest/meta-data/public-ipv4); for k in $(ls ./.hmy/blskeys/); do echo $k, $ip; done' > ostn-s2-actual.txt ./run_on_shard.sh -p os -y -T 3 'ip=$(curl http://169.254.169.254/latest/meta-data/public-ipv4); for k in $(ls ./.hmy/blskeys/); do echo $k, $ip; done' > ostn-s3-actual.txt sudo rm *52.202.206.131* # Log into the machine download cli ~/experiment-deploy/pipeline/node_ssh.sh 52.89.13.173 sudo yum update curl -LO https://harmony.one/hmycli && mv hmycli hmy && chmod +x hmy sudo rm -rf harmony_db* sudo rm -rf .dht* mkdir -p /home/ec2-user/.hmy/blskeys cd /home/ec2-user/.hmy/blskeys ll rm *.key aws s3 cp s3://harmony-secret-keys/bls-test/2c6281268374475e94f9e8dd8a078c21d6a3bf1be2b3e2dc4b1b497f89d881ac7cce008b18810adfa432fc4c617fd505.key . aws s3 cp s3://harmony-secret-keys/bls-test/7fe71878cee72268dfbd7685b74bca34fa70a47c85ca3730e4597468a0ad98a60b8a0b750732cfa88b91e03014c5ac11.key . aws s3 cp s3://harmony-secret-keys/bls-test/f6211dea58b0962894d9f8a01624531b7e67d2de83da3ea4e02249ad688321a6be04c10cda4dfd8c052e70fe8da9e801.key . ll # Clean up log files exit # Log into the machine download cli ~/experiment-deploy/pipeline/node_ssh.sh 54.214.173.40 sudo yum update curl -LO https://harmony.one/hmycli && mv hmycli hmy && chmod +x hmy sudo rm -rf harmony_db* sudo rm -rf .dht* mkdir -p /home/ec2-user/.hmy/blskeys cd /home/ec2-user/.hmy/blskeys ll rm *.key aws s3 cp s3://harmony-secret-keys/bls-test/174c95f97ff6b98e4f840bd84d05f735cc195d5d1caffc79a1335c9deaf85bee3b01184b0f741c32f22daa004c140401.key . aws s3 cp s3://harmony-secret-keys/bls-test/3a3d6481bb95279254ad74649e65e31a18818c56da38c3623af86e5527cc7bce62f84187f10c9b6c30fd485196501518.key . aws s3 cp s3://harmony-secret-keys/bls-test/f1136f1223d144c6a5fe164899b0e917359483dd407ad490bbcc9480881e12c27071e3c1342a2d636fde0ea30117c980.key . ll exit # Log into the machine download cli ~/experiment-deploy/pipeline/node_ssh.sh 52.26.48.137 sudo yum update curl -LO https://harmony.one/hmycli && mv hmycli hmy && chmod +x hmy sudo rm -rf harmony_db* sudo rm -rf .dht* mkdir -p /home/ec2-user/.hmy/blskeys cd /home/ec2-user/.hmy/blskeys ll rm *.key aws s3 cp s3://harmony-secret-keys/bls-test/81ce2082507783d0882a0e816a7063a2c5ae2aaf186dfa157038262b911d55c2916bb113d7bcaf59426059ac9fc8cb91.key . aws s3 cp s3://harmony-secret-keys/bls-test/bc55cd376184cb98e32b80aedcb1fe913fc96de7b881ef75f7119b23674291a1bd50f8c3a4d4739c9a3d1d55e6386b18.key . aws s3 cp s3://harmony-secret-keys/bls-test/ccf1141f8e55cba6c42ab2d14cbb87a277ff9be29c9ba5604a9e3e2fec92fd74db0d5e9dd62da1d75df86cc0350fdb10.key . ll exit ./restart_node.sh -t 0 -r 0 -R 0 52.89.13.173 ./restart_node.sh -t 0 -r 0 -R 0 54.214.173.40 ./restart_node.sh -t 0 -r 0 -R 0 52.26.48.137 Firefighter: JW, DM, AW Date: Mar 24, 2020 # Create the new init files ec2-user@ip-172-31-37-52 init (master) $ cp init-52.90.110.183.json init-35.167.201.23.json ec2-user@ip-172-31-37-52 init (master) $ cp init-52.90.110.183.json init-54.203.77.136.json ec2-user@ip-172-31-37-52 init (master) $ cp init-52.90.110.183.json init-54.214.100.72.json ec2-user@ip-172-31-37-52 init (master) $ cp init-52.90.110.183.json init-34.221.66.228.json ec2-user@ip-172-31-37-52 init (master) $ cp init-52.90.110.183.json init-52.25.255.161.json ec2-user@ip-172-31-37-52 init (master) $ cp init-52.90.110.183.json init-34.221.142.39.json ec2-user@ip-172-31-37-52 init (master) $ cp init-52.90.110.183.json init-34.214.124.156.json ec2-user@ip-172-31-37-52 init (master) $ cp init-52.90.110.183.json init-34.221.208.236.json ec2-user@ip-172-31-37-52 init (master) $ pwd /home/ec2-user/experiment-deploy/pipeline/logs/os/init # Update the shard*.txt /home/ec2-user/experiment-deploy/pipeline/logs/os **** ================== SHARD 0 ==================== Old - 35.171.157.97 and 3.84.194.194 New - 35.167.201.23 and 5 4.203.77.136 Andy did these 35.171.157.97 \u2192 35.167.201.23 3.84.194.194 \u2192 54.203.77.136 35.167.201.23 aws s3 cp s3://harmony-secret-keys/bls-test/99d0835797ca0683fb7b1d14a882879652ddcdcfe0d52385ffddf8012ee804d92e5c05a56c9d7fc663678e36a158a28c.key . aws s3 cp s3://harmony-secret-keys/bls-test/0a21f76b002c3d2ebdf9e9a761c8a26774f306d2e0eed329cd9c814efe0cda9cbd10d9b5cf04f30bbf0030d359c5a705.key . aws s3 cp s3://harmony-secret-keys/bls-test/b814e7bccaa54c71a5f3b4caa5df62851fd6f2dd793cc35777fde7f1a152b51b9031b8598ae5a0f17f852d0e53fce985.key . -- 54.203.77.136 aws s3 cp s3://harmony-secret-keys/bls-test/ba27796a04c1e4d2cb2d946ac520c2b41589517cb9ae22e64718086c1b13bec1c3d1d78c274d4ffafd78e1b66705e496.key . aws s3 cp s3://harmony-secret-keys/bls-test/42c100b423e14387862fa419d81b430c9c6068d665e8a21737e293f49e41739795567176ab18070066a216eadb808808.key . aws s3 cp s3://harmony-secret-keys/bls-test/f6dcead63386972fb00c26c7aefda614b8c58bc33c05d488df9bfef361c1dcced0088b245acb411b52a36ed287051215.key . **** ================== SHARD 1 ==================== https://us-west-2.console.aws.amazon.com/ec2/v2/home?region=us-west-2#Instances:search=i-009a1476eaaaa2582;sort=instanceId [1:15 PM ] https://us-west-2.console.aws.amazon.com/ec2/v2/home?region=us-west-2#Instances:search=i-0191f1f5a4b365b4b;sort=instanceId [1:15 PM ] https://us-west-2.console.aws.amazon.com/ec2/v2/home?region=us-west-2#Instances:search=i-01aff220768dae9d2;sort=instanceId [1:15 PM ] https://us-west-2.console.aws.amazon.com/ec2/v2/home?region=us-west-2#Instances:search=i-0dc7a0a124265df37;sort=instanceId [1:15 PM] https://us-west-2.console.aws.amazon.com/ec2/v2/home?region=us-west-2#Instances:search=i-05746d955b1df2f9d;sort=instanceId exec ssh -i ~/.ssh/keys/oregon-key-benchmark.pem ec2-user@devop.hmny.io # New Node export WHOAMI=OS; export HMY_PROFILE=os; profile_print # Create the new init files cd /home/ec2-user/experiment-deploy/pipeline/logs/os/init cp init-52.90.110.183.json init-35.162.31.74.json cp init-52.90.110.183.json init-54.69.211.255.json cp init-52.90.110.183.json init-35.161.237.184.json cp init-52.90.110.183.json init-34.219.241.32.json cp init-52.90.110.183.json init-34.220.149.222.json # Modify Shard1.txt to replace the old ip's with new cd /home/ec2-user/experiment-deploy/pipeline/logs/os vim shard1.txt cat shart1.txt 107.23.13.24 \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 54.197.198.245 \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 18.212.197.32 \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 3.84.250.64 \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 3.95.138.72 \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 34.220.149.222 \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 54.145.138.160 \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 3.82.147.230 \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 35.162.31.74 \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 3.86.221.120 \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 35.161.237.184 \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 54.161.192.112 \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 3.82.196.136 \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 3.84.119.75 \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 3.87.40.196 \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 52.202.206.131 \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 34.219.241.32 \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 34.204.69.56 \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 54.69.211.255 \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 54.175.96.222 \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 3.89.75.86 # Log into the machine download cli ~/experiment-deploy/pipeline/node_ssh.sh 35.162.31.74 curl -LO https://harmony.one/hmycli && mv hmycli hmy && chmod +x hmy mkdir -p /home/ec2-user/.hmy/blskeys cd /home/ec2-user/.hmy/blskeys ll rm *.key aws s3 cp s3://harmony-secret-keys/bls-test/021926136495a0adcdda5af0602cb4b4ce6d6529cfd451b844728a0e4e424f2a78879a8b5d5e4b3e42127f95f2e2858b.key . aws s3 cp s3://harmony-secret-keys/bls-test/e99c10f7969f3845cb467e23f0a5095d372198c834bb2efa1c0bb220d67bacc85d2637486e52f8acd5dccff36580de0f.key . aws s3 cp s3://harmony-secret-keys/bls-test/b08bc8548a1f59646d9b610d7cffeaa97c1d441721b2f0079cafd60a39437b2fbe2bda27b295fa03d3a2a72265e4da12.key . exit # Log into the machine download cli ~/experiment-deploy/pipeline/node_ssh.sh 54.69.211.255 curl -LO https://harmony.one/hmycli && mv hmycli hmy && chmod +x hmy mkdir -p /home/ec2-user/.hmy/blskeys cd /home/ec2-user/.hmy/blskeys ll rm *.key aws s3 cp s3://harmony-secret-keys/bls-test/3a3d6481bb95279254ad74649e65e31a18818c56da38c3623af86e5527cc7bce62f84187f10c9b6c30fd485196501518.key . aws s3 cp s3://harmony-secret-keys/bls-test/174c95f97ff6b98e4f840bd84d05f735cc195d5d1caffc79a1335c9deaf85bee3b01184b0f741c32f22daa004c140401.key . aws s3 cp s3://harmony-secret-keys/bls-test/f1136f1223d144c6a5fe164899b0e917359483dd407ad490bbcc9480881e12c27071e3c1342a2d636fde0ea30117c980.key . exit # Log into the machine download cli ~/experiment-deploy/pipeline/node_ssh.sh 35.161.237.184 curl -LO https://harmony.one/hmycli && mv hmycli hmy && chmod +x hmy mkdir -p /home/ec2-user/.hmy/blskeys cd /home/ec2-user/.hmy/blskeys ll rm *.key aws s3 cp s3://harmony-secret-keys/bls-test/81ce2082507783d0882a0e816a7063a2c5ae2aaf186dfa157038262b911d55c2916bb113d7bcaf59426059ac9fc8cb91.key . aws s3 cp s3://harmony-secret-keys/bls-test/bc55cd376184cb98e32b80aedcb1fe913fc96de7b881ef75f7119b23674291a1bd50f8c3a4d4739c9a3d1d55e6386b18.key . aws s3 cp s3://harmony-secret-keys/bls-test/ccf1141f8e55cba6c42ab2d14cbb87a277ff9be29c9ba5604a9e3e2fec92fd74db0d5e9dd62da1d75df86cc0350fdb10.key . exit # Log into the machine download cli ~/experiment-deploy/pipeline/node_ssh.sh 34.219.241.32 curl -LO https://harmony.one/hmycli && mv hmycli hmy && chmod +x hmy mkdir -p /home/ec2-user/.hmy/blskeys cd /home/ec2-user/.hmy/blskeys ll rm *.key aws s3 cp s3://harmony-secret-keys/bls-test/38de540c3df944e2982dda39f9a8d4ed69d0a23852580f7d818654d6ef9b0e1defdcfca3b33d36dcf04789659cc2878a.key . aws s3 cp s3://harmony-secret-keys/bls-test/a08abc8479ea3a37b3b2039691a4ee66ec6c8e5fa9bc130f2fff0000f0e747b7e47679d9b3a5be11ccb4132f701c158d.key . aws s3 cp s3://harmony-secret-keys/bls-test/744336d151fa5ad71eb2c25c01e20c5069f4daf6c69b4e4be5297fb6427f23826b21502490acf155a0d0985d25f2f006.key . exit # Log into the machine download cli ~/experiment-deploy/pipeline/node_ssh.sh 34.220.149.222 curl -LO https://harmony.one/hmycli && mv hmycli hmy && chmod +x hmy mkdir -p /home/ec2-user/.hmy/blskeys cd /home/ec2-user/.hmy/blskeys ll rm *.key aws s3 cp s3://harmony-secret-keys/bls-test/640bcc532b507981a832d3dce3d2f86d66b314a9d6cf4e6644629ce83786c6deaf9ec52ed15f9e08df695d6417a0ad8a.key . aws s3 cp s3://harmony-secret-keys/bls-test/e4f6913240790b74c26a8ddf571942ee55ae0a5ac99958d96253fd7a334afee39226434b0c960e77df48b860afb5850f.key . aws s3 cp s3://harmony-secret-keys/bls-test/3e5d1203314089e1952a2b4709b96db2084a57a7d08c24e936e459a2e49c182027f5dc7c2da8517eed4b7b2d95f82611.key . exit # Restart the whole shard cd ~/experiment-deploy/pipeline ./run_on_shard.sh -p os -T 1 \"sudo rm -r .dht*\" cat logs/os/shard1.txt | xargs -i{} -P50 bash -c './restart_node.sh -y -d logs/os -p os -t 0 -r 0 -R 0 {}' # Restart individual nodes cd ~/experiment-deploy/pipeline ./restart_node.sh -t 0 -r 0 -R 0 35.162.31.74 ================== SHARD 2 ==================== Old - 18.234.207.0 and 3.84.10.119 New - 54.214.100.72 and 34.221.66.228 **** ================== SHARD 3 ==================== Old - 52.87.240.253 and 18.205.149.223 and and 3.80.188.34 and 52.207.222.5 New - 52.25.255.161 and 34.221.142.39 and 34.214.124.156 and 34.221.208.236 # Log into the machine download cli ~/experiment-deploy/pipeline/node_ssh.sh 52.25.255.161 sudo yum update curl -LO https://harmony.one/hmycli && mv hmycli hmy && chmod +x hmy sudo rm -rf harmony_db* sudo rm -rf .dht* mkdir -p /home/ec2-user/.hmy/blskeys cd /home/ec2-user/.hmy/blskeys ll rm *.key aws s3 cp s3://harmony-secret-keys/bls-test/88b4da322731de51da65e6d2faba85782fa517002f6177c19932c10767cc6cef922ee17f7e46ff00424b8ffe4afeb291.key . aws s3 cp s3://harmony-secret-keys/bls-test/3074c2c46a0396d6720b4612a0641e29b13263eb4237ddfaa2317db99b8c0fd7e37a6b035c996265e82dd5c8286eb708.key . aws s3 cp s3://harmony-secret-keys/bls-test/8f4113299afb54e9301c0b10216a19555ddca1cb723b84102af59fcbe97e3efc746383e6edb0c68414cd9265e781e48d.key . exit # Log into the machine download cli ~/experiment-deploy/pipeline/node_ssh.sh 34.221.142.39 sudo yum update curl -LO https://harmony.one/hmycli && mv hmycli hmy && chmod +x hmy sudo rm -rf harmony_db* sudo rm -rf .dht* mkdir -p /home/ec2-user/.hmy/blskeys cd /home/ec2-user/.hmy/blskeys ll rm *.key aws s3 cp s3://harmony-secret-keys/bls-test/ab7df3e38a8423c31f8dd40d2952667bff711c9d00f717e528ffc661d1d26c3b431f403eb1c360a767fc8ad7fe2b3991.key . aws s3 cp s3://harmony-secret-keys/bls-test/eb84135858022bc149ebd50d7726640a63a32e8e866876ede8f9b7ef173dfd9d6d67615e2583b991652be28b56b40904.key . aws s3 cp s3://harmony-secret-keys/bls-test/7b864402962aeec98f6e48554492b9cb843e9c021fc6d5a7785b77f02ddf97434af174ef741e704682454d223d9d540f.key . ll exit # Log into the machine download cli ~/experiment-deploy/pipeline/node_ssh.sh 34.214.124.156 sudo yum update curl -LO https://harmony.one/hmycli && mv hmycli hmy && chmod +x hmy sudo rm -rf harmony_db* sudo rm -rf .dht* mkdir -p /home/ec2-user/.hmy/blskeys cd /home/ec2-user/.hmy/blskeys ll rm *.key aws s3 cp s3://harmony-secret-keys/bls-test/5f7a2faeaa55f46a2b07164bc33a2d2569e05316b8c5f8d4757545342aeae8cde5cf30970aad748aa424871940b5818c.key . aws s3 cp s3://harmony-secret-keys/bls-test/8797872afec84adf180f58425ce897ac3830cc102c872a304689a4fdcfb1bec157f1a9e9e3fb46afdbffd766cd53ca81.key . aws s3 cp s3://harmony-secret-keys/bls-test/80792a400e45ebdb18ff22d32a8de95b4766e40b8047d8d9836ecfdb075e5548e159e6bae372cdd6454b52409d4f5019.key . ll exit # Log into the machine download cli ~/experiment-deploy/pipeline/node_ssh.sh 34.221.208.236 sudo yum update curl -LO https://harmony.one/hmycli && mv hmycli hmy && chmod +x hmy sudo rm -rf harmony_db* sudo rm -rf .dht* mkdir -p /home/ec2-user/.hmy/blskeys cd /home/ec2-user/.hmy/blskeys ll rm *.key aws s3 cp s3://harmony-secret-keys/bls-test/e2b812729d73a3e4538ec19cc2a8ba694660dc6eca53531026b6e6a3d119de7de43ed994771457211f581600c7488c05.key . aws s3 cp s3://harmony-secret-keys/bls-test/0c9d3e30ce69ed358016e54c47d0643c2e417441c15612158ef52a06d609784b030b31d352252520a14058abdc514196.key . aws s3 cp s3://harmony-secret-keys/bls-test/54beb67b89b78dac97d6951919d8af883ef70750681d3912563ee5ce3dae9e1a11612200496c920f1deeff3d5eb3d60c.key . ll exit ./restart_node.sh -t 0 -r 0 -R 0 52.25.255.161 ./restart_node.sh -t 0 -r 0 -R 0 34.221.142.39 ./restart_node.sh -t 0 -r 0 -R 0 34.221.208.236 ./restart_node.sh -t 0 -r 0 -R 0 34.214.124.156 =========END of Mar 24 ========================================================== Firefighter: JW, DM, AW Date: Mar 23, 2020 Automation Ticket: https://github.com/harmony-one/harmony-ops/issues/497 ================== SHARD 0 ==================== 35.175.137.77(offine) -> 18.207.222.72(new) mkdir -p /home/ec2-user/.hmy/blskeys sudo mkdir -p ../tmp_log/log-20200318.212437 curl -LO https://harmony.one/hmycli && mv hmycli hmy && chmod +x hmy aws s3 cp s3://harmony-secret-keys/bls-test/d69c70aa8e43853487760533ad1cbeb9f8e91d409ede23f5db9e0038528bd9914ecd8710afe187bb303cc345a52f0b93.key . aws s3 cp s3://harmony-secret-keys/bls-test/d2756594a894175bcffa03ce8a945e8c73f8149e3a4acf0695a206b70a9a4c5782a16199f590ee1cdafb50a45488e518.key . aws s3 cp s3://harmony-secret-keys/bls-test/f4354e218f74d3d629586cb361d28025b4d8d2387eb173c49c86912f7f8e20f13c214f3351466a6140a4ee0071efdb8a.key . # then manually create an init file for the new node # check the latest header if needed ./hmy blockchain latest-header **3.85.98.85 \\(offine\\) - 18.205.115.81 \\(new\\)** > mkdir -p /home/ec2-user/.hmy/blskeys; sudo mkdir -p ../tmp_log/log-20200318.212437; curl -LO https://harmony.one/hmycli && mv hmycli hmy && chmod +x hmy aws s3 cp s3://harmony-secret-keys/bls-test/03406acec541e0e0d7cbcb7c0502b4901d09b4f563fe0db4cf3e3d18038373f71eb3f720d9d9c66244364bfd7ef09217.key . aws s3 cp s3://harmony-secret-keys/bls-test/069e433b4112cda534bf4171d33c13a832dbcbf8222afacb701b2e00bd2303ff107d2bc75ba02185e48958aeba7a7697.key . aws s3 cp s3://harmony-secret-keys/bls-test/e53407496e6c807be3e583c45b49b5a00c8c0550ced7fdadab9139109002625107035a5885f9d097a68791db48ecc803.key . **================== SHARD 1 ====================** 1. **3.87.15.177 \\(offine\\) - 54.161.192.112 \\(new\\)** > aws s3 cp s3://harmony-secret-keys/bls-test/90404f04db155afc0444210b83a1f6acb29e0c479a31222afe7827b643067754817af06fbda99600d5afcc0dfd510c89.key . aws s3 cp s3://harmony-secret-keys/bls-test/ba17088f82e461ace61eec13b48463b8bebef8046a2362fd9c0e302a0331228233c7ad6811d151f63e01db36c1093a83.key . aws s3 cp s3://harmony-secret-keys/bls-test/a7a3fef9449204c26de34129d30793c5adcc9ddb5aa1e02bad8bbe5662db336ab5538ee3e1156785486c4a75ca68b211.key . cp logs/os/init/init-3.87.15.177.json logs/os/init/init-54.161.192.112.json ./restart_node.sh -t 0 -r 0 -R 0 54.161.192.112 **54.85.84.1 \\(offine\\) - 54.175.96.222 \\(new\\)** > aws s3 cp s3://harmony-secret-keys/bls-test/867ae6f88a5edecd6d89df05d94e08785971b4611ccda62944a7773f5cdcd6f2d86af8364fc7670d38a18109b2416413.key . aws s3 cp s3://harmony-secret-keys/bls-test/3664120aa99f98a215819b4a4adffc59450f5ad73da7a7594dd9cc2633fad63ad9692b580326575a99250700a77d7717.key . aws s3 cp s3://harmony-secret-keys/bls-test/5eb082f818ea3c5a3b49079d8d86d8d43cec0863e4226d1c7facdf9537e17c5ebdcb53450cafd47d6c4ed0c51b7c2214.key . **================== SHARD 2 ====================** 1. **54.90.89.65 \\(offine\\) - 54.234.133.75 \\(new\\)** > mkdir -p /home/ec2-user/.hmy/blskeys; sudo mkdir -p ../tmp_log/log-20200318.212437; curl -LO https://harmony.one/hmycli && mv hmycli hmy && chmod +x hmy aws s3 cp s3://harmony-secret-keys/bls-test/1bf1ca37df49190578391d3c34cdb62cc9b2c88ebf5bbbe72a41db8da5236576fdb4513973045f23633a6ddd5a52488a.key . aws s3 cp s3://harmony-secret-keys/bls-test/9fd7463748f72c1a219ccd8e0e3388e7c5f8c426260d78baabd8c5ca172950661410d7a84ed25669edf9419ffa657618.key . aws s3 cp s3://harmony-secret-keys/bls-test/8e85ca728c071af97586b178d906dd27a652b426b8bd2c5e15149700741ee605310a3981232c9f6aca1a37274539948e.key . **18.234.240.64 \\(offine\\) - 54.167.129.45 \\(new\\)** | **aws s3 cp s3://harmony-secret-keys/bls-test/351f04e4329c8e3a49ea956b8d85307a8eaf56849f20c0006e7b59346922c3e038a1fee4bd7cbf1b34551a0270b40710.key . aws s3 cp s3://harmony-secret-keys/bls-test/7c880b17c5cec63bebc634ad4530ea32e4632b7b73085f5d9948c333ae3963cf4e448d29b194a2e304b68736c2b3a903.key . aws s3 cp s3://harmony-secret-keys/bls-test/a77967462bea74b9eb96608ee0e4e4ba444da7a3708da2f8f60f8ff53878adcb0cf25a38d8caddeb3be3b4a35e35fe0d.key .** | | :--- | 1. **184.72.206.164 \\(offine\\) - 3.95.137.99 \\(new\\)** | **aws s3 cp s3://harmony-secret-keys/bls-test/a4a75bfc607dd1bee6d60454309bb5fb4c9a48805bc514f29e56c5766e391545bc8d750011c6d1f4b12218adc7c15e95.key . aws s3 cp s3://harmony-secret-keys/bls-test/929d436cccbb46229f3405e57ebd44cb9b2987e1d8cfe48455738a9f2f8f77438771f53478a71dc247a857686c28b60a.key . aws s3 cp s3://harmony-secret-keys/bls-test/4af2bd9f1e91b9c7db1f6d239a0c76006e8d8d1219468a49d4c06893f15cc6844d5826083bb0f06d4f9af80e38e0b002.key .** | | :--- | 1. **3.95.225.36 \\(offine\\) - 35.173.221.246 \\(new\\)** | **aws s3 cp s3://harmony-secret-keys/bls-test/2d24f086b9cf9a7f3e934a9bf4bd9355a0aaf3b21c03d74725fe8253d01888bfa839eaafe5a99a41678d1d4750f2eb92.key . aws s3 cp s3://harmony-secret-keys/bls-test/50c3565ad3275e660a97ef29dae9d335f77871cfd5c09ee5c5f61306781c0478988ed1ca45e5c151a0fa5d483346de92.key . aws s3 cp s3://harmony-secret-keys/bls-test/49f9c2b3d90aa7dd1ead32ce40cf90864cc6420f5f11b136f35d58753838756f991561fc1350b5b7facdcc4c1d88ba88.key .** | | :--- | 1. **52.87.193.132 \\(offine\\) - 52.87.160.66 \\(new\\)** | **aws s3 cp s3://harmony-secret-keys/bls-test/6d8faf3a0ff828bfc59702755c8e84d1e4dbd434d798c56bfa4772aa22254ae4643d6b4a9d385941780b848e1aed6007.key . aws s3 cp s3://harmony-secret-keys/bls-test/60aae7000932b498084255484f94c394159650817095a2ca097f2031d63b04decfa24d659655241792276f14f64fa294.key . aws s3 cp s3://harmony-secret-keys/bls-test/6963a4a6283d8f7150aef2b2ca05cd15bf43c77a9e42dd544caf869ece8292510ca2e255d675407e14429bfb00335a92.key .** | | :--- | **================== SHARD 3 ====================** 1. **52.23.233.194 \\(offine\\) - 54.144.185.102 \\(new\\)** >>>>> mkdir -p /home/ec2-user/.hmy/blskeys; sudo mkdir -p ../tmp_log/log-20200318.212437; curl -LO https://harmony.one/hmycli && mv hmycli hmy && chmod +x hmy aws s3 cp s3://harmony-secret-keys/bls-test/8f657775630e2f58fe7fc679fd5827705eb19ad1ea47c78d3d5ac544ddc8d2fa0aa542bafd350d4eb7e9c822a89e3006.key . aws s3 cp s3://harmony-secret-keys/bls-test/fcacc28fdc2bacd2ea3f6b3bda853553522ed5cf1a335f67930ea7c7d981ec3f33ce00d1b4b30438287a77ec043b478f.key . aws s3 cp s3://harmony-secret-keys/bls-test/acb484265281f4f956f4b73221d1fb3df8f78adecfd59e693f961d0de46b1790c4d2d12856c35bdc733ebdf0da134d85.key .","title":"Copying Keys and restarting nodes"},{"location":"deploy/cicd/netdeploy/troubleshooting/recovering-nodes-killed-as-spot-instances/copying-keys-and-restarting-nodes/#copying-keys-and-restarting-nodes","text":"OSTN Offline Nodes Recovery **** April 4th 2020 Finding the Keys Date Mar 26,2020 - 6:10 a.m. Note when recovering made the instances on demand t3 instances Copying from 3.95.248.189 ======= 0 - 54.88.123.11 -> 34.239.247.106 0 - 18.209.51.64 -> 54.236.19.179 0 - 3.89.180.137 -> 3.90.29.120 1 - 3.88.107.86 -> 54.86.57.51 1 - 54.242.8.180 -> 34.201.50.140 1 - 34.224.25.234 -> 3.80.155.110 1 - 3.91.21.142 -> 3.85.184.167 3 - 54.88.117.227-> 34.226.208.122 3 - 3.89.55.66-> 3.90.108.3 3 - 52.70.34.203 -> 34.204.13.21","title":"Copying Keys and restarting nodes"},{"location":"deploy/cicd/netdeploy/troubleshooting/recovering-nodes-killed-as-spot-instances/copying-keys-and-restarting-nodes/#from-devops-machine","text":"Finding the Keys ## Shard 0 ec2-user@ip-172-31-37-52 pipeline (master) $ cat ostn-s0-actual.txt | grep 54.88.123.11 8c95e04a4826d4d80ef16183f13aa5d14eb3c96d2755407e15c440bb4edd6e4636a82e47975385c6223ba24759561103.key, 54.88.123.11 e215ebfefc9b1746990adec617b4094f25512f5f16d3cd715d67da7cb6a7aabb7df1f8f1134b0a8d85608d5144cc188c.key, 54.88.123.11 e27e4452d716fac92c46c4e0636ab05e1389a79c17555e2ba4e896ee9696be5e213b3b1ae9e2980eafd4425af3730d8f.key, 54.88.123.11 ec2-user@ip-172-31-37-52 pipeline (master) $ cat ostn-s0-actual.txt | grep 18.209.51.64 1e2b98c8eaac6624d64eff5c54d3dba9e7ad05b272df59deafbc8d8263ccc0beb0cfd3564d47c40300411a894a090398.key, 18.209.51.64 24044191bcc50e6f43dc21d052c88885aadc0c693675d9a418d00d1afd98286658812f17b612658fc433e8eb619b5c00.key, 18.209.51.64 f9a0be6a719e2c5ba86029f912fdcfbbbcfc7ff3c400e1e6e681e7ec01da214b597a03bfd0ed0d3f351c7036282aea97.key, 18.209.51.64 ec2-user@ip-172-31-37-52 pipeline (master) $ cat ostn-s0-actual.txt | grep 3.89.180.137 20b6f747fdf027718fccb8c48fb92b499c88d1b49e9dcfebb53107c2aec6b9de2bbe1b965e22a725b137462756bf2a84.key, 3.89.180.137 2d5edcee1cd1d4d921a31443b1872b333dc2293f543dd299f9061e6d0fe0731f814ba0b1c01f1fd41067ae6c3b79ee8c.key, 3.89.180.137 8e8b42296aef2ba1aed7e6a64b8734a0bd12a55c2c32d1a893129d0b3c0d04b2c2d778d5929cd8b460bc987141080a83.key, 3.89.180.137 ## Shard 1 ec2-user@ip-172-31-37-52 pipeline (master) $ cat ostn-s1-actual.txt | grep 3.88.107.86 4cf88358365733859717ccabc63c73a6ec01a03f07fef266342bfec2f1d57c14b543b9995c3a66b8a737db3a9b60920a.key, 3.88.107.86 8f95764298fa08f6624b7acc9731899778158d6264e42341ba55ac2918ed5d05cba452ebafead2a04100e2bf24a69216.key, 3.88.107.86 fb5c286f0ad78e1c029b874d96ee251c6761facf4279e95fe566af08221a1d05e1da580b9babe4f8a2f38ff0c5543c8f.key, 3.88.107.86 ec2-user@ip-172-31-37-52 pipeline (master) $ cat ostn-s1-actual.txt | grep 54.242.8.180 6ed606f323da02b0e18d64a87a1b42641d847c15e9e11596e77d87d34f26679785fb4e76d270dc9d14bb539f02157501.key, 54.242.8.180 6f064aaaf557ef56495ee6efa175ef050144d619fec89fb06893634c02773704d673712ca15c1b54806379405f31bb18.key, 54.242.8.180 851194219e2df66dc33203dcb3344b88ab6ff248236bf67422b5c9b5478e5c2f0a424050b4c5901d6bcb72ee03219c05.key, 54.242.8.180 ec2-user@ip-172-31-37-52 pipeline (master) $ cat ostn-s1-actual.txt | grep 34.224.25.234 174c95f97ff6b98e4f840bd84d05f735cc195d5d1caffc79a1335c9deaf85bee3b01184b0f741c32f22daa004c140401.key, 34.224.25.234 3a3d6481bb95279254ad74649e65e31a18818c56da38c3623af86e5527cc7bce62f84187f10c9b6c30fd485196501518.key, 34.224.25.234 f1136f1223d144c6a5fe164899b0e917359483dd407ad490bbcc9480881e12c27071e3c1342a2d636fde0ea30117c980.key, 34.224.25.234 ec2-user@ip-172-31-37-52 pipeline (master) $ cat ostn-s1-actual.txt | grep 3.91.21.142 021926136495a0adcdda5af0602cb4b4ce6d6529cfd451b844728a0e4e424f2a78879a8b5d5e4b3e42127f95f2e2858b.key, 3.91.21.142 b08bc8548a1f59646d9b610d7cffeaa97c1d441721b2f0079cafd60a39437b2fbe2bda27b295fa03d3a2a72265e4da12.key, 3.91.21.142 e99c10f7969f3845cb467e23f0a5095d372198c834bb2efa1c0bb220d67bacc85d2637486e52f8acd5dccff36580de0f.key, 3.91.21.142 ## Shard 3 ec2-user@ip-172-31-37-52 pipeline (master) $ cat ostn-s3-actual.txt | grep 54.88.117.227 3943095fcd433157cbc609e5293462f4ecd22fbb7b9a961c4075b3fa93471b59611a1bb05c0323c46201badef5aaf20e.key, 54.88.117.227 425240abe5de3d1878bed335d91e2ffc4e41606c45fb5a6edd4ede1b3f255fc4cf23f530a7160ac027ad42fb0f200e89.key, 54.88.117.227 7edc5e823ab766382c0d517cf914f5cd5b5297697fdfdc329de8e7b1c5da0fba121eb9c51cc2089cf9494986e02f0596.key, 54.88.117.227 ec2-user@ip-172-31-37-52 pipeline (master) $ cat ostn-s3-actual.txt | grep 3.89.55.66 3166f4502e3a7b1a1ccf24a56044d2ac4f1ae42b01b807fcb7583c9d0c56b46b3516cf5d3bcacdcb063da72a24c0d392.key, 3.89.55.66 546794217d78eb628fcc90b567c4e18eb9a7b110838d640412fb2f0f52c934b90cf33f698357c27088d741401a1f6d95.key, 3.89.55.66 6aec97cccb934f6c50c60737be830c92f480f2fd1106c0f9c910dfee0cfa458dded98e6618a500bc4f9b833c1ab20e95.key, 3.89.55.66 ec2-user@ip-172-31-37-52 pipeline (master) $ cat ostn-s3-actual.txt | grep 52.70.34.203 02b7698e95e30a87dee5e579926da604de094569c88f443e9ad0aae0be380b400ce26d50b983b6ea5730277f51fb1e10.key, 52.70.34.203 15e5b5b1b455d8814d8986f9fd00bd64e897506c8e958bbbfd6f43e2302837ab625096f19f05b751fceac5caf387f483.key, 52.70.34.203 e92333fd7866a3802e902b18b72f97df92627869a8222d3dde533e07948e43ea3d9bd969ee7967b872bf6c0327e6ba80.key, 52.70.34.203","title":"From Devops Machine"},{"location":"deploy/cicd/netdeploy/troubleshooting/recovering-nodes-killed-as-spot-instances/copying-keys-and-restarting-nodes/#update-the-machines","text":"## Machine 34.239.247.106 ~/experiment-deploy/pipeline/node_ssh.sh 34.239.247.106 sudo yum update curl -LO https://harmony.one/hmycli && mv hmycli hmy && chmod +x hmy sudo rm -rf harmony_db* sudo rm -rf .dht* mkdir -p /home/ec2-user/.hmy/blskeys mkdir .hmy cd .hmy mkdir blskeys mkdir .hmy/blskeys cd /home/ec2-user/.hmy/blskeys ll aws s3 cp s3://harmony-secret-keys/bls-test/8c95e04a4826d4d80ef16183f13aa5d14eb3c96d2755407e15c440bb4edd6e4636a82e47975385c6223ba24759561103.key . aws s3 cp s3://harmony-secret-keys/bls-test/e215ebfefc9b1746990adec617b4094f25512f5f16d3cd715d67da7cb6a7aabb7df1f8f1134b0a8d85608d5144cc188c.key . aws s3 cp s3://harmony-secret-keys/bls-test/e27e4452d716fac92c46c4e0636ab05e1389a79c17555e2ba4e896ee9696be5e213b3b1ae9e2980eafd4425af3730d8f.key . ll # Clean up log files rm -rf exit ./restart_node.sh -t 0 -r 0 -R 0 34.239.247.106","title":"Update the machines"},{"location":"deploy/cicd/netdeploy/troubleshooting/recovering-nodes-killed-as-spot-instances/copying-keys-and-restarting-nodes/#update-the-ips-and-config","text":"# Create the init files cd /home/ec2-user/experiment-deploy/pipeline/logs/os/init cp init-54.91.206.0.json init-34.239.247.106.json cp init-54.91.206.0.json init-54.236.19.179.json cp init-54.91.206.0.json init-3.90.29.120.json cp init-54.91.206.0.json init-54.86.57.51.json cp init-54.91.206.0.json init-34.201.50.140.json cp init-54.91.206.0.json init-3.80.155.110.json cp init-54.91.206.0.json init-3.85.184.167.json cp init-54.91.206.0.json init-34.226.208.122.json cp init-54.91.206.0.json init-3.90.108.3.json cp init-54.91.206.0.json init-34.204.13.21.json /home/ec2-user/experiment-deploy/pipeline/ Date: Mar 25, 2020 Firefighter: JW AW ==== SHARD 2 ==== SHARD 2 34.221.66.228 -> 52.89.13.173 SHARD 1 54.69.211.255 -> 54.214.173.40 SHARD 1 35.161.237.184 -> 52.26.48.137 To get the keys # Find the key files cat ostn-s2-actual.txt | grep 34.221.66.228 cat ostn-s1-actual.txt | grep 54.69.211.255 cat ostn-s1-actual.txt | grep 35.161.237.184 ## NOW LOAD THE KEYS ON THE MACHINES THEN COME BACK # Create the init files cd ./logs/os/init/ cp init-52.90.110.183.json init-52.89.13.173.json cp init-52.90.110.183.json init-54.214.173.40.json cp init-52.90.110.183.json init-52.26.48.137.json cd /home/ec2-user/experiment-deploy/pipeline/ # Restart the nodes ./restart_node.sh -t 0 -r 0 -R 0 52.89.13.173 ./restart_node.sh -t 0 -r 0 -R 0 54.214.173.40 ./restart_node.sh -t 0 -r 0 -R 0 52.26.48.137 # Update the Shard Entries cd ./logs/os vim shard1.txt vim shard2.txt cd /home/ec2-user/experiment-deploy/pipeline/ # Update the DNS Entries vim ./logs/os/updater53.sh ./logs/os/updater53.sh # Restart watchdog scp /home/ec2-user/experiment-deploy/pipeline/logs/os/shard?.txt watchdog:/home/ec2-user/staking ssh watchdog -- sudo systemctl restart harmony-watchdogd@staking.service # Update the ostn-s?-actual.txt with the correct ips mkdir ostn-20200325 || mv ostn-s?-actual.txt ./ostn-20200325/. ll ./ostn-20200325/* ./run_on_shard.sh -p os -y -T 0 'ip=$(curl http://169.254.169.254/latest/meta-data/public-ipv4); for k in $(ls ./.hmy/blskeys/); do echo $k, $ip; done' > ostn-s0-actual.txt ./run_on_shard.sh -p os -y -T 1 'ip=$(curl http://169.254.169.254/latest/meta-data/public-ipv4); for k in $(ls ./.hmy/blskeys/); do echo $k, $ip; done' > ostn-s1-actual.txt ./run_on_shard.sh -p os -y -T 2 'ip=$(curl http://169.254.169.254/latest/meta-data/public-ipv4); for k in $(ls ./.hmy/blskeys/); do echo $k, $ip; done' > ostn-s2-actual.txt ./run_on_shard.sh -p os -y -T 3 'ip=$(curl http://169.254.169.254/latest/meta-data/public-ipv4); for k in $(ls ./.hmy/blskeys/); do echo $k, $ip; done' > ostn-s3-actual.txt sudo rm *52.202.206.131* # Log into the machine download cli ~/experiment-deploy/pipeline/node_ssh.sh 52.89.13.173 sudo yum update curl -LO https://harmony.one/hmycli && mv hmycli hmy && chmod +x hmy sudo rm -rf harmony_db* sudo rm -rf .dht* mkdir -p /home/ec2-user/.hmy/blskeys cd /home/ec2-user/.hmy/blskeys ll rm *.key aws s3 cp s3://harmony-secret-keys/bls-test/2c6281268374475e94f9e8dd8a078c21d6a3bf1be2b3e2dc4b1b497f89d881ac7cce008b18810adfa432fc4c617fd505.key . aws s3 cp s3://harmony-secret-keys/bls-test/7fe71878cee72268dfbd7685b74bca34fa70a47c85ca3730e4597468a0ad98a60b8a0b750732cfa88b91e03014c5ac11.key . aws s3 cp s3://harmony-secret-keys/bls-test/f6211dea58b0962894d9f8a01624531b7e67d2de83da3ea4e02249ad688321a6be04c10cda4dfd8c052e70fe8da9e801.key . ll # Clean up log files exit # Log into the machine download cli ~/experiment-deploy/pipeline/node_ssh.sh 54.214.173.40 sudo yum update curl -LO https://harmony.one/hmycli && mv hmycli hmy && chmod +x hmy sudo rm -rf harmony_db* sudo rm -rf .dht* mkdir -p /home/ec2-user/.hmy/blskeys cd /home/ec2-user/.hmy/blskeys ll rm *.key aws s3 cp s3://harmony-secret-keys/bls-test/174c95f97ff6b98e4f840bd84d05f735cc195d5d1caffc79a1335c9deaf85bee3b01184b0f741c32f22daa004c140401.key . aws s3 cp s3://harmony-secret-keys/bls-test/3a3d6481bb95279254ad74649e65e31a18818c56da38c3623af86e5527cc7bce62f84187f10c9b6c30fd485196501518.key . aws s3 cp s3://harmony-secret-keys/bls-test/f1136f1223d144c6a5fe164899b0e917359483dd407ad490bbcc9480881e12c27071e3c1342a2d636fde0ea30117c980.key . ll exit # Log into the machine download cli ~/experiment-deploy/pipeline/node_ssh.sh 52.26.48.137 sudo yum update curl -LO https://harmony.one/hmycli && mv hmycli hmy && chmod +x hmy sudo rm -rf harmony_db* sudo rm -rf .dht* mkdir -p /home/ec2-user/.hmy/blskeys cd /home/ec2-user/.hmy/blskeys ll rm *.key aws s3 cp s3://harmony-secret-keys/bls-test/81ce2082507783d0882a0e816a7063a2c5ae2aaf186dfa157038262b911d55c2916bb113d7bcaf59426059ac9fc8cb91.key . aws s3 cp s3://harmony-secret-keys/bls-test/bc55cd376184cb98e32b80aedcb1fe913fc96de7b881ef75f7119b23674291a1bd50f8c3a4d4739c9a3d1d55e6386b18.key . aws s3 cp s3://harmony-secret-keys/bls-test/ccf1141f8e55cba6c42ab2d14cbb87a277ff9be29c9ba5604a9e3e2fec92fd74db0d5e9dd62da1d75df86cc0350fdb10.key . ll exit ./restart_node.sh -t 0 -r 0 -R 0 52.89.13.173 ./restart_node.sh -t 0 -r 0 -R 0 54.214.173.40 ./restart_node.sh -t 0 -r 0 -R 0 52.26.48.137 Firefighter: JW, DM, AW Date: Mar 24, 2020 # Create the new init files ec2-user@ip-172-31-37-52 init (master) $ cp init-52.90.110.183.json init-35.167.201.23.json ec2-user@ip-172-31-37-52 init (master) $ cp init-52.90.110.183.json init-54.203.77.136.json ec2-user@ip-172-31-37-52 init (master) $ cp init-52.90.110.183.json init-54.214.100.72.json ec2-user@ip-172-31-37-52 init (master) $ cp init-52.90.110.183.json init-34.221.66.228.json ec2-user@ip-172-31-37-52 init (master) $ cp init-52.90.110.183.json init-52.25.255.161.json ec2-user@ip-172-31-37-52 init (master) $ cp init-52.90.110.183.json init-34.221.142.39.json ec2-user@ip-172-31-37-52 init (master) $ cp init-52.90.110.183.json init-34.214.124.156.json ec2-user@ip-172-31-37-52 init (master) $ cp init-52.90.110.183.json init-34.221.208.236.json ec2-user@ip-172-31-37-52 init (master) $ pwd /home/ec2-user/experiment-deploy/pipeline/logs/os/init # Update the shard*.txt /home/ec2-user/experiment-deploy/pipeline/logs/os **** ================== SHARD 0 ==================== Old - 35.171.157.97 and 3.84.194.194 New - 35.167.201.23 and 5 4.203.77.136 Andy did these 35.171.157.97 \u2192 35.167.201.23 3.84.194.194 \u2192 54.203.77.136 35.167.201.23 aws s3 cp s3://harmony-secret-keys/bls-test/99d0835797ca0683fb7b1d14a882879652ddcdcfe0d52385ffddf8012ee804d92e5c05a56c9d7fc663678e36a158a28c.key . aws s3 cp s3://harmony-secret-keys/bls-test/0a21f76b002c3d2ebdf9e9a761c8a26774f306d2e0eed329cd9c814efe0cda9cbd10d9b5cf04f30bbf0030d359c5a705.key . aws s3 cp s3://harmony-secret-keys/bls-test/b814e7bccaa54c71a5f3b4caa5df62851fd6f2dd793cc35777fde7f1a152b51b9031b8598ae5a0f17f852d0e53fce985.key . -- 54.203.77.136 aws s3 cp s3://harmony-secret-keys/bls-test/ba27796a04c1e4d2cb2d946ac520c2b41589517cb9ae22e64718086c1b13bec1c3d1d78c274d4ffafd78e1b66705e496.key . aws s3 cp s3://harmony-secret-keys/bls-test/42c100b423e14387862fa419d81b430c9c6068d665e8a21737e293f49e41739795567176ab18070066a216eadb808808.key . aws s3 cp s3://harmony-secret-keys/bls-test/f6dcead63386972fb00c26c7aefda614b8c58bc33c05d488df9bfef361c1dcced0088b245acb411b52a36ed287051215.key . **** ================== SHARD 1 ==================== https://us-west-2.console.aws.amazon.com/ec2/v2/home?region=us-west-2#Instances:search=i-009a1476eaaaa2582;sort=instanceId [1:15 PM ] https://us-west-2.console.aws.amazon.com/ec2/v2/home?region=us-west-2#Instances:search=i-0191f1f5a4b365b4b;sort=instanceId [1:15 PM ] https://us-west-2.console.aws.amazon.com/ec2/v2/home?region=us-west-2#Instances:search=i-01aff220768dae9d2;sort=instanceId [1:15 PM ] https://us-west-2.console.aws.amazon.com/ec2/v2/home?region=us-west-2#Instances:search=i-0dc7a0a124265df37;sort=instanceId [1:15 PM] https://us-west-2.console.aws.amazon.com/ec2/v2/home?region=us-west-2#Instances:search=i-05746d955b1df2f9d;sort=instanceId exec ssh -i ~/.ssh/keys/oregon-key-benchmark.pem ec2-user@devop.hmny.io # New Node export WHOAMI=OS; export HMY_PROFILE=os; profile_print # Create the new init files cd /home/ec2-user/experiment-deploy/pipeline/logs/os/init cp init-52.90.110.183.json init-35.162.31.74.json cp init-52.90.110.183.json init-54.69.211.255.json cp init-52.90.110.183.json init-35.161.237.184.json cp init-52.90.110.183.json init-34.219.241.32.json cp init-52.90.110.183.json init-34.220.149.222.json # Modify Shard1.txt to replace the old ip's with new cd /home/ec2-user/experiment-deploy/pipeline/logs/os vim shard1.txt cat shart1.txt 107.23.13.24 \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 54.197.198.245 \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 18.212.197.32 \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 3.84.250.64 \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 3.95.138.72 \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 34.220.149.222 \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 54.145.138.160 \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 3.82.147.230 \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 35.162.31.74 \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 3.86.221.120 \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 35.161.237.184 \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 54.161.192.112 \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 3.82.196.136 \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 3.84.119.75 \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 3.87.40.196 \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 52.202.206.131 \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 34.219.241.32 \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 34.204.69.56 \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 54.69.211.255 \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 54.175.96.222 \u2502\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 3.89.75.86 # Log into the machine download cli ~/experiment-deploy/pipeline/node_ssh.sh 35.162.31.74 curl -LO https://harmony.one/hmycli && mv hmycli hmy && chmod +x hmy mkdir -p /home/ec2-user/.hmy/blskeys cd /home/ec2-user/.hmy/blskeys ll rm *.key aws s3 cp s3://harmony-secret-keys/bls-test/021926136495a0adcdda5af0602cb4b4ce6d6529cfd451b844728a0e4e424f2a78879a8b5d5e4b3e42127f95f2e2858b.key . aws s3 cp s3://harmony-secret-keys/bls-test/e99c10f7969f3845cb467e23f0a5095d372198c834bb2efa1c0bb220d67bacc85d2637486e52f8acd5dccff36580de0f.key . aws s3 cp s3://harmony-secret-keys/bls-test/b08bc8548a1f59646d9b610d7cffeaa97c1d441721b2f0079cafd60a39437b2fbe2bda27b295fa03d3a2a72265e4da12.key . exit # Log into the machine download cli ~/experiment-deploy/pipeline/node_ssh.sh 54.69.211.255 curl -LO https://harmony.one/hmycli && mv hmycli hmy && chmod +x hmy mkdir -p /home/ec2-user/.hmy/blskeys cd /home/ec2-user/.hmy/blskeys ll rm *.key aws s3 cp s3://harmony-secret-keys/bls-test/3a3d6481bb95279254ad74649e65e31a18818c56da38c3623af86e5527cc7bce62f84187f10c9b6c30fd485196501518.key . aws s3 cp s3://harmony-secret-keys/bls-test/174c95f97ff6b98e4f840bd84d05f735cc195d5d1caffc79a1335c9deaf85bee3b01184b0f741c32f22daa004c140401.key . aws s3 cp s3://harmony-secret-keys/bls-test/f1136f1223d144c6a5fe164899b0e917359483dd407ad490bbcc9480881e12c27071e3c1342a2d636fde0ea30117c980.key . exit # Log into the machine download cli ~/experiment-deploy/pipeline/node_ssh.sh 35.161.237.184 curl -LO https://harmony.one/hmycli && mv hmycli hmy && chmod +x hmy mkdir -p /home/ec2-user/.hmy/blskeys cd /home/ec2-user/.hmy/blskeys ll rm *.key aws s3 cp s3://harmony-secret-keys/bls-test/81ce2082507783d0882a0e816a7063a2c5ae2aaf186dfa157038262b911d55c2916bb113d7bcaf59426059ac9fc8cb91.key . aws s3 cp s3://harmony-secret-keys/bls-test/bc55cd376184cb98e32b80aedcb1fe913fc96de7b881ef75f7119b23674291a1bd50f8c3a4d4739c9a3d1d55e6386b18.key . aws s3 cp s3://harmony-secret-keys/bls-test/ccf1141f8e55cba6c42ab2d14cbb87a277ff9be29c9ba5604a9e3e2fec92fd74db0d5e9dd62da1d75df86cc0350fdb10.key . exit # Log into the machine download cli ~/experiment-deploy/pipeline/node_ssh.sh 34.219.241.32 curl -LO https://harmony.one/hmycli && mv hmycli hmy && chmod +x hmy mkdir -p /home/ec2-user/.hmy/blskeys cd /home/ec2-user/.hmy/blskeys ll rm *.key aws s3 cp s3://harmony-secret-keys/bls-test/38de540c3df944e2982dda39f9a8d4ed69d0a23852580f7d818654d6ef9b0e1defdcfca3b33d36dcf04789659cc2878a.key . aws s3 cp s3://harmony-secret-keys/bls-test/a08abc8479ea3a37b3b2039691a4ee66ec6c8e5fa9bc130f2fff0000f0e747b7e47679d9b3a5be11ccb4132f701c158d.key . aws s3 cp s3://harmony-secret-keys/bls-test/744336d151fa5ad71eb2c25c01e20c5069f4daf6c69b4e4be5297fb6427f23826b21502490acf155a0d0985d25f2f006.key . exit # Log into the machine download cli ~/experiment-deploy/pipeline/node_ssh.sh 34.220.149.222 curl -LO https://harmony.one/hmycli && mv hmycli hmy && chmod +x hmy mkdir -p /home/ec2-user/.hmy/blskeys cd /home/ec2-user/.hmy/blskeys ll rm *.key aws s3 cp s3://harmony-secret-keys/bls-test/640bcc532b507981a832d3dce3d2f86d66b314a9d6cf4e6644629ce83786c6deaf9ec52ed15f9e08df695d6417a0ad8a.key . aws s3 cp s3://harmony-secret-keys/bls-test/e4f6913240790b74c26a8ddf571942ee55ae0a5ac99958d96253fd7a334afee39226434b0c960e77df48b860afb5850f.key . aws s3 cp s3://harmony-secret-keys/bls-test/3e5d1203314089e1952a2b4709b96db2084a57a7d08c24e936e459a2e49c182027f5dc7c2da8517eed4b7b2d95f82611.key . exit # Restart the whole shard cd ~/experiment-deploy/pipeline ./run_on_shard.sh -p os -T 1 \"sudo rm -r .dht*\" cat logs/os/shard1.txt | xargs -i{} -P50 bash -c './restart_node.sh -y -d logs/os -p os -t 0 -r 0 -R 0 {}' # Restart individual nodes cd ~/experiment-deploy/pipeline ./restart_node.sh -t 0 -r 0 -R 0 35.162.31.74 ================== SHARD 2 ==================== Old - 18.234.207.0 and 3.84.10.119 New - 54.214.100.72 and 34.221.66.228 **** ================== SHARD 3 ==================== Old - 52.87.240.253 and 18.205.149.223 and and 3.80.188.34 and 52.207.222.5 New - 52.25.255.161 and 34.221.142.39 and 34.214.124.156 and 34.221.208.236 # Log into the machine download cli ~/experiment-deploy/pipeline/node_ssh.sh 52.25.255.161 sudo yum update curl -LO https://harmony.one/hmycli && mv hmycli hmy && chmod +x hmy sudo rm -rf harmony_db* sudo rm -rf .dht* mkdir -p /home/ec2-user/.hmy/blskeys cd /home/ec2-user/.hmy/blskeys ll rm *.key aws s3 cp s3://harmony-secret-keys/bls-test/88b4da322731de51da65e6d2faba85782fa517002f6177c19932c10767cc6cef922ee17f7e46ff00424b8ffe4afeb291.key . aws s3 cp s3://harmony-secret-keys/bls-test/3074c2c46a0396d6720b4612a0641e29b13263eb4237ddfaa2317db99b8c0fd7e37a6b035c996265e82dd5c8286eb708.key . aws s3 cp s3://harmony-secret-keys/bls-test/8f4113299afb54e9301c0b10216a19555ddca1cb723b84102af59fcbe97e3efc746383e6edb0c68414cd9265e781e48d.key . exit # Log into the machine download cli ~/experiment-deploy/pipeline/node_ssh.sh 34.221.142.39 sudo yum update curl -LO https://harmony.one/hmycli && mv hmycli hmy && chmod +x hmy sudo rm -rf harmony_db* sudo rm -rf .dht* mkdir -p /home/ec2-user/.hmy/blskeys cd /home/ec2-user/.hmy/blskeys ll rm *.key aws s3 cp s3://harmony-secret-keys/bls-test/ab7df3e38a8423c31f8dd40d2952667bff711c9d00f717e528ffc661d1d26c3b431f403eb1c360a767fc8ad7fe2b3991.key . aws s3 cp s3://harmony-secret-keys/bls-test/eb84135858022bc149ebd50d7726640a63a32e8e866876ede8f9b7ef173dfd9d6d67615e2583b991652be28b56b40904.key . aws s3 cp s3://harmony-secret-keys/bls-test/7b864402962aeec98f6e48554492b9cb843e9c021fc6d5a7785b77f02ddf97434af174ef741e704682454d223d9d540f.key . ll exit # Log into the machine download cli ~/experiment-deploy/pipeline/node_ssh.sh 34.214.124.156 sudo yum update curl -LO https://harmony.one/hmycli && mv hmycli hmy && chmod +x hmy sudo rm -rf harmony_db* sudo rm -rf .dht* mkdir -p /home/ec2-user/.hmy/blskeys cd /home/ec2-user/.hmy/blskeys ll rm *.key aws s3 cp s3://harmony-secret-keys/bls-test/5f7a2faeaa55f46a2b07164bc33a2d2569e05316b8c5f8d4757545342aeae8cde5cf30970aad748aa424871940b5818c.key . aws s3 cp s3://harmony-secret-keys/bls-test/8797872afec84adf180f58425ce897ac3830cc102c872a304689a4fdcfb1bec157f1a9e9e3fb46afdbffd766cd53ca81.key . aws s3 cp s3://harmony-secret-keys/bls-test/80792a400e45ebdb18ff22d32a8de95b4766e40b8047d8d9836ecfdb075e5548e159e6bae372cdd6454b52409d4f5019.key . ll exit # Log into the machine download cli ~/experiment-deploy/pipeline/node_ssh.sh 34.221.208.236 sudo yum update curl -LO https://harmony.one/hmycli && mv hmycli hmy && chmod +x hmy sudo rm -rf harmony_db* sudo rm -rf .dht* mkdir -p /home/ec2-user/.hmy/blskeys cd /home/ec2-user/.hmy/blskeys ll rm *.key aws s3 cp s3://harmony-secret-keys/bls-test/e2b812729d73a3e4538ec19cc2a8ba694660dc6eca53531026b6e6a3d119de7de43ed994771457211f581600c7488c05.key . aws s3 cp s3://harmony-secret-keys/bls-test/0c9d3e30ce69ed358016e54c47d0643c2e417441c15612158ef52a06d609784b030b31d352252520a14058abdc514196.key . aws s3 cp s3://harmony-secret-keys/bls-test/54beb67b89b78dac97d6951919d8af883ef70750681d3912563ee5ce3dae9e1a11612200496c920f1deeff3d5eb3d60c.key . ll exit ./restart_node.sh -t 0 -r 0 -R 0 52.25.255.161 ./restart_node.sh -t 0 -r 0 -R 0 34.221.142.39 ./restart_node.sh -t 0 -r 0 -R 0 34.221.208.236 ./restart_node.sh -t 0 -r 0 -R 0 34.214.124.156 =========END of Mar 24 ========================================================== Firefighter: JW, DM, AW Date: Mar 23, 2020 Automation Ticket: https://github.com/harmony-one/harmony-ops/issues/497 ================== SHARD 0 ==================== 35.175.137.77(offine) -> 18.207.222.72(new) mkdir -p /home/ec2-user/.hmy/blskeys sudo mkdir -p ../tmp_log/log-20200318.212437 curl -LO https://harmony.one/hmycli && mv hmycli hmy && chmod +x hmy aws s3 cp s3://harmony-secret-keys/bls-test/d69c70aa8e43853487760533ad1cbeb9f8e91d409ede23f5db9e0038528bd9914ecd8710afe187bb303cc345a52f0b93.key . aws s3 cp s3://harmony-secret-keys/bls-test/d2756594a894175bcffa03ce8a945e8c73f8149e3a4acf0695a206b70a9a4c5782a16199f590ee1cdafb50a45488e518.key . aws s3 cp s3://harmony-secret-keys/bls-test/f4354e218f74d3d629586cb361d28025b4d8d2387eb173c49c86912f7f8e20f13c214f3351466a6140a4ee0071efdb8a.key . # then manually create an init file for the new node # check the latest header if needed ./hmy blockchain latest-header **3.85.98.85 \\(offine\\) - 18.205.115.81 \\(new\\)** > mkdir -p /home/ec2-user/.hmy/blskeys; sudo mkdir -p ../tmp_log/log-20200318.212437; curl -LO https://harmony.one/hmycli && mv hmycli hmy && chmod +x hmy aws s3 cp s3://harmony-secret-keys/bls-test/03406acec541e0e0d7cbcb7c0502b4901d09b4f563fe0db4cf3e3d18038373f71eb3f720d9d9c66244364bfd7ef09217.key . aws s3 cp s3://harmony-secret-keys/bls-test/069e433b4112cda534bf4171d33c13a832dbcbf8222afacb701b2e00bd2303ff107d2bc75ba02185e48958aeba7a7697.key . aws s3 cp s3://harmony-secret-keys/bls-test/e53407496e6c807be3e583c45b49b5a00c8c0550ced7fdadab9139109002625107035a5885f9d097a68791db48ecc803.key . **================== SHARD 1 ====================** 1. **3.87.15.177 \\(offine\\) - 54.161.192.112 \\(new\\)** > aws s3 cp s3://harmony-secret-keys/bls-test/90404f04db155afc0444210b83a1f6acb29e0c479a31222afe7827b643067754817af06fbda99600d5afcc0dfd510c89.key . aws s3 cp s3://harmony-secret-keys/bls-test/ba17088f82e461ace61eec13b48463b8bebef8046a2362fd9c0e302a0331228233c7ad6811d151f63e01db36c1093a83.key . aws s3 cp s3://harmony-secret-keys/bls-test/a7a3fef9449204c26de34129d30793c5adcc9ddb5aa1e02bad8bbe5662db336ab5538ee3e1156785486c4a75ca68b211.key . cp logs/os/init/init-3.87.15.177.json logs/os/init/init-54.161.192.112.json ./restart_node.sh -t 0 -r 0 -R 0 54.161.192.112 **54.85.84.1 \\(offine\\) - 54.175.96.222 \\(new\\)** > aws s3 cp s3://harmony-secret-keys/bls-test/867ae6f88a5edecd6d89df05d94e08785971b4611ccda62944a7773f5cdcd6f2d86af8364fc7670d38a18109b2416413.key . aws s3 cp s3://harmony-secret-keys/bls-test/3664120aa99f98a215819b4a4adffc59450f5ad73da7a7594dd9cc2633fad63ad9692b580326575a99250700a77d7717.key . aws s3 cp s3://harmony-secret-keys/bls-test/5eb082f818ea3c5a3b49079d8d86d8d43cec0863e4226d1c7facdf9537e17c5ebdcb53450cafd47d6c4ed0c51b7c2214.key . **================== SHARD 2 ====================** 1. **54.90.89.65 \\(offine\\) - 54.234.133.75 \\(new\\)** > mkdir -p /home/ec2-user/.hmy/blskeys; sudo mkdir -p ../tmp_log/log-20200318.212437; curl -LO https://harmony.one/hmycli && mv hmycli hmy && chmod +x hmy aws s3 cp s3://harmony-secret-keys/bls-test/1bf1ca37df49190578391d3c34cdb62cc9b2c88ebf5bbbe72a41db8da5236576fdb4513973045f23633a6ddd5a52488a.key . aws s3 cp s3://harmony-secret-keys/bls-test/9fd7463748f72c1a219ccd8e0e3388e7c5f8c426260d78baabd8c5ca172950661410d7a84ed25669edf9419ffa657618.key . aws s3 cp s3://harmony-secret-keys/bls-test/8e85ca728c071af97586b178d906dd27a652b426b8bd2c5e15149700741ee605310a3981232c9f6aca1a37274539948e.key . **18.234.240.64 \\(offine\\) - 54.167.129.45 \\(new\\)** | **aws s3 cp s3://harmony-secret-keys/bls-test/351f04e4329c8e3a49ea956b8d85307a8eaf56849f20c0006e7b59346922c3e038a1fee4bd7cbf1b34551a0270b40710.key . aws s3 cp s3://harmony-secret-keys/bls-test/7c880b17c5cec63bebc634ad4530ea32e4632b7b73085f5d9948c333ae3963cf4e448d29b194a2e304b68736c2b3a903.key . aws s3 cp s3://harmony-secret-keys/bls-test/a77967462bea74b9eb96608ee0e4e4ba444da7a3708da2f8f60f8ff53878adcb0cf25a38d8caddeb3be3b4a35e35fe0d.key .** | | :--- | 1. **184.72.206.164 \\(offine\\) - 3.95.137.99 \\(new\\)** | **aws s3 cp s3://harmony-secret-keys/bls-test/a4a75bfc607dd1bee6d60454309bb5fb4c9a48805bc514f29e56c5766e391545bc8d750011c6d1f4b12218adc7c15e95.key . aws s3 cp s3://harmony-secret-keys/bls-test/929d436cccbb46229f3405e57ebd44cb9b2987e1d8cfe48455738a9f2f8f77438771f53478a71dc247a857686c28b60a.key . aws s3 cp s3://harmony-secret-keys/bls-test/4af2bd9f1e91b9c7db1f6d239a0c76006e8d8d1219468a49d4c06893f15cc6844d5826083bb0f06d4f9af80e38e0b002.key .** | | :--- | 1. **3.95.225.36 \\(offine\\) - 35.173.221.246 \\(new\\)** | **aws s3 cp s3://harmony-secret-keys/bls-test/2d24f086b9cf9a7f3e934a9bf4bd9355a0aaf3b21c03d74725fe8253d01888bfa839eaafe5a99a41678d1d4750f2eb92.key . aws s3 cp s3://harmony-secret-keys/bls-test/50c3565ad3275e660a97ef29dae9d335f77871cfd5c09ee5c5f61306781c0478988ed1ca45e5c151a0fa5d483346de92.key . aws s3 cp s3://harmony-secret-keys/bls-test/49f9c2b3d90aa7dd1ead32ce40cf90864cc6420f5f11b136f35d58753838756f991561fc1350b5b7facdcc4c1d88ba88.key .** | | :--- | 1. **52.87.193.132 \\(offine\\) - 52.87.160.66 \\(new\\)** | **aws s3 cp s3://harmony-secret-keys/bls-test/6d8faf3a0ff828bfc59702755c8e84d1e4dbd434d798c56bfa4772aa22254ae4643d6b4a9d385941780b848e1aed6007.key . aws s3 cp s3://harmony-secret-keys/bls-test/60aae7000932b498084255484f94c394159650817095a2ca097f2031d63b04decfa24d659655241792276f14f64fa294.key . aws s3 cp s3://harmony-secret-keys/bls-test/6963a4a6283d8f7150aef2b2ca05cd15bf43c77a9e42dd544caf869ece8292510ca2e255d675407e14429bfb00335a92.key .** | | :--- | **================== SHARD 3 ====================** 1. **52.23.233.194 \\(offine\\) - 54.144.185.102 \\(new\\)** >>>>> mkdir -p /home/ec2-user/.hmy/blskeys; sudo mkdir -p ../tmp_log/log-20200318.212437; curl -LO https://harmony.one/hmycli && mv hmycli hmy && chmod +x hmy aws s3 cp s3://harmony-secret-keys/bls-test/8f657775630e2f58fe7fc679fd5827705eb19ad1ea47c78d3d5ac544ddc8d2fa0aa542bafd350d4eb7e9c822a89e3006.key . aws s3 cp s3://harmony-secret-keys/bls-test/fcacc28fdc2bacd2ea3f6b3bda853553522ed5cf1a335f67930ea7c7d981ec3f33ce00d1b4b30438287a77ec043b478f.key . aws s3 cp s3://harmony-secret-keys/bls-test/acb484265281f4f956f4b73221d1fb3df8f78adecfd59e693f961d0de46b1790c4d2d12856c35bdc733ebdf0da134d85.key .","title":"Update the IPS and config"},{"location":"deploy/cicd/netdeploy/troubleshooting/recovering-nodes-killed-as-spot-instances/creating-a-new-aws-node-image/","text":"Creating a new aws node image Overview This documents how to create an image and spin up new instances which are used in the next step of Copying keys and restarting nodes . This work is done via AWS through the web interface {% hint style=\"info\" %} Create using image copies all directories and you need to clean up the extra log files and key files. Launch more like this does not create all the directories so you need to manuall create the key directory and log directory (use session-id from /home/ec2-user/experiment-deploy/pipeline/logs/os/init e.g. \"sessionID\":\"20200326.180455\", means create ../tmp_logs/logs-20200326.180455 {% endhint %} Log into AWS Log in to AWS Console Switch to your harmony role - e.g. john-harmony Go to the EC2 console and select the region Select an instance and action launch more like this 2nd tab choose t3.small Enter the number of instances on the 3rd tab we chose 3 Use the key pair of harmony-testnet Using an image","title":"Creating a new aws node image"},{"location":"deploy/cicd/netdeploy/troubleshooting/recovering-nodes-killed-as-spot-instances/creating-a-new-aws-node-image/#creating-a-new-aws-node-image","text":"","title":"Creating a new aws node image"},{"location":"deploy/cicd/netdeploy/troubleshooting/recovering-nodes-killed-as-spot-instances/creating-a-new-aws-node-image/#overview","text":"This documents how to create an image and spin up new instances which are used in the next step of Copying keys and restarting nodes . This work is done via AWS through the web interface {% hint style=\"info\" %} Create using image copies all directories and you need to clean up the extra log files and key files. Launch more like this does not create all the directories so you need to manuall create the key directory and log directory (use session-id from /home/ec2-user/experiment-deploy/pipeline/logs/os/init e.g. \"sessionID\":\"20200326.180455\", means create ../tmp_logs/logs-20200326.180455 {% endhint %}","title":"Overview"},{"location":"deploy/cicd/netdeploy/troubleshooting/recovering-nodes-killed-as-spot-instances/creating-a-new-aws-node-image/#log-into-aws","text":"Log in to AWS Console Switch to your harmony role - e.g. john-harmony","title":"Log into AWS"},{"location":"deploy/cicd/netdeploy/troubleshooting/recovering-nodes-killed-as-spot-instances/creating-a-new-aws-node-image/#go-to-the-ec2-console-and-select-the-region","text":"","title":"Go to the EC2 console and select the region"},{"location":"deploy/cicd/netdeploy/troubleshooting/recovering-nodes-killed-as-spot-instances/creating-a-new-aws-node-image/#select-an-instance-and-action-launch-more-like-this","text":"2nd tab choose t3.small Enter the number of instances on the 3rd tab we chose 3 Use the key pair of harmony-testnet","title":"Select an instance and action launch more like this"},{"location":"deploy/cicd/netdeploy/troubleshooting/recovering-nodes-killed-as-spot-instances/creating-a-new-aws-node-image/#using-an-image","text":"","title":"Using an image"},{"location":"deploy/cicd/netdeploy/troubleshooting/tmux-magic/","text":"tmux magic Following are some handy tmux commands and more information is here # Attach to tmux session if you only have one tmux att # Create new session e.g. os tmux new-session -s os # List tmux sessions tmux ls # Attach to a specific tmux session tmux attach-session -t os # Move between windows # There are a list of windows at the bottom of the tmux session <CTL>b 0 # Split panes horizontally and vertically 0 # Move between panes forward <CTL>b 0 # Move between panes backward <CTL>b 1","title":"tmux magic"},{"location":"deploy/cicd/netdeploy/troubleshooting/tmux-magic/#tmux-magic","text":"Following are some handy tmux commands and more information is here # Attach to tmux session if you only have one tmux att # Create new session e.g. os tmux new-session -s os # List tmux sessions tmux ls # Attach to a specific tmux session tmux attach-session -t os # Move between windows # There are a list of windows at the bottom of the tmux session <CTL>b 0 # Split panes horizontally and vertically 0 # Move between panes forward <CTL>b 0 # Move between panes backward <CTL>b 1","title":"tmux magic"},{"location":"deploy/cicd/netdeploy/troubleshooting/tmux-magic/validation-overview/","text":"Validation Overview Your local mac environment Build and run your cli cd /Users/johnwhitton/go/src/github.com/harmony-one git pull git make source ../harmony/scripts/setup_bls_build_flags.sh ./hmy cookbook Earning script Stress Testing Instructions Checklist Token Transfer Troubleshooting tail -f ./latest/*.log tail -f ./latest/*.log | grep Height tail -f ./latest/*.log | grep SYNC tail -f ./latest/*.log | grep OnAnnounce tail -f ./latest/*.log | grep OnPrepared ./hmy --node=\"https://api.s0.os.hmny.io\" blockchain validator information one1m6j80t6rhc3ypaumtsfmqwjwp0mrqk9ff50prh tac ./latest/*.log | grep invalid cat ./latest/*.log | grep invalid","title":"Validation Overview"},{"location":"deploy/cicd/netdeploy/troubleshooting/tmux-magic/validation-overview/#validation-overview","text":"","title":"Validation Overview"},{"location":"deploy/cicd/netdeploy/troubleshooting/tmux-magic/validation-overview/#your-local-mac-environment","text":"","title":"Your local mac environment"},{"location":"deploy/cicd/netdeploy/troubleshooting/tmux-magic/validation-overview/#build-and-run-your-cli","text":"cd /Users/johnwhitton/go/src/github.com/harmony-one git pull git make source ../harmony/scripts/setup_bls_build_flags.sh ./hmy cookbook","title":"Build and run your cli"},{"location":"deploy/cicd/netdeploy/troubleshooting/tmux-magic/validation-overview/#earning-script","text":"","title":"Earning script"},{"location":"deploy/cicd/netdeploy/troubleshooting/tmux-magic/validation-overview/#stress-testing","text":"Instructions Checklist","title":"Stress Testing"},{"location":"deploy/cicd/netdeploy/troubleshooting/tmux-magic/validation-overview/#token-transfer","text":"Troubleshooting tail -f ./latest/*.log tail -f ./latest/*.log | grep Height tail -f ./latest/*.log | grep SYNC tail -f ./latest/*.log | grep OnAnnounce tail -f ./latest/*.log | grep OnPrepared ./hmy --node=\"https://api.s0.os.hmny.io\" blockchain validator information one1m6j80t6rhc3ypaumtsfmqwjwp0mrqk9ff50prh tac ./latest/*.log | grep invalid cat ./latest/*.log | grep invalid","title":"Token Transfer"},{"location":"deploy/monitoring/consensus/","text":"Component Name Overview Functional overview of what this component does Status - Built, Q2, Roadmap, Tenative Business Driver Ecosystem Grant - Eligible, Priority, Amount Deliverable Technical Specification Reference Material Level of Effort Developer or Partner Identified Harmony Owner Developer Guide","title":"Consensus Monitoring"},{"location":"deploy/monitoring/consensus/#component-name","text":"","title":"Component Name"},{"location":"deploy/monitoring/consensus/#overview","text":"Functional overview of what this component does","title":"Overview"},{"location":"deploy/monitoring/consensus/#status-built-q2-roadmap-tenative","text":"","title":"Status - Built, Q2, Roadmap, Tenative"},{"location":"deploy/monitoring/consensus/#business-driver","text":"","title":"Business Driver"},{"location":"deploy/monitoring/consensus/#ecosystem-grant-eligible-priority-amount","text":"","title":"Ecosystem Grant - Eligible, Priority, Amount"},{"location":"deploy/monitoring/consensus/#deliverable","text":"","title":"Deliverable"},{"location":"deploy/monitoring/consensus/#technical-specification","text":"","title":"Technical Specification"},{"location":"deploy/monitoring/consensus/#reference-material","text":"","title":"Reference Material"},{"location":"deploy/monitoring/consensus/#level-of-effort","text":"","title":"Level of Effort"},{"location":"deploy/monitoring/consensus/#developer-or-partner-identified","text":"","title":"Developer or Partner Identified"},{"location":"deploy/monitoring/consensus/#harmony-owner","text":"","title":"Harmony Owner"},{"location":"deploy/monitoring/consensus/#developer-guide","text":"","title":"Developer Guide"},{"location":"deploy/monitoring/loganalysis/","text":"Component Name Overview Functional overview of what this component does Status - Built, Q2, Roadmap, Tenative Business Driver Ecosystem Grant - Eligible, Priority, Amount Deliverable Technical Specification Reference Material Level of Effort Developer or Partner Identified Harmony Owner Developer Guide","title":"Log Analysis"},{"location":"deploy/monitoring/loganalysis/#component-name","text":"","title":"Component Name"},{"location":"deploy/monitoring/loganalysis/#overview","text":"Functional overview of what this component does","title":"Overview"},{"location":"deploy/monitoring/loganalysis/#status-built-q2-roadmap-tenative","text":"","title":"Status - Built, Q2, Roadmap, Tenative"},{"location":"deploy/monitoring/loganalysis/#business-driver","text":"","title":"Business Driver"},{"location":"deploy/monitoring/loganalysis/#ecosystem-grant-eligible-priority-amount","text":"","title":"Ecosystem Grant - Eligible, Priority, Amount"},{"location":"deploy/monitoring/loganalysis/#deliverable","text":"","title":"Deliverable"},{"location":"deploy/monitoring/loganalysis/#technical-specification","text":"","title":"Technical Specification"},{"location":"deploy/monitoring/loganalysis/#reference-material","text":"","title":"Reference Material"},{"location":"deploy/monitoring/loganalysis/#level-of-effort","text":"","title":"Level of Effort"},{"location":"deploy/monitoring/loganalysis/#developer-or-partner-identified","text":"","title":"Developer or Partner Identified"},{"location":"deploy/monitoring/loganalysis/#harmony-owner","text":"","title":"Harmony Owner"},{"location":"deploy/monitoring/loganalysis/#developer-guide","text":"","title":"Developer Guide"},{"location":"deploy/monitoring/monitorsite/","text":"Component Name Overview Functional overview of what this component does Status - Built, Q2, Roadmap, Tenative Business Driver Ecosystem Grant - Eligible, Priority, Amount Deliverable Technical Specification Reference Material Level of Effort Developer or Partner Identified Harmony Owner Developer Guide","title":"Monitoring Site"},{"location":"deploy/monitoring/monitorsite/#component-name","text":"","title":"Component Name"},{"location":"deploy/monitoring/monitorsite/#overview","text":"Functional overview of what this component does","title":"Overview"},{"location":"deploy/monitoring/monitorsite/#status-built-q2-roadmap-tenative","text":"","title":"Status - Built, Q2, Roadmap, Tenative"},{"location":"deploy/monitoring/monitorsite/#business-driver","text":"","title":"Business Driver"},{"location":"deploy/monitoring/monitorsite/#ecosystem-grant-eligible-priority-amount","text":"","title":"Ecosystem Grant - Eligible, Priority, Amount"},{"location":"deploy/monitoring/monitorsite/#deliverable","text":"","title":"Deliverable"},{"location":"deploy/monitoring/monitorsite/#technical-specification","text":"","title":"Technical Specification"},{"location":"deploy/monitoring/monitorsite/#reference-material","text":"","title":"Reference Material"},{"location":"deploy/monitoring/monitorsite/#level-of-effort","text":"","title":"Level of Effort"},{"location":"deploy/monitoring/monitorsite/#developer-or-partner-identified","text":"","title":"Developer or Partner Identified"},{"location":"deploy/monitoring/monitorsite/#harmony-owner","text":"","title":"Harmony Owner"},{"location":"deploy/monitoring/monitorsite/#developer-guide","text":"","title":"Developer Guide"},{"location":"deploy/monitoring/pyhmy/","text":"Component Name Overview Functional overview of what this component does Status - Built, Q2, Roadmap, Tenative Business Driver Ecosystem Grant - Eligible, Priority, Amount Deliverable Technical Specification Reference Material Level of Effort Developer or Partner Identified Harmony Owner Developer Guide","title":"Harmony Python"},{"location":"deploy/monitoring/pyhmy/#component-name","text":"","title":"Component Name"},{"location":"deploy/monitoring/pyhmy/#overview","text":"Functional overview of what this component does","title":"Overview"},{"location":"deploy/monitoring/pyhmy/#status-built-q2-roadmap-tenative","text":"","title":"Status - Built, Q2, Roadmap, Tenative"},{"location":"deploy/monitoring/pyhmy/#business-driver","text":"","title":"Business Driver"},{"location":"deploy/monitoring/pyhmy/#ecosystem-grant-eligible-priority-amount","text":"","title":"Ecosystem Grant - Eligible, Priority, Amount"},{"location":"deploy/monitoring/pyhmy/#deliverable","text":"","title":"Deliverable"},{"location":"deploy/monitoring/pyhmy/#technical-specification","text":"","title":"Technical Specification"},{"location":"deploy/monitoring/pyhmy/#reference-material","text":"","title":"Reference Material"},{"location":"deploy/monitoring/pyhmy/#level-of-effort","text":"","title":"Level of Effort"},{"location":"deploy/monitoring/pyhmy/#developer-or-partner-identified","text":"","title":"Developer or Partner Identified"},{"location":"deploy/monitoring/pyhmy/#harmony-owner","text":"","title":"Harmony Owner"},{"location":"deploy/monitoring/pyhmy/#developer-guide","text":"","title":"Developer Guide"},{"location":"deploy/validator/autonode/","text":"Component Name Overview Functional overview of what this component does Status - Built, Q2, Roadmap, Tenative Business Driver Ecosystem Grant - Eligible, Priority, Amount Deliverable Technical Specification Reference Material Level of Effort Developer or Partner Identified Harmony Owner Developer Guide","title":"autonode"},{"location":"deploy/validator/autonode/#component-name","text":"","title":"Component Name"},{"location":"deploy/validator/autonode/#overview","text":"Functional overview of what this component does","title":"Overview"},{"location":"deploy/validator/autonode/#status-built-q2-roadmap-tenative","text":"","title":"Status - Built, Q2, Roadmap, Tenative"},{"location":"deploy/validator/autonode/#business-driver","text":"","title":"Business Driver"},{"location":"deploy/validator/autonode/#ecosystem-grant-eligible-priority-amount","text":"","title":"Ecosystem Grant - Eligible, Priority, Amount"},{"location":"deploy/validator/autonode/#deliverable","text":"","title":"Deliverable"},{"location":"deploy/validator/autonode/#technical-specification","text":"","title":"Technical Specification"},{"location":"deploy/validator/autonode/#reference-material","text":"","title":"Reference Material"},{"location":"deploy/validator/autonode/#level-of-effort","text":"","title":"Level of Effort"},{"location":"deploy/validator/autonode/#developer-or-partner-identified","text":"","title":"Developer or Partner Identified"},{"location":"deploy/validator/autonode/#harmony-owner","text":"","title":"Harmony Owner"},{"location":"deploy/validator/autonode/#developer-guide","text":"","title":"Developer Guide"},{"location":"deploy/validator/cli/","text":"Component Name Overview Functional overview of what this component does Status - Built, Q2, Roadmap, Tenative Business Driver Ecosystem Grant - Eligible, Priority, Amount Deliverable Technical Specification Reference Material Level of Effort Developer or Partner Identified Harmony Owner Developer Guide","title":"Command Line Interface"},{"location":"deploy/validator/cli/#component-name","text":"","title":"Component Name"},{"location":"deploy/validator/cli/#overview","text":"Functional overview of what this component does","title":"Overview"},{"location":"deploy/validator/cli/#status-built-q2-roadmap-tenative","text":"","title":"Status - Built, Q2, Roadmap, Tenative"},{"location":"deploy/validator/cli/#business-driver","text":"","title":"Business Driver"},{"location":"deploy/validator/cli/#ecosystem-grant-eligible-priority-amount","text":"","title":"Ecosystem Grant - Eligible, Priority, Amount"},{"location":"deploy/validator/cli/#deliverable","text":"","title":"Deliverable"},{"location":"deploy/validator/cli/#technical-specification","text":"","title":"Technical Specification"},{"location":"deploy/validator/cli/#reference-material","text":"","title":"Reference Material"},{"location":"deploy/validator/cli/#level-of-effort","text":"","title":"Level of Effort"},{"location":"deploy/validator/cli/#developer-or-partner-identified","text":"","title":"Developer or Partner Identified"},{"location":"deploy/validator/cli/#harmony-owner","text":"","title":"Harmony Owner"},{"location":"deploy/validator/cli/#developer-guide","text":"","title":"Developer Guide"},{"location":"deploy/validator/knowledge/","text":"Component Name Overview Functional overview of what this component does Status - Built, Q2, Roadmap, Tenative Business Driver Ecosystem Grant - Eligible, Priority, Amount Deliverable Technical Specification Reference Material Level of Effort Developer or Partner Identified Harmony Owner Developer Guide","title":"Node Knowledgebase"},{"location":"deploy/validator/knowledge/#component-name","text":"","title":"Component Name"},{"location":"deploy/validator/knowledge/#overview","text":"Functional overview of what this component does","title":"Overview"},{"location":"deploy/validator/knowledge/#status-built-q2-roadmap-tenative","text":"","title":"Status - Built, Q2, Roadmap, Tenative"},{"location":"deploy/validator/knowledge/#business-driver","text":"","title":"Business Driver"},{"location":"deploy/validator/knowledge/#ecosystem-grant-eligible-priority-amount","text":"","title":"Ecosystem Grant - Eligible, Priority, Amount"},{"location":"deploy/validator/knowledge/#deliverable","text":"","title":"Deliverable"},{"location":"deploy/validator/knowledge/#technical-specification","text":"","title":"Technical Specification"},{"location":"deploy/validator/knowledge/#reference-material","text":"","title":"Reference Material"},{"location":"deploy/validator/knowledge/#level-of-effort","text":"","title":"Level of Effort"},{"location":"deploy/validator/knowledge/#developer-or-partner-identified","text":"","title":"Developer or Partner Identified"},{"location":"deploy/validator/knowledge/#harmony-owner","text":"","title":"Harmony Owner"},{"location":"deploy/validator/knowledge/#developer-guide","text":"","title":"Developer Guide"},{"location":"deploy/validator/tui/","text":"Component Name Overview Functional overview of what this component does Status - Built, Q2, Roadmap, Tenative Business Driver Ecosystem Grant - Eligible, Priority, Amount Deliverable Technical Specification Reference Material Level of Effort Developer or Partner Identified Harmony Owner Developer Guide","title":"Node Terminal UI"},{"location":"deploy/validator/tui/#component-name","text":"","title":"Component Name"},{"location":"deploy/validator/tui/#overview","text":"Functional overview of what this component does","title":"Overview"},{"location":"deploy/validator/tui/#status-built-q2-roadmap-tenative","text":"","title":"Status - Built, Q2, Roadmap, Tenative"},{"location":"deploy/validator/tui/#business-driver","text":"","title":"Business Driver"},{"location":"deploy/validator/tui/#ecosystem-grant-eligible-priority-amount","text":"","title":"Ecosystem Grant - Eligible, Priority, Amount"},{"location":"deploy/validator/tui/#deliverable","text":"","title":"Deliverable"},{"location":"deploy/validator/tui/#technical-specification","text":"","title":"Technical Specification"},{"location":"deploy/validator/tui/#reference-material","text":"","title":"Reference Material"},{"location":"deploy/validator/tui/#level-of-effort","text":"","title":"Level of Effort"},{"location":"deploy/validator/tui/#developer-or-partner-identified","text":"","title":"Developer or Partner Identified"},{"location":"deploy/validator/tui/#harmony-owner","text":"","title":"Harmony Owner"},{"location":"deploy/validator/tui/#developer-guide","text":"","title":"Developer Guide"},{"location":"develop/building/","text":"Building on Harmony The simplest way to build on Harmony is to follow the tutorials in this section. They come complete with examples and sample code. Harmony provides hosted endpoints which makes it simple for developers to deploy smart contracts to a testnet without needing to run a blockchain locally. For more advanced users you will also find instructions for developing locally.","title":"Building"},{"location":"develop/building/#building-on-harmony","text":"The simplest way to build on Harmony is to follow the tutorials in this section. They come complete with examples and sample code. Harmony provides hosted endpoints which makes it simple for developers to deploy smart contracts to a testnet without needing to run a blockchain locally. For more advanced users you will also find instructions for developing locally.","title":"Building on Harmony"},{"location":"develop/connecting/","text":"Harmony Development Environments Harmony provides hosted endpoints on all of it's networks to simplify the development and integration process. You can also deploy your own node with endpoints enabled if you wish to develop your own infrastructure. Similar to Ethereum harmony provides JSON-RPC which is a remote procedure call protocol encoded in JSON. Following are a list of networks and endpoints which uou can use this API to access data from the Harmony nodes. The JSON-RPC API server runs on: Chains URLs mainnet https://api.s0.t.hmny.io testnet https://api.s0.b.hmny.io localnet http://localhost:9500 Web sockets can also be used Chains URLs mainnet wss://ws.s0.t.hmny.io testnet wss://ws.s0.b.hmny.io localnet wss://localhost:9800","title":"Connecting"},{"location":"develop/connecting/#harmony-development-environments","text":"Harmony provides hosted endpoints on all of it's networks to simplify the development and integration process. You can also deploy your own node with endpoints enabled if you wish to develop your own infrastructure. Similar to Ethereum harmony provides JSON-RPC which is a remote procedure call protocol encoded in JSON. Following are a list of networks and endpoints which uou can use this API to access data from the Harmony nodes. The JSON-RPC API server runs on: Chains URLs mainnet https://api.s0.t.hmny.io testnet https://api.s0.b.hmny.io localnet http://localhost:9500 Web sockets can also be used Chains URLs mainnet wss://ws.s0.t.hmny.io testnet wss://ws.s0.b.hmny.io localnet wss://localhost:9800","title":"Harmony Development Environments"},{"location":"develop/contribute/","text":"Contributing to Harmony Codebase Overview Harmony uses a fork-based workflow for contributing code. You can find instructions on how to contribute here . For more information about git in general please read the documentation and information on local-branching . Git Cheat Sheets DISCLAIMER: This is NOT a team policy document. It\u2019s a collection of best practices FYI. Fork-based Workflow Create fork \u2013 once per each repo If you haven\u2019t yet, \u201cgo get\u201d the main repo to clone it into $GOPATH/src : go get github.com/harmony-one/harmony Go to the GitHub page of the main repo, such as https://github.com/harmony-one/harmony . Fork into your own account ( astralblue , mikedoan , LeoHChen , rlan35 \u2026) Do not clone the fork. Instead, add your fork as a remote in the main clone , and push to it by default (substitute your account name, such as LeoHChen , for the ME placeholder below) cd ~/go/src/github.com/harmony-one/harmony git remote add -f ME git@github.com:ME/harmony git config --local --replace-all remote.pushDefault ME ## For johnwhitton it's as follows cd ~/go/src/github.com/harmony-one/harmony git remote add -f johnwhitton git@github.com:johnwhitton/harmony git config --local --replace-all remote.pushDefault johnwhitton Start a working branch Create a branch in your local clone (choose a name, then substitute it for the MY_WORK placeholder below), making it track the target branch where you will eventually be merging into ( origin/master for example): git checkout -b MY_WORK --track origin/master git pull Hack away! Sync with upstream Commit or stash your local changes away. A simple pull would merge (rebase if --rebase ) upstream update into your working copy: text `git pull` If you stashed your local changes, bring them back. Keep hacking! Checkpoint/publish your progress A simple push would back your progress up in your own fork: text `git push` Keep hacking! File a pull request Visit this URL (replace the ME and MY_WORK placeholders with your username and branch): https://github.com/ME/harmony/pull/new/MY_WORK Note : For convenience, the above URL is shown on the first push to your fork. Examine the pull request page. Make sure: i. The \u201cbase repository\u201d and \u201cbase\u201d are the target text \\(such as harmony-one master\\); ii. The \u201chead repository\u201d and \u201ccompare\u201d are the source text \\(that is, your fork & branch\\). Proceed to open a pull request. Some examples Forking the harmony repo and creating your first pull request # Get the harmony repo go get github.com/harmony-one/harmony # Add your fork cd ~/go/src/github.com/harmony-one/harmony git remote add -f john git@github.com:john-harmony/harmony git config --local --replace-all remote.pushDefault john # Synch your master branch with origin git checkout master git fetch origin ## Add your branch git checkout -b swagger-update --track origin/master # Push to your local repo git push # Create a pull request Release Management - Merging Master into t3 (for OSTN build) git status git checkout master git clean -fdx git fetch origin git log --pretty=oneline git push john HEAD:merge-master-t3-0404 # Create PR (into the t3 branch on harmony repo) # Merger the PR (do not squash merge) # Delete the branch","title":"Contributing to Harmony Codebase"},{"location":"develop/contribute/#contributing-to-harmony-codebase","text":"","title":"Contributing to Harmony Codebase"},{"location":"develop/contribute/#overview","text":"Harmony uses a fork-based workflow for contributing code. You can find instructions on how to contribute here . For more information about git in general please read the documentation and information on local-branching .","title":"Overview"},{"location":"develop/contribute/#git-cheat-sheets","text":"DISCLAIMER: This is NOT a team policy document. It\u2019s a collection of best practices FYI.","title":"Git Cheat Sheets"},{"location":"develop/contribute/#fork-based-workflow","text":"","title":"Fork-based Workflow"},{"location":"develop/contribute/#create-fork-once-per-each-repo","text":"If you haven\u2019t yet, \u201cgo get\u201d the main repo to clone it into $GOPATH/src : go get github.com/harmony-one/harmony Go to the GitHub page of the main repo, such as https://github.com/harmony-one/harmony . Fork into your own account ( astralblue , mikedoan , LeoHChen , rlan35 \u2026) Do not clone the fork. Instead, add your fork as a remote in the main clone , and push to it by default (substitute your account name, such as LeoHChen , for the ME placeholder below) cd ~/go/src/github.com/harmony-one/harmony git remote add -f ME git@github.com:ME/harmony git config --local --replace-all remote.pushDefault ME ## For johnwhitton it's as follows cd ~/go/src/github.com/harmony-one/harmony git remote add -f johnwhitton git@github.com:johnwhitton/harmony git config --local --replace-all remote.pushDefault johnwhitton","title":"Create fork \u2013 once per each repo"},{"location":"develop/contribute/#start-a-working-branch","text":"Create a branch in your local clone (choose a name, then substitute it for the MY_WORK placeholder below), making it track the target branch where you will eventually be merging into ( origin/master for example): git checkout -b MY_WORK --track origin/master git pull Hack away!","title":"Start a working branch"},{"location":"develop/contribute/#sync-with-upstream","text":"Commit or stash your local changes away. A simple pull would merge (rebase if --rebase ) upstream update into your working copy: text `git pull` If you stashed your local changes, bring them back. Keep hacking!","title":"Sync with upstream"},{"location":"develop/contribute/#checkpointpublish-your-progress","text":"A simple push would back your progress up in your own fork: text `git push` Keep hacking!","title":"Checkpoint/publish your progress"},{"location":"develop/contribute/#file-a-pull-request","text":"Visit this URL (replace the ME and MY_WORK placeholders with your username and branch): https://github.com/ME/harmony/pull/new/MY_WORK Note : For convenience, the above URL is shown on the first push to your fork. Examine the pull request page. Make sure: i. The \u201cbase repository\u201d and \u201cbase\u201d are the target text \\(such as harmony-one master\\); ii. The \u201chead repository\u201d and \u201ccompare\u201d are the source text \\(that is, your fork & branch\\). Proceed to open a pull request.","title":"File a pull request"},{"location":"develop/contribute/#some-examples","text":"","title":"Some examples"},{"location":"develop/contribute/#forking-the-harmony-repo-and-creating-your-first-pull-request","text":"# Get the harmony repo go get github.com/harmony-one/harmony # Add your fork cd ~/go/src/github.com/harmony-one/harmony git remote add -f john git@github.com:john-harmony/harmony git config --local --replace-all remote.pushDefault john # Synch your master branch with origin git checkout master git fetch origin ## Add your branch git checkout -b swagger-update --track origin/master # Push to your local repo git push # Create a pull request","title":"Forking the harmony repo and creating your first pull request"},{"location":"develop/contribute/#release-management-merging-master-into-t3-for-ostn-build","text":"git status git checkout master git clean -fdx git fetch origin git log --pretty=oneline git push john HEAD:merge-master-t3-0404 # Create PR (into the t3 branch on harmony repo) # Merger the PR (do not squash merge) # Delete the branch","title":"Release Management - Merging Master into t3 (for OSTN build)"},{"location":"develop/deploy-hrc-token/","text":"Deploy HRC Token Overview This sample project can be used to deploy an HRC token on Harmony's local, testnet and mainnet. Pre-requisites HRC token use the same standard as ERC-20 see ERC-20 Token Standard Step 1: Install Truffle Be careful, we want to install the specific truffle version 5.0.38 $ npm install -g truffle@5.0.38 See at the end of truffle-config.js, we list which version of compiler needed! compilers: { solc: { version: \"0.5.8\", } } Step 2: clone the repo and set-up the environment 2.1) Clone the HRC repo Before you begin, make sure you have your SSH keys set up to communicate with Github $ git clone git@github.com:harmony-one/HRC.git We provide .envSample for you to show how to set your .env file. for now, you can just copy and rename it as .env , you could customize it later. $ cd HRC $ cp .envSample .env Step 3: Compile the Contract We use truffle to compile the contract: $ truffle compile Step 4: Deploy smart contract Sample: Deploy Smart Contract to testnet $ truffle migrate --network testnet --reset Actually, if you open the Truffle-config.js and .env , you could see that we set up three networks for you to choose deploy the smart-contract. You could try them both! Local Test-net main-net # for local $ truffle migrate --network local --reset # for mainnet $ truffle migrate --network mainnet0 --reset Step 5: List the Smart Contract on networks This command will list all the smart contract you deployed on all the networks $ truffle networks Reference Here list some references may useful for you to get more deep-understanding of this topic! OpenZepplin: https://docs.openzeppelin.com/contracts/2.x/tokens Truffle: https://www.trufflesuite.com/docs/truffle/overview","title":"Deploy a HRC Token"},{"location":"develop/deploy-hrc-token/#deploy-hrc-token","text":"","title":"Deploy HRC Token"},{"location":"develop/deploy-hrc-token/#overview","text":"This sample project can be used to deploy an HRC token on Harmony's local, testnet and mainnet.","title":"Overview"},{"location":"develop/deploy-hrc-token/#pre-requisites","text":"HRC token use the same standard as ERC-20 see ERC-20 Token Standard","title":"Pre-requisites"},{"location":"develop/deploy-hrc-token/#step-1-install-truffle","text":"Be careful, we want to install the specific truffle version 5.0.38 $ npm install -g truffle@5.0.38 See at the end of truffle-config.js, we list which version of compiler needed! compilers: { solc: { version: \"0.5.8\", } }","title":"Step 1: Install Truffle"},{"location":"develop/deploy-hrc-token/#step-2-clone-the-repo-and-set-up-the-environment","text":"","title":"Step 2: clone the repo and set-up the environment"},{"location":"develop/deploy-hrc-token/#21-clone-the-hrc-repo","text":"Before you begin, make sure you have your SSH keys set up to communicate with Github $ git clone git@github.com:harmony-one/HRC.git We provide .envSample for you to show how to set your .env file. for now, you can just copy and rename it as .env , you could customize it later. $ cd HRC $ cp .envSample .env","title":"2.1) Clone the HRC repo"},{"location":"develop/deploy-hrc-token/#step-3-compile-the-contract","text":"We use truffle to compile the contract: $ truffle compile","title":"Step 3: Compile the Contract"},{"location":"develop/deploy-hrc-token/#step-4-deploy-smart-contract","text":"Sample: Deploy Smart Contract to testnet $ truffle migrate --network testnet --reset Actually, if you open the Truffle-config.js and .env , you could see that we set up three networks for you to choose deploy the smart-contract. You could try them both! Local Test-net main-net # for local $ truffle migrate --network local --reset # for mainnet $ truffle migrate --network mainnet0 --reset","title":"Step 4: Deploy smart contract"},{"location":"develop/deploy-hrc-token/#step-5-list-the-smart-contract-on-networks","text":"This command will list all the smart contract you deployed on all the networks $ truffle networks","title":"Step 5: List the Smart Contract on networks"},{"location":"develop/deploy-hrc-token/#reference","text":"Here list some references may useful for you to get more deep-understanding of this topic! OpenZepplin: https://docs.openzeppelin.com/contracts/2.x/tokens Truffle: https://www.trufflesuite.com/docs/truffle/overview","title":"Reference"},{"location":"develop/deploy-new-project/","text":"Deploy Smart Contract (using truffle) Step 1: Prepare an Empty Project We start from an empty project! Find any place you like, and create a project folder $ mkdir whatEverYouLike $ cd whatEverYouLike Step 2: Truffle Initialize We use truffle init to create a bare Truffle project with no smart contracts included $ Truffle init Once the operation is completed, you'll now have project structure with the following items: contracts/: Directory of Solidity contracts migrations/: Directory of scriptable deployment files test/: Directory for test files for testing your application and contracts truffle-config.js : Truffle configuration file Reference: Truffle Create a Project Step 3: NPM Initialize Create the package.json for the new project by using npm init $ npm init Step 4: Install Harmony SDK For this step, you can open the instruction of this page to get more information and details. $ npm install @harmony-js/core@next $ npm install tslib Step 5: Change Truffle-config and add .env from HRC repo Install dotenv dotenv is a zero-dependency module that loads environment variables from a .env file into process.env npm install dotenv Because we will use truffle to interact with our JS-SDK, so we should set-up our network(harmony local/ Test-net/ main-net) for it. I will list the truffle-config and .env here, so you could just copy! However, If you want to know why we need to do that, please read the comment and the code carefully. .env // Local net-work // Local uses account one103q7qe5t2505lypvltkqtddaef5tzfxwsse4z7 on Shard 0 LOCAL_PRIVATE_KEY='45e497bd45a9049bcb649016594489ac67b9f052a6cdf5cb74ee2427a60bf25e' LOCAL_MNEMONIC='urge clog right example dish drill card maximum mix bachelor section select' LOCAL_0_URL='http://localhost:9500' GAS_LIMIT=3321900 GAS_PRICE=1000000000 truffle-config * Use this file to configure your truffle project. It's seeded with some * common settings for different networks and features like migrations, * compilation and testing. Uncomment the ones you need or modify * them to suit your project as necessary. * * More information about configuration can be found at: * * truffleframework.com/docs/advanced/configuration * * To deploy via Infura you'll need a wallet provider (like truffle-hdwallet-provider) * to sign your transactions before they're sent to a remote public node. Infura accounts * are available for free at: infura.io/register. * * You'll also need a mnemonic - the twelve word phrase the wallet uses to generate * public/private key pairs. If you're publishing your code to GitHub make sure you load this * phrase from a file you've .gitignored so it doesn't accidentally become public. * */ require('dotenv').config() const { TruffleProvider } = require('@harmony-js/core') //Local const local_mnemonic = process.env.LOCAL_MNEMONIC const local_private_key = process.env.LOCAL_PRIVATE_KEY const local_url = process.env.LOCAL_0_URL; //GAS - Currently using same GAS accross all environments gasLimit = process.env.GAS_LIMIT gasPrice = process.env.GAS_PRICE module.exports = { /** * Networks define how you connect to your client and let you * send transactions. If you don't specify one truffle * You can ask a truffle command to use a specific * network from the command line, e.g * * $ truffle test --network <network-name> */ networks: { local: { network_id: '2', provider: () => { const truffleProvider = new TruffleProvider( local_url, { memonic: local_mnemonic }, { shardID: 0, chainId: 2 }, { gasLimit: gasLimit, gasPrice: gasPrice}, ); const newAcc = truffleProvider.addByPrivateKey(local_private_key); truffleProvider.setSigner(newAcc); return truffleProvider; }, }, }, mocha: { }, // Configure your compilers compilers: { solc: { version: \"0.5.8\" } } } Step 6: Create your Smart-Contract For this step, we will create a very simple smart Contract, just make sure you can read message from it and can write message to it, for more complicate things, see the next tutorial :) 6.1: Create a file named Inbox.sol under the contracts folder, and copy the follow code into it. pragma solidity >= 0.4.17; contract Inbox { string public message; constructor() public { message = \"hello\"; } function setMessage(string memory newMessage) public { message = newMessage; } } 6.2: Create a file named 2_deploy_contracts.js under migrations folder, and copy the follow code into it! var Inbox = artifacts.require(\"Inbox\"); module.exports = function(deployer) { deployer.deploy(Inbox); }; Step 7: Compile your Contract Now, it's time to compile your contract and deploy it on the local net-work $ truffle compile Remember to run your harmony local before you migrate your contract to it!! if you don't know how to do it? Please check the Deploy Harmony Locally $ truffle migrate --network local --reset Step 8: Test it! Now, you smart contract should be deployed successful, it's time to test it!! Create a file named inbox.test.js under the test folder, and copy the follow code. \ud83d\ude07The comments will explain in the code, please read it! const { Harmony } = require('@harmony-js/core'); const { ChainID, ChainType } = require('@harmony-js/utils'); // hmy is the instance of our sdk, like web3 const url = `ws://localhost:9800`; const hmy = new Harmony(url, { chainType: ChainType.Harmony, chainId: ChainID.HmyLocal }); const privateKey = '45e497bd45a9049bcb649016594489ac67b9f052a6cdf5cb74ee2427a60bf25e'; const myAccount = hmy.wallet.addByPrivateKey(privateKey); myAccount.getBalance().then(res => { console.log(`-- hint: account balance of ${myAccount.address}`) console.log(``) console.log({ account: res }) console.log(``) console.log(``) }) console.log(myAccount.address); const inboxJson = require('../build/contracts/Inbox.json'); const getContractInstance = (hmy, artifact) => { return hmy.contracts.createContract(artifact.abi, artifact.networks[2].address); } const inbox = getContractInstance(hmy, inboxJson); contract(\"Inbox\", (myAccount) => { // test 1: make sure the contract is deployed it('deploys a contract', () => { assert.ok(inbox.address); console.log(inbox.address); }); // test 2: make sure you can get message from the contract. it('has a default message', async () => { const message = await inbox.methods.message().call({ gasLimit: '1000000', gasPrice: new hmy.utils.Unit('10').asGwei().toWei(), }); console.log(message); assert.equal(message, '345'); }); // test 3: make sure you can write message into the contract. it('can change the message', async () => { inbox.methods.setMessage(\"666\").send({from: myAccount}); }); }); Finally, run this code to test it! $ truffle test Congratulations! You deployed a smart contract!","title":"Deploy a new Project"},{"location":"develop/deploy-new-project/#deploy-smart-contract-using-truffle","text":"","title":"Deploy Smart Contract (using truffle)"},{"location":"develop/deploy-new-project/#step-1-prepare-an-empty-project","text":"We start from an empty project! Find any place you like, and create a project folder $ mkdir whatEverYouLike $ cd whatEverYouLike","title":"Step 1: Prepare an Empty Project"},{"location":"develop/deploy-new-project/#step-2-truffle-initialize","text":"We use truffle init to create a bare Truffle project with no smart contracts included $ Truffle init Once the operation is completed, you'll now have project structure with the following items: contracts/: Directory of Solidity contracts migrations/: Directory of scriptable deployment files test/: Directory for test files for testing your application and contracts truffle-config.js : Truffle configuration file Reference: Truffle Create a Project","title":"Step 2: Truffle Initialize"},{"location":"develop/deploy-new-project/#step-3-npm-initialize","text":"Create the package.json for the new project by using npm init $ npm init","title":"Step 3: NPM Initialize"},{"location":"develop/deploy-new-project/#step-4-install-harmony-sdk","text":"For this step, you can open the instruction of this page to get more information and details. $ npm install @harmony-js/core@next $ npm install tslib","title":"Step 4: Install Harmony SDK"},{"location":"develop/deploy-new-project/#step-5-changetruffle-config-and-add-env-from-hrc-repo","text":"","title":"Step 5: ChangeTruffle-config and add .env from HRC repo"},{"location":"develop/deploy-new-project/#install-dotenv","text":"dotenv is a zero-dependency module that loads environment variables from a .env file into process.env npm install dotenv Because we will use truffle to interact with our JS-SDK, so we should set-up our network(harmony local/ Test-net/ main-net) for it. I will list the truffle-config and .env here, so you could just copy! However, If you want to know why we need to do that, please read the comment and the code carefully.","title":"Install dotenv"},{"location":"develop/deploy-new-project/#env","text":"// Local net-work // Local uses account one103q7qe5t2505lypvltkqtddaef5tzfxwsse4z7 on Shard 0 LOCAL_PRIVATE_KEY='45e497bd45a9049bcb649016594489ac67b9f052a6cdf5cb74ee2427a60bf25e' LOCAL_MNEMONIC='urge clog right example dish drill card maximum mix bachelor section select' LOCAL_0_URL='http://localhost:9500' GAS_LIMIT=3321900 GAS_PRICE=1000000000","title":".env"},{"location":"develop/deploy-new-project/#truffle-config","text":"* Use this file to configure your truffle project. It's seeded with some * common settings for different networks and features like migrations, * compilation and testing. Uncomment the ones you need or modify * them to suit your project as necessary. * * More information about configuration can be found at: * * truffleframework.com/docs/advanced/configuration * * To deploy via Infura you'll need a wallet provider (like truffle-hdwallet-provider) * to sign your transactions before they're sent to a remote public node. Infura accounts * are available for free at: infura.io/register. * * You'll also need a mnemonic - the twelve word phrase the wallet uses to generate * public/private key pairs. If you're publishing your code to GitHub make sure you load this * phrase from a file you've .gitignored so it doesn't accidentally become public. * */ require('dotenv').config() const { TruffleProvider } = require('@harmony-js/core') //Local const local_mnemonic = process.env.LOCAL_MNEMONIC const local_private_key = process.env.LOCAL_PRIVATE_KEY const local_url = process.env.LOCAL_0_URL; //GAS - Currently using same GAS accross all environments gasLimit = process.env.GAS_LIMIT gasPrice = process.env.GAS_PRICE module.exports = { /** * Networks define how you connect to your client and let you * send transactions. If you don't specify one truffle * You can ask a truffle command to use a specific * network from the command line, e.g * * $ truffle test --network <network-name> */ networks: { local: { network_id: '2', provider: () => { const truffleProvider = new TruffleProvider( local_url, { memonic: local_mnemonic }, { shardID: 0, chainId: 2 }, { gasLimit: gasLimit, gasPrice: gasPrice}, ); const newAcc = truffleProvider.addByPrivateKey(local_private_key); truffleProvider.setSigner(newAcc); return truffleProvider; }, }, }, mocha: { }, // Configure your compilers compilers: { solc: { version: \"0.5.8\" } } }","title":"truffle-config"},{"location":"develop/deploy-new-project/#step-6-create-your-smart-contract","text":"For this step, we will create a very simple smart Contract, just make sure you can read message from it and can write message to it, for more complicate things, see the next tutorial :) 6.1: Create a file named Inbox.sol under the contracts folder, and copy the follow code into it. pragma solidity >= 0.4.17; contract Inbox { string public message; constructor() public { message = \"hello\"; } function setMessage(string memory newMessage) public { message = newMessage; } } 6.2: Create a file named 2_deploy_contracts.js under migrations folder, and copy the follow code into it! var Inbox = artifacts.require(\"Inbox\"); module.exports = function(deployer) { deployer.deploy(Inbox); };","title":"Step 6: Create your Smart-Contract"},{"location":"develop/deploy-new-project/#step-7-compile-your-contract","text":"Now, it's time to compile your contract and deploy it on the local net-work $ truffle compile Remember to run your harmony local before you migrate your contract to it!! if you don't know how to do it? Please check the Deploy Harmony Locally $ truffle migrate --network local --reset","title":"Step 7: Compile your Contract"},{"location":"develop/deploy-new-project/#step-8-test-it","text":"Now, you smart contract should be deployed successful, it's time to test it!! Create a file named inbox.test.js under the test folder, and copy the follow code. \ud83d\ude07The comments will explain in the code, please read it! const { Harmony } = require('@harmony-js/core'); const { ChainID, ChainType } = require('@harmony-js/utils'); // hmy is the instance of our sdk, like web3 const url = `ws://localhost:9800`; const hmy = new Harmony(url, { chainType: ChainType.Harmony, chainId: ChainID.HmyLocal }); const privateKey = '45e497bd45a9049bcb649016594489ac67b9f052a6cdf5cb74ee2427a60bf25e'; const myAccount = hmy.wallet.addByPrivateKey(privateKey); myAccount.getBalance().then(res => { console.log(`-- hint: account balance of ${myAccount.address}`) console.log(``) console.log({ account: res }) console.log(``) console.log(``) }) console.log(myAccount.address); const inboxJson = require('../build/contracts/Inbox.json'); const getContractInstance = (hmy, artifact) => { return hmy.contracts.createContract(artifact.abi, artifact.networks[2].address); } const inbox = getContractInstance(hmy, inboxJson); contract(\"Inbox\", (myAccount) => { // test 1: make sure the contract is deployed it('deploys a contract', () => { assert.ok(inbox.address); console.log(inbox.address); }); // test 2: make sure you can get message from the contract. it('has a default message', async () => { const message = await inbox.methods.message().call({ gasLimit: '1000000', gasPrice: new hmy.utils.Unit('10').asGwei().toWei(), }); console.log(message); assert.equal(message, '345'); }); // test 3: make sure you can write message into the contract. it('can change the message', async () => { inbox.methods.setMessage(\"666\").send({from: myAccount}); }); }); Finally, run this code to test it! $ truffle test","title":"Step 8: Test it!"},{"location":"develop/deploy-new-project/#congratulations-you-deployed-a-smart-contract","text":"","title":"Congratulations! You deployed a smart contract!"},{"location":"develop/deploy-your-first-dapp/","text":"Deploy your First Dapp (Lottery) Part 1: Lottery Contract Step 1: Set up the environment! $ truffle init Install Harmony SDK $ npm install @harmony-js/core@next $ npm install tslib Change truffle-config and add .env Don't forget to install dotenv $ npm isntall dotenv Truffle-config require('dotenv').config() const { TruffleProvider } = require('@harmony-js/core') //Local const local_mnemonic = process.env.LOCAL_MNEMONIC const local_private_key = process.env.LOCAL_PRIVATE_KEY const local_url = process.env.LOCAL_0_URL; //Testnet const testnet_mnemonic = process.env.TESTNET_MNEMONIC const testnet_private_key = process.env.TESTNET_PRIVATE_KEY const testnet_url = process.env.TESTNET_0_URL //Mainnet const mainnet_mnemonic = process.env.MAINNET_MNEMONIC const mainnet_private_key = process.env.MAINNET_PRIVATE_KEY const mainnet_url = process.env.MAINNET_0_URL; //GAS - Currently using same GAS accross all environments gasLimit = process.env.GAS_LIMIT gasPrice = process.env.GAS_PRICE module.exports = { networks: { local: { network_id: '2', provider: () => { const truffleProvider = new TruffleProvider( local_url, { memonic: local_mnemonic }, { shardID: 0, chainId: 2 }, { gasLimit: gasLimit, gasPrice: gasPrice}, ); const newAcc = truffleProvider.addByPrivateKey(local_private_key); truffleProvider.setSigner(newAcc); return truffleProvider; }, }, testnet: { network_id: '2', provider: () => { const truffleProvider = new TruffleProvider( testnet_url, { memonic: testnet_mnemonic }, { shardID: 0, chainId: 2 }, { gasLimit: gasLimit, gasPrice: gasPrice}, ); const newAcc = truffleProvider.addByPrivateKey(testnet_private_key); truffleProvider.setSigner(newAcc); return truffleProvider; }, }, mainnet: { network_id: '1', provider: () => { const truffleProvider = new TruffleProvider( mainnet_url, { memonic: mainnet_mnemonic }, { shardID: 0, chainId: 1 }, { gasLimit: gasLimit, gasPrice: gasPrice }, ); const newAcc = truffleProvider.addByPrivateKey(mainnet_private_key); truffleProvider.setSigner(newAcc); return truffleProvider; }, }, }, mocha: { }, // Configure your compilers compilers: { solc: { version: \"0.5.8\" } } } .env //LOCAL //Local uses account one103q7qe5t2505lypvltkqtddaef5tzfxwsse4z7 on Shard 0 LOCAL_PRIVATE_KEY='45e497bd45a9049bcb649016594489ac67b9f052a6cdf5cb74ee2427a60bf25e' LOCAL_MNEMONIC='urge clog right example dish drill card maximum mix bachelor section select' LOCAL_0_URL='http://localhost:9500' //TESTNET //Account: one18t4yj4fuutj83uwqckkvxp9gfa0568uc48ggj7 TESTNET_PRIVATE_KEY='01F903CE0C960FF3A9E68E80FF5FFC344358D80CE1C221C3F9711AF07F83A3BD' TESTNET_MNEMONIC='urge clog right example dish drill card maximum mix bachelor section select' TESTNET_0_URL='https://api.s0.b.hmny.io' //MAINNET //Please replace MAINNET_PRIVATE_KEY and MAINNET_MNEMONIC with your own! //Account: one18t4yj4fuutj83uwqckkvxp9gfa0568uc48ggj7 MAINNET_PRIVATE_KEY='01F903CE0C960FF3A9E68E80FF5FFC344358D80CE1C221C3F9711AF07F83A3BD' MAINNET_MNEMONIC='urge clog right example dish drill card maximum mix bachelor section select' MAINNET_0_URL='https://api.s0.t.hmny.io' GAS_LIMIT=3321900 GAS_PRICE=1000000000 Step 2: Create your Smart Contract (lottery) Create a file name Lottery.sol under contracts folder. {% hint style=\"info\" %} Write smart contract by using Solidity which is a language designed for implementing smart contracts. Solidity Documentation {% endhint %} pragma solidity >=0.5.8; contract Lottery { address payable public manager; address payable[] public players; modifier restricted { require(msg.sender == manager); _; // '_': run all the reset of codes inside the function. } constructor() public { manager = msg.sender; } function enter() public payable { players.push(msg.sender); } // Pseudo Random Number Generator (Not exist in solidity, should write by ourself) function random() private view returns (uint) { return uint(uint(keccak256(abi.encodePacked(block.difficulty,now,players)))); } function pickWinner() public restricted { uint index = random() % players.length; players[index].transfer(address(this).balance); resetPlayers(); } function resetPlayers() private { players = new address payable[](0); } function getPlayers() public view returns (address payable[] memory) { return players; } } {% hint style=\"info\" %} After creating the contract, you could use remix to test it! Remix is an online IDE designed for smart-contract, is very useful! {% endhint %} Create the file 2_deploy_contracts.js under migrations folder var Lottery = artifacts.require(\"Lottery\"); module.exports = function(deployer) { deployer.deploy(Lottery); }; Compile and deploy the contract! $ truffle compile $ truffle migrate --network local --reset $ truffle migrate --network testnet --reset Part 2: Lottery Frontend This contract required MathWallet to sign the transaction! Please install it before continue and setting the network to the corresponding endpoints local: http://127.0.0.1:9500 testnet: https://api.s0.b.hmny.io Much more details will list in the subfolders Using react to create an front-end module We used the create-react-app to generate a simple front-end for our app // do that if you never used create-react-app before $ sudo npm install -g create-react-app $ create-react-app frontend(NAME) Install Harmony js SDK $ npm install @harmony-js/core@next $ npm install tslib After that, Create a file named lottery.js which would be used for create the instance of contract remember to replace the address to your smart-contract address which could be found when you deploy your contract const { Harmony, HarmonyExtension } = require('@harmony-js/core'); const { ChainID, ChainType } = require('@harmony-js/utils'); const url = 'http://localhost:9500'; const hmy = new Harmony(url, { chainType: ChainType.Harmony, chainId: ChainID.HmyLocal }); // replace the address to your smart-contract address const address = '0x2C85312662258F7cc063E421DCF16bb0189b0531'; // this abi could be found in this path: contract/build/contracts/Lottery.json const abi = [ { \"constant\": true, \"inputs\": [], \"name\": \"manager\", \"outputs\": [ { \"name\": \"\", \"type\": \"address\" } ], \"payable\": false, \"stateMutability\": \"view\", \"type\": \"function\" }, { \"constant\": true, \"inputs\": [ { \"name\": \"\", \"type\": \"uint256\" } ], \"name\": \"players\", \"outputs\": [ { \"name\": \"\", \"type\": \"address\" } ], \"payable\": false, \"stateMutability\": \"view\", \"type\": \"function\" }, { \"inputs\": [], \"payable\": false, \"stateMutability\": \"nonpayable\", \"type\": \"constructor\" }, { \"constant\": false, \"inputs\": [], \"name\": \"enter\", \"outputs\": [], \"payable\": true, \"stateMutability\": \"payable\", \"type\": \"function\" }, { \"constant\": false, \"inputs\": [], \"name\": \"pickWinner\", \"outputs\": [], \"payable\": false, \"stateMutability\": \"nonpayable\", \"type\": \"function\" }, { \"constant\": true, \"inputs\": [], \"name\": \"getPlayers\", \"outputs\": [ { \"name\": \"\", \"type\": \"address[]\" } ], \"payable\": false, \"stateMutability\": \"view\", \"type\": \"function\" } ]; export const waitForInjected = () => new Promise((resolve) => { const check = () => { if (!window.harmony) setTimeout(check, 250); else resolve(window.harmony); } check(); }); let harmonyEx, extLottery; export const initExtension = async() => { harmonyEx = await new HarmonyExtension(window.harmony); extLottery = harmonyEx.contracts.createContract(abi, address); return extLottery; }; export { hmy }; Then, change the content in App.js import React, { Component } from 'react'; import './App.css'; import { waitForInjected, initExtension, hmy } from './lottery'; class App extends Component { state = { manager: '', players: [], balance: '', value: '', message: '' }; async componentDidMount() { await waitForInjected() const extLottery = await initExtension() const manager = await extLottery.methods.manager().call({ gasLimit: '1000000', gasPrice: new hmy.utils.Unit('10').asGwei().toWei(), }); const players = await extLottery.methods.getPlayers().call({ gasLimit: '1000000', gasPrice: new hmy.utils.Unit('10').asGwei().toWei(), }); const balance = await hmy.blockchain.getBalance({address: extLottery.address}); this.setState({ manager, players, balance }); } onSubmit = async event => { event.preventDefault(); this.setState({ message: 'Waiting on transaction success...' }) const extLottery = await initExtension() await extLottery.methods.enter().send({ value: new hmy.utils.Unit(this.state.value).asOne().toWei(), gasLimit: '1000001', gasPrice: new hmy.utils.Unit('10').asGwei().toWei(), }); this.setState({ message: 'You have been entered!' }) }; onClick = async () => { this.setState({ message: 'Waiting on transaction success...' }); const extLottery = await initExtension() await extLottery.methods.pickWinner().send({ gasLimit: '1000000', gasPrice: new hmy.utils.Unit('10').asGwei().toWei(), }); this.setState({ message: 'A winner has been picked!' }); }; render() { return ( <div> <h2> Lottery Contract </h2> <p> This contract is managed by {this.state.manager}. <br /> There are currently {this.state.players.length} people entered, <br /> </p> <hr /> <form onSubmit={this.onSubmit}> <h4>Want to try your luck?</h4> <div> <label>Amount of ONE to enter</label> <input value={this.state.value} onChange={event => this.setState({ value: event.target.value })} /> </div> <button>Enter</button> </form> <hr /> <h4> Ready to pick a winner?</h4> <button onClick={this.onClick}>Pick a Winner!</button> <hr /> <h1>{this.state.message}</h1> </div> ); }; } export default App; Now the dapp should be finished! Using npm start to try it! npm start More examples can be found in the HRC Repository Congratulations you have deployed your first Dapp!!","title":"Deploy your first DApp"},{"location":"develop/deploy-your-first-dapp/#deploy-your-first-dapp-lottery","text":"","title":"Deploy your First Dapp (Lottery)"},{"location":"develop/deploy-your-first-dapp/#part-1-lottery-contract","text":"","title":"Part 1: Lottery Contract"},{"location":"develop/deploy-your-first-dapp/#step-1-set-up-the-environment","text":"$ truffle init","title":"Step 1: Set up the environment!"},{"location":"develop/deploy-your-first-dapp/#install-harmony-sdk","text":"$ npm install @harmony-js/core@next $ npm install tslib Change truffle-config and add .env Don't forget to install dotenv $ npm isntall dotenv Truffle-config require('dotenv').config() const { TruffleProvider } = require('@harmony-js/core') //Local const local_mnemonic = process.env.LOCAL_MNEMONIC const local_private_key = process.env.LOCAL_PRIVATE_KEY const local_url = process.env.LOCAL_0_URL; //Testnet const testnet_mnemonic = process.env.TESTNET_MNEMONIC const testnet_private_key = process.env.TESTNET_PRIVATE_KEY const testnet_url = process.env.TESTNET_0_URL //Mainnet const mainnet_mnemonic = process.env.MAINNET_MNEMONIC const mainnet_private_key = process.env.MAINNET_PRIVATE_KEY const mainnet_url = process.env.MAINNET_0_URL; //GAS - Currently using same GAS accross all environments gasLimit = process.env.GAS_LIMIT gasPrice = process.env.GAS_PRICE module.exports = { networks: { local: { network_id: '2', provider: () => { const truffleProvider = new TruffleProvider( local_url, { memonic: local_mnemonic }, { shardID: 0, chainId: 2 }, { gasLimit: gasLimit, gasPrice: gasPrice}, ); const newAcc = truffleProvider.addByPrivateKey(local_private_key); truffleProvider.setSigner(newAcc); return truffleProvider; }, }, testnet: { network_id: '2', provider: () => { const truffleProvider = new TruffleProvider( testnet_url, { memonic: testnet_mnemonic }, { shardID: 0, chainId: 2 }, { gasLimit: gasLimit, gasPrice: gasPrice}, ); const newAcc = truffleProvider.addByPrivateKey(testnet_private_key); truffleProvider.setSigner(newAcc); return truffleProvider; }, }, mainnet: { network_id: '1', provider: () => { const truffleProvider = new TruffleProvider( mainnet_url, { memonic: mainnet_mnemonic }, { shardID: 0, chainId: 1 }, { gasLimit: gasLimit, gasPrice: gasPrice }, ); const newAcc = truffleProvider.addByPrivateKey(mainnet_private_key); truffleProvider.setSigner(newAcc); return truffleProvider; }, }, }, mocha: { }, // Configure your compilers compilers: { solc: { version: \"0.5.8\" } } } .env //LOCAL //Local uses account one103q7qe5t2505lypvltkqtddaef5tzfxwsse4z7 on Shard 0 LOCAL_PRIVATE_KEY='45e497bd45a9049bcb649016594489ac67b9f052a6cdf5cb74ee2427a60bf25e' LOCAL_MNEMONIC='urge clog right example dish drill card maximum mix bachelor section select' LOCAL_0_URL='http://localhost:9500' //TESTNET //Account: one18t4yj4fuutj83uwqckkvxp9gfa0568uc48ggj7 TESTNET_PRIVATE_KEY='01F903CE0C960FF3A9E68E80FF5FFC344358D80CE1C221C3F9711AF07F83A3BD' TESTNET_MNEMONIC='urge clog right example dish drill card maximum mix bachelor section select' TESTNET_0_URL='https://api.s0.b.hmny.io' //MAINNET //Please replace MAINNET_PRIVATE_KEY and MAINNET_MNEMONIC with your own! //Account: one18t4yj4fuutj83uwqckkvxp9gfa0568uc48ggj7 MAINNET_PRIVATE_KEY='01F903CE0C960FF3A9E68E80FF5FFC344358D80CE1C221C3F9711AF07F83A3BD' MAINNET_MNEMONIC='urge clog right example dish drill card maximum mix bachelor section select' MAINNET_0_URL='https://api.s0.t.hmny.io' GAS_LIMIT=3321900 GAS_PRICE=1000000000","title":"Install Harmony SDK"},{"location":"develop/deploy-your-first-dapp/#step-2-create-your-smart-contract-lottery","text":"","title":"Step 2: Create your Smart Contract (lottery)"},{"location":"develop/deploy-your-first-dapp/#create-a-file-name-lotterysol-under-contracts-folder","text":"{% hint style=\"info\" %} Write smart contract by using Solidity which is a language designed for implementing smart contracts. Solidity Documentation {% endhint %} pragma solidity >=0.5.8; contract Lottery { address payable public manager; address payable[] public players; modifier restricted { require(msg.sender == manager); _; // '_': run all the reset of codes inside the function. } constructor() public { manager = msg.sender; } function enter() public payable { players.push(msg.sender); } // Pseudo Random Number Generator (Not exist in solidity, should write by ourself) function random() private view returns (uint) { return uint(uint(keccak256(abi.encodePacked(block.difficulty,now,players)))); } function pickWinner() public restricted { uint index = random() % players.length; players[index].transfer(address(this).balance); resetPlayers(); } function resetPlayers() private { players = new address payable[](0); } function getPlayers() public view returns (address payable[] memory) { return players; } } {% hint style=\"info\" %} After creating the contract, you could use remix to test it! Remix is an online IDE designed for smart-contract, is very useful! {% endhint %}","title":"Create a file name Lottery.sol under contracts folder."},{"location":"develop/deploy-your-first-dapp/#create-the-file-2_deploy_contractsjs-under-migrations-folder","text":"var Lottery = artifacts.require(\"Lottery\"); module.exports = function(deployer) { deployer.deploy(Lottery); };","title":"Create the file 2_deploy_contracts.js under migrations folder"},{"location":"develop/deploy-your-first-dapp/#compile-and-deploy-the-contract","text":"$ truffle compile $ truffle migrate --network local --reset $ truffle migrate --network testnet --reset","title":"Compile and deploy the contract!"},{"location":"develop/deploy-your-first-dapp/#part-2-lottery-frontend","text":"This contract required MathWallet to sign the transaction! Please install it before continue and setting the network to the corresponding endpoints local: http://127.0.0.1:9500 testnet: https://api.s0.b.hmny.io Much more details will list in the subfolders","title":"Part 2: Lottery Frontend"},{"location":"develop/deploy-your-first-dapp/#using-react-to-create-an-front-end-module","text":"","title":"Using react to create an front-end module"},{"location":"develop/deploy-your-first-dapp/#we-used-the-create-react-app-to-generate-a-simple-front-end-for-our-app","text":"// do that if you never used create-react-app before $ sudo npm install -g create-react-app $ create-react-app frontend(NAME)","title":"We used the create-react-app to generate a simple front-end for our app"},{"location":"develop/deploy-your-first-dapp/#install-harmony-js-sdk","text":"$ npm install @harmony-js/core@next $ npm install tslib","title":"Install Harmony js SDK"},{"location":"develop/deploy-your-first-dapp/#after-that-create-a-file-named-lotteryjs-which-would-be-used-for-create-the-instance-of-contract","text":"remember to replace the address to your smart-contract address which could be found when you deploy your contract const { Harmony, HarmonyExtension } = require('@harmony-js/core'); const { ChainID, ChainType } = require('@harmony-js/utils'); const url = 'http://localhost:9500'; const hmy = new Harmony(url, { chainType: ChainType.Harmony, chainId: ChainID.HmyLocal }); // replace the address to your smart-contract address const address = '0x2C85312662258F7cc063E421DCF16bb0189b0531'; // this abi could be found in this path: contract/build/contracts/Lottery.json const abi = [ { \"constant\": true, \"inputs\": [], \"name\": \"manager\", \"outputs\": [ { \"name\": \"\", \"type\": \"address\" } ], \"payable\": false, \"stateMutability\": \"view\", \"type\": \"function\" }, { \"constant\": true, \"inputs\": [ { \"name\": \"\", \"type\": \"uint256\" } ], \"name\": \"players\", \"outputs\": [ { \"name\": \"\", \"type\": \"address\" } ], \"payable\": false, \"stateMutability\": \"view\", \"type\": \"function\" }, { \"inputs\": [], \"payable\": false, \"stateMutability\": \"nonpayable\", \"type\": \"constructor\" }, { \"constant\": false, \"inputs\": [], \"name\": \"enter\", \"outputs\": [], \"payable\": true, \"stateMutability\": \"payable\", \"type\": \"function\" }, { \"constant\": false, \"inputs\": [], \"name\": \"pickWinner\", \"outputs\": [], \"payable\": false, \"stateMutability\": \"nonpayable\", \"type\": \"function\" }, { \"constant\": true, \"inputs\": [], \"name\": \"getPlayers\", \"outputs\": [ { \"name\": \"\", \"type\": \"address[]\" } ], \"payable\": false, \"stateMutability\": \"view\", \"type\": \"function\" } ]; export const waitForInjected = () => new Promise((resolve) => { const check = () => { if (!window.harmony) setTimeout(check, 250); else resolve(window.harmony); } check(); }); let harmonyEx, extLottery; export const initExtension = async() => { harmonyEx = await new HarmonyExtension(window.harmony); extLottery = harmonyEx.contracts.createContract(abi, address); return extLottery; }; export { hmy };","title":"After that, Create a file named lottery.js which would be used for create the instance of contract"},{"location":"develop/deploy-your-first-dapp/#then-change-the-content-in-appjs","text":"import React, { Component } from 'react'; import './App.css'; import { waitForInjected, initExtension, hmy } from './lottery'; class App extends Component { state = { manager: '', players: [], balance: '', value: '', message: '' }; async componentDidMount() { await waitForInjected() const extLottery = await initExtension() const manager = await extLottery.methods.manager().call({ gasLimit: '1000000', gasPrice: new hmy.utils.Unit('10').asGwei().toWei(), }); const players = await extLottery.methods.getPlayers().call({ gasLimit: '1000000', gasPrice: new hmy.utils.Unit('10').asGwei().toWei(), }); const balance = await hmy.blockchain.getBalance({address: extLottery.address}); this.setState({ manager, players, balance }); } onSubmit = async event => { event.preventDefault(); this.setState({ message: 'Waiting on transaction success...' }) const extLottery = await initExtension() await extLottery.methods.enter().send({ value: new hmy.utils.Unit(this.state.value).asOne().toWei(), gasLimit: '1000001', gasPrice: new hmy.utils.Unit('10').asGwei().toWei(), }); this.setState({ message: 'You have been entered!' }) }; onClick = async () => { this.setState({ message: 'Waiting on transaction success...' }); const extLottery = await initExtension() await extLottery.methods.pickWinner().send({ gasLimit: '1000000', gasPrice: new hmy.utils.Unit('10').asGwei().toWei(), }); this.setState({ message: 'A winner has been picked!' }); }; render() { return ( <div> <h2> Lottery Contract </h2> <p> This contract is managed by {this.state.manager}. <br /> There are currently {this.state.players.length} people entered, <br /> </p> <hr /> <form onSubmit={this.onSubmit}> <h4>Want to try your luck?</h4> <div> <label>Amount of ONE to enter</label> <input value={this.state.value} onChange={event => this.setState({ value: event.target.value })} /> </div> <button>Enter</button> </form> <hr /> <h4> Ready to pick a winner?</h4> <button onClick={this.onClick}>Pick a Winner!</button> <hr /> <h1>{this.state.message}</h1> </div> ); }; } export default App; Now the dapp should be finished! Using npm start to try it! npm start","title":"Then, change the content in App.js"},{"location":"develop/deploy-your-first-dapp/#more-examples-can-be-found-in-the-hrc-repository","text":"","title":"More examples can be found in the HRC Repository"},{"location":"develop/deploy-your-first-dapp/#congratulations-you-have-deployed-your-first-dapp","text":"","title":"Congratulations you have deployed your first Dapp!!"},{"location":"develop/hrc-sample/","text":"Sample Files truffle_config.js require('dotenv').config() const { TruffleProvider } = require('@harmony-js/core') //Local const local_mnemonic = process.env.LOCAL_MNEMONIC const local_private_key = process.env.LOCAL_PRIVATE_KEY const local_url = process.env.LOCAL_0_URL; //Testnet const testnet_mnemonic = process.env.TESTNET_MNEMONIC const testnet_private_key = process.env.TESTNET_PRIVATE_KEY const testnet_url = process.env.TESTNET_0_URL //Mainnet const mainnet_mnemonic = process.env.MAINNET_MNEMONIC const mainnet_private_key = process.env.MAINNET_PRIVATE_KEY const mainnet_url = process.env.MAINNET_0_URL; //GAS - Currently using same GAS accross all environments gasLimit = process.env.GAS_LIMIT gasPrice = process.env.GAS_PRICE module.exports = { networks: { local: { network_id: '2', // Any network (default: none) provider: () => { const truffleProvider = new TruffleProvider( local_url, { memonic: local_mnemonic }, { shardID: 0, chainId: 2 }, { gasLimit: gasLimit, gasPrice: gasPrice}, ); const newAcc = truffleProvider.addByPrivateKey(local_private_key); truffleProvider.setSigner(newAcc); return truffleProvider; }, }, testnet: { network_id: '2', // Any network (default: none) provider: () => { const truffleProvider = new TruffleProvider( testnet_url, { memonic: testnet_mnemonic }, { shardID: 0, chainId: 2 }, { gasLimit: gasLimit, gasPrice: gasPrice}, ); const newAcc = truffleProvider.addByPrivateKey(testnet_private_key); truffleProvider.setSigner(newAcc); return truffleProvider; }, }, mainnet0: { network_id: '1', // Any network (default: none) provider: () => { const truffleProvider = new TruffleProvider( mainnet_url, { memonic: mainnet_mnemonic }, { shardID: 0, chainId: 1 }, { gasLimit: gasLimit, gasPrice: gasPrice }, ); const newAcc = truffleProvider.addByPrivateKey(mainnet_private_key); truffleProvider.setSigner(newAcc); return truffleProvider; }, }, }, // Set default mocha options here, use special reporters etc. mocha: { // timeout: 100000 }, // Configure your compilers compilers: { solc: { version: \"0.5.8\", } } } 2_deploy_HarmonyERC20.js var HarmonyERC20 = artifacts.require(\"HarmonyERC20\"); module.exports = function(deployer, network, accounts) { const name = \"HarmonyERC20\" const symbol = \"H20\" const decimals = 18 const amount = 1000000 const tokens = web3.utils.toWei(amount.toString(), 'ether') deployer.then(function() { return deployer.deploy(HarmonyERC20, name, symbol, decimals, tokens).then(function() { }); }); }; HarmonyMintable.sol pragma solidity >=0.4.21 <0.6.0; import \"openzeppelin-solidity/contracts/token/ERC20/ERC20Detailed.sol\"; import \"openzeppelin-solidity/contracts/token/ERC20/ERC20Mintable.sol\"; import \"openzeppelin-solidity/contracts/token/ERC20/ERC20.sol\"; contract HarmonyERC20 is ERC20, ERC20Detailed, ERC20Mintable { constructor(string memory _name, string memory _symbols, uint8 _decimals, uint256 _amount) ERC20Detailed(_name, _symbols, _decimals) public { _mint(msg.sender, _amount); } } HarmonyERC20.sol pragma solidity >=0.4.21 <0.6.0; import \"openzeppelin-solidity/contracts/token/ERC20/ERC20Detailed.sol\"; import \"openzeppelin-solidity/contracts/token/ERC20/ERC20.sol\"; contract HarmonyERC20 is ERC20, ERC20Detailed { constructor(string memory _name, string memory _symbols, uint8 _decimals, uint256 _amount) ERC20Detailed(_name, _symbols, _decimals) public { _mint(msg.sender, _amount); } } Package.json { \"name\": \"harmony-erc20\", \"version\": \"1.0.0\", \"description\": \"Harmony sample ERC20 deploy\", \"main\": \"truffle.js\", \"dependencies\": { \"@harmony-js/core\": \"^0.1.22\", \"dotenv\": \"^8.2.0\", \"tslib\": \"^1.10.0\", \"openzeppelin-solidity\": \"^2.2.0\" } } .env //LOCAL //Local uses account one103q7qe5t2505lypvltkqtddaef5tzfxwsse4z7 on Shard 0 LOCAL_PRIVATE_KEY='45e497bd45a9049bcb649016594489ac67b9f052a6cdf5cb74ee2427a60bf25e' LOCAL_MNEMONIC='urge clog right example dish drill card maximum mix bachelor section select' LOCAL_0_URL='http://localhost:9500' //TESTNET //Account: one18t4yj4fuutj83uwqckkvxp9gfa0568uc48ggj7 TESTNET_PRIVATE_KEY='01F903CE0C960FF3A9E68E80FF5FFC344358D80CE1C221C3F9711AF07F83A3BD' TESTNET_MNEMONIC='urge clog right example dish drill card maximum mix bachelor section select' TESTNET_0_URL='https://api.s0.b.hmny.io' TESTNET_1_URL='https://api.s1.b.hmny.io' //MAINNET //Please replace MAINNET_PRIVATE_KEY and MAINNET_MNEMONIC with your own! //Account: one18t4yj4fuutj83uwqckkvxp9gfa0568uc48ggj7 MAINNET_PRIVATE_KEY='01F903CE0C960FF3A9E68E80FF5FFC344358D80CE1C221C3F9711AF07F83A3BD' MAINNET_MNEMONIC='urge clog right example dish drill card maximum mix bachelor section select' MAINNET_0_URL='https://api.s0.t.hmny.io' GAS_LIMIT=3321900 GAS_PRICE=1000000000","title":"Sample Files"},{"location":"develop/hrc-sample/#sample-files","text":"","title":"Sample Files"},{"location":"develop/hrc-sample/#truffle_configjs","text":"require('dotenv').config() const { TruffleProvider } = require('@harmony-js/core') //Local const local_mnemonic = process.env.LOCAL_MNEMONIC const local_private_key = process.env.LOCAL_PRIVATE_KEY const local_url = process.env.LOCAL_0_URL; //Testnet const testnet_mnemonic = process.env.TESTNET_MNEMONIC const testnet_private_key = process.env.TESTNET_PRIVATE_KEY const testnet_url = process.env.TESTNET_0_URL //Mainnet const mainnet_mnemonic = process.env.MAINNET_MNEMONIC const mainnet_private_key = process.env.MAINNET_PRIVATE_KEY const mainnet_url = process.env.MAINNET_0_URL; //GAS - Currently using same GAS accross all environments gasLimit = process.env.GAS_LIMIT gasPrice = process.env.GAS_PRICE module.exports = { networks: { local: { network_id: '2', // Any network (default: none) provider: () => { const truffleProvider = new TruffleProvider( local_url, { memonic: local_mnemonic }, { shardID: 0, chainId: 2 }, { gasLimit: gasLimit, gasPrice: gasPrice}, ); const newAcc = truffleProvider.addByPrivateKey(local_private_key); truffleProvider.setSigner(newAcc); return truffleProvider; }, }, testnet: { network_id: '2', // Any network (default: none) provider: () => { const truffleProvider = new TruffleProvider( testnet_url, { memonic: testnet_mnemonic }, { shardID: 0, chainId: 2 }, { gasLimit: gasLimit, gasPrice: gasPrice}, ); const newAcc = truffleProvider.addByPrivateKey(testnet_private_key); truffleProvider.setSigner(newAcc); return truffleProvider; }, }, mainnet0: { network_id: '1', // Any network (default: none) provider: () => { const truffleProvider = new TruffleProvider( mainnet_url, { memonic: mainnet_mnemonic }, { shardID: 0, chainId: 1 }, { gasLimit: gasLimit, gasPrice: gasPrice }, ); const newAcc = truffleProvider.addByPrivateKey(mainnet_private_key); truffleProvider.setSigner(newAcc); return truffleProvider; }, }, }, // Set default mocha options here, use special reporters etc. mocha: { // timeout: 100000 }, // Configure your compilers compilers: { solc: { version: \"0.5.8\", } } }","title":"truffle_config.js"},{"location":"develop/hrc-sample/#2_deploy_harmonyerc20js","text":"var HarmonyERC20 = artifacts.require(\"HarmonyERC20\"); module.exports = function(deployer, network, accounts) { const name = \"HarmonyERC20\" const symbol = \"H20\" const decimals = 18 const amount = 1000000 const tokens = web3.utils.toWei(amount.toString(), 'ether') deployer.then(function() { return deployer.deploy(HarmonyERC20, name, symbol, decimals, tokens).then(function() { }); }); };","title":"2_deploy_HarmonyERC20.js"},{"location":"develop/hrc-sample/#harmonymintablesol","text":"pragma solidity >=0.4.21 <0.6.0; import \"openzeppelin-solidity/contracts/token/ERC20/ERC20Detailed.sol\"; import \"openzeppelin-solidity/contracts/token/ERC20/ERC20Mintable.sol\"; import \"openzeppelin-solidity/contracts/token/ERC20/ERC20.sol\"; contract HarmonyERC20 is ERC20, ERC20Detailed, ERC20Mintable { constructor(string memory _name, string memory _symbols, uint8 _decimals, uint256 _amount) ERC20Detailed(_name, _symbols, _decimals) public { _mint(msg.sender, _amount); } }","title":"HarmonyMintable.sol"},{"location":"develop/hrc-sample/#harmonyerc20sol","text":"pragma solidity >=0.4.21 <0.6.0; import \"openzeppelin-solidity/contracts/token/ERC20/ERC20Detailed.sol\"; import \"openzeppelin-solidity/contracts/token/ERC20/ERC20.sol\"; contract HarmonyERC20 is ERC20, ERC20Detailed { constructor(string memory _name, string memory _symbols, uint8 _decimals, uint256 _amount) ERC20Detailed(_name, _symbols, _decimals) public { _mint(msg.sender, _amount); } }","title":"HarmonyERC20.sol"},{"location":"develop/hrc-sample/#packagejson","text":"{ \"name\": \"harmony-erc20\", \"version\": \"1.0.0\", \"description\": \"Harmony sample ERC20 deploy\", \"main\": \"truffle.js\", \"dependencies\": { \"@harmony-js/core\": \"^0.1.22\", \"dotenv\": \"^8.2.0\", \"tslib\": \"^1.10.0\", \"openzeppelin-solidity\": \"^2.2.0\" } }","title":"Package.json"},{"location":"develop/hrc-sample/#env","text":"//LOCAL //Local uses account one103q7qe5t2505lypvltkqtddaef5tzfxwsse4z7 on Shard 0 LOCAL_PRIVATE_KEY='45e497bd45a9049bcb649016594489ac67b9f052a6cdf5cb74ee2427a60bf25e' LOCAL_MNEMONIC='urge clog right example dish drill card maximum mix bachelor section select' LOCAL_0_URL='http://localhost:9500' //TESTNET //Account: one18t4yj4fuutj83uwqckkvxp9gfa0568uc48ggj7 TESTNET_PRIVATE_KEY='01F903CE0C960FF3A9E68E80FF5FFC344358D80CE1C221C3F9711AF07F83A3BD' TESTNET_MNEMONIC='urge clog right example dish drill card maximum mix bachelor section select' TESTNET_0_URL='https://api.s0.b.hmny.io' TESTNET_1_URL='https://api.s1.b.hmny.io' //MAINNET //Please replace MAINNET_PRIVATE_KEY and MAINNET_MNEMONIC with your own! //Account: one18t4yj4fuutj83uwqckkvxp9gfa0568uc48ggj7 MAINNET_PRIVATE_KEY='01F903CE0C960FF3A9E68E80FF5FFC344358D80CE1C221C3F9711AF07F83A3BD' MAINNET_MNEMONIC='urge clog right example dish drill card maximum mix bachelor section select' MAINNET_0_URL='https://api.s0.t.hmny.io' GAS_LIMIT=3321900 GAS_PRICE=1000000000","title":".env"},{"location":"develop/hrc/","text":"Smart Contract Development using Truffle Setup Pre-requisites The following tools should be installed for local Harmony Solidity development npm install -g truffle@5.0.38 Initializing your codebase Here we make an initial folder to create your smart contracts in. For more information you can refer to truffle overview . mkdir harmonyERC20 cd harmonyERC20 truffle init Installing Harmony Core For deploying to Harmony you need to install @harmony-js/core npm install --save @harmony-js/core@next npm install --save tslib Installing additional reference libraries If developing standard ERC-20 or ERC-721 contracts than it is useful to install the open zeppelin libraries. npm install openzeppelin-solidity -s npm install --save dotenv Installing Everything at once For your convenience you can install all the dependencies by copying this package.json and running npm install Configure truffle to use Harmony To build against the Harmony instance you need to modify truffle_config.js here is a sample truffle_config.js for the Harmony Network. also, you need to copy this .env under the harmonyERC20 folder. Fund your wallet Ensure your account is funded. Add your contracts We have included two contracts needed to deploy the Harmony HRC20 token. Simply copy these files into the contracts sub-folder HarmonyMintable.sol HarmonyERC20.sol Add your migration file Finally the migration file used to deploy HarmonyERC20.sol can be copied under the migrations sub_folder 2_deploy_HarmonyERC20.js Compile and deploy your contracts The following commands are used to deploy the contract to testnet truffle compile truffle migrate --network testnet --reset truffle networks You should see the following Johns-MacBook-Pro:harmony-erc20 johnwhitton$ truffle compile Compiling your contracts... =========================== > Compiling ./contracts/HarmonyERC20.sol > Artifacts written to /Users/johnwhitton/projects/sdk/harmony-erc20/build/contracts > Compiled successfully using: - solc: 0.5.8+commit.23d335f2.Emscripten.clang Johns-MacBook-Pro:harmony-erc20 johnwhitton$ truffle migrate --network testnet --reset Compiling your contracts... =========================== > Compiling ./contracts/HarmonyMintable.sol > Artifacts written to /Users/johnwhitton/projects/sdk/harmony-erc20/build/contracts > Compiled successfully using: - solc: 0.5.8+commit.23d335f2.Emscripten.clang Migrations dry-run (simulation) =============================== > Network name: 'testnet-fork' > Network id: 2 > Block gas limit: 0x66916c 1_initial_migration.js ====================== Replacing 'Migrations' ---------------------- > block number: 202311 > block timestamp: 1569917046 > account: 0x3aea49553Ce2E478f1c0c5ACC304a84F5F4d1f98 > balance: 1073.236894617399407586 > gas used: 246329 > gas price: 2 gwei > value sent: 0 ETH > total cost: 0.000492658 ETH ------------------------------------- > Total cost: 0.000492658 ETH 2_deploy_HarmonyERC20.js ======================== Replacing 'HarmonyERC20' ------------------------ > block number: 202313 > block timestamp: 1569917053 > account: 0x3aea49553Ce2E478f1c0c5ACC304a84F5F4d1f98 > balance: 1073.233299613399407586 > gas used: 1770479 > gas price: 2 gwei > value sent: 0 ETH > total cost: 0.003540958 ETH ------------------------------------- > Total cost: 0.003540958 ETH Summary ======= > Total deployments: 2 > Final cost: 0.004033616 ETH Starting migrations... ====================== > Network name: 'testnet' > Network id: 2 > Block gas limit: 0x66916c 1_initial_migration.js ====================== Replacing 'Migrations' ---------------------- > transaction hash: 0x2f2a03ffcf9d2e4fb9314d4e35360a4c9f0580a35efc791dd4e4c4d89ea7f1eb > Blocks: 0 Seconds: 4 > contract address: 0xaE80fb77479Aa309831D411c2DC44F1EcFA703CC > block number: 202312 > block timestamp: 1569917059 > account: 0x3aea49553Ce2E478f1c0c5ACC304a84F5F4d1f98 > balance: 1073.237125946399407586 > gas used: 261329 > gas price: 1 gwei > value sent: 0 ETH > total cost: 0.000261329 ETH > Saving migration to chain. > Saving artifacts ------------------------------------- > Total cost: 0.000261329 ETH 2_deploy_HarmonyERC20.js ======================== Replacing 'HarmonyERC20' ------------------------ > transaction hash: 0xdb1ab69342770ab559c41e5df32d255bce6f59584839fba8f181a9f08010dff8 > Blocks: 0 Seconds: 4 > contract address: 0x23d048d437615A346F9f50AcF051b0279B6d9bE2 > block number: 202314 > block timestamp: 1569917075 > account: 0x3aea49553Ce2E478f1c0c5ACC304a84F5F4d1f98 > balance: 1073.235223444399407586 > gas used: 1860479 > gas price: 1 gwei > value sent: 0 ETH > total cost: 0.001860479 ETH > Saving migration to chain. > Saving artifacts ------------------------------------- > Total cost: 0.001860479 ETH Summary ======= > Total deployments: 2 > Final cost: 0.002121808 ETH Johns-MacBook-Pro:harmony-erc20 johnwhitton$ truffle networks Network: UNKNOWN (id: 5777) HarmonyERC20: 0x6C061Ff6624c408d4A7b09704c853fa26D4C6218 Migrations: 0x8AEF5F5A61420777fcfB2F3313a77292C66fb3B1 Network: development (id: 2) No contracts deployed. Network: testnet (id: 2) HarmonyERC20: 0x23d048d437615A346F9f50AcF051b0279B6d9bE2 Migrations: 0xaE80fb77479Aa309831D411c2DC44F1EcFA703CC Johns-MacBook-Pro:harmony-erc20 johnwhitton$ Your contract is now available at 0x23d048d437615A346F9f50AcF051b0279B6d9bE2","title":"Smart Contract Development using Truffle"},{"location":"develop/hrc/#smart-contract-development-using-truffle","text":"","title":"Smart Contract Development using Truffle"},{"location":"develop/hrc/#setup","text":"","title":"Setup"},{"location":"develop/hrc/#pre-requisites","text":"The following tools should be installed for local Harmony Solidity development npm install -g truffle@5.0.38","title":"Pre-requisites"},{"location":"develop/hrc/#initializing-your-codebase","text":"Here we make an initial folder to create your smart contracts in. For more information you can refer to truffle overview . mkdir harmonyERC20 cd harmonyERC20 truffle init","title":"Initializing your codebase"},{"location":"develop/hrc/#installing-harmony-core","text":"For deploying to Harmony you need to install @harmony-js/core npm install --save @harmony-js/core@next npm install --save tslib","title":"Installing Harmony Core"},{"location":"develop/hrc/#installing-additional-reference-libraries","text":"If developing standard ERC-20 or ERC-721 contracts than it is useful to install the open zeppelin libraries. npm install openzeppelin-solidity -s npm install --save dotenv","title":"Installing additional reference libraries"},{"location":"develop/hrc/#installing-everything-at-once","text":"For your convenience you can install all the dependencies by copying this package.json and running npm install","title":"Installing Everything at once"},{"location":"develop/hrc/#configure-truffle-to-use-harmony","text":"To build against the Harmony instance you need to modify truffle_config.js here is a sample truffle_config.js for the Harmony Network. also, you need to copy this .env under the harmonyERC20 folder.","title":"Configure truffle to use Harmony"},{"location":"develop/hrc/#fund-your-wallet","text":"Ensure your account is funded.","title":"Fund your wallet"},{"location":"develop/hrc/#add-your-contracts","text":"We have included two contracts needed to deploy the Harmony HRC20 token. Simply copy these files into the contracts sub-folder HarmonyMintable.sol HarmonyERC20.sol","title":"Add your contracts"},{"location":"develop/hrc/#add-your-migration-file","text":"Finally the migration file used to deploy HarmonyERC20.sol can be copied under the migrations sub_folder 2_deploy_HarmonyERC20.js","title":"Add your migration file"},{"location":"develop/hrc/#compile-and-deploy-your-contracts","text":"The following commands are used to deploy the contract to testnet truffle compile truffle migrate --network testnet --reset truffle networks You should see the following Johns-MacBook-Pro:harmony-erc20 johnwhitton$ truffle compile Compiling your contracts... =========================== > Compiling ./contracts/HarmonyERC20.sol > Artifacts written to /Users/johnwhitton/projects/sdk/harmony-erc20/build/contracts > Compiled successfully using: - solc: 0.5.8+commit.23d335f2.Emscripten.clang Johns-MacBook-Pro:harmony-erc20 johnwhitton$ truffle migrate --network testnet --reset Compiling your contracts... =========================== > Compiling ./contracts/HarmonyMintable.sol > Artifacts written to /Users/johnwhitton/projects/sdk/harmony-erc20/build/contracts > Compiled successfully using: - solc: 0.5.8+commit.23d335f2.Emscripten.clang Migrations dry-run (simulation) =============================== > Network name: 'testnet-fork' > Network id: 2 > Block gas limit: 0x66916c 1_initial_migration.js ====================== Replacing 'Migrations' ---------------------- > block number: 202311 > block timestamp: 1569917046 > account: 0x3aea49553Ce2E478f1c0c5ACC304a84F5F4d1f98 > balance: 1073.236894617399407586 > gas used: 246329 > gas price: 2 gwei > value sent: 0 ETH > total cost: 0.000492658 ETH ------------------------------------- > Total cost: 0.000492658 ETH 2_deploy_HarmonyERC20.js ======================== Replacing 'HarmonyERC20' ------------------------ > block number: 202313 > block timestamp: 1569917053 > account: 0x3aea49553Ce2E478f1c0c5ACC304a84F5F4d1f98 > balance: 1073.233299613399407586 > gas used: 1770479 > gas price: 2 gwei > value sent: 0 ETH > total cost: 0.003540958 ETH ------------------------------------- > Total cost: 0.003540958 ETH Summary ======= > Total deployments: 2 > Final cost: 0.004033616 ETH Starting migrations... ====================== > Network name: 'testnet' > Network id: 2 > Block gas limit: 0x66916c 1_initial_migration.js ====================== Replacing 'Migrations' ---------------------- > transaction hash: 0x2f2a03ffcf9d2e4fb9314d4e35360a4c9f0580a35efc791dd4e4c4d89ea7f1eb > Blocks: 0 Seconds: 4 > contract address: 0xaE80fb77479Aa309831D411c2DC44F1EcFA703CC > block number: 202312 > block timestamp: 1569917059 > account: 0x3aea49553Ce2E478f1c0c5ACC304a84F5F4d1f98 > balance: 1073.237125946399407586 > gas used: 261329 > gas price: 1 gwei > value sent: 0 ETH > total cost: 0.000261329 ETH > Saving migration to chain. > Saving artifacts ------------------------------------- > Total cost: 0.000261329 ETH 2_deploy_HarmonyERC20.js ======================== Replacing 'HarmonyERC20' ------------------------ > transaction hash: 0xdb1ab69342770ab559c41e5df32d255bce6f59584839fba8f181a9f08010dff8 > Blocks: 0 Seconds: 4 > contract address: 0x23d048d437615A346F9f50AcF051b0279B6d9bE2 > block number: 202314 > block timestamp: 1569917075 > account: 0x3aea49553Ce2E478f1c0c5ACC304a84F5F4d1f98 > balance: 1073.235223444399407586 > gas used: 1860479 > gas price: 1 gwei > value sent: 0 ETH > total cost: 0.001860479 ETH > Saving migration to chain. > Saving artifacts ------------------------------------- > Total cost: 0.001860479 ETH Summary ======= > Total deployments: 2 > Final cost: 0.002121808 ETH Johns-MacBook-Pro:harmony-erc20 johnwhitton$ truffle networks Network: UNKNOWN (id: 5777) HarmonyERC20: 0x6C061Ff6624c408d4A7b09704c853fa26D4C6218 Migrations: 0x8AEF5F5A61420777fcfB2F3313a77292C66fb3B1 Network: development (id: 2) No contracts deployed. Network: testnet (id: 2) HarmonyERC20: 0x23d048d437615A346F9f50AcF051b0279B6d9bE2 Migrations: 0xaE80fb77479Aa309831D411c2DC44F1EcFA703CC Johns-MacBook-Pro:harmony-erc20 johnwhitton$","title":"Compile and deploy your contracts"},{"location":"develop/hrc/#your-contract-is-now-available-at","text":"0x23d048d437615A346F9f50AcF051b0279B6d9bE2","title":"Your contract is now available at"},{"location":"develop/introduction/","text":"Introduction to smart contracts and DApps Harmony is EVM compatible which means that you can deploy smart contracts using tools like truffle and leverage smart contract standards such a open-zepplin. Harmony has the HRC smart contract github repository which holds many examples . It is recommended to peruse this repository and start with the node-hrc20 example . After completing this we recommend following the nft-store example which inculedes all the functionality for a fully functioning DApp. Sample Demonstrations Harmony deploy contract slides Harmony deploy contract video","title":"Introduction"},{"location":"develop/introduction/#introduction-to-smart-contracts-and-dapps","text":"Harmony is EVM compatible which means that you can deploy smart contracts using tools like truffle and leverage smart contract standards such a open-zepplin. Harmony has the HRC smart contract github repository which holds many examples . It is recommended to peruse this repository and start with the node-hrc20 example . After completing this we recommend following the nft-store example which inculedes all the functionality for a fully functioning DApp.","title":"Introduction to smart contracts and DApps"},{"location":"develop/introduction/#sample-demonstrations","text":"","title":"Sample Demonstrations"},{"location":"develop/introduction/#harmony-deploy-contract-slides","text":"","title":"Harmony deploy contract slides"},{"location":"develop/introduction/#harmony-deploy-contract-video","text":"","title":"Harmony deploy contract video"},{"location":"develop/orientation/","text":"Building Applications on Harmony Harmony is a fast, cheap, secure, EVM compatible layer one blockchain protocol. This section is for developers building smart contracts and Decentralized Applications (DApps) on Harmony. If you wish to contribute to the core protocol, tooling or operations please see the contribute section for a comprehensive guide to the ecoystem and grants available for contributors.","title":"Orientation"},{"location":"develop/orientation/#building-applications-on-harmony","text":"Harmony is a fast, cheap, secure, EVM compatible layer one blockchain protocol. This section is for developers building smart contracts and Decentralized Applications (DApps) on Harmony. If you wish to contribute to the core protocol, tooling or operations please see the contribute section for a comprehensive guide to the ecoystem and grants available for contributors.","title":"Building Applications on Harmony"},{"location":"develop/pull/","text":"Pull request from GitHub Introduction This document proposes the guidance on the pull request (PR) for our development projects. The goals are to improve the quality of our code commits and to ease the communication cost of the engineering team. A self-explanatory, self-contained PR will increase the development velocity and increase the team productivity. Tenets The tenets of the guidance is the following, borrowed from Amazon LP. Insist on the highest standard As a proud engineering team, we are consistently looking for high quality of the code review and commits. This is also in line with our open source strategy to exemplify our engineering excellence to the community. Bias for action We shall also move fast when needed. We believe in a fast iteration is the best way to improve our product. Ownership Code view and PR should be owned by engineers and the owner will drive the consensus as leaders. All comments have to be addressed/agreed. Mandatory Requirement Each commit submitted to master branch and release branch has to have sound commit message and logical scope. Run ./ test/test_before_submit.sh to ensure that the code conforms to basic standards and passes tests, and that the build is successful. You may need to install all the build tools in order to have a successful run. Run ./ test/debug.sh to ensure there is no regression on the basic consensus. Use [category] to classify the commit into a different category, such like [consensus], [p2p], [resharding], [staking], [leader], [wallet], [misc], etc \u2026 If your commit is to fix a certain issue, please add the issue number/link to the commit message, such #575, https://github.com/harmony-one/harmony/issues/767 , and so on. Add a [TEST] section in every PR describing your test process and results Add the test logs to https://gist.github.com/ and link in the PR Automation Travis-CI Every PR in github.com will be built in Travis-CI Jenkins Every PR in github.com will be sent to Jenkins job. http://jenkins.harmony.one/job/build_test_on_pr/ The result will be notified in #team-dev-jenkins discord channel. Use \" Jenkins, test this please \", in the comment to re-trigger the Jenkins test. Best Practices Use a WIP branch to save your daily work Back up your WIP branch in your own GitHub fork (not in the main harmony-one repo) Rebase every day to make sure your code integrates with the latest ToT (top of the tree) git pull --rebase https://www.atlassian.com/git/tutorials/rewriting-history/git-rebase Use interactive rebase to squash, reorder, remove small commits, especially before submitting the initial PR. git rebase -i <SHA1>; https://git-scm.com/book/en/v2/Git-Tools-Rewriting-History Submit Github Issues for every TODO or FIXME that you intended to put into the comments. This will help us keep track of the issues better in GitHub. Other references GitHub Cheatsheet","title":"Pull request from GitHub"},{"location":"develop/pull/#pull-request-from-github","text":"","title":"Pull request from GitHub"},{"location":"develop/pull/#introduction","text":"This document proposes the guidance on the pull request (PR) for our development projects. The goals are to improve the quality of our code commits and to ease the communication cost of the engineering team. A self-explanatory, self-contained PR will increase the development velocity and increase the team productivity.","title":"Introduction"},{"location":"develop/pull/#tenets","text":"The tenets of the guidance is the following, borrowed from Amazon LP. Insist on the highest standard As a proud engineering team, we are consistently looking for high quality of the code review and commits. This is also in line with our open source strategy to exemplify our engineering excellence to the community. Bias for action We shall also move fast when needed. We believe in a fast iteration is the best way to improve our product. Ownership Code view and PR should be owned by engineers and the owner will drive the consensus as leaders. All comments have to be addressed/agreed.","title":"Tenets"},{"location":"develop/pull/#mandatory-requirement","text":"Each commit submitted to master branch and release branch has to have sound commit message and logical scope. Run ./ test/test_before_submit.sh to ensure that the code conforms to basic standards and passes tests, and that the build is successful. You may need to install all the build tools in order to have a successful run. Run ./ test/debug.sh to ensure there is no regression on the basic consensus. Use [category] to classify the commit into a different category, such like [consensus], [p2p], [resharding], [staking], [leader], [wallet], [misc], etc \u2026 If your commit is to fix a certain issue, please add the issue number/link to the commit message, such #575, https://github.com/harmony-one/harmony/issues/767 , and so on. Add a [TEST] section in every PR describing your test process and results Add the test logs to https://gist.github.com/ and link in the PR","title":"Mandatory Requirement"},{"location":"develop/pull/#automation","text":"Travis-CI Every PR in github.com will be built in Travis-CI Jenkins Every PR in github.com will be sent to Jenkins job. http://jenkins.harmony.one/job/build_test_on_pr/ The result will be notified in #team-dev-jenkins discord channel. Use \" Jenkins, test this please \", in the comment to re-trigger the Jenkins test.","title":"Automation"},{"location":"develop/pull/#best-practices","text":"Use a WIP branch to save your daily work Back up your WIP branch in your own GitHub fork (not in the main harmony-one repo) Rebase every day to make sure your code integrates with the latest ToT (top of the tree) git pull --rebase https://www.atlassian.com/git/tutorials/rewriting-history/git-rebase Use interactive rebase to squash, reorder, remove small commits, especially before submitting the initial PR. git rebase -i <SHA1>; https://git-scm.com/book/en/v2/Git-Tools-Rewriting-History Submit Github Issues for every TODO or FIXME that you intended to put into the comments. This will help us keep track of the issues better in GitHub.","title":"Best Practices"},{"location":"develop/pull/#other-references","text":"GitHub Cheatsheet","title":"Other references"},{"location":"develop/sdk/","text":"SDK Harmony has a javascript sdk which can be used to integrate with the Harmony Protocol. Following are some links for more information Codebase NPM Packages Draft Documentation","title":"SDK Overview"},{"location":"develop/sdk/#sdk","text":"Harmony has a javascript sdk which can be used to integrate with the Harmony Protocol. Following are some links for more information Codebase NPM Packages Draft Documentation","title":"SDK"},{"location":"develop/temp/","text":"Component Name Overview Functional overview of what this component does Status - Built, Q2, Roadmap, Tenative Business Driver Ecosystem Grant - Eligible, Priority, Amount Deliverable Technical Specification Reference Material Level of Effort Developer or Partner Identified Harmony Owner Developer Guide","title":"Component Name"},{"location":"develop/temp/#component-name","text":"","title":"Component Name"},{"location":"develop/temp/#overview","text":"Functional overview of what this component does","title":"Overview"},{"location":"develop/temp/#status-built-q2-roadmap-tenative","text":"","title":"Status - Built, Q2, Roadmap, Tenative"},{"location":"develop/temp/#business-driver","text":"","title":"Business Driver"},{"location":"develop/temp/#ecosystem-grant-eligible-priority-amount","text":"","title":"Ecosystem Grant - Eligible, Priority, Amount"},{"location":"develop/temp/#deliverable","text":"","title":"Deliverable"},{"location":"develop/temp/#technical-specification","text":"","title":"Technical Specification"},{"location":"develop/temp/#reference-material","text":"","title":"Reference Material"},{"location":"develop/temp/#level-of-effort","text":"","title":"Level of Effort"},{"location":"develop/temp/#developer-or-partner-identified","text":"","title":"Developer or Partner Identified"},{"location":"develop/temp/#harmony-owner","text":"","title":"Harmony Owner"},{"location":"develop/temp/#developer-guide","text":"","title":"Developer Guide"},{"location":"ecosystem/ecosystem/","text":"Ecosystem Overview Here you will find partners in the Harmony ecosystem. Exchanges Buy ONE Tokens From 9 Exchanges Wallets Secure ONE Tokens In 6 Wallets Stakers Delegate ONE Tokens To 16 Pools Partners Integrate ONE Tokens With 9 Partners Investors Backed By 17 Global Investors","title":"Orientation"},{"location":"ecosystem/ecosystem/#ecosystem-overview","text":"Here you will find partners in the Harmony ecosystem.","title":"Ecosystem Overview"},{"location":"ecosystem/ecosystem/#exchanges","text":"Buy ONE Tokens From 9 Exchanges","title":"Exchanges"},{"location":"ecosystem/ecosystem/#wallets","text":"Secure ONE Tokens In 6 Wallets","title":"Wallets"},{"location":"ecosystem/ecosystem/#stakers","text":"Delegate ONE Tokens To 16 Pools","title":"Stakers"},{"location":"ecosystem/ecosystem/#partners","text":"Integrate ONE Tokens With 9 Partners","title":"Partners"},{"location":"ecosystem/ecosystem/#investors","text":"Backed By 17 Global Investors","title":"Investors"},{"location":"github/contribute/","text":"Contributing to Harmony Codebase Overview Harmony uses a fork-based workflow for contributing code. You can find instructions on how to contribute here . For more information about git in general please read the documentation and information on local-branching . Git Cheat Sheets DISCLAIMER: This is NOT a team policy document. It\u2019s a collection of best practices FYI. Fork-based Workflow Create fork \u2013 once per each repo If you haven\u2019t yet, \u201cgo get\u201d the main repo to clone it into $GOPATH/src : go get github.com/harmony-one/harmony Go to the GitHub page of the main repo, such as https://github.com/harmony-one/harmony . Fork into your own account ( astralblue , mikedoan , LeoHChen , rlan35 \u2026) Do not clone the fork. Instead, add your fork as a remote in the main clone , and push to it by default (substitute your account name, such as LeoHChen , for the ME placeholder below) cd ~/go/src/github.com/harmony-one/harmony git remote add -f ME git@github.com:ME/harmony git config --local --replace-all remote.pushDefault ME ## For johnwhitton it's as follows cd ~/go/src/github.com/harmony-one/harmony git remote add -f johnwhitton git@github.com:johnwhitton/harmony git config --local --replace-all remote.pushDefault johnwhitton Start a working branch Create a branch in your local clone (choose a name, then substitute it for the MY_WORK placeholder below), making it track the target branch where you will eventually be merging into ( origin/master for example): git checkout -b MY_WORK --track origin/master git pull Hack away! Sync with upstream Commit or stash your local changes away. A simple pull would merge (rebase if --rebase ) upstream update into your working copy: text `git pull` If you stashed your local changes, bring them back. Keep hacking! Checkpoint/publish your progress A simple push would back your progress up in your own fork: text `git push` Keep hacking! File a pull request Visit this URL (replace the ME and MY_WORK placeholders with your username and branch): https://github.com/ME/harmony/pull/new/MY_WORK Note : For convenience, the above URL is shown on the first push to your fork. Examine the pull request page. Make sure: i. The \u201cbase repository\u201d and \u201cbase\u201d are the target text \\(such as harmony-one master\\); ii. The \u201chead repository\u201d and \u201ccompare\u201d are the source text \\(that is, your fork & branch\\). Proceed to open a pull request. Some examples Forking the harmony repo and creating your first pull request # Get the harmony repo go get github.com/harmony-one/harmony # Add your fork cd ~/go/src/github.com/harmony-one/harmony git remote add -f john git@github.com:john-harmony/harmony git config --local --replace-all remote.pushDefault john # Synch your master branch with origin git checkout master git fetch origin ## Add your branch git checkout -b swagger-update --track origin/master # Push to your local repo git push # Create a pull request Release Management - Merging Master into t3 (for OSTN build) git status git checkout master git clean -fdx git fetch origin git log --pretty=oneline git push john HEAD:merge-master-t3-0404 # Create PR (into the t3 branch on harmony repo) # Merger the PR (do not squash merge) # Delete the branch","title":"Contribute"},{"location":"github/contribute/#contributing-to-harmony-codebase","text":"","title":"Contributing to Harmony Codebase"},{"location":"github/contribute/#overview","text":"Harmony uses a fork-based workflow for contributing code. You can find instructions on how to contribute here . For more information about git in general please read the documentation and information on local-branching .","title":"Overview"},{"location":"github/contribute/#git-cheat-sheets","text":"DISCLAIMER: This is NOT a team policy document. It\u2019s a collection of best practices FYI.","title":"Git Cheat Sheets"},{"location":"github/contribute/#fork-based-workflow","text":"","title":"Fork-based Workflow"},{"location":"github/contribute/#create-fork-once-per-each-repo","text":"If you haven\u2019t yet, \u201cgo get\u201d the main repo to clone it into $GOPATH/src : go get github.com/harmony-one/harmony Go to the GitHub page of the main repo, such as https://github.com/harmony-one/harmony . Fork into your own account ( astralblue , mikedoan , LeoHChen , rlan35 \u2026) Do not clone the fork. Instead, add your fork as a remote in the main clone , and push to it by default (substitute your account name, such as LeoHChen , for the ME placeholder below) cd ~/go/src/github.com/harmony-one/harmony git remote add -f ME git@github.com:ME/harmony git config --local --replace-all remote.pushDefault ME ## For johnwhitton it's as follows cd ~/go/src/github.com/harmony-one/harmony git remote add -f johnwhitton git@github.com:johnwhitton/harmony git config --local --replace-all remote.pushDefault johnwhitton","title":"Create fork \u2013 once per each repo"},{"location":"github/contribute/#start-a-working-branch","text":"Create a branch in your local clone (choose a name, then substitute it for the MY_WORK placeholder below), making it track the target branch where you will eventually be merging into ( origin/master for example): git checkout -b MY_WORK --track origin/master git pull Hack away!","title":"Start a working branch"},{"location":"github/contribute/#sync-with-upstream","text":"Commit or stash your local changes away. A simple pull would merge (rebase if --rebase ) upstream update into your working copy: text `git pull` If you stashed your local changes, bring them back. Keep hacking!","title":"Sync with upstream"},{"location":"github/contribute/#checkpointpublish-your-progress","text":"A simple push would back your progress up in your own fork: text `git push` Keep hacking!","title":"Checkpoint/publish your progress"},{"location":"github/contribute/#file-a-pull-request","text":"Visit this URL (replace the ME and MY_WORK placeholders with your username and branch): https://github.com/ME/harmony/pull/new/MY_WORK Note : For convenience, the above URL is shown on the first push to your fork. Examine the pull request page. Make sure: i. The \u201cbase repository\u201d and \u201cbase\u201d are the target text \\(such as harmony-one master\\); ii. The \u201chead repository\u201d and \u201ccompare\u201d are the source text \\(that is, your fork & branch\\). Proceed to open a pull request.","title":"File a pull request"},{"location":"github/contribute/#some-examples","text":"","title":"Some examples"},{"location":"github/contribute/#forking-the-harmony-repo-and-creating-your-first-pull-request","text":"# Get the harmony repo go get github.com/harmony-one/harmony # Add your fork cd ~/go/src/github.com/harmony-one/harmony git remote add -f john git@github.com:john-harmony/harmony git config --local --replace-all remote.pushDefault john # Synch your master branch with origin git checkout master git fetch origin ## Add your branch git checkout -b swagger-update --track origin/master # Push to your local repo git push # Create a pull request","title":"Forking the harmony repo and creating your first pull request"},{"location":"github/contribute/#release-management-merging-master-into-t3-for-ostn-build","text":"git status git checkout master git clean -fdx git fetch origin git log --pretty=oneline git push john HEAD:merge-master-t3-0404 # Create PR (into the t3 branch on harmony repo) # Merger the PR (do not squash merge) # Delete the branch","title":"Release Management - Merging Master into t3 (for OSTN build)"},{"location":"github/pull/","text":"Pull request from GitHub Introduction This document proposes the guidance on the pull request (PR) for our development projects. The goals are to improve the quality of our code commits and to ease the communication cost of the engineering team. A self-explanatory, self-contained PR will increase the development velocity and increase the team productivity. Tenets The tenets of the guidance is the following, borrowed from Amazon LP. Insist on the highest standard As a proud engineering team, we are consistently looking for high quality of the code review and commits. This is also in line with our open source strategy to exemplify our engineering excellence to the community. Bias for action We shall also move fast when needed. We believe in a fast iteration is the best way to improve our product. Ownership Code view and PR should be owned by engineers and the owner will drive the consensus as leaders. All comments have to be addressed/agreed. Mandatory Requirement Each commit submitted to master branch and release branch has to have sound commit message and logical scope. Run ./ test/test_before_submit.sh to ensure that the code conforms to basic standards and passes tests, and that the build is successful. You may need to install all the build tools in order to have a successful run. Run ./ test/debug.sh to ensure there is no regression on the basic consensus. Use [category] to classify the commit into a different category, such like [consensus], [p2p], [resharding], [staking], [leader], [wallet], [misc], etc \u2026 If your commit is to fix a certain issue, please add the issue number/link to the commit message, such #575, https://github.com/harmony-one/harmony/issues/767 , and so on. Add a [TEST] section in every PR describing your test process and results Add the test logs to https://gist.github.com/ and link in the PR Automation Travis-CI Every PR in github.com will be built in Travis-CI Jenkins Every PR in github.com will be sent to Jenkins job. http://jenkins.harmony.one/job/build_test_on_pr/ The result will be notified in #team-dev-jenkins discord channel. Use \" Jenkins, test this please \", in the comment to re-trigger the Jenkins test. Best Practices Use a WIP branch to save your daily work Back up your WIP branch in your own GitHub fork (not in the main harmony-one repo) Rebase every day to make sure your code integrates with the latest ToT (top of the tree) git pull --rebase https://www.atlassian.com/git/tutorials/rewriting-history/git-rebase Use interactive rebase to squash, reorder, remove small commits, especially before submitting the initial PR. git rebase -i <SHA1>; https://git-scm.com/book/en/v2/Git-Tools-Rewriting-History Submit Github Issues for every TODO or FIXME that you intended to put into the comments. This will help us keep track of the issues better in GitHub. Other references GitHub Cheatsheet","title":"Best Practices"},{"location":"github/pull/#pull-request-from-github","text":"","title":"Pull request from GitHub"},{"location":"github/pull/#introduction","text":"This document proposes the guidance on the pull request (PR) for our development projects. The goals are to improve the quality of our code commits and to ease the communication cost of the engineering team. A self-explanatory, self-contained PR will increase the development velocity and increase the team productivity.","title":"Introduction"},{"location":"github/pull/#tenets","text":"The tenets of the guidance is the following, borrowed from Amazon LP. Insist on the highest standard As a proud engineering team, we are consistently looking for high quality of the code review and commits. This is also in line with our open source strategy to exemplify our engineering excellence to the community. Bias for action We shall also move fast when needed. We believe in a fast iteration is the best way to improve our product. Ownership Code view and PR should be owned by engineers and the owner will drive the consensus as leaders. All comments have to be addressed/agreed.","title":"Tenets"},{"location":"github/pull/#mandatory-requirement","text":"Each commit submitted to master branch and release branch has to have sound commit message and logical scope. Run ./ test/test_before_submit.sh to ensure that the code conforms to basic standards and passes tests, and that the build is successful. You may need to install all the build tools in order to have a successful run. Run ./ test/debug.sh to ensure there is no regression on the basic consensus. Use [category] to classify the commit into a different category, such like [consensus], [p2p], [resharding], [staking], [leader], [wallet], [misc], etc \u2026 If your commit is to fix a certain issue, please add the issue number/link to the commit message, such #575, https://github.com/harmony-one/harmony/issues/767 , and so on. Add a [TEST] section in every PR describing your test process and results Add the test logs to https://gist.github.com/ and link in the PR","title":"Mandatory Requirement"},{"location":"github/pull/#automation","text":"Travis-CI Every PR in github.com will be built in Travis-CI Jenkins Every PR in github.com will be sent to Jenkins job. http://jenkins.harmony.one/job/build_test_on_pr/ The result will be notified in #team-dev-jenkins discord channel. Use \" Jenkins, test this please \", in the comment to re-trigger the Jenkins test.","title":"Automation"},{"location":"github/pull/#best-practices","text":"Use a WIP branch to save your daily work Back up your WIP branch in your own GitHub fork (not in the main harmony-one repo) Rebase every day to make sure your code integrates with the latest ToT (top of the tree) git pull --rebase https://www.atlassian.com/git/tutorials/rewriting-history/git-rebase Use interactive rebase to squash, reorder, remove small commits, especially before submitting the initial PR. git rebase -i <SHA1>; https://git-scm.com/book/en/v2/Git-Tools-Rewriting-History Submit Github Issues for every TODO or FIXME that you intended to put into the comments. This will help us keep track of the issues better in GitHub.","title":"Best Practices"},{"location":"github/pull/#other-references","text":"GitHub Cheatsheet","title":"Other references"},{"location":"harmony-cli/","text":"Command-line Tools Introduction hmy is the official Command Line Interface (CLI) provided by Harmony. You can use it as a local wallet and as a way to interact with your Ledger Nano device. The hmy CLI is completely open-source. You can track its development and post any issues encountered and your feature suggestions here . Features With the hmy CLI you can create a wallet, check your balance, send signed transactions to the Harmony blockchain, look up previous transactions, recover keys from previous mnemonics, create new keystores, and create new BLS keys. Supported Platforms OSX: main development platform Linux: tested Windows: tested / working under Windows Subsystem for Linux (WSL) Release information We will always upload the latest production release on github and announce future uploads in pre-production releases.","title":"Command-line Tools"},{"location":"harmony-cli/#command-line-tools","text":"","title":"Command-line Tools"},{"location":"harmony-cli/#introduction","text":"hmy is the official Command Line Interface (CLI) provided by Harmony. You can use it as a local wallet and as a way to interact with your Ledger Nano device. The hmy CLI is completely open-source. You can track its development and post any issues encountered and your feature suggestions here .","title":"Introduction"},{"location":"harmony-cli/#features","text":"With the hmy CLI you can create a wallet, check your balance, send signed transactions to the Harmony blockchain, look up previous transactions, recover keys from previous mnemonics, create new keystores, and create new BLS keys.","title":"Features "},{"location":"harmony-cli/#supported-platforms","text":"OSX: main development platform Linux: tested Windows: tested / working under Windows Subsystem for Linux (WSL)","title":"Supported Platforms "},{"location":"harmony-cli/#release-information","text":"We will always upload the latest production release on github and announce future uploads in pre-production releases.","title":"Release information"},{"location":"harmony-cli/cookbook/","text":"Cookbook The easiest way to get detailed help is to use the cli itself. For example below is the cookbook which gives an overview of various commands. {% hint style=\"success\" %} By default, cookbook will show the mainnet shard 0 ( https://api.s0.t.hmny.io ) RPC endpoint. Use the parameter --node=\"<RPC>\" so the example would show the s0 in the targeted network, example ./hmy cookbook --node=\"https://api.s1.os.hmny.io\" would show s0 in OSTN {% endhint %} ./hmy cookbook --node=\"https://api.s0.t.hmny.io\" #Cookbook of Usage #Note: #1) Every subcommand recognizes a '--help' flag #2) If a passphrase is used by a subcommand, one can enter their own passphrase interactively # with the --passphrase option. Alternatively, one can pass their own passphrase via a file # using the --passphrase-file option. If no passphrase option is selected, the default # passphrase of '' is used. #3) These examples use Shard 0 of Open Staking Network as argument for --node #Examples: #1. Check account balance on given chain ./hmy --node=\"https://api.s0.t.hmny.io\" balances <SOME_ONE_ADDRESS> #2. Check sent transaction ./hmy --node=\"https://api.s0.t.hmny.io\" blockchain transaction-by-hash <SOME_TX_HASH> #3. List local account keys ./hmy keys list #4. Sending a transaction (waits 40 seconds for transaction confirmation) ./hmy --node=\"https://api.s0.t.hmny.io\" transfer \\ --from <SOME_ONE_ADDRESS> --to <SOME_ONE_ADDRESS> \\ --from-shard 0 --to-shard 1 --amount 200 --passphrase #5. Sending a batch of transactions as dictated from a file (the `--dry-run` options still apply) ./hmy --node=\"https://api.s0.t.hmny.io\" transfer --file <PATH_TO_JSON_FILE> #Check README for details on json file format. #6. Check a completed transaction receipt ./hmy --node=\"https://api.s0.t.hmny.io\" blockchain transaction-receipt <SOME_TX_HASH> #7. Import an account using the mnemonic. Prompts the user to give the mnemonic. ./hmy keys recover-from-mnemonic <ACCOUNT_NAME> #8. Import an existing keystore file ./hmy keys import-ks <PATH_TO_KEYSTORE_JSON> #9. Import a keystore file using a secp256k1 private key ./hmy keys import-private-key <secp256k1_PRIVATE_KEY> #10. Export a keystore file's secp256k1 private key ./hmy keys export-private-key <ACCOUNT_ADDRESS> --passphrase #11. Generate a BLS key then encrypt and save the private key to the specified location. ./hmy keys generate-bls-key --bls-file-path <PATH_FOR_BLS_KEY_FILE> #12. Create a new validator with a list of BLS keys ./hmy --node=https://api.s0.os.hmny.io staking create-validator --amount 10 --validator-addr <SOME_ONE_ADDRESS> \\ --bls-pubkeys <BLS_KEY_1>,<BLS_KEY_2>,<BLS_KEY_3> \\ --identity foo --details bar --name baz --max-change-rate 0.1 --max-rate 0.1 --max-total-delegation 10 \\ --min-self-delegation 10 --rate 0.1 --security-contact Leo --website harmony.one --passphrase #13. Edit an existing validator ./hmy --node=\"https://api.s0.t.hmny.io\" staking edit-validator \\ --validator-addr <SOME_ONE_ADDRESS> --identity foo --details bar \\ --name baz --security-contact EK --website harmony.one \\ --min-self-delegation 0 --max-total-delegation 10 --rate 0.1\\ --add-bls-key <SOME_BLS_KEY> --remove-bls-key <OTHER_BLS_KEY> --passphrase #14. Delegate an amount to a validator ./hmy --node=\"https://api.s0.t.hmny.io\" staking delegate \\ --delegator-addr <SOME_ONE_ADDRESS> --validator-addr <VALIDATOR_ONE_ADDRESS> \\ --amount 10 --passphrase #15. Undelegate to a validator ./hmy --node=\"https://api.s0.t.hmny.io\" staking undelegate \\ --delegator-addr <SOME_ONE_ADDRESS> --validator-addr <VALIDATOR_ONE_ADDRESS> \\ --amount 10 --passphrase #16. Collect block rewards as a delegator ./hmy --node=\"https://api.s0.t.hmny.io\" staking collect-rewards \\ --delegator-addr <SOME_ONE_ADDRESS> --passphrase #17. Check elected validators ./hmy --node=\"https://api.s0.t.hmny.io\" blockchain validator elected #18. Get current staking utility metrics ./hmy --node=\"https://api.s0.t.hmny.io\" blockchain utility-metrics #19. Check in-memory record of failed staking transactions ./hmy --node=\"https://api.s0.t.hmny.io\" failures staking #20. Check which shard your BLS public key would be assigned to as a validator ./hmy --node=\"https://api.s0.t.hmny.io\" utility shard-for-bls 2d61379e44a772e5757e27ee2b3874254f56073e6bd226eb8b160371cc3c18b8c4977bd3dcb71fd57dc62bf0e143fd08","title":"Cookbook"},{"location":"harmony-cli/cookbook/#cookbook","text":"The easiest way to get detailed help is to use the cli itself. For example below is the cookbook which gives an overview of various commands. {% hint style=\"success\" %} By default, cookbook will show the mainnet shard 0 ( https://api.s0.t.hmny.io ) RPC endpoint. Use the parameter --node=\"<RPC>\" so the example would show the s0 in the targeted network, example ./hmy cookbook --node=\"https://api.s1.os.hmny.io\" would show s0 in OSTN {% endhint %} ./hmy cookbook --node=\"https://api.s0.t.hmny.io\" #Cookbook of Usage #Note: #1) Every subcommand recognizes a '--help' flag #2) If a passphrase is used by a subcommand, one can enter their own passphrase interactively # with the --passphrase option. Alternatively, one can pass their own passphrase via a file # using the --passphrase-file option. If no passphrase option is selected, the default # passphrase of '' is used. #3) These examples use Shard 0 of Open Staking Network as argument for --node #Examples: #1. Check account balance on given chain ./hmy --node=\"https://api.s0.t.hmny.io\" balances <SOME_ONE_ADDRESS> #2. Check sent transaction ./hmy --node=\"https://api.s0.t.hmny.io\" blockchain transaction-by-hash <SOME_TX_HASH> #3. List local account keys ./hmy keys list #4. Sending a transaction (waits 40 seconds for transaction confirmation) ./hmy --node=\"https://api.s0.t.hmny.io\" transfer \\ --from <SOME_ONE_ADDRESS> --to <SOME_ONE_ADDRESS> \\ --from-shard 0 --to-shard 1 --amount 200 --passphrase #5. Sending a batch of transactions as dictated from a file (the `--dry-run` options still apply) ./hmy --node=\"https://api.s0.t.hmny.io\" transfer --file <PATH_TO_JSON_FILE> #Check README for details on json file format. #6. Check a completed transaction receipt ./hmy --node=\"https://api.s0.t.hmny.io\" blockchain transaction-receipt <SOME_TX_HASH> #7. Import an account using the mnemonic. Prompts the user to give the mnemonic. ./hmy keys recover-from-mnemonic <ACCOUNT_NAME> #8. Import an existing keystore file ./hmy keys import-ks <PATH_TO_KEYSTORE_JSON> #9. Import a keystore file using a secp256k1 private key ./hmy keys import-private-key <secp256k1_PRIVATE_KEY> #10. Export a keystore file's secp256k1 private key ./hmy keys export-private-key <ACCOUNT_ADDRESS> --passphrase #11. Generate a BLS key then encrypt and save the private key to the specified location. ./hmy keys generate-bls-key --bls-file-path <PATH_FOR_BLS_KEY_FILE> #12. Create a new validator with a list of BLS keys ./hmy --node=https://api.s0.os.hmny.io staking create-validator --amount 10 --validator-addr <SOME_ONE_ADDRESS> \\ --bls-pubkeys <BLS_KEY_1>,<BLS_KEY_2>,<BLS_KEY_3> \\ --identity foo --details bar --name baz --max-change-rate 0.1 --max-rate 0.1 --max-total-delegation 10 \\ --min-self-delegation 10 --rate 0.1 --security-contact Leo --website harmony.one --passphrase #13. Edit an existing validator ./hmy --node=\"https://api.s0.t.hmny.io\" staking edit-validator \\ --validator-addr <SOME_ONE_ADDRESS> --identity foo --details bar \\ --name baz --security-contact EK --website harmony.one \\ --min-self-delegation 0 --max-total-delegation 10 --rate 0.1\\ --add-bls-key <SOME_BLS_KEY> --remove-bls-key <OTHER_BLS_KEY> --passphrase #14. Delegate an amount to a validator ./hmy --node=\"https://api.s0.t.hmny.io\" staking delegate \\ --delegator-addr <SOME_ONE_ADDRESS> --validator-addr <VALIDATOR_ONE_ADDRESS> \\ --amount 10 --passphrase #15. Undelegate to a validator ./hmy --node=\"https://api.s0.t.hmny.io\" staking undelegate \\ --delegator-addr <SOME_ONE_ADDRESS> --validator-addr <VALIDATOR_ONE_ADDRESS> \\ --amount 10 --passphrase #16. Collect block rewards as a delegator ./hmy --node=\"https://api.s0.t.hmny.io\" staking collect-rewards \\ --delegator-addr <SOME_ONE_ADDRESS> --passphrase #17. Check elected validators ./hmy --node=\"https://api.s0.t.hmny.io\" blockchain validator elected #18. Get current staking utility metrics ./hmy --node=\"https://api.s0.t.hmny.io\" blockchain utility-metrics #19. Check in-memory record of failed staking transactions ./hmy --node=\"https://api.s0.t.hmny.io\" failures staking #20. Check which shard your BLS public key would be assigned to as a validator ./hmy --node=\"https://api.s0.t.hmny.io\" utility shard-for-bls 2d61379e44a772e5757e27ee2b3874254f56073e6bd226eb8b160371cc3c18b8c4977bd3dcb71fd57dc62bf0e143fd08","title":"Cookbook"},{"location":"harmony-cli/create-import-wallet/","text":"Create or import wallet {% hint style=\"info\" %} When we mention the binary, we are referencing the ./hmy binary from the setup procedure . When we mention the shell scripts, we are referencing the ./hmy.sh shell script from the setup procedure. {% endhint %} New Wallet {% hint style=\"info\" %} Creation of a new account is done as a function of a generated bip39 mnemonic with 256 bits of entropy. You must provide an account alias name. {% endhint %} Using the Binary: ./hmy keys add <account-name> [--passphrase] Using the Shell Script: ./hmy.sh -- keys add <account-name1> [--passphrase] Example: ./hmy keys add test-account --passphrase {% hint style=\"warning\" %} Write/store this seed phrase in a safe place. it is the only way to recover your account if you ever forget your password. {% endhint %} This creates a keystore at the following directory: (hmy keys location)/account-name1/UTC--2019-09-16T21-25-35.297331000Z--678e7ea3dcb5f4e9724c0e761843572f10c49b73 When creating keys this way, hmy will ask you to provide a passphrase.\u200c Make sure you keep track of this passphrase for future use because the passphrase is used to decrypt the keystore when signing transactions. Also make sure you save the seed phrase, also called a mnemonic. {% hint style=\"info\" %} If you don't provide a passphrase using the --passphrase flag, the default passphrase is an empty string \"\" . The passphrase is used to decrypt the keystore when signing transactions. {% endhint %} To know where your wallet file has been created, run the following command: Using the Binary: ./hmy keys location Using the Shell Script: ./hmy.sh -- keys location You can check the list of wallets (local accounts) with the following command: Using the Binary: ./hmy keys list Using the Shell Script: ./hmy.sh -- keys list Import Wallet Importing a Keystore \u200cYou might have an existing keystore made by Harmony's old wallet.sh program that ends with \".key\" in the file name (example): one16qsd5ant9v94jrs89mruzx62h7ekcfxmduh2rx.key Or that starts with \"UTC\" in the file name (example): UTC--2020-01-15T01-02-06.606670000Z--9689a0711642bf08ea92ed98d552f0c1b8c8cefb Both these files can be imported into hmy using the command import-ks as shown below. {% hint style=\"warning\" %} Note that the --passphrase flag only enables a password prompt after the command is entered, there are no other arguments necessary here (if you dont put --passphrase flag in the command it will assume no password needed and will not prompt you for one, which basically means that your wallet keyfile will not be password protected!). {% endhint %} Using the Binary: ./hmy keys import-ks <absolute_path_to_keystore> --passphrase Using the Shell Script: ./hmy.sh -- keys import-ks <absolute_path_to_keystore> --passphrase Examples: ./hmy keys import-ks /home/harmony/one16qsd5ant9v94jrs89mruzx62h7ekcfxmduh2rx.key --passphrase ./hmy keys import-ks /home/harmony/UTC--2020-01-15T01-02-06.606670000Z--9689a0711642bf08ea92ed98d552f0c1b8c8cefb --passphrase \u200cKeep in mind that you should know the passphrase associated with the imported keystore and pass it as a parameter as shown in the commands above. For keystores created by Harmony's wallet.sh , the default passphrase is an empty string; this matters for signing transactions.\u200c Importing a Private Key Sometimes you might have a secp256k1 private key, such as the one generated from the following command: openssl ecparam -genkey -name secp256k1 -text -noout -outform DER | xxd -p -c 1000 | sed 's/41534e31204f49443a20736563703235366b310a30740201010420/PrivKey: /' | sed 's/a00706052b8104000aa144034200/\\'$'\\nPubKey: /' You can import the key with an optional name and passphrase Using the Binary: ./hmy keys import-private-key <secp256k1_private_key> [wallet_name] [--passphrase] Using the Shell Script: ./hmy.sh -- keys import-private-key <secp256k1_private_key> [wallet_name] [--passphrase] Example: ./hmy keys import-private-key b8798ca0a56ce16517ea37c6b1229cbb67cf0e022c423b044fe8f537830d8be5 my_wallet_name_here --passphrase If no account name is provided, a random word concatenated with -imported will be used. If no passphrase is provided, the default passphrase will be used (which is blank). Note that the CLI currently only supports importing secp256k1 private keys. Importing a Mnemonic Phrase You can recover lost wallet keys by entering the mnemonic words you received (and hopefully saved) when creating it: Using the Binary: ./hmy keys recover-from-mnemonic [wallet_name] Using the Shell Script: ./hmy.sh -- keys recover-from-mnemonic [wallet_name] Example: ./hmy keys recover-from-mnemonic nameofyourkey","title":"Create or import wallet"},{"location":"harmony-cli/create-import-wallet/#create-or-import-wallet","text":"{% hint style=\"info\" %} When we mention the binary, we are referencing the ./hmy binary from the setup procedure . When we mention the shell scripts, we are referencing the ./hmy.sh shell script from the setup procedure. {% endhint %}","title":"Create or import wallet"},{"location":"harmony-cli/create-import-wallet/#new-wallet","text":"{% hint style=\"info\" %} Creation of a new account is done as a function of a generated bip39 mnemonic with 256 bits of entropy. You must provide an account alias name. {% endhint %}","title":"New Wallet"},{"location":"harmony-cli/create-import-wallet/#using-the-binary","text":"./hmy keys add <account-name> [--passphrase]","title":"Using the Binary:"},{"location":"harmony-cli/create-import-wallet/#using-the-shell-script","text":"./hmy.sh -- keys add <account-name1> [--passphrase]","title":"Using the Shell Script:"},{"location":"harmony-cli/create-import-wallet/#example","text":"./hmy keys add test-account --passphrase {% hint style=\"warning\" %} Write/store this seed phrase in a safe place. it is the only way to recover your account if you ever forget your password. {% endhint %} This creates a keystore at the following directory: (hmy keys location)/account-name1/UTC--2019-09-16T21-25-35.297331000Z--678e7ea3dcb5f4e9724c0e761843572f10c49b73 When creating keys this way, hmy will ask you to provide a passphrase.\u200c Make sure you keep track of this passphrase for future use because the passphrase is used to decrypt the keystore when signing transactions. Also make sure you save the seed phrase, also called a mnemonic. {% hint style=\"info\" %} If you don't provide a passphrase using the --passphrase flag, the default passphrase is an empty string \"\" . The passphrase is used to decrypt the keystore when signing transactions. {% endhint %} To know where your wallet file has been created, run the following command:","title":"Example:"},{"location":"harmony-cli/create-import-wallet/#using-the-binary_1","text":"./hmy keys location","title":"Using the Binary:"},{"location":"harmony-cli/create-import-wallet/#using-the-shell-script_1","text":"./hmy.sh -- keys location You can check the list of wallets (local accounts) with the following command:","title":"Using the Shell Script:"},{"location":"harmony-cli/create-import-wallet/#using-the-binary_2","text":"./hmy keys list","title":"Using the Binary:"},{"location":"harmony-cli/create-import-wallet/#using-the-shell-script_2","text":"./hmy.sh -- keys list","title":"Using the Shell Script:"},{"location":"harmony-cli/create-import-wallet/#import-wallet","text":"","title":"Import Wallet"},{"location":"harmony-cli/create-import-wallet/#importing-a-keystore","text":"\u200cYou might have an existing keystore made by Harmony's old wallet.sh program that ends with \".key\" in the file name (example): one16qsd5ant9v94jrs89mruzx62h7ekcfxmduh2rx.key Or that starts with \"UTC\" in the file name (example): UTC--2020-01-15T01-02-06.606670000Z--9689a0711642bf08ea92ed98d552f0c1b8c8cefb Both these files can be imported into hmy using the command import-ks as shown below. {% hint style=\"warning\" %} Note that the --passphrase flag only enables a password prompt after the command is entered, there are no other arguments necessary here (if you dont put --passphrase flag in the command it will assume no password needed and will not prompt you for one, which basically means that your wallet keyfile will not be password protected!). {% endhint %}","title":"Importing a Keystore "},{"location":"harmony-cli/create-import-wallet/#using-the-binary_3","text":"./hmy keys import-ks <absolute_path_to_keystore> --passphrase","title":"Using the Binary:"},{"location":"harmony-cli/create-import-wallet/#using-the-shell-script_3","text":"./hmy.sh -- keys import-ks <absolute_path_to_keystore> --passphrase","title":"Using the Shell Script:"},{"location":"harmony-cli/create-import-wallet/#examples","text":"./hmy keys import-ks /home/harmony/one16qsd5ant9v94jrs89mruzx62h7ekcfxmduh2rx.key --passphrase ./hmy keys import-ks /home/harmony/UTC--2020-01-15T01-02-06.606670000Z--9689a0711642bf08ea92ed98d552f0c1b8c8cefb --passphrase \u200cKeep in mind that you should know the passphrase associated with the imported keystore and pass it as a parameter as shown in the commands above. For keystores created by Harmony's wallet.sh , the default passphrase is an empty string; this matters for signing transactions.\u200c","title":"Examples:"},{"location":"harmony-cli/create-import-wallet/#importing-a-private-key","text":"Sometimes you might have a secp256k1 private key, such as the one generated from the following command: openssl ecparam -genkey -name secp256k1 -text -noout -outform DER | xxd -p -c 1000 | sed 's/41534e31204f49443a20736563703235366b310a30740201010420/PrivKey: /' | sed 's/a00706052b8104000aa144034200/\\'$'\\nPubKey: /' You can import the key with an optional name and passphrase","title":"Importing a Private Key "},{"location":"harmony-cli/create-import-wallet/#using-the-binary_4","text":"./hmy keys import-private-key <secp256k1_private_key> [wallet_name] [--passphrase]","title":"Using the Binary:"},{"location":"harmony-cli/create-import-wallet/#using-the-shell-script_4","text":"./hmy.sh -- keys import-private-key <secp256k1_private_key> [wallet_name] [--passphrase]","title":"Using the Shell Script:"},{"location":"harmony-cli/create-import-wallet/#example_1","text":"./hmy keys import-private-key b8798ca0a56ce16517ea37c6b1229cbb67cf0e022c423b044fe8f537830d8be5 my_wallet_name_here --passphrase If no account name is provided, a random word concatenated with -imported will be used. If no passphrase is provided, the default passphrase will be used (which is blank). Note that the CLI currently only supports importing secp256k1 private keys.","title":"Example:"},{"location":"harmony-cli/create-import-wallet/#importing-a-mnemonic-phrase","text":"You can recover lost wallet keys by entering the mnemonic words you received (and hopefully saved) when creating it:","title":"Importing a Mnemonic Phrase "},{"location":"harmony-cli/create-import-wallet/#using-the-binary_5","text":"./hmy keys recover-from-mnemonic [wallet_name]","title":"Using the Binary:"},{"location":"harmony-cli/create-import-wallet/#using-the-shell-script_5","text":"./hmy.sh -- keys recover-from-mnemonic [wallet_name]","title":"Using the Shell Script:"},{"location":"harmony-cli/create-import-wallet/#example_2","text":"./hmy keys recover-from-mnemonic nameofyourkey","title":"Example:"},{"location":"harmony-cli/download-setup/","text":"Download & setup {% hint style=\"info\" %} Throughout this guide, we will use the following syntax: ./hmy : This is the CLI program ./hmy.sh -- : This is the command to use the CLI with a shell wrapper (for macOS) <argument> : This is a required argument [argument] : This is an optional argument / : This is a line break, used to break up a line while writing a command {% endhint %} Download Harmony CLI tool 1. For Linux Enter the following command into your shell of choice: curl -LO https://harmony.one/hmycli && mv hmycli hmy && chmod +x hmy {% hint style=\"info\" %} If you have permission issues, enter the commands with \"sudo\" at the beginning, i.e. \"sudo curl -LO https://harmony.one/hmycli && mv hmycli hmy && chmod +x hmy\" {% endhint %} 2. For MacOS hmy depends on some dynamic libraries, hence we recommend using the shell wrapper. Enter there commands into your terminal: curl -O https://raw.githubusercontent.com/harmony-one/go-sdk/master/scripts/hmy.sh chmod u+x hmy.sh ./hmy.sh -d Now you can use hmy.sh as a wrapper over hmy and you should assume that all references to hmy in these documents refer to hmy.sh . For example, the command ./hmy becomes ./hmy.sh -- . {% hint style=\"warning\" %} Note that since hmy is not statically linked, you cannot arbitrarily move hmy.sh to anywhere on your filesystem like you could with a single binary. {% endhint %} 3. Compiling from source If you are interested in compiling from source, then the process is more involved. Steps: Clone the repository at the same level as the main Harmony repo: {% hint style=\"warning\" %} Have mcl , bls all built and prepared. This may require you to see instructions in the harmony repo's readme. {% endhint %} cd /Users/edgar/Repos/harmony-work/src/github.com/harmony-one ls bls harmony mcl git clone https://github.com/harmony-one/go-sdk.git Then setup the build flags: source harmony/scripts/setup_bls_build_flags.sh Call make in the go-sdk repo. This builds a binary named hmy : cd go-sdk make Congratulations! You can now use the binary to run the CLI.","title":"Download and setup"},{"location":"harmony-cli/download-setup/#download-setup","text":"{% hint style=\"info\" %} Throughout this guide, we will use the following syntax: ./hmy : This is the CLI program ./hmy.sh -- : This is the command to use the CLI with a shell wrapper (for macOS) <argument> : This is a required argument [argument] : This is an optional argument / : This is a line break, used to break up a line while writing a command {% endhint %}","title":"Download &amp; setup"},{"location":"harmony-cli/download-setup/#download-harmony-cli-tool","text":"","title":"Download Harmony CLI tool"},{"location":"harmony-cli/download-setup/#1-for-linux","text":"Enter the following command into your shell of choice: curl -LO https://harmony.one/hmycli && mv hmycli hmy && chmod +x hmy {% hint style=\"info\" %} If you have permission issues, enter the commands with \"sudo\" at the beginning, i.e. \"sudo curl -LO https://harmony.one/hmycli && mv hmycli hmy && chmod +x hmy\" {% endhint %}","title":"1. For Linux"},{"location":"harmony-cli/download-setup/#2-for-macos","text":"hmy depends on some dynamic libraries, hence we recommend using the shell wrapper. Enter there commands into your terminal: curl -O https://raw.githubusercontent.com/harmony-one/go-sdk/master/scripts/hmy.sh chmod u+x hmy.sh ./hmy.sh -d Now you can use hmy.sh as a wrapper over hmy and you should assume that all references to hmy in these documents refer to hmy.sh . For example, the command ./hmy becomes ./hmy.sh -- . {% hint style=\"warning\" %} Note that since hmy is not statically linked, you cannot arbitrarily move hmy.sh to anywhere on your filesystem like you could with a single binary. {% endhint %}","title":"2. For MacOS"},{"location":"harmony-cli/download-setup/#3-compiling-from-source","text":"If you are interested in compiling from source, then the process is more involved. Steps: Clone the repository at the same level as the main Harmony repo: {% hint style=\"warning\" %} Have mcl , bls all built and prepared. This may require you to see instructions in the harmony repo's readme. {% endhint %} cd /Users/edgar/Repos/harmony-work/src/github.com/harmony-one ls bls harmony mcl git clone https://github.com/harmony-one/go-sdk.git Then setup the build flags: source harmony/scripts/setup_bls_build_flags.sh Call make in the go-sdk repo. This builds a binary named hmy : cd go-sdk make Congratulations! You can now use the binary to run the CLI.","title":"3. Compiling from source"},{"location":"harmony-cli/list-of-transaction-error-messages/","text":"List of transaction error messages Here is the list of failed transaction messages which can be checked by querying your transaction hash, checking the transaction hash on explorer or checking the blockchain pool transactions. Here is how with the hmy cli : ./hmy failures plain --node=\"https://api.s0.t.hmny.io\" {% hint style=\"info\" %} failed messages are network and shard specifics, please use the shard you were sending the transaction from and change the --node value accordingly Example above is for shard 1 in the test network. Mainnet example on shard 0 would be : https://api.s0.t.hmny.io {% endhint %} Message Notes transaction size is <tx size in Bytes>: oversized data A transaction cannot be more than 32KB to prevent DDOS attacks transaction value is <tx value>: negative value Transaction value is negative transaction gas is <tx gas-limit>: exceeds block gas limit Assumed to be hardcoded / config transaction sender is <tx from addr>: invalid sender Transaction sent from an invalid account transaction gas-price is <tx gas-price> ONE: transaction underpriced Too low transaction fee transaction nonce is <tx nonce>: nonce too low Occurs when the nonce associated with that transaction is too lower than the actual nonce insufficient funds for gas * price + value Usually when not enough holdings to pay for gas transaction gas is <tx gas-limit>: intrinsic gas too low Intrinsic gas is based on the size of the transaction including data transaction gas-price is <tx gas-price> ONE in full transaction pool: transaction underpriced Transactions can get dropped if tx pool is full and tx has lowest gas existing transaction price was not bumped enough: replacement transaction underpriced If a transaction attempts to replace another with less gas than the original, it will get dropped old transaction, nonce <tx nonce> is too low During promotion (from 'future' txs to pending txs in pool) the nonce is checked again unpayable transaction, out of gas or balance of <acc bal in ONE >cannot pay cost of <cost on ONE> During promotion (from 'future' txs to pending txs in pool) balance is checked again exceeds cap for queued transactions for account <one1... address> Each account has a limit in the number of txs it can put into the tx pool fairness-exceeding pending transaction If tx pool is full, txs from accounts with highest number of total transactions in pool will be dropped exceeds global cap for queued transactions Occurs when the tx can\u00b4t be queued because global cap for queued tx pool exceeds the max old transaction, nonce <tx nonce> is too low During demote (from pending txs in pool to 'future' txs) the nonce is checked again unpayable transaction, out of gas or balance of <acc bal in ONE > cannot pay cost of <cost in ONE> During demote (from pending txs in pool to 'future' txs) balance is checked again demoting pending transaction Tx was not added to the pool and move to queue of 'future' txs","title":"List of transaction error messages"},{"location":"harmony-cli/list-of-transaction-error-messages/#list-of-transaction-error-messages","text":"Here is the list of failed transaction messages which can be checked by querying your transaction hash, checking the transaction hash on explorer or checking the blockchain pool transactions. Here is how with the hmy cli : ./hmy failures plain --node=\"https://api.s0.t.hmny.io\" {% hint style=\"info\" %} failed messages are network and shard specifics, please use the shard you were sending the transaction from and change the --node value accordingly Example above is for shard 1 in the test network. Mainnet example on shard 0 would be : https://api.s0.t.hmny.io {% endhint %} Message Notes transaction size is <tx size in Bytes>: oversized data A transaction cannot be more than 32KB to prevent DDOS attacks transaction value is <tx value>: negative value Transaction value is negative transaction gas is <tx gas-limit>: exceeds block gas limit Assumed to be hardcoded / config transaction sender is <tx from addr>: invalid sender Transaction sent from an invalid account transaction gas-price is <tx gas-price> ONE: transaction underpriced Too low transaction fee transaction nonce is <tx nonce>: nonce too low Occurs when the nonce associated with that transaction is too lower than the actual nonce insufficient funds for gas * price + value Usually when not enough holdings to pay for gas transaction gas is <tx gas-limit>: intrinsic gas too low Intrinsic gas is based on the size of the transaction including data transaction gas-price is <tx gas-price> ONE in full transaction pool: transaction underpriced Transactions can get dropped if tx pool is full and tx has lowest gas existing transaction price was not bumped enough: replacement transaction underpriced If a transaction attempts to replace another with less gas than the original, it will get dropped old transaction, nonce <tx nonce> is too low During promotion (from 'future' txs to pending txs in pool) the nonce is checked again unpayable transaction, out of gas or balance of <acc bal in ONE >cannot pay cost of <cost on ONE> During promotion (from 'future' txs to pending txs in pool) balance is checked again exceeds cap for queued transactions for account <one1... address> Each account has a limit in the number of txs it can put into the tx pool fairness-exceeding pending transaction If tx pool is full, txs from accounts with highest number of total transactions in pool will be dropped exceeds global cap for queued transactions Occurs when the tx can\u00b4t be queued because global cap for queued tx pool exceeds the max old transaction, nonce <tx nonce> is too low During demote (from pending txs in pool to 'future' txs) the nonce is checked again unpayable transaction, out of gas or balance of <acc bal in ONE > cannot pay cost of <cost in ONE> During demote (from pending txs in pool to 'future' txs) balance is checked again demoting pending transaction Tx was not added to the pool and move to queue of 'future' txs","title":"List of transaction error messages"},{"location":"harmony-cli/other-cli-references/","text":"Other CLI references Generate Markdown Documentation if you want a full list of commands the hmy tool knows in markdown format, please run the following command: ./hmy docs Then in the same directory, hmy creates a directory named hmy-docs in which you can find all markdown files for the commands and subcommands. Delete Account Deletion of a one account is possible by issuing the below command ./hmy keys remove [ACCOUNT-NAME] {% hint style=\"danger\" %} Be sure to have saved your private keys before if you had fund in that account. Deleting the account without backing it up means you'll lose it forever. {% endhint %}","title":"Other CLI references"},{"location":"harmony-cli/other-cli-references/#other-cli-references","text":"","title":"Other CLI references"},{"location":"harmony-cli/other-cli-references/#generate-markdown-documentation","text":"if you want a full list of commands the hmy tool knows in markdown format, please run the following command: ./hmy docs Then in the same directory, hmy creates a directory named hmy-docs in which you can find all markdown files for the commands and subcommands.","title":"Generate Markdown Documentation"},{"location":"harmony-cli/other-cli-references/#delete-account","text":"Deletion of a one account is possible by issuing the below command ./hmy keys remove [ACCOUNT-NAME] {% hint style=\"danger\" %} Be sure to have saved your private keys before if you had fund in that account. Deleting the account without backing it up means you'll lose it forever. {% endhint %}","title":"Delete Account"},{"location":"harmony-cli/querying-balances/","text":"Querying balances Get JSON output of balances on all shards of a given ONE address with the balances subcommand: Using the Binary: ./hmy balances <ONE-address> --node=\"<endpoint-address>\" Using the Shell Wrapper: ./hmy.sh -- balances <ONE-address> --node=\"<endpoint-address>\" Example: ./hmy balances one1km7xg8e3xjys7azp9f4xp8hkw79vm2h3f2lade --node=\"https://api.s0.t.hmny.io\"","title":"Querying balances"},{"location":"harmony-cli/querying-balances/#querying-balances","text":"Get JSON output of balances on all shards of a given ONE address with the balances subcommand:","title":"Querying balances"},{"location":"harmony-cli/querying-balances/#using-the-binary","text":"./hmy balances <ONE-address> --node=\"<endpoint-address>\"","title":"Using the Binary:"},{"location":"harmony-cli/querying-balances/#using-the-shell-wrapper","text":"./hmy.sh -- balances <ONE-address> --node=\"<endpoint-address>\"","title":"Using the Shell Wrapper:"},{"location":"harmony-cli/querying-balances/#example","text":"./hmy balances one1km7xg8e3xjys7azp9f4xp8hkw79vm2h3f2lade --node=\"https://api.s0.t.hmny.io\"","title":"Example:"},{"location":"harmony-cli/querying-the-blockchain/","text":"Querying the blockchain hmy provides several subcommands under the blockchain subcommand which let you query the blockchain. {% hint style=\"info\" %} The Harmony blockchain is a sharded blockchain, therefore some commands depend on which shard you target. The shard you target when querying is controlled by the --node flag. For example, if a transaction is made between shard 0 and shard 1, the transaction receipt must be queried from whichever shard sent the funds - in this case shard 0, so the --node flag would look like this: --node=\"https://api.s0.t.hmny.io\" For other shards, please replace the s0 with the appropriate shard number - eg. s1 for shard 1, s2 for shard 2 etc. {% endhint %} List of available commands By using ./hmy blockchain help command we can see that the following options are available: {% hint style=\"info\" %} * block-by-number - get a harmony blockchain block by block number * current-nonce - current nonce of an account delegation information about delegations * known-chains - print out the known chain-ids * latest-header - get the latest header * median-stake - median stake of top 320 validators with delegations applied stake (pre-epos processing) * protocol-version - the version of the Harmony Protocol * transaction-by-hash - get transaction by hash * transaction-receipt - get information about a finalized transaction validator information about validators * pool - get transaction pool information {% endhint %} Here are some examples of the above commands that you will use frequently: transaction-by-hash Checking the hash of your transaction to see the transaction data and if the transaction has been completed Using the Binary: ./hmy blockchain transaction-by-hash <transaction-hash> --node=\"<endpoint-address>\" Using the Shell Wrapper: ./hmy.sh -- blockchain transaction-by-hash <transaction-hash> --node=\"<endpoint-address>\" Example: ./hmy blockchain transaction-by-hash 0x75d91100734edcd1497200cb438f0864d2ed4a44a88bf8c87855cb2b3cc54001 --node=\"https://api.s0.t.hmny.io\" { \"id\": \"0\", \"jsonrpc\": \"2.0\", \"result\": { \"blockHash\": \"0xf9c7e165d5636c7dd8a06bf2c53c364d7597028d7e10a3c5256462adf97b1f73\", \"blockNumber\": \"0xa35\", \"from\": \"one1mrrq665uarrmfur6hptevx9furph4293a37zme\", \"gas\": \"0x5208\", \"gasPrice\": \"0x3b9aca00\", \"hash\": \"0x75d91100734edcd1497200cb438f0864d2ed4a44a88bf8c87855cb2b3cc54001\", \"input\": \"0x\", \"nonce\": \"0xe\", \"r\": \"0x4a17d89f7b1818fe72d480a64fecfede1d73bd7242fcaabf907204a7022be806\", \"s\": \"0x557be1b9c378ecbae972e71ec6fc5d484abfe8cb7961ccd87724865c3a7020bc\", \"shardID\": 0, \"timestamp\": \"0x5e1cfcc1\", \"to\": \"one1mrrq665uarrmfur6hptevx9furph4293a37zme\", \"toShardID\": 1, \"transactionIndex\": \"0x0\", \"v\": \"0x2a\", \"value\": \"0xde0b6b3a7640000\" } } transaction-receipt Get information about a finalized transaction: Using the Binary: ./hmy blockchain transaction-receipt <transaction-hash> --node=\"<endpoint-address>\" Using the Shell Wrapper: ./hmy.sh -- blockchain transaction-receipt <transaction-hash> --node=\"<endpoint-address>\" Example: ./hmy blockchain transaction-receipt 0x599793f313ee17566f8d09728b9d043b8e26135ddce86beeee13f98767d452f7 --node=\"https://api.s0.t.hmny.io\" { \"id\": \"0\", \"jsonrpc\": \"2.0\", \"result\": { \"blockHash\": \"0x52171a8f3af94f639f1e6044679c4189c3cd088ffe7f1c216ce3089212373af9\", \"blockNumber\": \"0x6177\", \"contractAddress\": null, \"cumulativeGasUsed\": \"0x5208\", \"from\": \"0x261fa45c6a09cd3faa277d829e91d9473973357c\", \"gasUsed\": \"0x5208\", \"logs\": [], \"logsBloom\": \"0x00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000\", \"shardID\": 0, \"status\": \"0x1\", \"to\": \"0x06916163a17f07ce70e3d43ed37395f05b5738ae\", \"transactionHash\": \"0x599793f313ee17566f8d09728b9d043b8e26135ddce86beeee13f98767d452f7\", \"transactionIndex\": \"0x0\" } } latest-header command Checking the network status, last block, epoch, leaders, based on the shard number: Using the Binary: ./hmy blockchain latest-header --node=\"<endpoint-address>\" Using the Shell Wrapper: ./hmy.sh -- blockchain latest-header --node=\"<endpoint-address>\" Example: {% tabs %} {% tab title=\"Shard 0\" %} ./hmy blockchain latest-header --node=\"https://api.s0.t.hmny.io\" { \"id\": \"0\", \"jsonrpc\": \"2.0\", \"result\": { \"blockHash\": \"0xae23db112d22062be6a0f065ecc3989d4e9559ad6a1f34fe4344d021907e8c2e\", \"blockNumber\": 415749, \"epoch\": 5543, \"lastCommitBitmap\": \"fffffffffffffffb0f00\", \"lastCommitSig\": \"06efa677bdd327d3d9602fd246c214edb35e447692dccc2219ef08ce2fa026b96f3826fcb5a2a3f724222ecef4af66029f3b5d677e54534519ad2a405ad3b336dd5145dcc083fc2330b9d0bb398affd1745cab274b5019f32cba0287bd5e5a17\", \"leader\": \"one18ahxsrk9g4h4gz5r8ema7nyw6g9zpun5hhp54d\", \"shardID\": 0, \"timestamp\": \"2019-12-11 12:18:21 +0000 UTC\", \"unixtime\": 1576066701, \"viewID\": 415745 } } {% endtab %} {% tab title=\"Shard 1\" %} ./hmy blockchain latest-header --node=\"https://api.s1.t.hmny.io\" { \"id\": \"0\", \"jsonrpc\": \"2.0\", \"result\": { \"blockHash\": \"0x65d528672301b1c086b4f2db89ce20f6977f7aeaa494073352e211ac29f55179\", \"blockNumber\": 456065, \"epoch\": 5543, \"lastCommitBitmap\": \"ffffffffffffffff0f00\", \"lastCommitSig\": \"c8e049810c1f649625259f684e99f4a9cfc51cf01b2dd032f884136c9922ebb8fe0929e366bbf8122e430402d04d4804362013302994d4924c2990bdffeacb4b79e075c1897947a7ec5be44eef6f1bd1e013b80008f28085c15e17aa49629a09\", \"leader\": \"one1vaqzxt50ltk9hq4d44lgxmj4pj2x533fsp2acx\", \"shardID\": 1, \"timestamp\": \"2019-12-11 12:21:52 +0000 UTC\", \"unixtime\": 1576066912, \"viewID\": 456065 } } {% endtab %} {% tab title=\"Shard 2\" %} ./hmy blockchain latest-header --node=\"https://api.s2.t.hmny.io\" { \"id\": \"0\", \"jsonrpc\": \"2.0\", \"result\": { \"blockHash\": \"0xd5775e720a9bcc5a88fd13aac27d72365f4724d6a513ecf39af53c1bb826823d\", \"blockNumber\": 453475, \"epoch\": 5543, \"lastCommitBitmap\": \"ffffffffffffffff0f4000\", \"lastCommitSig\": \"701bad22a95b7ee937446c3f614755d1729f19b5976f1230af6de65fd7ecc0d8b95795396a55d78994b5a8ecaed77d028721f76a58e9919ab01f4aba36a6f3a3dda3aaf39b313e5d623e73ca83d71fc1631ae964e1747826662652be85fada18\", \"leader\": \"one18vn4hpu8jpu8p9pql59m7p0x8dqrpsw0jzav9u\", \"shardID\": 2, \"timestamp\": \"2019-12-11 12:22:26 +0000 UTC\", \"unixtime\": 1576066946, \"viewID\": 453508 } } {% endtab %} {% tab title=\"Shard 3\" %} ./hmy blockchain latest-header --node=\"https://api.s3.t.hmny.io\" { \"id\": \"0\", \"jsonrpc\": \"2.0\", \"result\": { \"blockHash\": \"0xd5775e720a9bcc5a88fd13aac27d72365f4724d6a513ecf39af53c1bb826823d\", \"blockNumber\": 453475, \"epoch\": 5543, \"lastCommitBitmap\": \"ffffffffffffffff0f4000\", \"lastCommitSig\": \"701bad22a95b7ee937446c3f614755d1729f19b5976f1230af6de65fd7ecc0d8b95795396a55d78994b5a8ecaed77d028721f76a58e9919ab01f4aba36a6f3a3dda3aaf39b313e5d623e73ca83d71fc1631ae964e1747826662652be85fada18\", \"leader\": \"one188345hbsgdsgstw6eenjgxsgusgs\", \"shardID\": 2, \"timestamp\": \"2019-12-11 12:22:26 +0000 UTC\", \"unixtime\": 1576066946, \"viewID\": 453508 } } {% endtab %} {% endtabs %} block-by-number {% hint style=\"info\" %} Note the block-number provided must be in hex with a 0x prefix. For example if you call latest-header and get a result of 10657 you convert this to hex which is 29A1 and then use the value 0x29A1 for block-number. This can be done using printf '0x%x\\n' 10617 #0X29a1 {% endhint %} Using the Binary: ./hmy blockchain block-by-number <block-number> --node=\"<endpoint-address>\" Using the Shell Wrapper: ./hmy.sh -- blockchain block-by-number <block-number> --node=\"<endpoint-address>\" Example: ./hmy blockchain block-by-number 0x29A1 --node=\"https://api.s0.t.hmny.io\" { \"id\": \"0\", \"jsonrpc\": \"2.0\", \"result\": { \"difficulty\": 0, \"extraData\": \"0x\", \"gasLimit\": \"0x4c4b400\", \"gasUsed\": \"0x0\", \"hash\": \"0x5cb6e0752530cef5e25c52539feca22b8ad197cca60c04cf06f4ee05d6537096\", \"logsBloom\": \"0x00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000\", \"miner\": \"0x3f6e680ec5456f540a833e77df4c8ed20a20f274\", \"mixHash\": \"0x0000000000000000000000000000000000000000000000000000000000000000\", \"nonce\": 0, \"number\": \"0x29a1\", \"parentHash\": \"0x30d28fb69701f8348e0cd6a7abbacceb4286009fc43827dc243e79508da057d7\", \"receiptsRoot\": \"0x56e81f171bcc55a6ff8345e692c0f86e5b48e01b996cadc001622fb5e363b421\", \"size\": \"0x50c\", \"stakingTransactions\": [], \"stateRoot\": \"0x096fac171e818e54e611d3543fd43b1929a4468d17dcb8766d18eaf1e426749c\", \"timestamp\": \"0x5e755a56\", \"transactions\": [], \"transactionsRoot\": \"0x56e81f171bcc55a6ff8345e692c0f86e5b48e01b996cadc001622fb5e363b421\", \"uncles\": [] } }","title":"Querying the blockchain"},{"location":"harmony-cli/querying-the-blockchain/#querying-the-blockchain","text":"hmy provides several subcommands under the blockchain subcommand which let you query the blockchain. {% hint style=\"info\" %} The Harmony blockchain is a sharded blockchain, therefore some commands depend on which shard you target. The shard you target when querying is controlled by the --node flag. For example, if a transaction is made between shard 0 and shard 1, the transaction receipt must be queried from whichever shard sent the funds - in this case shard 0, so the --node flag would look like this: --node=\"https://api.s0.t.hmny.io\" For other shards, please replace the s0 with the appropriate shard number - eg. s1 for shard 1, s2 for shard 2 etc. {% endhint %}","title":"Querying the blockchain"},{"location":"harmony-cli/querying-the-blockchain/#list-of-available-commands","text":"By using ./hmy blockchain help command we can see that the following options are available: {% hint style=\"info\" %} * block-by-number - get a harmony blockchain block by block number * current-nonce - current nonce of an account delegation information about delegations * known-chains - print out the known chain-ids * latest-header - get the latest header * median-stake - median stake of top 320 validators with delegations applied stake (pre-epos processing) * protocol-version - the version of the Harmony Protocol * transaction-by-hash - get transaction by hash * transaction-receipt - get information about a finalized transaction validator information about validators * pool - get transaction pool information {% endhint %} Here are some examples of the above commands that you will use frequently:","title":"List of available commands"},{"location":"harmony-cli/querying-the-blockchain/#transaction-by-hash","text":"Checking the hash of your transaction to see the transaction data and if the transaction has been completed","title":"transaction-by-hash"},{"location":"harmony-cli/querying-the-blockchain/#using-the-binary","text":"./hmy blockchain transaction-by-hash <transaction-hash> --node=\"<endpoint-address>\"","title":"Using the Binary:"},{"location":"harmony-cli/querying-the-blockchain/#using-the-shell-wrapper","text":"./hmy.sh -- blockchain transaction-by-hash <transaction-hash> --node=\"<endpoint-address>\"","title":"Using the Shell Wrapper:"},{"location":"harmony-cli/querying-the-blockchain/#example","text":"./hmy blockchain transaction-by-hash 0x75d91100734edcd1497200cb438f0864d2ed4a44a88bf8c87855cb2b3cc54001 --node=\"https://api.s0.t.hmny.io\" { \"id\": \"0\", \"jsonrpc\": \"2.0\", \"result\": { \"blockHash\": \"0xf9c7e165d5636c7dd8a06bf2c53c364d7597028d7e10a3c5256462adf97b1f73\", \"blockNumber\": \"0xa35\", \"from\": \"one1mrrq665uarrmfur6hptevx9furph4293a37zme\", \"gas\": \"0x5208\", \"gasPrice\": \"0x3b9aca00\", \"hash\": \"0x75d91100734edcd1497200cb438f0864d2ed4a44a88bf8c87855cb2b3cc54001\", \"input\": \"0x\", \"nonce\": \"0xe\", \"r\": \"0x4a17d89f7b1818fe72d480a64fecfede1d73bd7242fcaabf907204a7022be806\", \"s\": \"0x557be1b9c378ecbae972e71ec6fc5d484abfe8cb7961ccd87724865c3a7020bc\", \"shardID\": 0, \"timestamp\": \"0x5e1cfcc1\", \"to\": \"one1mrrq665uarrmfur6hptevx9furph4293a37zme\", \"toShardID\": 1, \"transactionIndex\": \"0x0\", \"v\": \"0x2a\", \"value\": \"0xde0b6b3a7640000\" } }","title":"Example:"},{"location":"harmony-cli/querying-the-blockchain/#transaction-receipt","text":"Get information about a finalized transaction:","title":"transaction-receipt"},{"location":"harmony-cli/querying-the-blockchain/#using-the-binary_1","text":"./hmy blockchain transaction-receipt <transaction-hash> --node=\"<endpoint-address>\"","title":"Using the Binary:"},{"location":"harmony-cli/querying-the-blockchain/#using-the-shell-wrapper_1","text":"./hmy.sh -- blockchain transaction-receipt <transaction-hash> --node=\"<endpoint-address>\"","title":"Using the Shell Wrapper:"},{"location":"harmony-cli/querying-the-blockchain/#example_1","text":"./hmy blockchain transaction-receipt 0x599793f313ee17566f8d09728b9d043b8e26135ddce86beeee13f98767d452f7 --node=\"https://api.s0.t.hmny.io\" { \"id\": \"0\", \"jsonrpc\": \"2.0\", \"result\": { \"blockHash\": \"0x52171a8f3af94f639f1e6044679c4189c3cd088ffe7f1c216ce3089212373af9\", \"blockNumber\": \"0x6177\", \"contractAddress\": null, \"cumulativeGasUsed\": \"0x5208\", \"from\": \"0x261fa45c6a09cd3faa277d829e91d9473973357c\", \"gasUsed\": \"0x5208\", \"logs\": [], \"logsBloom\": \"0x00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000\", \"shardID\": 0, \"status\": \"0x1\", \"to\": \"0x06916163a17f07ce70e3d43ed37395f05b5738ae\", \"transactionHash\": \"0x599793f313ee17566f8d09728b9d043b8e26135ddce86beeee13f98767d452f7\", \"transactionIndex\": \"0x0\" } }","title":"Example:"},{"location":"harmony-cli/querying-the-blockchain/#latest-header-command","text":"Checking the network status, last block, epoch, leaders, based on the shard number:","title":"latest-header command"},{"location":"harmony-cli/querying-the-blockchain/#using-the-binary_2","text":"./hmy blockchain latest-header --node=\"<endpoint-address>\"","title":"Using the Binary:"},{"location":"harmony-cli/querying-the-blockchain/#using-the-shell-wrapper_2","text":"./hmy.sh -- blockchain latest-header --node=\"<endpoint-address>\"","title":"Using the Shell Wrapper:"},{"location":"harmony-cli/querying-the-blockchain/#example_2","text":"{% tabs %} {% tab title=\"Shard 0\" %} ./hmy blockchain latest-header --node=\"https://api.s0.t.hmny.io\" { \"id\": \"0\", \"jsonrpc\": \"2.0\", \"result\": { \"blockHash\": \"0xae23db112d22062be6a0f065ecc3989d4e9559ad6a1f34fe4344d021907e8c2e\", \"blockNumber\": 415749, \"epoch\": 5543, \"lastCommitBitmap\": \"fffffffffffffffb0f00\", \"lastCommitSig\": \"06efa677bdd327d3d9602fd246c214edb35e447692dccc2219ef08ce2fa026b96f3826fcb5a2a3f724222ecef4af66029f3b5d677e54534519ad2a405ad3b336dd5145dcc083fc2330b9d0bb398affd1745cab274b5019f32cba0287bd5e5a17\", \"leader\": \"one18ahxsrk9g4h4gz5r8ema7nyw6g9zpun5hhp54d\", \"shardID\": 0, \"timestamp\": \"2019-12-11 12:18:21 +0000 UTC\", \"unixtime\": 1576066701, \"viewID\": 415745 } } {% endtab %} {% tab title=\"Shard 1\" %} ./hmy blockchain latest-header --node=\"https://api.s1.t.hmny.io\" { \"id\": \"0\", \"jsonrpc\": \"2.0\", \"result\": { \"blockHash\": \"0x65d528672301b1c086b4f2db89ce20f6977f7aeaa494073352e211ac29f55179\", \"blockNumber\": 456065, \"epoch\": 5543, \"lastCommitBitmap\": \"ffffffffffffffff0f00\", \"lastCommitSig\": \"c8e049810c1f649625259f684e99f4a9cfc51cf01b2dd032f884136c9922ebb8fe0929e366bbf8122e430402d04d4804362013302994d4924c2990bdffeacb4b79e075c1897947a7ec5be44eef6f1bd1e013b80008f28085c15e17aa49629a09\", \"leader\": \"one1vaqzxt50ltk9hq4d44lgxmj4pj2x533fsp2acx\", \"shardID\": 1, \"timestamp\": \"2019-12-11 12:21:52 +0000 UTC\", \"unixtime\": 1576066912, \"viewID\": 456065 } } {% endtab %} {% tab title=\"Shard 2\" %} ./hmy blockchain latest-header --node=\"https://api.s2.t.hmny.io\" { \"id\": \"0\", \"jsonrpc\": \"2.0\", \"result\": { \"blockHash\": \"0xd5775e720a9bcc5a88fd13aac27d72365f4724d6a513ecf39af53c1bb826823d\", \"blockNumber\": 453475, \"epoch\": 5543, \"lastCommitBitmap\": \"ffffffffffffffff0f4000\", \"lastCommitSig\": \"701bad22a95b7ee937446c3f614755d1729f19b5976f1230af6de65fd7ecc0d8b95795396a55d78994b5a8ecaed77d028721f76a58e9919ab01f4aba36a6f3a3dda3aaf39b313e5d623e73ca83d71fc1631ae964e1747826662652be85fada18\", \"leader\": \"one18vn4hpu8jpu8p9pql59m7p0x8dqrpsw0jzav9u\", \"shardID\": 2, \"timestamp\": \"2019-12-11 12:22:26 +0000 UTC\", \"unixtime\": 1576066946, \"viewID\": 453508 } } {% endtab %} {% tab title=\"Shard 3\" %} ./hmy blockchain latest-header --node=\"https://api.s3.t.hmny.io\" { \"id\": \"0\", \"jsonrpc\": \"2.0\", \"result\": { \"blockHash\": \"0xd5775e720a9bcc5a88fd13aac27d72365f4724d6a513ecf39af53c1bb826823d\", \"blockNumber\": 453475, \"epoch\": 5543, \"lastCommitBitmap\": \"ffffffffffffffff0f4000\", \"lastCommitSig\": \"701bad22a95b7ee937446c3f614755d1729f19b5976f1230af6de65fd7ecc0d8b95795396a55d78994b5a8ecaed77d028721f76a58e9919ab01f4aba36a6f3a3dda3aaf39b313e5d623e73ca83d71fc1631ae964e1747826662652be85fada18\", \"leader\": \"one188345hbsgdsgstw6eenjgxsgusgs\", \"shardID\": 2, \"timestamp\": \"2019-12-11 12:22:26 +0000 UTC\", \"unixtime\": 1576066946, \"viewID\": 453508 } } {% endtab %} {% endtabs %}","title":"Example:"},{"location":"harmony-cli/querying-the-blockchain/#block-by-number","text":"{% hint style=\"info\" %} Note the block-number provided must be in hex with a 0x prefix. For example if you call latest-header and get a result of 10657 you convert this to hex which is 29A1 and then use the value 0x29A1 for block-number. This can be done using printf '0x%x\\n' 10617 #0X29a1 {% endhint %}","title":"block-by-number"},{"location":"harmony-cli/querying-the-blockchain/#using-the-binary_3","text":"./hmy blockchain block-by-number <block-number> --node=\"<endpoint-address>\"","title":"Using the Binary:"},{"location":"harmony-cli/querying-the-blockchain/#using-the-shell-wrapper_3","text":"./hmy.sh -- blockchain block-by-number <block-number> --node=\"<endpoint-address>\"","title":"Using the Shell Wrapper:"},{"location":"harmony-cli/querying-the-blockchain/#example_3","text":"./hmy blockchain block-by-number 0x29A1 --node=\"https://api.s0.t.hmny.io\" { \"id\": \"0\", \"jsonrpc\": \"2.0\", \"result\": { \"difficulty\": 0, \"extraData\": \"0x\", \"gasLimit\": \"0x4c4b400\", \"gasUsed\": \"0x0\", \"hash\": \"0x5cb6e0752530cef5e25c52539feca22b8ad197cca60c04cf06f4ee05d6537096\", \"logsBloom\": \"0x00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000\", \"miner\": \"0x3f6e680ec5456f540a833e77df4c8ed20a20f274\", \"mixHash\": \"0x0000000000000000000000000000000000000000000000000000000000000000\", \"nonce\": 0, \"number\": \"0x29a1\", \"parentHash\": \"0x30d28fb69701f8348e0cd6a7abbacceb4286009fc43827dc243e79508da057d7\", \"receiptsRoot\": \"0x56e81f171bcc55a6ff8345e692c0f86e5b48e01b996cadc001622fb5e363b421\", \"size\": \"0x50c\", \"stakingTransactions\": [], \"stateRoot\": \"0x096fac171e818e54e611d3543fd43b1929a4468d17dcb8766d18eaf1e426749c\", \"timestamp\": \"0x5e755a56\", \"transactions\": [], \"transactionsRoot\": \"0x56e81f171bcc55a6ff8345e692c0f86e5b48e01b996cadc001622fb5e363b421\", \"uncles\": [] } }","title":"Example:"},{"location":"harmony-cli/send-tx/","text":"Sending transactions Perhaps the most important feature of the hmy CLI is the ability to create and send signed transactions to the Harmony blockchain. Overview Sending a transaction Using the Binary: ./hmy transfer --node=\"<endpoint-address>\" \\ --from <ONE_address> --to <ONE_address> \\ --from-shard <shard> --to-shard <shard> \\ --amount <amount> --chain-id <chain-id> --passphrase Using the Shell Script: ./hmy.sh -- transfer --node=\"<endpoint-address>\" \\ --from <ONE_address> --to <ONE_address> \\ --from-shard <shard> --to-shard <shard> \\ --amount <amount> --chain-id <chain-id> --passphrase Example: ./hmy --node=\"https://api.s0.t.hmny.io\" \\ transfer --from one1yc06ghr2p8xnl2380kpfayweguuhxdtupkhqzw \\ --to one1q6gkzcap0uruuu8r6sldxuu47pd4ww9w9t7tg6 \\ --from-shard 0 --to-shard 1 --amount 12.5 --chain-id mainnet --passphrase mypassword Checking the transaction hash Check for finality of the transaction by using the transaction hash like so: Using the Binary: ./hmy blockchain transaction-receipt <transaction_id> --node=\"<endpoint-address>\" Using the Shell Script: ./hmy.sh -- blockchain transaction-receipt <transaction_id> --node=\"<endpoint-address>\" Example: ./hmy --node=\"https://api.s0.t.hmny.io\" \\ blockchain transaction-receipt \\ 0x599793f313ee17566f8d09728b9d043b8e26135ddce86beeee13f98767d452f7 Detail ChainIDs Let's first check what chain-ids are available for us to use, we can do that easily with: Using the Binary: ./hmy blockchain known-chains Using the Shell Script: ./hmy.sh -- blockchain known-chains Example: ./hmy blockchain known-chains [ \"mainnet\", \"testnet\", \"devnet\" ] Notice that the output is pretty printed JSON , most outputs of hmy are JSON encoded and hmy defaults to showing it nicely indented. Sometimes though you might want to turn that off, you can do that for any command with the flag --no-pretty . By default, hmy assumes the testnet chain-id; override that with the --chain-id flag Our first transaction We'll use the transfer subcommand of hmy to send a transaction. ./hmy transfer Error: required flag(s) \"amount\", \"from\", \"from-shard\", \"to\", \"to-shard\" not set Notice that simply invoking the transfer subcommand gave us an error message about certain flags not being set. We'll need to provide legitimate values for these flags for our transaction to proceed successfully. Reading off the flags in the error message from left to right, the semantic meanings are as follows: amount : The quantity of Harmony One token to transfer from the senders to the receiver from : The sender's one address from-shard : Shard from which sender's balance will be drawn from to : Receiver's ONE address to-shard : Shard in which receiver will receive the amount sent by the sender passphrase: your wallet passphrase, which is prompted when you hit enter (or you can use a txt file with password and add it: --passphrase file.txt) A sharded blockchain is a new kind of blockchain architecture where the network is partitioned into sub-networks called shards. Sharding is one of the distinguishing features of Harmony and it is key to solving the traditional scalability problems encountered in other blockchain protocols. Note: The same ONE address will have a different balance in each shard. Currently Harmony mainnet has four shards while testnet has three shards. Sending a transaction from one shard to another is called a \"cross-shard transaction.\" Thus, a correct usage of transfer looks like: Using the Binary: ./hmy transfer --node=\"<endpoint-address>\" \\ --from <ONE_address> --to <ONE_address> \\ --from-shard <shard> --to-shard <shard> \\ --amount <amount> --chain-id <chain-id> --passphrase Using the Shell Wrapper: ./hmy.sh -- transfer --node=\"<endpoint-address>\" \\ --from <ONE_address> --to <ONE_address> \\ --from-shard <shard> --to-shard <shard> \\ --amount <amount> --chain-id <chain-id> --passphrase Example: ./hmy transfer --node=\"https://api.s0.t.hmny.io\" \\ --from one1yc06ghr2p8xnl2380kpfayweguuhxdtupkhqzw \\ --to one1q6gkzcap0uruuu8r6sldxuu47pd4ww9w9t7tg6 \\ --from-shard 0 --to-shard 1 --amount 10 --chain-id mainnet {\"transaction-receipt\":\"0x455f98a3aa11ef50ee5cc5ac8bbd79e04f2fe353180bb7e25fc6c921fc8fdc83\"} {% hint style=\"info\" %} hmy assumes that the private keys needed for signing the transaction on behalf of the sender ( one1yc06ghr2p8xnl2380kpfayweguuhxdtupkhqzw in this example) exist in the local keystore or in the hardware wallet if the --ledger flag was used. {% endhint %} {% hint style=\"info\" %} The sender's account must have enough of a balance on the from-shard to send a transaction. In our example, one1yc06ghr2p8xnl2380kpfayweguuhxdtupkhqzw must have an amount balance of at least 10 in shard 0. {% endhint %} Try out your transaction with the flag --dry-run , this flag tells hmy to create, cryptographically sign the transaction but not actually send it off. Sender's balances are checked and the output is a JSON dump of the signed transaction. Signing and sending a transaction is very quick, about 2 seconds maximum. The actual sending of the transaction is done via an RPC (Remote Procedure Call), you'll notice that we did not explicitly say where to send the transaction to. This is because the default destination of the RPC call goes to http://localhost:9500 , the default HTTP RPC server running when you start a local harmony blockchain. For real world usage though, you'll want a different location. You can control that with the --node flag (see the top of this page for an example). Result of the transaction Once an RPC machine receives a transaction, it sends you back a transaction hash. This transaction hash is the key identifier used when querying the blockchain for transactions. {% hint style=\"warning\" %} Simply having a transaction hash does NOT imply that the transaction was successfully accepted by the blockchain. A transaction is successfully accepted once it has been added to the blockchain. In the case of cross-shard transactions (when the from-shard, to-shard values are different), this means each shard has added the transaction to their blockchain. {% endhint %} We can pull down details of the finalized transaction with ./hmy blockchain transaction-receipt as well: Using the Binary: ./hmy blockchain transaction-receipt --node=\"<endpoint-address>\" <transaction-hash> Using the Shell Wrapper: ./hmy.sh -- blockchain transaction-receipt --node=\"<endpoint-address>\" <transaction-hash> Example: ./hmy blockchain transaction-receipt \\ --node=\"https://api.s0.t.hmny.io\" \\ 0x25dd32397b5a69146b2dc3bbdc8ef8aae271e9b12a36c6dff1eb8995cac9dcba { \"id\": \"0\", \"jsonrpc\": \"2.0\", \"result\": { \"blockHash\": \"0x67eb5d671af76814d9ab326f9ec36c5b889b872e0c34e8cbe484aea20f0611ea\", \"blockNumber\": \"0x21017f\", \"contractAddress\": null, \"cumulativeGasUsed\": \"0x5208\", \"from\": \"one1sp4q22r7cc78742mzrufu6xwcekqxjgq78jk3m\", \"gasUsed\": \"0x5208\", \"logs\": [], \"logsBloom\": \"0x00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000\", \"shardID\": 0, \"status\": \"0x1\", \"to\": \"one129r9pj3sk0re76f7zs3qz92rggmdgjhtwge62k\", \"transactionHash\": \"0x25dd32397b5a69146b2dc3bbdc8ef8aae271e9b12a36c6dff1eb8995cac9dcba\", \"transactionIndex\": \"0x0\" } } {% hint style=\"info\" %} If the transaction has not finalized then the \"result\" key in the JSON output will have value of null . {% endhint %} {% hint style=\"warning\" %} You should set the value of --node to the same shard that sent the transaction, notice that the URL we used, https://api.s0.t.hmny.io contained s0 , this means that this URL is targeting shard 0. For further information, see Querying the Blockchain . {% endhint %} You can tell hmy to wait until transaction confirmation by providing a positive integer value to flag --wait-for-confirm . For example, --wait-for-confirm=10 will try checking the receipt of the transaction for 10 seconds.","title":"Sending transactions"},{"location":"harmony-cli/send-tx/#sending-transactions","text":"Perhaps the most important feature of the hmy CLI is the ability to create and send signed transactions to the Harmony blockchain.","title":"Sending transactions"},{"location":"harmony-cli/send-tx/#overview","text":"","title":"Overview "},{"location":"harmony-cli/send-tx/#sending-a-transaction","text":"","title":"Sending a transaction "},{"location":"harmony-cli/send-tx/#using-the-binary","text":"./hmy transfer --node=\"<endpoint-address>\" \\ --from <ONE_address> --to <ONE_address> \\ --from-shard <shard> --to-shard <shard> \\ --amount <amount> --chain-id <chain-id> --passphrase","title":"Using the Binary:"},{"location":"harmony-cli/send-tx/#using-the-shell-script","text":"./hmy.sh -- transfer --node=\"<endpoint-address>\" \\ --from <ONE_address> --to <ONE_address> \\ --from-shard <shard> --to-shard <shard> \\ --amount <amount> --chain-id <chain-id> --passphrase","title":"Using the Shell Script:"},{"location":"harmony-cli/send-tx/#example","text":"./hmy --node=\"https://api.s0.t.hmny.io\" \\ transfer --from one1yc06ghr2p8xnl2380kpfayweguuhxdtupkhqzw \\ --to one1q6gkzcap0uruuu8r6sldxuu47pd4ww9w9t7tg6 \\ --from-shard 0 --to-shard 1 --amount 12.5 --chain-id mainnet --passphrase mypassword","title":"Example:"},{"location":"harmony-cli/send-tx/#checking-the-transaction-hash","text":"Check for finality of the transaction by using the transaction hash like so:","title":"Checking the transaction hash "},{"location":"harmony-cli/send-tx/#using-the-binary_1","text":"./hmy blockchain transaction-receipt <transaction_id> --node=\"<endpoint-address>\"","title":"Using the Binary:"},{"location":"harmony-cli/send-tx/#using-the-shell-script_1","text":"./hmy.sh -- blockchain transaction-receipt <transaction_id> --node=\"<endpoint-address>\"","title":"Using the Shell Script:"},{"location":"harmony-cli/send-tx/#example_1","text":"./hmy --node=\"https://api.s0.t.hmny.io\" \\ blockchain transaction-receipt \\ 0x599793f313ee17566f8d09728b9d043b8e26135ddce86beeee13f98767d452f7","title":"Example:"},{"location":"harmony-cli/send-tx/#detail","text":"","title":"Detail "},{"location":"harmony-cli/send-tx/#chainids","text":"Let's first check what chain-ids are available for us to use, we can do that easily with:","title":"ChainIDs "},{"location":"harmony-cli/send-tx/#using-the-binary_2","text":"./hmy blockchain known-chains","title":"Using the Binary:"},{"location":"harmony-cli/send-tx/#using-the-shell-script_2","text":"./hmy.sh -- blockchain known-chains","title":"Using the Shell Script:"},{"location":"harmony-cli/send-tx/#example_2","text":"./hmy blockchain known-chains [ \"mainnet\", \"testnet\", \"devnet\" ] Notice that the output is pretty printed JSON , most outputs of hmy are JSON encoded and hmy defaults to showing it nicely indented. Sometimes though you might want to turn that off, you can do that for any command with the flag --no-pretty . By default, hmy assumes the testnet chain-id; override that with the --chain-id flag","title":"Example:"},{"location":"harmony-cli/send-tx/#our-first-transaction","text":"We'll use the transfer subcommand of hmy to send a transaction. ./hmy transfer Error: required flag(s) \"amount\", \"from\", \"from-shard\", \"to\", \"to-shard\" not set Notice that simply invoking the transfer subcommand gave us an error message about certain flags not being set. We'll need to provide legitimate values for these flags for our transaction to proceed successfully. Reading off the flags in the error message from left to right, the semantic meanings are as follows: amount : The quantity of Harmony One token to transfer from the senders to the receiver from : The sender's one address from-shard : Shard from which sender's balance will be drawn from to : Receiver's ONE address to-shard : Shard in which receiver will receive the amount sent by the sender passphrase: your wallet passphrase, which is prompted when you hit enter (or you can use a txt file with password and add it: --passphrase file.txt) A sharded blockchain is a new kind of blockchain architecture where the network is partitioned into sub-networks called shards. Sharding is one of the distinguishing features of Harmony and it is key to solving the traditional scalability problems encountered in other blockchain protocols. Note: The same ONE address will have a different balance in each shard. Currently Harmony mainnet has four shards while testnet has three shards. Sending a transaction from one shard to another is called a \"cross-shard transaction.\" Thus, a correct usage of transfer looks like:","title":"Our first transaction "},{"location":"harmony-cli/send-tx/#using-the-binary_3","text":"./hmy transfer --node=\"<endpoint-address>\" \\ --from <ONE_address> --to <ONE_address> \\ --from-shard <shard> --to-shard <shard> \\ --amount <amount> --chain-id <chain-id> --passphrase","title":"Using the Binary:"},{"location":"harmony-cli/send-tx/#using-the-shell-wrapper","text":"./hmy.sh -- transfer --node=\"<endpoint-address>\" \\ --from <ONE_address> --to <ONE_address> \\ --from-shard <shard> --to-shard <shard> \\ --amount <amount> --chain-id <chain-id> --passphrase","title":"Using the Shell Wrapper:"},{"location":"harmony-cli/send-tx/#example_3","text":"./hmy transfer --node=\"https://api.s0.t.hmny.io\" \\ --from one1yc06ghr2p8xnl2380kpfayweguuhxdtupkhqzw \\ --to one1q6gkzcap0uruuu8r6sldxuu47pd4ww9w9t7tg6 \\ --from-shard 0 --to-shard 1 --amount 10 --chain-id mainnet {\"transaction-receipt\":\"0x455f98a3aa11ef50ee5cc5ac8bbd79e04f2fe353180bb7e25fc6c921fc8fdc83\"} {% hint style=\"info\" %} hmy assumes that the private keys needed for signing the transaction on behalf of the sender ( one1yc06ghr2p8xnl2380kpfayweguuhxdtupkhqzw in this example) exist in the local keystore or in the hardware wallet if the --ledger flag was used. {% endhint %} {% hint style=\"info\" %} The sender's account must have enough of a balance on the from-shard to send a transaction. In our example, one1yc06ghr2p8xnl2380kpfayweguuhxdtupkhqzw must have an amount balance of at least 10 in shard 0. {% endhint %} Try out your transaction with the flag --dry-run , this flag tells hmy to create, cryptographically sign the transaction but not actually send it off. Sender's balances are checked and the output is a JSON dump of the signed transaction. Signing and sending a transaction is very quick, about 2 seconds maximum. The actual sending of the transaction is done via an RPC (Remote Procedure Call), you'll notice that we did not explicitly say where to send the transaction to. This is because the default destination of the RPC call goes to http://localhost:9500 , the default HTTP RPC server running when you start a local harmony blockchain. For real world usage though, you'll want a different location. You can control that with the --node flag (see the top of this page for an example).","title":"Example:"},{"location":"harmony-cli/send-tx/#result-of-the-transaction","text":"Once an RPC machine receives a transaction, it sends you back a transaction hash. This transaction hash is the key identifier used when querying the blockchain for transactions. {% hint style=\"warning\" %} Simply having a transaction hash does NOT imply that the transaction was successfully accepted by the blockchain. A transaction is successfully accepted once it has been added to the blockchain. In the case of cross-shard transactions (when the from-shard, to-shard values are different), this means each shard has added the transaction to their blockchain. {% endhint %} We can pull down details of the finalized transaction with ./hmy blockchain transaction-receipt as well:","title":"Result of the transaction "},{"location":"harmony-cli/send-tx/#using-the-binary_4","text":"./hmy blockchain transaction-receipt --node=\"<endpoint-address>\" <transaction-hash>","title":"Using the Binary:"},{"location":"harmony-cli/send-tx/#using-the-shell-wrapper_1","text":"./hmy.sh -- blockchain transaction-receipt --node=\"<endpoint-address>\" <transaction-hash>","title":"Using the Shell Wrapper:"},{"location":"harmony-cli/send-tx/#example_4","text":"./hmy blockchain transaction-receipt \\ --node=\"https://api.s0.t.hmny.io\" \\ 0x25dd32397b5a69146b2dc3bbdc8ef8aae271e9b12a36c6dff1eb8995cac9dcba { \"id\": \"0\", \"jsonrpc\": \"2.0\", \"result\": { \"blockHash\": \"0x67eb5d671af76814d9ab326f9ec36c5b889b872e0c34e8cbe484aea20f0611ea\", \"blockNumber\": \"0x21017f\", \"contractAddress\": null, \"cumulativeGasUsed\": \"0x5208\", \"from\": \"one1sp4q22r7cc78742mzrufu6xwcekqxjgq78jk3m\", \"gasUsed\": \"0x5208\", \"logs\": [], \"logsBloom\": \"0x00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000\", \"shardID\": 0, \"status\": \"0x1\", \"to\": \"one129r9pj3sk0re76f7zs3qz92rggmdgjhtwge62k\", \"transactionHash\": \"0x25dd32397b5a69146b2dc3bbdc8ef8aae271e9b12a36c6dff1eb8995cac9dcba\", \"transactionIndex\": \"0x0\" } } {% hint style=\"info\" %} If the transaction has not finalized then the \"result\" key in the JSON output will have value of null . {% endhint %} {% hint style=\"warning\" %} You should set the value of --node to the same shard that sent the transaction, notice that the URL we used, https://api.s0.t.hmny.io contained s0 , this means that this URL is targeting shard 0. For further information, see Querying the Blockchain . {% endhint %} You can tell hmy to wait until transaction confirmation by providing a positive integer value to flag --wait-for-confirm . For example, --wait-for-confirm=10 will try checking the receipt of the transaction for 10 seconds.","title":"Example:"},{"location":"harmony-cli/staking-transactions/","text":"Staking Transactions Delegating to a Validator You can delegate tokens to a validator using the following command. {% tabs %} {% tab title=\"Mainnet\" %} ./hmy --node=\"https://api.s0.t.hmny.io\" staking delegate \\ --delegator-addr [ONE ADDRESS] --validator-addr [ONE ADDRESS] \\ --amount [AMOUNT] --passphrase {% endtab %} {% endtabs %} The CLI will ask for the passphrase for the delegator-addr keystore file. --delegator-addr is the ONE address of the delegator (string) --validator-addr is the ONE address of the validator (string) --amount is the number of ONE tokens to delegate to the validator (float) {% hint style=\"info\" %} As a validator, if you want to increase your stake, you will have to delegate to yourself. For delegating to your own validator, delegator-addr and validator-addr will be the same. {% endhint %} Undelegating from a Validator You can un-delegate tokens from a validator using the following command: {% tabs %} {% tab title=\"Mainnet\" %} ./hmy --node=\"https://api.s0.t.hmny.io\" staking undelegate \\ --delegator-addr [ONE ADDRESS] --validator-addr [ONE ADDRESS] \\ --amount [AMOUNT] --passphrase {% endtab %} {% endtabs %} The CLI will ask for the passphrase for the delegator-addr keystore file. --delegator-addr is the ONE address of the delegator (string) --validator-addr is the ONE address of the validator (string) --amount is the number of ONE tokens to un-delegate (float) {% hint style=\"info\" %} As a validator, for un-delegating from your own validator, delegator-addr and validator-addr will be the same. {% endhint %} Collecting Rewards You can collect your block rewards with the following command. {% tabs %} {% tab title=\"Mainnet\" %} ./hmy --node=\"https://api.s0.t.hmny.io\" staking collect-rewards \\ --delegator-addr [ONE ADDRESS] --passphrase {% endtab %} {% endtabs %} The CLI will prompt your for the passphrase of the delegation account. --delegator-addr is the account to collect rewards for {% hint style=\"warning\" %} You can only collect ALL of your block rewards at once, not partially. {% endhint %}","title":"Staking Transactions"},{"location":"harmony-cli/staking-transactions/#staking-transactions","text":"","title":"Staking Transactions"},{"location":"harmony-cli/staking-transactions/#delegating-to-a-validator","text":"You can delegate tokens to a validator using the following command. {% tabs %} {% tab title=\"Mainnet\" %} ./hmy --node=\"https://api.s0.t.hmny.io\" staking delegate \\ --delegator-addr [ONE ADDRESS] --validator-addr [ONE ADDRESS] \\ --amount [AMOUNT] --passphrase {% endtab %} {% endtabs %} The CLI will ask for the passphrase for the delegator-addr keystore file. --delegator-addr is the ONE address of the delegator (string) --validator-addr is the ONE address of the validator (string) --amount is the number of ONE tokens to delegate to the validator (float) {% hint style=\"info\" %} As a validator, if you want to increase your stake, you will have to delegate to yourself. For delegating to your own validator, delegator-addr and validator-addr will be the same. {% endhint %}","title":"Delegating to a Validator"},{"location":"harmony-cli/staking-transactions/#undelegating-from-a-validator","text":"You can un-delegate tokens from a validator using the following command: {% tabs %} {% tab title=\"Mainnet\" %} ./hmy --node=\"https://api.s0.t.hmny.io\" staking undelegate \\ --delegator-addr [ONE ADDRESS] --validator-addr [ONE ADDRESS] \\ --amount [AMOUNT] --passphrase {% endtab %} {% endtabs %} The CLI will ask for the passphrase for the delegator-addr keystore file. --delegator-addr is the ONE address of the delegator (string) --validator-addr is the ONE address of the validator (string) --amount is the number of ONE tokens to un-delegate (float) {% hint style=\"info\" %} As a validator, for un-delegating from your own validator, delegator-addr and validator-addr will be the same. {% endhint %}","title":"Undelegating from a Validator"},{"location":"harmony-cli/staking-transactions/#collecting-rewards","text":"You can collect your block rewards with the following command. {% tabs %} {% tab title=\"Mainnet\" %} ./hmy --node=\"https://api.s0.t.hmny.io\" staking collect-rewards \\ --delegator-addr [ONE ADDRESS] --passphrase {% endtab %} {% endtabs %} The CLI will prompt your for the passphrase of the delegation account. --delegator-addr is the account to collect rewards for {% hint style=\"warning\" %} You can only collect ALL of your block rewards at once, not partially. {% endhint %}","title":"Collecting Rewards"},{"location":"hold/hold/","text":"Ecosystem Exchanges Buy ONE Tokens From 9 Exchanges {% tabs %} {% tab title=\"Binance\" %} {% embed url=\"https://www.binance.com/en/trade/ONE_USDT\" %} {% endtab %} {% tab title=\"Huobi\" %} {% embed url=\"https://www.huobi.com/en-us/exchange/one_usdt/\" %} {% endtab %} {% tab title=\"Gate\" %} {% embed url=\"https://www.gate.io/trade/ONE_USDT\" %} {% endtab %} {% tab title=\"WazirX\" %} {% embed url=\"https://wazirx.com/exchange/ONE-USDT\" %} {% endtab %} {% tab title=\"Kucoin\" %} {% embed url=\"https://trade.kucoin.com/spot\" %} {% endtab %} {% tab title=\"Bitmax\" %} {% embed url=\"https://bitmax.io/#/trade/usdt/one\" %} {% endtab %} {% tab title=\"Bitsonic\" %} {% embed url=\"https://bitsonic.co.kr/front/en/exchange/one-krw\" %} {% endtab %} {% tab title=\"Vitex\" %} {% embed url=\"https://x.vite.net/trade?symbol=ONE-000_BTC-000\" %} {% endtab %} {% tab title=\"HitBTC\" %} {% embed url=\"https://hitbtc.com/\" %} {% endtab %} {% endtabs %} Wallets Secure ONE Tokens In 6 Wallets {% tabs %} {% tab title=\"Trust Wallet\" %} {% embed url=\"https://trustwallet.com/harmony-wallet/\" %} {% endtab %} {% tab title=\"Ledger\" %} {% embed url=\"https://www.ledger.com/\" %} {% endtab %} {% tab title=\"Math Wallet \" %} {% embed url=\"https://www.mathwallet.org/harmony-wallet/en/\" %} {% endtab %} {% tab title=\" Guarda Wallet\" %} {% embed url=\"https://guarda.co/\" %} {% endtab %} {% tab title=\"Safepal\" %} {% embed url=\"https://safepal.io/\" %} {% endtab %} {% tab title=\"Sprout\" %} {% embed url=\"https://sprout.sesameseed.org/\" %} {% endtab %} {% endtabs %} Stakers Delegate ONE Tokens To 16 Pools {% tabs %} {% tab title=\"Blockdaemon\" %} {% embed url=\"https://blockdaemon.com/\" %} {% endtab %} {% tab title=\"Stakefish\" %} {% embed url=\"https://stake.fish/\" %} {% endtab %} {% tab title=\"Staked\" %} {% embed url=\"https://staked.us/\" %} {% endtab %} {% tab title=\"Figment Networks\" %} {% embed url=\"https://figment.network/networks/harmony/\" %} {% endtab %} {% tab title=\"P-Ops\" %} {% embed url=\"http://pops.one\" %} {% endtab %} {% tab title=\"Chainode Tech\" %} {% embed url=\"https://chainode.tech/\" %} {% endtab %} {% tab title=\"Wetez\" %} {% embed url=\"https://www.wetez.io/\" %} {% endtab %} {% endtabs %} {% tabs %} {% tab title=\"EverStake\" %} {% embed url=\"https://everstake.one/\" %} {% endtab %} {% tab title=\"Infstones\" %} {% embed url=\"https://infinitystones.io/\" %} {% endtab %} {% tab title=\"HashQuark\" %} {% embed url=\"https://www.hashquark.io/#/\" %} {% endtab %} {% tab title=\"Stakin\" %} {% embed url=\"https://stakin.com/\" %} {% endtab %} {% tab title=\"HonestMining\" %} {% embed url=\"https://honestmining.com/\" %} {% endtab %} {% tab title=\"Staking Team\" %} {% embed url=\"https://www.stakingrewards.com/provider/staking-team\" %} {% endtab %} {% tab title=\"SesameSeed\" %} {% embed url=\"https://sprout.sesameseed.org/\" %} {% endtab %} {% endtabs %} {% tabs %} {% tab title=\"My Constant\" %} {% embed url=\"https://www.myconstant.com/\" %} {% endtab %} {% tab title=\"Moonstake\" %} {% embed url=\"https://www.moonstake.io/\" %} {% endtab %} {% tab title=\"JetStake\" %} {% embed url=\"https://dev.jetstake.com/\" %} {% endtab %} {% endtabs %} Partners Integrate ONE Tokens With 9 Partners {% tabs %} {% tab title=\"Animoca Brands\" %} {% embed url=\"https://medium.com/harmony-one/harmony-partners-with-gaming-industry-leader-animoca-e29f4624c055\" %} {% endtab %} {% tab title=\"Quidd\" %} {% embed url=\"https://cryptobriefing.com/harmony-blockchain-gaming-speed/\" %} {% endtab %} {% tab title=\"Lympo\" %} {% embed url=\"https://lympo.com/harmony-and-lympo-partner-to-provide-scalable-and-secure-sharing-of-health-data/\" %} {% endtab %} {% tab title=\"Ankr\" %} {% embed url=\"https://www.ankr.com/article/161\" %} {% endtab %} {% tab title=\"Safehaven\" %} {% embed url=\"https://medium.com/@safehavenio\" %} {% endtab %} {% tab title=\"Incognito\" %} {% embed url=\"https://incognito.org/\" %} {% endtab %} {% tab title=\"Debrief\" %} {% embed url=\"https://debrief.co/\" %} {% endtab %} {% tab title=\"Suterusu\" %} {% embed url=\"https://www.suterusu.io/\" %} {% endtab %} {% tab title=\"IBC\" %} {% embed url=\"https://ibc.media/\" %} {% endtab %} {% endtabs %} Investors Backed By 17 Global Investors {% tabs %} {% tab title=\"Anmi Group\" %} {% embed url=\"https://anmi.group/en/\" %} {% endtab %} {% tab title=\"Lemniscap\" %} {% embed url=\"https://lemniscap.com/portfolio\" %} {% endtab %} {% tab title=\"Binance Labs\" %} {% embed url=\"https://labs.binance.com/\" %} {% endtab %} {% tab title=\"Hashkey\" %} {% embed url=\"https://www.hashkey.com/\" %} {% endtab %} {% tab title=\"Blockchain Assets \" %} {% embed url=\"https://www.bca.fund/\" %} {% endtab %} {% tab title=\"BTC12 Capital \" %} {% embed url=\"https://btc12.com/\" %} {% endtab %} {% endtabs %} {% tabs %} {% tab title=\"Coinfund\" %} {% embed url=\"https://coinfund.io/\" %} {% endtab %} {% tab title=\"Consensus Capital \" %} {% embed url=\"http://consensuscapital.ca/\" %} {% endtab %} {% tab title=\"Continue Capital\" %} {% embed url=\"https://continue.capital/\" %} {% endtab %} {% tab title=\"QTUM\" %} {% embed url=\"https://qtum.org/\" %} {% endtab %} {% tab title=\"Skunk Capital \" %} {% embed url=\"https://skunk.capital/\" %} {% endtab %} {% tab title=\"UniValues Associates \" %} {% embed url=\"https://uva.fund/\" %} {% endtab %} {% tab title=\"SNZ\" %} {% embed url=\"https://snzholding.com/portfolio.html\" %} {% endtab %} {% endtabs %} {% tabs %} {% tab title=\"DACM\" %} {% embed url=\"https://dacm.io/portfolio.html\" %} {% endtab %} {% tab title=\"Cyphermines\" %} {% embed url=\"https://www.cyphermines.io/\" %} {% endtab %} {% tab title=\"Hayek Capital\" %} {% embed url=\"https://www.crunchbase.com/organization/hayek-capital\" %} {% endtab %} {% endtabs %}","title":"Ecosystem"},{"location":"hold/hold/#ecosystem","text":"","title":"Ecosystem"},{"location":"hold/hold/#exchanges","text":"Buy ONE Tokens From 9 Exchanges {% tabs %} {% tab title=\"Binance\" %} {% embed url=\"https://www.binance.com/en/trade/ONE_USDT\" %} {% endtab %} {% tab title=\"Huobi\" %} {% embed url=\"https://www.huobi.com/en-us/exchange/one_usdt/\" %} {% endtab %} {% tab title=\"Gate\" %} {% embed url=\"https://www.gate.io/trade/ONE_USDT\" %} {% endtab %} {% tab title=\"WazirX\" %} {% embed url=\"https://wazirx.com/exchange/ONE-USDT\" %} {% endtab %} {% tab title=\"Kucoin\" %} {% embed url=\"https://trade.kucoin.com/spot\" %} {% endtab %} {% tab title=\"Bitmax\" %} {% embed url=\"https://bitmax.io/#/trade/usdt/one\" %} {% endtab %} {% tab title=\"Bitsonic\" %} {% embed url=\"https://bitsonic.co.kr/front/en/exchange/one-krw\" %} {% endtab %} {% tab title=\"Vitex\" %} {% embed url=\"https://x.vite.net/trade?symbol=ONE-000_BTC-000\" %} {% endtab %} {% tab title=\"HitBTC\" %} {% embed url=\"https://hitbtc.com/\" %} {% endtab %} {% endtabs %}","title":"Exchanges"},{"location":"hold/hold/#wallets","text":"Secure ONE Tokens In 6 Wallets {% tabs %} {% tab title=\"Trust Wallet\" %} {% embed url=\"https://trustwallet.com/harmony-wallet/\" %} {% endtab %} {% tab title=\"Ledger\" %} {% embed url=\"https://www.ledger.com/\" %} {% endtab %} {% tab title=\"Math Wallet \" %} {% embed url=\"https://www.mathwallet.org/harmony-wallet/en/\" %} {% endtab %} {% tab title=\" Guarda Wallet\" %} {% embed url=\"https://guarda.co/\" %} {% endtab %} {% tab title=\"Safepal\" %} {% embed url=\"https://safepal.io/\" %} {% endtab %} {% tab title=\"Sprout\" %} {% embed url=\"https://sprout.sesameseed.org/\" %} {% endtab %} {% endtabs %}","title":"Wallets"},{"location":"hold/hold/#stakers","text":"Delegate ONE Tokens To 16 Pools {% tabs %} {% tab title=\"Blockdaemon\" %} {% embed url=\"https://blockdaemon.com/\" %} {% endtab %} {% tab title=\"Stakefish\" %} {% embed url=\"https://stake.fish/\" %} {% endtab %} {% tab title=\"Staked\" %} {% embed url=\"https://staked.us/\" %} {% endtab %} {% tab title=\"Figment Networks\" %} {% embed url=\"https://figment.network/networks/harmony/\" %} {% endtab %} {% tab title=\"P-Ops\" %} {% embed url=\"http://pops.one\" %} {% endtab %} {% tab title=\"Chainode Tech\" %} {% embed url=\"https://chainode.tech/\" %} {% endtab %} {% tab title=\"Wetez\" %} {% embed url=\"https://www.wetez.io/\" %} {% endtab %} {% endtabs %} {% tabs %} {% tab title=\"EverStake\" %} {% embed url=\"https://everstake.one/\" %} {% endtab %} {% tab title=\"Infstones\" %} {% embed url=\"https://infinitystones.io/\" %} {% endtab %} {% tab title=\"HashQuark\" %} {% embed url=\"https://www.hashquark.io/#/\" %} {% endtab %} {% tab title=\"Stakin\" %} {% embed url=\"https://stakin.com/\" %} {% endtab %} {% tab title=\"HonestMining\" %} {% embed url=\"https://honestmining.com/\" %} {% endtab %} {% tab title=\"Staking Team\" %} {% embed url=\"https://www.stakingrewards.com/provider/staking-team\" %} {% endtab %} {% tab title=\"SesameSeed\" %} {% embed url=\"https://sprout.sesameseed.org/\" %} {% endtab %} {% endtabs %} {% tabs %} {% tab title=\"My Constant\" %} {% embed url=\"https://www.myconstant.com/\" %} {% endtab %} {% tab title=\"Moonstake\" %} {% embed url=\"https://www.moonstake.io/\" %} {% endtab %} {% tab title=\"JetStake\" %} {% embed url=\"https://dev.jetstake.com/\" %} {% endtab %} {% endtabs %}","title":"Stakers"},{"location":"hold/hold/#partners","text":"Integrate ONE Tokens With 9 Partners {% tabs %} {% tab title=\"Animoca Brands\" %} {% embed url=\"https://medium.com/harmony-one/harmony-partners-with-gaming-industry-leader-animoca-e29f4624c055\" %} {% endtab %} {% tab title=\"Quidd\" %} {% embed url=\"https://cryptobriefing.com/harmony-blockchain-gaming-speed/\" %} {% endtab %} {% tab title=\"Lympo\" %} {% embed url=\"https://lympo.com/harmony-and-lympo-partner-to-provide-scalable-and-secure-sharing-of-health-data/\" %} {% endtab %} {% tab title=\"Ankr\" %} {% embed url=\"https://www.ankr.com/article/161\" %} {% endtab %} {% tab title=\"Safehaven\" %} {% embed url=\"https://medium.com/@safehavenio\" %} {% endtab %} {% tab title=\"Incognito\" %} {% embed url=\"https://incognito.org/\" %} {% endtab %} {% tab title=\"Debrief\" %} {% embed url=\"https://debrief.co/\" %} {% endtab %} {% tab title=\"Suterusu\" %} {% embed url=\"https://www.suterusu.io/\" %} {% endtab %} {% tab title=\"IBC\" %} {% embed url=\"https://ibc.media/\" %} {% endtab %} {% endtabs %}","title":"Partners"},{"location":"hold/hold/#investors","text":"Backed By 17 Global Investors {% tabs %} {% tab title=\"Anmi Group\" %} {% embed url=\"https://anmi.group/en/\" %} {% endtab %} {% tab title=\"Lemniscap\" %} {% embed url=\"https://lemniscap.com/portfolio\" %} {% endtab %} {% tab title=\"Binance Labs\" %} {% embed url=\"https://labs.binance.com/\" %} {% endtab %} {% tab title=\"Hashkey\" %} {% embed url=\"https://www.hashkey.com/\" %} {% endtab %} {% tab title=\"Blockchain Assets \" %} {% embed url=\"https://www.bca.fund/\" %} {% endtab %} {% tab title=\"BTC12 Capital \" %} {% embed url=\"https://btc12.com/\" %} {% endtab %} {% endtabs %} {% tabs %} {% tab title=\"Coinfund\" %} {% embed url=\"https://coinfund.io/\" %} {% endtab %} {% tab title=\"Consensus Capital \" %} {% embed url=\"http://consensuscapital.ca/\" %} {% endtab %} {% tab title=\"Continue Capital\" %} {% embed url=\"https://continue.capital/\" %} {% endtab %} {% tab title=\"QTUM\" %} {% embed url=\"https://qtum.org/\" %} {% endtab %} {% tab title=\"Skunk Capital \" %} {% embed url=\"https://skunk.capital/\" %} {% endtab %} {% tab title=\"UniValues Associates \" %} {% embed url=\"https://uva.fund/\" %} {% endtab %} {% tab title=\"SNZ\" %} {% embed url=\"https://snzholding.com/portfolio.html\" %} {% endtab %} {% endtabs %} {% tabs %} {% tab title=\"DACM\" %} {% embed url=\"https://dacm.io/portfolio.html\" %} {% endtab %} {% tab title=\"Cyphermines\" %} {% embed url=\"https://www.cyphermines.io/\" %} {% endtab %} {% tab title=\"Hayek Capital\" %} {% embed url=\"https://www.crunchbase.com/organization/hayek-capital\" %} {% endtab %} {% endtabs %}","title":"Investors"},{"location":"hold/intro/","text":"Harmony ONE holders As a Harmony ONE token holder you have options to hold, delegate, trade and invest your tokens. Here you can learn about how to do each of these, including user guides and journeys also see the ecosystem for detailed information on our partners. Below is an overview of some of our partners. Exchanges Buy ONE Tokens From 9 Exchanges Wallets Secure ONE Tokens In 6 Wallets Stakers Delegate ONE Tokens To 16 Pools Partners Integrate ONE Tokens With 9 Partners Investors Backed By 17 Global Investors","title":"Introduction"},{"location":"hold/intro/#harmony-one-holders","text":"As a Harmony ONE token holder you have options to hold, delegate, trade and invest your tokens. Here you can learn about how to do each of these, including user guides and journeys also see the ecosystem for detailed information on our partners. Below is an overview of some of our partners.","title":"Harmony ONE holders"},{"location":"hold/intro/#exchanges","text":"Buy ONE Tokens From 9 Exchanges","title":"Exchanges"},{"location":"hold/intro/#wallets","text":"Secure ONE Tokens In 6 Wallets","title":"Wallets"},{"location":"hold/intro/#stakers","text":"Delegate ONE Tokens To 16 Pools","title":"Stakers"},{"location":"hold/intro/#partners","text":"Integrate ONE Tokens With 9 Partners","title":"Partners"},{"location":"hold/intro/#investors","text":"Backed By 17 Global Investors","title":"Investors"},{"location":"hold/invest/","text":"Harmony Investors Harmony is backed by 17 Global Investors, please see ecoystem for more information.","title":"Invest"},{"location":"hold/invest/#harmony-investors","text":"Harmony is backed by 17 Global Investors, please see ecoystem for more information.","title":"Harmony Investors"},{"location":"hold/trade/","text":"Trading Overview Harmony is listed on a number of exchanges for more information please see ecosystem Exchanges Buy ONE Tokens From 9 Exchanges","title":"Trade"},{"location":"hold/trade/#trading-overview","text":"Harmony is listed on a number of exchanges for more information please see ecosystem","title":"Trading Overview"},{"location":"hold/trade/#exchanges","text":"Buy ONE Tokens From 9 Exchanges","title":"Exchanges"},{"location":"hold/delegate/choosing-a-validator/","text":"Dashboard Walkthrough In order to choose their validators and manage their delegation, delegators have access to a range of information on the Staking Dashboard. Portfolio Page Delegators can claim full rewards and monitor validators in their delegation portfolio. Staked Amount of ONE delegated Available Amount of ONE that available to delegate Rewards Rewards yet to be claimed Portfolio allocation Delegation amount across different validators Expected return expected annual percentage return rate Returned in Epochs left until undelegation funds will be accessible Reward (up to date) Unclaimed rewards Status Election status of the validator in current epoch Validator list Delegators can access necessary information of validators at a glance to choose desired validator(s). Effective Median Stake Median of ONE staked among the top elected slots Total Stake Total ONE staked in the Harmony network Current block height current block height of Harmony blockchain All All validators created & listed onchain Elected Validator currently selected & eligible to sign blocks & earn rewards Not Elected Validator currently not-selected to sign blocks due to low stake or insufficient uptime Expected return Expected annual return rate Stake Total ONE staked by the validator Fees Commission on rewards charged by validator Uptime (AVG) Signing percentage for this validator's nodes Status Election status of validator in current epoch Name The validators' moniker Validator Profile Delegators can check detailed information of a validator and delegate/undelegate this validator. Delegated Total ONE delegated to this validator Self stake Amount of ONE staked by validator Max delegation Maximum ONE stake allowed by the validator, including self-stake Validator since Block number at which validator registered Fee Commission on rewards charged by validator Max daily change daily change in commission allowed for this validator Uptime (AVG) Signing percentage for this validator's nodes Slots Number of seats (bls keys) associated with the Validator Elected slots Number of seats (bls keys) elected in the current committee Expected return Expected annual return rate Lifetime rewards all rewards collected by the validator Shards Shards in which validator's BLS keys belong, shown order is based on time to add Stake & delegation history Stake and delegation amount for the validator at every epoch Reward rate history Expected annual percentage return rate for validator at every epoch Delegators List of accounts that delegated to this validator and delegation amount Analytics Delegator can access both intuitive and statistical information on the stake distribution among validators and 4 shards. Slots The slots occupied by this validator Bid Bid per BLS key Effective Validator's effective ONE staked total Validator's total ONE staked Self stake Amount of ONE staked by validator","title":"Dashboard walkthrough"},{"location":"hold/delegate/choosing-a-validator/#dashboard-walkthrough","text":"In order to choose their validators and manage their delegation, delegators have access to a range of information on the Staking Dashboard. Portfolio Page Delegators can claim full rewards and monitor validators in their delegation portfolio. Staked Amount of ONE delegated Available Amount of ONE that available to delegate Rewards Rewards yet to be claimed Portfolio allocation Delegation amount across different validators Expected return expected annual percentage return rate Returned in Epochs left until undelegation funds will be accessible Reward (up to date) Unclaimed rewards Status Election status of the validator in current epoch Validator list Delegators can access necessary information of validators at a glance to choose desired validator(s). Effective Median Stake Median of ONE staked among the top elected slots Total Stake Total ONE staked in the Harmony network Current block height current block height of Harmony blockchain All All validators created & listed onchain Elected Validator currently selected & eligible to sign blocks & earn rewards Not Elected Validator currently not-selected to sign blocks due to low stake or insufficient uptime Expected return Expected annual return rate Stake Total ONE staked by the validator Fees Commission on rewards charged by validator Uptime (AVG) Signing percentage for this validator's nodes Status Election status of validator in current epoch Name The validators' moniker Validator Profile Delegators can check detailed information of a validator and delegate/undelegate this validator. Delegated Total ONE delegated to this validator Self stake Amount of ONE staked by validator Max delegation Maximum ONE stake allowed by the validator, including self-stake Validator since Block number at which validator registered Fee Commission on rewards charged by validator Max daily change daily change in commission allowed for this validator Uptime (AVG) Signing percentage for this validator's nodes Slots Number of seats (bls keys) associated with the Validator Elected slots Number of seats (bls keys) elected in the current committee Expected return Expected annual return rate Lifetime rewards all rewards collected by the validator Shards Shards in which validator's BLS keys belong, shown order is based on time to add Stake & delegation history Stake and delegation amount for the validator at every epoch Reward rate history Expected annual percentage return rate for validator at every epoch Delegators List of accounts that delegated to this validator and delegation amount Analytics Delegator can access both intuitive and statistical information on the stake distribution among validators and 4 shards. Slots The slots occupied by this validator Bid Bid per BLS key Effective Validator's effective ONE staked total Validator's total ONE staked Self stake Amount of ONE staked by validator","title":"Dashboard Walkthrough"},{"location":"hold/delegate/delegator-journey/","text":"Delegator Journey (video) Harmony's revolutionary Effective Proof of Stake mechanism ( https://youtu.be/M8c06bxWyQc ) is the fairest yet for allowing open participation in a public blockchain. In this video we run through the journey of the Delegator getting started in staking through the full-featured dashboard. With the introduction of effective stake, higher ranked validators are actually economically punished to stake too much in a single validator and the lower-ranked validators are enjoying extra reward for their stake. The effective stake is acting as an equalizer that pushes for a more evenly distributed stake among validators, thus avoiding stake centralization.","title":"Delegation on Harmony (video)"},{"location":"hold/delegate/delegator-journey/#delegator-journey-video","text":"Harmony's revolutionary Effective Proof of Stake mechanism ( https://youtu.be/M8c06bxWyQc ) is the fairest yet for allowing open participation in a public blockchain. In this video we run through the journey of the Delegator getting started in staking through the full-featured dashboard. With the introduction of effective stake, higher ranked validators are actually economically punished to stake too much in a single validator and the lower-ranked validators are enjoying extra reward for their stake. The effective stake is acting as an equalizer that pushes for a more evenly distributed stake among validators, thus avoiding stake centralization.","title":"Delegator Journey (video)"},{"location":"hold/delegate/overview/","text":"Delegators For those wishing to participate in staking without running a validator, delegation is the best approach to still get involved and earn block rewards. Harmony ONE holders can delegate their tokens to existing validators using our staking explorer: https://staking.harmony.one/ . If the tokens are delegated to an elected validator, a portion of the block reward earned by the validator will be credited to the delegator (according to section Block Reward). The earned block rewards are stored in a separate reward balance of the delegator, which can be immediately withdrawn to the delegator\u2019s account balance. The block rewards can also be staked again to achieve the compounding effect of staking. Your delegated tokens are also associated with slashing risks of the validator. As a delegator, you should carefully choose validators based on their historical performance metrics such as APR, uptime and commission. In case of indifference or indecisiveness, you should distribute your delegations among multiple validators in order to minimize risk. For better understanding of the staking mechanism, also refer to Terms & Concepts under the Validators section.","title":"Overview"},{"location":"hold/delegate/overview/#delegators","text":"For those wishing to participate in staking without running a validator, delegation is the best approach to still get involved and earn block rewards. Harmony ONE holders can delegate their tokens to existing validators using our staking explorer: https://staking.harmony.one/ . If the tokens are delegated to an elected validator, a portion of the block reward earned by the validator will be credited to the delegator (according to section Block Reward). The earned block rewards are stored in a separate reward balance of the delegator, which can be immediately withdrawn to the delegator\u2019s account balance. The block rewards can also be staked again to achieve the compounding effect of staking. Your delegated tokens are also associated with slashing risks of the validator. As a delegator, you should carefully choose validators based on their historical performance metrics such as APR, uptime and commission. In case of indifference or indecisiveness, you should distribute your delegations among multiple validators in order to minimize risk. For better understanding of the staking mechanism, also refer to Terms & Concepts under the Validators section.","title":"Delegators"},{"location":"hold/delegate/undelegation/","text":"Undelegation If a delegator decides to stop delegating to a validator, he or she can choose to undelegate their tokens from the validator. After undelegation is initiated from a currently elected validator, the tokens will be locked for 7 epochs (10.5 days) before being credited to the delegator\u2019s account balance. Note that the unlocking of the undelegated tokens only happens at the end of every epoch. Locked tokens are still slashable if the validator double signs. For undelegating from a non-elected validator, the token will be unlocked 7 epochs after the validator was last elected. For example, if you are undelegating from a validator who was last elected 3 epochs ago, your token will be locked for 4 epochs after the undelegation starts. This leads to a convenient result that if you undelegate from a validator who is never elected before, you can have your token returned in the current epoch.","title":"Undelegation"},{"location":"hold/delegate/undelegation/#undelegation","text":"If a delegator decides to stop delegating to a validator, he or she can choose to undelegate their tokens from the validator. After undelegation is initiated from a currently elected validator, the tokens will be locked for 7 epochs (10.5 days) before being credited to the delegator\u2019s account balance. Note that the unlocking of the undelegated tokens only happens at the end of every epoch. Locked tokens are still slashable if the validator double signs. For undelegating from a non-elected validator, the token will be unlocked 7 epochs after the validator was last elected. For example, if you are undelegating from a validator who was last elected 3 epochs ago, your token will be locked for 4 epochs after the undelegation starts. This leads to a convenient result that if you undelegate from a validator who is never elected before, you can have your token returned in the current epoch.","title":"Undelegation"},{"location":"hold/delegate/staking-dashboard/overview/","text":"Staking Dashboard You can go to Harmony Staking Dashboard to delegate/undelegate tokens, claim rewards and manage your delegations. Currently, staking transaction is supported on Ledger Nano S, Harmony Browser Extension and Math Wallet, you can log in or create a new address via those three wallets.","title":"Overview"},{"location":"hold/delegate/staking-dashboard/overview/#staking-dashboard","text":"You can go to Harmony Staking Dashboard to delegate/undelegate tokens, claim rewards and manage your delegations. Currently, staking transaction is supported on Ledger Nano S, Harmony Browser Extension and Math Wallet, you can log in or create a new address via those three wallets.","title":"Staking Dashboard"},{"location":"hold/delegate/staking-dashboard/sending-transactions/","text":"Sending Transactions {% hint style=\"danger\" %} Note: staking dashboard only process transactions on shard 0. {% endhint %} To send ONE tokens to an address, click the \" Transfer funds\" button and the send window will pop-up. Input the amount of tokens to send and the destination address, then click the \"next\" buttons. Click the \"Confirm and Sign\" button to sign the transaction. Different wallets use different ways to confirm signature request. Please check the Wallet section for details. Once transaction is signed, Delegate window will pop-up on the staking dashboard and display the transaction status. It will display \"Successful Send\" once the transactions completes.","title":"Sending Transactions"},{"location":"hold/delegate/staking-dashboard/sending-transactions/#sending-transactions","text":"{% hint style=\"danger\" %} Note: staking dashboard only process transactions on shard 0. {% endhint %} To send ONE tokens to an address, click the \" Transfer funds\" button and the send window will pop-up. Input the amount of tokens to send and the destination address, then click the \"next\" buttons. Click the \"Confirm and Sign\" button to sign the transaction. Different wallets use different ways to confirm signature request. Please check the Wallet section for details. Once transaction is signed, Delegate window will pop-up on the staking dashboard and display the transaction status. It will display \"Successful Send\" once the transactions completes.","title":"Sending Transactions"},{"location":"hold/delegate/staking-dashboard/staking-transactions/","text":"Staking Transactions Delegate If the tokens are delegated to an elected validator, a portion of the block reward earned by the validator will be credited to the delegator Delegate transaction Check the validators page to see list of validators. Click on desired validator logo to direct to the Validator profile for more details. Click on the \"Delegate\" button to delegate to this validator. Enter the desired delegation amount or scroll the percentage slider in the pop-up Delegate window. Delegation must be at least 1000 ONE. Click on \"Next\" and confirm the signature request. Different wallets use different ways to confirm signature request. Please check the Wallet section for details. Once transaction is signed, Delegate window will pop-up on the staking dashboard and display the transaction status. Undelegate If a delegator decides to stop delegating to a validator, he or she can choose to undelegate their tokens from the validator. After undelegation is initiated from a currently elected validator, the tokens will be locked for 7 epochs (10.5 days) before being credited to the delegator\u2019s account balance. Note that the unlocking of the undelegated tokens only happens at the end of every epoch. Locked tokens are still slashable if the validator double signs. For undelegating from a non-elected validator, the token will be unlocked 7 epochs after the validator was last elected. For example, if you are undelegating from a validator who was last elected 3 epochs ago, your token will be locked for 4 epochs after the undelegation starts. This leads to a convenient result that if you undelegate from a validator who is never elected before, you can have your token returned in the current epoch. Undelegate transaction Click the \"Undelegate\" button on validator profile. Signing process same as Delegate transactions. This transaction will display on the Pending Undelegations section on the Portfolio page. Claim rewards The earned block rewards are stored in a separate reward balance of the delegator, which can be immediately withdrawn to the delegator\u2019s account balance. The block rewards can also be staked again to achieve the compounding effect of staking. You can only claim full rewards, not partially. Claim Rewards transaction Click on Claim Rewards button. Signing process same as Delegate transactions.","title":"Staking Transactions"},{"location":"hold/delegate/staking-dashboard/staking-transactions/#staking-transactions","text":"","title":"Staking Transactions"},{"location":"hold/delegate/staking-dashboard/staking-transactions/#delegate","text":"If the tokens are delegated to an elected validator, a portion of the block reward earned by the validator will be credited to the delegator","title":"Delegate"},{"location":"hold/delegate/staking-dashboard/staking-transactions/#delegate-transaction","text":"Check the validators page to see list of validators. Click on desired validator logo to direct to the Validator profile for more details. Click on the \"Delegate\" button to delegate to this validator. Enter the desired delegation amount or scroll the percentage slider in the pop-up Delegate window. Delegation must be at least 1000 ONE. Click on \"Next\" and confirm the signature request. Different wallets use different ways to confirm signature request. Please check the Wallet section for details. Once transaction is signed, Delegate window will pop-up on the staking dashboard and display the transaction status.","title":"Delegate transaction"},{"location":"hold/delegate/staking-dashboard/staking-transactions/#undelegate","text":"If a delegator decides to stop delegating to a validator, he or she can choose to undelegate their tokens from the validator. After undelegation is initiated from a currently elected validator, the tokens will be locked for 7 epochs (10.5 days) before being credited to the delegator\u2019s account balance. Note that the unlocking of the undelegated tokens only happens at the end of every epoch. Locked tokens are still slashable if the validator double signs. For undelegating from a non-elected validator, the token will be unlocked 7 epochs after the validator was last elected. For example, if you are undelegating from a validator who was last elected 3 epochs ago, your token will be locked for 4 epochs after the undelegation starts. This leads to a convenient result that if you undelegate from a validator who is never elected before, you can have your token returned in the current epoch.","title":"Undelegate"},{"location":"hold/delegate/staking-dashboard/staking-transactions/#undelegate-transaction","text":"Click the \"Undelegate\" button on validator profile. Signing process same as Delegate transactions. This transaction will display on the Pending Undelegations section on the Portfolio page.","title":"Undelegate transaction"},{"location":"hold/delegate/staking-dashboard/staking-transactions/#claim-rewards","text":"The earned block rewards are stored in a separate reward balance of the delegator, which can be immediately withdrawn to the delegator\u2019s account balance. The block rewards can also be staked again to achieve the compounding effect of staking. You can only claim full rewards, not partially.","title":"Claim rewards"},{"location":"hold/delegate/staking-dashboard/staking-transactions/#claim-rewards-transaction","text":"Click on Claim Rewards button. Signing process same as Delegate transactions.","title":"Claim Rewards transaction"},{"location":"hold/wallets/","text":"Wallet Management {% page-ref page=\"key-management.md\" %} {% page-ref page=\"missing-funds-on-exchange.md\" %}","title":"Wallet Management"},{"location":"hold/wallets/#wallet-management","text":"{% page-ref page=\"key-management.md\" %} {% page-ref page=\"missing-funds-on-exchange.md\" %}","title":"Wallet Management"},{"location":"hold/wallets/chrome-extension/","text":"Harmony Wallet (Harmony Browser Extension) Step 1: Install the Harmony Wallet Chrome Extension Go to Harmony.one/chrome-store and install extension Step 2: Create a new address Click on the HARMONY H icon on top right and select create a new address. Choose a name and password for your account and copy the seed phrase somewhere safe as a backup. This is VERY IMPORTANT because lost seeds cannot be recovered. After you have created a new address you can click on the \"Go to Harmony\" button which will direct you to the staking dashboard. Step 3: Add another account If you want to import your account from other wallets, e.g. cli, you can recover account with Mnemonic or Private Key. Transferring Funds After logging into your account on the extension you'll be directed to the staking dashboard. Click on \"Portfolio\" , and then \"Transfer funds\" In the pop-up input the destination address and amount you want to transfer. Click next, and then click \"Confirm and Sign\" to authorize the transfer {% hint style=\"danger\" %} IMPORTANT DISCLAIMER Please note that Harmony Wallet does not support Harmony's sharded network architecture yet, so all transactions to or from Trust Wallet must go through shard 0. You can only view and access your funds in shard 0. {% endhint %} Staking Click on \"Validators\" in the staking dashboard to see all the validators Select the validator you would like to stake by clicking on their name, and then click \"Delegate\". Enter the amount you would like to stake, and confirm the transaction","title":"Harmony Wallet"},{"location":"hold/wallets/chrome-extension/#harmony-wallet-harmony-browser-extension","text":"","title":"Harmony Wallet (Harmony Browser Extension)"},{"location":"hold/wallets/chrome-extension/#step-1-install-the-harmony-wallet-chrome-extension","text":"Go to Harmony.one/chrome-store and install extension","title":"Step 1: Install the Harmony Wallet Chrome Extension"},{"location":"hold/wallets/chrome-extension/#step-2-create-a-new-address","text":"Click on the HARMONY H icon on top right and select create a new address. Choose a name and password for your account and copy the seed phrase somewhere safe as a backup. This is VERY IMPORTANT because lost seeds cannot be recovered. After you have created a new address you can click on the \"Go to Harmony\" button which will direct you to the staking dashboard.","title":"Step 2: Create a new address"},{"location":"hold/wallets/chrome-extension/#step-3-add-another-account","text":"If you want to import your account from other wallets, e.g. cli, you can recover account with Mnemonic or Private Key.","title":"Step 3: Add another account"},{"location":"hold/wallets/chrome-extension/#transferring-funds","text":"After logging into your account on the extension you'll be directed to the staking dashboard. Click on \"Portfolio\" , and then \"Transfer funds\" In the pop-up input the destination address and amount you want to transfer. Click next, and then click \"Confirm and Sign\" to authorize the transfer {% hint style=\"danger\" %}","title":"Transferring Funds"},{"location":"hold/wallets/chrome-extension/#important-disclaimer","text":"Please note that Harmony Wallet does not support Harmony's sharded network architecture yet, so all transactions to or from Trust Wallet must go through shard 0. You can only view and access your funds in shard 0. {% endhint %}","title":"IMPORTANT DISCLAIMER"},{"location":"hold/wallets/chrome-extension/#staking","text":"Click on \"Validators\" in the staking dashboard to see all the validators Select the validator you would like to stake by clicking on their name, and then click \"Delegate\". Enter the amount you would like to stake, and confirm the transaction","title":"Staking"},{"location":"hold/wallets/key-management/","text":"Private Key Management Below is an index that shows you which wallets can allow to you import or export your account via mnemonic and private key, as well as which wallet has sharded network support. Wallet Export Mnemonic Export Private Key Import Mnemonic Import Private Key Sharded Network Support Harmony Wallet No No Yes Yes No Trust Wallet Yes No Yes No No Ledger No Yes No Yes Yes Math Wallet Yes Yes Yes Yes Yes Harmony CLI No Yes Yes Yes Yes SafePal No No Yes No Yes Trust Wallet How to Restore a Multi-Coin Wallet How to Import a Wallet","title":"Key Management"},{"location":"hold/wallets/key-management/#private-key-management","text":"Below is an index that shows you which wallets can allow to you import or export your account via mnemonic and private key, as well as which wallet has sharded network support. Wallet Export Mnemonic Export Private Key Import Mnemonic Import Private Key Sharded Network Support Harmony Wallet No No Yes Yes No Trust Wallet Yes No Yes No No Ledger No Yes No Yes Yes Math Wallet Yes Yes Yes Yes Yes Harmony CLI No Yes Yes Yes Yes SafePal No No Yes No Yes Trust Wallet","title":"Private Key Management"},{"location":"hold/wallets/key-management/#how-to-restore-a-multi-coin-wallet","text":"","title":"How to Restore a Multi-Coin Wallet"},{"location":"hold/wallets/key-management/#how-to-import-a-wallet","text":"","title":"How to Import a Wallet"},{"location":"hold/wallets/missing-funds-on-exchange/","text":"Missing Funds on Exchange If you transfer funds to an exchange wallet on any shard other than shard 0, the funds will not reflect in your exchange account. Fear not, your funds are not lost! You will need to contact the exchange and provide them the corresponding transaction ID for them to help you fix the problem. Locate transaction ID: Go to your wallet (i.e. Math Wallet), and log into your account Select your Harmony account, and then find transactions record Select the transaction in question, and copy the transaction ID to provide to the exchange you're in contact with Contact Exchange Support: Select the exchange you are using below, and that will lead you to their support page where you can submit a request your transaction ID to resolve the issue. Binance Support Page Bitmax Support Page","title":"Missing Funds"},{"location":"hold/wallets/missing-funds-on-exchange/#missing-funds-on-exchange","text":"If you transfer funds to an exchange wallet on any shard other than shard 0, the funds will not reflect in your exchange account. Fear not, your funds are not lost! You will need to contact the exchange and provide them the corresponding transaction ID for them to help you fix the problem.","title":"Missing Funds on Exchange"},{"location":"hold/wallets/missing-funds-on-exchange/#locate-transaction-id","text":"Go to your wallet (i.e. Math Wallet), and log into your account Select your Harmony account, and then find transactions record Select the transaction in question, and copy the transaction ID to provide to the exchange you're in contact with","title":"Locate transaction ID:"},{"location":"hold/wallets/missing-funds-on-exchange/#contact-exchange-support","text":"Select the exchange you are using below, and that will lead you to their support page where you can submit a request your transaction ID to resolve the issue. Binance Support Page Bitmax Support Page","title":"Contact Exchange Support:"},{"location":"hold/wallets/overview/","text":"Wallets As a Harmony ONE holder there are two main ways to hold and transfer your tokens. Non-custodal wallets In this section we will provide information about a number of wallet providers which have partnered with Harmony who you can use to hold and transfer your takens. Currently, staking transaction is supported by Harmony Wallet, Ledger and Math Wallet. Staking transaction is only supported on Shard0: Custodial wallets (Exchanges) Harmony has partnered with several tier 1 exchanges for a complete list please see our exchange partners in ecosystem","title":"Overview"},{"location":"hold/wallets/overview/#wallets","text":"As a Harmony ONE holder there are two main ways to hold and transfer your tokens.","title":"Wallets"},{"location":"hold/wallets/overview/#non-custodal-wallets","text":"In this section we will provide information about a number of wallet providers which have partnered with Harmony who you can use to hold and transfer your takens. Currently, staking transaction is supported by Harmony Wallet, Ledger and Math Wallet. Staking transaction is only supported on Shard0:","title":"Non-custodal wallets"},{"location":"hold/wallets/overview/#custodial-wallets-exchanges","text":"Harmony has partnered with several tier 1 exchanges for a complete list please see our exchange partners in ecosystem","title":"Custodial wallets (Exchanges)"},{"location":"hold/wallets/trustwallet/","text":"Trust Wallet Trust Wallet is a mobile cryptocurrency wallet. Please visit https://trustwallet.com with your mobile device to download the app. {% hint style=\"danger\" %} IMPORTANT DISCLAIMER Please note that Trust Wallet does not support Harmony's sharded network architecture yet, so all transactions to or from Trust Wallet must go through shard 0. You can only view and access your funds in shard 0. {% endhint %} Incoming transactions The funds that are sent within shard 0 will be viewed correctly in Trust Wallet. If you receive funds in a shard other than shard 0 (i.e. in shard 2), you will not see the transaction receipt in the Trust Wallet app. Since your account balance will only show the funds in shard 0, your total balance will not change. Outgoing transactions Since there is no shard selection in the Trust Wallet UI, all transactions will originate from shard 0 and will be sent to shard 0. For more details, please see these example cross-shard transactions using Trust Wallet: What to do if you receive funds in a shard other than shard 0 when using Trust Wallet? You will need to export the account in which you received the funds and import it to another wallet such as the CLI or Math Wallet. Example Using Trust Wallet: Open Trust Wallet app Click on \"Settings\" on the bottom right Click on \"Wallets\" Click on the info circle next to \"Multi-Coin Wallet\" The screen will show backup options, select \"show recovery phrase\" Your mnemonic recovery phrase will show up, make sure to note them down accurately and securely Open Math Wallet Chrome Extension Click the + sign next to Harmony Select \"Import Wallet\" Select \"Import by mnemonic\" Type in your mnemonic that you noted from Trust Wallet, and click next Name your new imported wallet Open \"web wallet\" from the extension and you can access all your funds in all shards Import/Export Wallet Below are the official instructions on how to restore/import Recovery Phrase (mnemonic) on Trust wallet. How to Restore a Multi-Coin Wallet How to Import a Wallet","title":"Trust Wallet"},{"location":"hold/wallets/trustwallet/#trust-wallet","text":"Trust Wallet is a mobile cryptocurrency wallet. Please visit https://trustwallet.com with your mobile device to download the app. {% hint style=\"danger\" %} IMPORTANT DISCLAIMER Please note that Trust Wallet does not support Harmony's sharded network architecture yet, so all transactions to or from Trust Wallet must go through shard 0. You can only view and access your funds in shard 0. {% endhint %}","title":"Trust Wallet"},{"location":"hold/wallets/trustwallet/#incoming-transactions","text":"The funds that are sent within shard 0 will be viewed correctly in Trust Wallet. If you receive funds in a shard other than shard 0 (i.e. in shard 2), you will not see the transaction receipt in the Trust Wallet app. Since your account balance will only show the funds in shard 0, your total balance will not change.","title":"Incoming transactions"},{"location":"hold/wallets/trustwallet/#outgoing-transactions","text":"Since there is no shard selection in the Trust Wallet UI, all transactions will originate from shard 0 and will be sent to shard 0.","title":"Outgoing transactions"},{"location":"hold/wallets/trustwallet/#for-more-details-please-see-these-example-cross-shard-transactions-using-trust-wallet","text":"","title":"For more details, please see these example cross-shard transactions using Trust Wallet:"},{"location":"hold/wallets/trustwallet/#what-to-do-if-you-receive-funds-in-a-shard-other-than-shard-0-when-using-trust-wallet","text":"You will need to export the account in which you received the funds and import it to another wallet such as the CLI or Math Wallet. Example Using Trust Wallet: Open Trust Wallet app Click on \"Settings\" on the bottom right Click on \"Wallets\" Click on the info circle next to \"Multi-Coin Wallet\" The screen will show backup options, select \"show recovery phrase\" Your mnemonic recovery phrase will show up, make sure to note them down accurately and securely Open Math Wallet Chrome Extension Click the + sign next to Harmony Select \"Import Wallet\" Select \"Import by mnemonic\" Type in your mnemonic that you noted from Trust Wallet, and click next Name your new imported wallet Open \"web wallet\" from the extension and you can access all your funds in all shards","title":"What to do if you receive funds in a shard other than shard 0 when using Trust Wallet?"},{"location":"hold/wallets/trustwallet/#importexport-wallet","text":"Below are the official instructions on how to restore/import Recovery Phrase (mnemonic) on Trust wallet.","title":"Import/Export Wallet"},{"location":"hold/wallets/trustwallet/#how-to-restore-a-multi-coin-wallet","text":"","title":"How to Restore a Multi-Coin Wallet"},{"location":"hold/wallets/trustwallet/#how-to-import-a-wallet","text":"","title":"How to Import a Wallet"},{"location":"hold/wallets/harmony-cli/","text":"Command-line Tools Introduction hmy is the official Command Line Interface (CLI) provided by Harmony. You can use it as a local wallet and as a way to interact with your Ledger Nano device. The hmy CLI is completely open-source. You can track its development and post any issues encountered and your feature suggestions here . Features With the hmy CLI you can create a wallet, check your balance, send signed transactions to the Harmony blockchain, look up previous transactions, recover keys from previous mnemonics, create new keystores, and create new BLS keys. Supported Platforms OSX: main development platform Linux: tested Windows: tested / working under Windows Subsystem for Linux (WSL) Release information We will always upload the latest production release on github and announce future uploads in pre-production releases.","title":"Command-line Tools"},{"location":"hold/wallets/harmony-cli/#command-line-tools","text":"","title":"Command-line Tools"},{"location":"hold/wallets/harmony-cli/#introduction","text":"hmy is the official Command Line Interface (CLI) provided by Harmony. You can use it as a local wallet and as a way to interact with your Ledger Nano device. The hmy CLI is completely open-source. You can track its development and post any issues encountered and your feature suggestions here .","title":"Introduction"},{"location":"hold/wallets/harmony-cli/#features","text":"With the hmy CLI you can create a wallet, check your balance, send signed transactions to the Harmony blockchain, look up previous transactions, recover keys from previous mnemonics, create new keystores, and create new BLS keys.","title":"Features "},{"location":"hold/wallets/harmony-cli/#supported-platforms","text":"OSX: main development platform Linux: tested Windows: tested / working under Windows Subsystem for Linux (WSL)","title":"Supported Platforms "},{"location":"hold/wallets/harmony-cli/#release-information","text":"We will always upload the latest production release on github and announce future uploads in pre-production releases.","title":"Release information"},{"location":"hold/wallets/harmony-cli/cookbook/","text":"Cookbook The easiest way to get detailed help is to use the cli itself. For example below is the cookbook which gives an overview of various commands. {% hint style=\"success\" %} By default, cookbook will show the mainnet shard 0 ( https://api.s0.t.hmny.io ) RPC endpoint. Use the parameter --node=\"<RPC>\" so the example would show the s0 in the targeted network, example ./hmy cookbook --node=\"https://api.s1.os.hmny.io\" would show s0 in OSTN {% endhint %} ./hmy cookbook --node=\"https://api.s0.t.hmny.io\" #Cookbook of Usage #Note: #1) Every subcommand recognizes a '--help' flag #2) If a passphrase is used by a subcommand, one can enter their own passphrase interactively # with the --passphrase option. Alternatively, one can pass their own passphrase via a file # using the --passphrase-file option. If no passphrase option is selected, the default # passphrase of '' is used. #3) These examples use Shard 0 of Open Staking Network as argument for --node #Examples: #1. Check account balance on given chain ./hmy --node=\"https://api.s0.t.hmny.io\" balances <SOME_ONE_ADDRESS> #2. Check sent transaction ./hmy --node=\"https://api.s0.t.hmny.io\" blockchain transaction-by-hash <SOME_TX_HASH> #3. List local account keys ./hmy keys list #4. Sending a transaction (waits 40 seconds for transaction confirmation) ./hmy --node=\"https://api.s0.t.hmny.io\" transfer \\ --from <SOME_ONE_ADDRESS> --to <SOME_ONE_ADDRESS> \\ --from-shard 0 --to-shard 1 --amount 200 --passphrase #5. Sending a batch of transactions as dictated from a file (the `--dry-run` options still apply) ./hmy --node=\"https://api.s0.t.hmny.io\" transfer --file <PATH_TO_JSON_FILE> #Check README for details on json file format. #6. Check a completed transaction receipt ./hmy --node=\"https://api.s0.t.hmny.io\" blockchain transaction-receipt <SOME_TX_HASH> #7. Import an account using the mnemonic. Prompts the user to give the mnemonic. ./hmy keys recover-from-mnemonic <ACCOUNT_NAME> #8. Import an existing keystore file ./hmy keys import-ks <PATH_TO_KEYSTORE_JSON> #9. Import a keystore file using a secp256k1 private key ./hmy keys import-private-key <secp256k1_PRIVATE_KEY> #10. Export a keystore file's secp256k1 private key ./hmy keys export-private-key <ACCOUNT_ADDRESS> --passphrase #11. Generate a BLS key then encrypt and save the private key to the specified location. ./hmy keys generate-bls-key --bls-file-path <PATH_FOR_BLS_KEY_FILE> #12. Create a new validator with a list of BLS keys ./hmy --node=https://api.s0.os.hmny.io staking create-validator --amount 10 --validator-addr <SOME_ONE_ADDRESS> \\ --bls-pubkeys <BLS_KEY_1>,<BLS_KEY_2>,<BLS_KEY_3> \\ --identity foo --details bar --name baz --max-change-rate 0.1 --max-rate 0.1 --max-total-delegation 10 \\ --min-self-delegation 10 --rate 0.1 --security-contact Leo --website harmony.one --passphrase #13. Edit an existing validator ./hmy --node=\"https://api.s0.t.hmny.io\" staking edit-validator \\ --validator-addr <SOME_ONE_ADDRESS> --identity foo --details bar \\ --name baz --security-contact EK --website harmony.one \\ --min-self-delegation 0 --max-total-delegation 10 --rate 0.1\\ --add-bls-key <SOME_BLS_KEY> --remove-bls-key <OTHER_BLS_KEY> --passphrase #14. Delegate an amount to a validator ./hmy --node=\"https://api.s0.t.hmny.io\" staking delegate \\ --delegator-addr <SOME_ONE_ADDRESS> --validator-addr <VALIDATOR_ONE_ADDRESS> \\ --amount 10 --passphrase #15. Undelegate to a validator ./hmy --node=\"https://api.s0.t.hmny.io\" staking undelegate \\ --delegator-addr <SOME_ONE_ADDRESS> --validator-addr <VALIDATOR_ONE_ADDRESS> \\ --amount 10 --passphrase #16. Collect block rewards as a delegator ./hmy --node=\"https://api.s0.t.hmny.io\" staking collect-rewards \\ --delegator-addr <SOME_ONE_ADDRESS> --passphrase #17. Check elected validators ./hmy --node=\"https://api.s0.t.hmny.io\" blockchain validator elected #18. Get current staking utility metrics ./hmy --node=\"https://api.s0.t.hmny.io\" blockchain utility-metrics #19. Check in-memory record of failed staking transactions ./hmy --node=\"https://api.s0.t.hmny.io\" failures staking #20. Check which shard your BLS public key would be assigned to as a validator ./hmy --node=\"https://api.s0.t.hmny.io\" utility shard-for-bls 2d61379e44a772e5757e27ee2b3874254f56073e6bd226eb8b160371cc3c18b8c4977bd3dcb71fd57dc62bf0e143fd08","title":"Cookbook"},{"location":"hold/wallets/harmony-cli/cookbook/#cookbook","text":"The easiest way to get detailed help is to use the cli itself. For example below is the cookbook which gives an overview of various commands. {% hint style=\"success\" %} By default, cookbook will show the mainnet shard 0 ( https://api.s0.t.hmny.io ) RPC endpoint. Use the parameter --node=\"<RPC>\" so the example would show the s0 in the targeted network, example ./hmy cookbook --node=\"https://api.s1.os.hmny.io\" would show s0 in OSTN {% endhint %} ./hmy cookbook --node=\"https://api.s0.t.hmny.io\" #Cookbook of Usage #Note: #1) Every subcommand recognizes a '--help' flag #2) If a passphrase is used by a subcommand, one can enter their own passphrase interactively # with the --passphrase option. Alternatively, one can pass their own passphrase via a file # using the --passphrase-file option. If no passphrase option is selected, the default # passphrase of '' is used. #3) These examples use Shard 0 of Open Staking Network as argument for --node #Examples: #1. Check account balance on given chain ./hmy --node=\"https://api.s0.t.hmny.io\" balances <SOME_ONE_ADDRESS> #2. Check sent transaction ./hmy --node=\"https://api.s0.t.hmny.io\" blockchain transaction-by-hash <SOME_TX_HASH> #3. List local account keys ./hmy keys list #4. Sending a transaction (waits 40 seconds for transaction confirmation) ./hmy --node=\"https://api.s0.t.hmny.io\" transfer \\ --from <SOME_ONE_ADDRESS> --to <SOME_ONE_ADDRESS> \\ --from-shard 0 --to-shard 1 --amount 200 --passphrase #5. Sending a batch of transactions as dictated from a file (the `--dry-run` options still apply) ./hmy --node=\"https://api.s0.t.hmny.io\" transfer --file <PATH_TO_JSON_FILE> #Check README for details on json file format. #6. Check a completed transaction receipt ./hmy --node=\"https://api.s0.t.hmny.io\" blockchain transaction-receipt <SOME_TX_HASH> #7. Import an account using the mnemonic. Prompts the user to give the mnemonic. ./hmy keys recover-from-mnemonic <ACCOUNT_NAME> #8. Import an existing keystore file ./hmy keys import-ks <PATH_TO_KEYSTORE_JSON> #9. Import a keystore file using a secp256k1 private key ./hmy keys import-private-key <secp256k1_PRIVATE_KEY> #10. Export a keystore file's secp256k1 private key ./hmy keys export-private-key <ACCOUNT_ADDRESS> --passphrase #11. Generate a BLS key then encrypt and save the private key to the specified location. ./hmy keys generate-bls-key --bls-file-path <PATH_FOR_BLS_KEY_FILE> #12. Create a new validator with a list of BLS keys ./hmy --node=https://api.s0.os.hmny.io staking create-validator --amount 10 --validator-addr <SOME_ONE_ADDRESS> \\ --bls-pubkeys <BLS_KEY_1>,<BLS_KEY_2>,<BLS_KEY_3> \\ --identity foo --details bar --name baz --max-change-rate 0.1 --max-rate 0.1 --max-total-delegation 10 \\ --min-self-delegation 10 --rate 0.1 --security-contact Leo --website harmony.one --passphrase #13. Edit an existing validator ./hmy --node=\"https://api.s0.t.hmny.io\" staking edit-validator \\ --validator-addr <SOME_ONE_ADDRESS> --identity foo --details bar \\ --name baz --security-contact EK --website harmony.one \\ --min-self-delegation 0 --max-total-delegation 10 --rate 0.1\\ --add-bls-key <SOME_BLS_KEY> --remove-bls-key <OTHER_BLS_KEY> --passphrase #14. Delegate an amount to a validator ./hmy --node=\"https://api.s0.t.hmny.io\" staking delegate \\ --delegator-addr <SOME_ONE_ADDRESS> --validator-addr <VALIDATOR_ONE_ADDRESS> \\ --amount 10 --passphrase #15. Undelegate to a validator ./hmy --node=\"https://api.s0.t.hmny.io\" staking undelegate \\ --delegator-addr <SOME_ONE_ADDRESS> --validator-addr <VALIDATOR_ONE_ADDRESS> \\ --amount 10 --passphrase #16. Collect block rewards as a delegator ./hmy --node=\"https://api.s0.t.hmny.io\" staking collect-rewards \\ --delegator-addr <SOME_ONE_ADDRESS> --passphrase #17. Check elected validators ./hmy --node=\"https://api.s0.t.hmny.io\" blockchain validator elected #18. Get current staking utility metrics ./hmy --node=\"https://api.s0.t.hmny.io\" blockchain utility-metrics #19. Check in-memory record of failed staking transactions ./hmy --node=\"https://api.s0.t.hmny.io\" failures staking #20. Check which shard your BLS public key would be assigned to as a validator ./hmy --node=\"https://api.s0.t.hmny.io\" utility shard-for-bls 2d61379e44a772e5757e27ee2b3874254f56073e6bd226eb8b160371cc3c18b8c4977bd3dcb71fd57dc62bf0e143fd08","title":"Cookbook"},{"location":"hold/wallets/harmony-cli/create-import-wallet/","text":"Create or import wallet {% hint style=\"info\" %} When we mention the binary, we are referencing the ./hmy binary from the setup procedure . When we mention the shell scripts, we are referencing the ./hmy.sh shell script from the setup procedure. {% endhint %} New Wallet {% hint style=\"info\" %} Creation of a new account is done as a function of a generated bip39 mnemonic with 256 bits of entropy. You must provide an account alias name. {% endhint %} Using the Binary: ./hmy keys add <account-name> [--passphrase] Using the Shell Script: ./hmy.sh -- keys add <account-name1> [--passphrase] Example: ./hmy keys add test-account --passphrase {% hint style=\"warning\" %} Write/store this seed phrase in a safe place. it is the only way to recover your account if you ever forget your password. {% endhint %} This creates a keystore at the following directory: (hmy keys location)/account-name1/UTC--2019-09-16T21-25-35.297331000Z--678e7ea3dcb5f4e9724c0e761843572f10c49b73 When creating keys this way, hmy will ask you to provide a passphrase.\u200c Make sure you keep track of this passphrase for future use because the passphrase is used to decrypt the keystore when signing transactions. Also make sure you save the seed phrase, also called a mnemonic. {% hint style=\"info\" %} If you don't provide a passphrase using the --passphrase flag, the default passphrase is an empty string \"\" . The passphrase is used to decrypt the keystore when signing transactions. {% endhint %} To know where your wallet file has been created, run the following command: Using the Binary: ./hmy keys location Using the Shell Script: ./hmy.sh -- keys location You can check the list of wallets (local accounts) with the following command: Using the Binary: ./hmy keys list Using the Shell Script: ./hmy.sh -- keys list Import Wallet Importing a Keystore \u200cYou might have an existing keystore made by Harmony's old wallet.sh program that ends with \".key\" in the file name (example): one16qsd5ant9v94jrs89mruzx62h7ekcfxmduh2rx.key Or that starts with \"UTC\" in the file name (example): UTC--2020-01-15T01-02-06.606670000Z--9689a0711642bf08ea92ed98d552f0c1b8c8cefb Both these files can be imported into hmy using the command import-ks as shown below. {% hint style=\"warning\" %} Note that the --passphrase flag only enables a password prompt after the command is entered, there are no other arguments necessary here (if you dont put --passphrase flag in the command it will assume no password needed and will not prompt you for one, which basically means that your wallet keyfile will not be password protected!). {% endhint %} Using the Binary: ./hmy keys import-ks <absolute_path_to_keystore> --passphrase Using the Shell Script: ./hmy.sh -- keys import-ks <absolute_path_to_keystore> --passphrase Examples: ./hmy keys import-ks /home/harmony/one16qsd5ant9v94jrs89mruzx62h7ekcfxmduh2rx.key --passphrase ./hmy keys import-ks /home/harmony/UTC--2020-01-15T01-02-06.606670000Z--9689a0711642bf08ea92ed98d552f0c1b8c8cefb --passphrase \u200cKeep in mind that you should know the passphrase associated with the imported keystore and pass it as a parameter as shown in the commands above. For keystores created by Harmony's wallet.sh , the default passphrase is an empty string; this matters for signing transactions.\u200c Importing a Private Key Sometimes you might have a secp256k1 private key, such as the one generated from the following command: openssl ecparam -genkey -name secp256k1 -text -noout -outform DER | xxd -p -c 1000 | sed 's/41534e31204f49443a20736563703235366b310a30740201010420/PrivKey: /' | sed 's/a00706052b8104000aa144034200/\\'$'\\nPubKey: /' You can import the key with an optional name and passphrase Using the Binary: ./hmy keys import-private-key <secp256k1_private_key> [wallet_name] [--passphrase] Using the Shell Script: ./hmy.sh -- keys import-private-key <secp256k1_private_key> [wallet_name] [--passphrase] Example: ./hmy keys import-private-key b8798ca0a56ce16517ea37c6b1229cbb67cf0e022c423b044fe8f537830d8be5 my_wallet_name_here --passphrase If no account name is provided, a random word concatenated with -imported will be used. If no passphrase is provided, the default passphrase will be used (which is blank). Note that the CLI currently only supports importing secp256k1 private keys. Importing a Mnemonic Phrase You can recover lost wallet keys by entering the mnemonic words you received (and hopefully saved) when creating it: Using the Binary: ./hmy keys recover-from-mnemonic [wallet_name] Using the Shell Script: ./hmy.sh -- keys recover-from-mnemonic [wallet_name] Example: ./hmy keys recover-from-mnemonic nameofyourkey","title":"Create or import wallet"},{"location":"hold/wallets/harmony-cli/create-import-wallet/#create-or-import-wallet","text":"{% hint style=\"info\" %} When we mention the binary, we are referencing the ./hmy binary from the setup procedure . When we mention the shell scripts, we are referencing the ./hmy.sh shell script from the setup procedure. {% endhint %}","title":"Create or import wallet"},{"location":"hold/wallets/harmony-cli/create-import-wallet/#new-wallet","text":"{% hint style=\"info\" %} Creation of a new account is done as a function of a generated bip39 mnemonic with 256 bits of entropy. You must provide an account alias name. {% endhint %}","title":"New Wallet"},{"location":"hold/wallets/harmony-cli/create-import-wallet/#using-the-binary","text":"./hmy keys add <account-name> [--passphrase]","title":"Using the Binary:"},{"location":"hold/wallets/harmony-cli/create-import-wallet/#using-the-shell-script","text":"./hmy.sh -- keys add <account-name1> [--passphrase]","title":"Using the Shell Script:"},{"location":"hold/wallets/harmony-cli/create-import-wallet/#example","text":"./hmy keys add test-account --passphrase {% hint style=\"warning\" %} Write/store this seed phrase in a safe place. it is the only way to recover your account if you ever forget your password. {% endhint %} This creates a keystore at the following directory: (hmy keys location)/account-name1/UTC--2019-09-16T21-25-35.297331000Z--678e7ea3dcb5f4e9724c0e761843572f10c49b73 When creating keys this way, hmy will ask you to provide a passphrase.\u200c Make sure you keep track of this passphrase for future use because the passphrase is used to decrypt the keystore when signing transactions. Also make sure you save the seed phrase, also called a mnemonic. {% hint style=\"info\" %} If you don't provide a passphrase using the --passphrase flag, the default passphrase is an empty string \"\" . The passphrase is used to decrypt the keystore when signing transactions. {% endhint %} To know where your wallet file has been created, run the following command:","title":"Example:"},{"location":"hold/wallets/harmony-cli/create-import-wallet/#using-the-binary_1","text":"./hmy keys location","title":"Using the Binary:"},{"location":"hold/wallets/harmony-cli/create-import-wallet/#using-the-shell-script_1","text":"./hmy.sh -- keys location You can check the list of wallets (local accounts) with the following command:","title":"Using the Shell Script:"},{"location":"hold/wallets/harmony-cli/create-import-wallet/#using-the-binary_2","text":"./hmy keys list","title":"Using the Binary:"},{"location":"hold/wallets/harmony-cli/create-import-wallet/#using-the-shell-script_2","text":"./hmy.sh -- keys list","title":"Using the Shell Script:"},{"location":"hold/wallets/harmony-cli/create-import-wallet/#import-wallet","text":"","title":"Import Wallet"},{"location":"hold/wallets/harmony-cli/create-import-wallet/#importing-a-keystore","text":"\u200cYou might have an existing keystore made by Harmony's old wallet.sh program that ends with \".key\" in the file name (example): one16qsd5ant9v94jrs89mruzx62h7ekcfxmduh2rx.key Or that starts with \"UTC\" in the file name (example): UTC--2020-01-15T01-02-06.606670000Z--9689a0711642bf08ea92ed98d552f0c1b8c8cefb Both these files can be imported into hmy using the command import-ks as shown below. {% hint style=\"warning\" %} Note that the --passphrase flag only enables a password prompt after the command is entered, there are no other arguments necessary here (if you dont put --passphrase flag in the command it will assume no password needed and will not prompt you for one, which basically means that your wallet keyfile will not be password protected!). {% endhint %}","title":"Importing a Keystore "},{"location":"hold/wallets/harmony-cli/create-import-wallet/#using-the-binary_3","text":"./hmy keys import-ks <absolute_path_to_keystore> --passphrase","title":"Using the Binary:"},{"location":"hold/wallets/harmony-cli/create-import-wallet/#using-the-shell-script_3","text":"./hmy.sh -- keys import-ks <absolute_path_to_keystore> --passphrase","title":"Using the Shell Script:"},{"location":"hold/wallets/harmony-cli/create-import-wallet/#examples","text":"./hmy keys import-ks /home/harmony/one16qsd5ant9v94jrs89mruzx62h7ekcfxmduh2rx.key --passphrase ./hmy keys import-ks /home/harmony/UTC--2020-01-15T01-02-06.606670000Z--9689a0711642bf08ea92ed98d552f0c1b8c8cefb --passphrase \u200cKeep in mind that you should know the passphrase associated with the imported keystore and pass it as a parameter as shown in the commands above. For keystores created by Harmony's wallet.sh , the default passphrase is an empty string; this matters for signing transactions.\u200c","title":"Examples:"},{"location":"hold/wallets/harmony-cli/create-import-wallet/#importing-a-private-key","text":"Sometimes you might have a secp256k1 private key, such as the one generated from the following command: openssl ecparam -genkey -name secp256k1 -text -noout -outform DER | xxd -p -c 1000 | sed 's/41534e31204f49443a20736563703235366b310a30740201010420/PrivKey: /' | sed 's/a00706052b8104000aa144034200/\\'$'\\nPubKey: /' You can import the key with an optional name and passphrase","title":"Importing a Private Key "},{"location":"hold/wallets/harmony-cli/create-import-wallet/#using-the-binary_4","text":"./hmy keys import-private-key <secp256k1_private_key> [wallet_name] [--passphrase]","title":"Using the Binary:"},{"location":"hold/wallets/harmony-cli/create-import-wallet/#using-the-shell-script_4","text":"./hmy.sh -- keys import-private-key <secp256k1_private_key> [wallet_name] [--passphrase]","title":"Using the Shell Script:"},{"location":"hold/wallets/harmony-cli/create-import-wallet/#example_1","text":"./hmy keys import-private-key b8798ca0a56ce16517ea37c6b1229cbb67cf0e022c423b044fe8f537830d8be5 my_wallet_name_here --passphrase If no account name is provided, a random word concatenated with -imported will be used. If no passphrase is provided, the default passphrase will be used (which is blank). Note that the CLI currently only supports importing secp256k1 private keys.","title":"Example:"},{"location":"hold/wallets/harmony-cli/create-import-wallet/#importing-a-mnemonic-phrase","text":"You can recover lost wallet keys by entering the mnemonic words you received (and hopefully saved) when creating it:","title":"Importing a Mnemonic Phrase "},{"location":"hold/wallets/harmony-cli/create-import-wallet/#using-the-binary_5","text":"./hmy keys recover-from-mnemonic [wallet_name]","title":"Using the Binary:"},{"location":"hold/wallets/harmony-cli/create-import-wallet/#using-the-shell-script_5","text":"./hmy.sh -- keys recover-from-mnemonic [wallet_name]","title":"Using the Shell Script:"},{"location":"hold/wallets/harmony-cli/create-import-wallet/#example_2","text":"./hmy keys recover-from-mnemonic nameofyourkey","title":"Example:"},{"location":"hold/wallets/harmony-cli/download-setup/","text":"Download & setup {% hint style=\"info\" %} Throughout this guide, we will use the following syntax: ./hmy : This is the CLI program ./hmy.sh -- : This is the command to use the CLI with a shell wrapper (for macOS) <argument> : This is a required argument [argument] : This is an optional argument / : This is a line break, used to break up a line while writing a command {% endhint %} Download Harmony CLI tool 1. For Linux Enter the following command into your shell of choice: curl -LO https://harmony.one/hmycli && mv hmycli hmy && chmod +x hmy {% hint style=\"info\" %} If you have permission issues, enter the commands with \"sudo\" at the beginning, i.e. \"sudo curl -LO https://harmony.one/hmycli && mv hmycli hmy && chmod +x hmy\" {% endhint %} 2. For MacOS hmy depends on some dynamic libraries, hence we recommend using the shell wrapper. Enter there commands into your terminal: curl -O https://raw.githubusercontent.com/harmony-one/go-sdk/master/scripts/hmy.sh chmod u+x hmy.sh ./hmy.sh -d Now you can use hmy.sh as a wrapper over hmy and you should assume that all references to hmy in these documents refer to hmy.sh . For example, the command ./hmy becomes ./hmy.sh -- . {% hint style=\"warning\" %} Note that since hmy is not statically linked, you cannot arbitrarily move hmy.sh to anywhere on your filesystem like you could with a single binary. {% endhint %} 3. Compiling from source If you are interested in compiling from source, then the process is more involved. Steps: Clone the repository at the same level as the main Harmony repo: {% hint style=\"warning\" %} Have mcl , bls all built and prepared. This may require you to see instructions in the harmony repo's readme. {% endhint %} cd /Users/edgar/Repos/harmony-work/src/github.com/harmony-one ls bls harmony mcl git clone https://github.com/harmony-one/go-sdk.git Then setup the build flags: source harmony/scripts/setup_bls_build_flags.sh Call make in the go-sdk repo. This builds a binary named hmy : cd go-sdk make Congratulations! You can now use the binary to run the CLI.","title":"Download & setup"},{"location":"hold/wallets/harmony-cli/download-setup/#download-setup","text":"{% hint style=\"info\" %} Throughout this guide, we will use the following syntax: ./hmy : This is the CLI program ./hmy.sh -- : This is the command to use the CLI with a shell wrapper (for macOS) <argument> : This is a required argument [argument] : This is an optional argument / : This is a line break, used to break up a line while writing a command {% endhint %}","title":"Download &amp; setup"},{"location":"hold/wallets/harmony-cli/download-setup/#download-harmony-cli-tool","text":"","title":"Download Harmony CLI tool"},{"location":"hold/wallets/harmony-cli/download-setup/#1-for-linux","text":"Enter the following command into your shell of choice: curl -LO https://harmony.one/hmycli && mv hmycli hmy && chmod +x hmy {% hint style=\"info\" %} If you have permission issues, enter the commands with \"sudo\" at the beginning, i.e. \"sudo curl -LO https://harmony.one/hmycli && mv hmycli hmy && chmod +x hmy\" {% endhint %}","title":"1. For Linux"},{"location":"hold/wallets/harmony-cli/download-setup/#2-for-macos","text":"hmy depends on some dynamic libraries, hence we recommend using the shell wrapper. Enter there commands into your terminal: curl -O https://raw.githubusercontent.com/harmony-one/go-sdk/master/scripts/hmy.sh chmod u+x hmy.sh ./hmy.sh -d Now you can use hmy.sh as a wrapper over hmy and you should assume that all references to hmy in these documents refer to hmy.sh . For example, the command ./hmy becomes ./hmy.sh -- . {% hint style=\"warning\" %} Note that since hmy is not statically linked, you cannot arbitrarily move hmy.sh to anywhere on your filesystem like you could with a single binary. {% endhint %}","title":"2. For MacOS"},{"location":"hold/wallets/harmony-cli/download-setup/#3-compiling-from-source","text":"If you are interested in compiling from source, then the process is more involved. Steps: Clone the repository at the same level as the main Harmony repo: {% hint style=\"warning\" %} Have mcl , bls all built and prepared. This may require you to see instructions in the harmony repo's readme. {% endhint %} cd /Users/edgar/Repos/harmony-work/src/github.com/harmony-one ls bls harmony mcl git clone https://github.com/harmony-one/go-sdk.git Then setup the build flags: source harmony/scripts/setup_bls_build_flags.sh Call make in the go-sdk repo. This builds a binary named hmy : cd go-sdk make Congratulations! You can now use the binary to run the CLI.","title":"3. Compiling from source"},{"location":"hold/wallets/harmony-cli/list-of-transaction-error-messages/","text":"List of transaction error messages Here is the list of failed transaction messages which can be checked by querying your transaction hash, checking the transaction hash on explorer or checking the blockchain pool transactions. Here is how with the hmy cli : ./hmy failures plain --node=\"https://api.s0.t.hmny.io\" {% hint style=\"info\" %} failed messages are network and shard specifics, please use the shard you were sending the transaction from and change the --node value accordingly Example above is for shard 1 in the test network. Mainnet example on shard 0 would be : https://api.s0.t.hmny.io {% endhint %} Message Notes transaction size is <tx size in Bytes>: oversized data A transaction cannot be more than 32KB to prevent DDOS attacks transaction value is <tx value>: negative value Transaction value is negative transaction gas is <tx gas-limit>: exceeds block gas limit Assumed to be hardcoded / config transaction sender is <tx from addr>: invalid sender Transaction sent from an invalid account transaction gas-price is <tx gas-price> ONE: transaction underpriced Too low transaction fee transaction nonce is <tx nonce>: nonce too low Occurs when the nonce associated with that transaction is too lower than the actual nonce insufficient funds for gas * price + value Usually when not enough holdings to pay for gas transaction gas is <tx gas-limit>: intrinsic gas too low Intrinsic gas is based on the size of the transaction including data transaction gas-price is <tx gas-price> ONE in full transaction pool: transaction underpriced Transactions can get dropped if tx pool is full and tx has lowest gas existing transaction price was not bumped enough: replacement transaction underpriced If a transaction attempts to replace another with less gas than the original, it will get dropped old transaction, nonce <tx nonce> is too low During promotion (from 'future' txs to pending txs in pool) the nonce is checked again unpayable transaction, out of gas or balance of <acc bal in ONE >cannot pay cost of <cost on ONE> During promotion (from 'future' txs to pending txs in pool) balance is checked again exceeds cap for queued transactions for account <one1... address> Each account has a limit in the number of txs it can put into the tx pool fairness-exceeding pending transaction If tx pool is full, txs from accounts with highest number of total transactions in pool will be dropped exceeds global cap for queued transactions Occurs when the tx can\u00b4t be queued because global cap for queued tx pool exceeds the max old transaction, nonce <tx nonce> is too low During demote (from pending txs in pool to 'future' txs) the nonce is checked again unpayable transaction, out of gas or balance of <acc bal in ONE > cannot pay cost of <cost in ONE> During demote (from pending txs in pool to 'future' txs) balance is checked again demoting pending transaction Tx was not added to the pool and move to queue of 'future' txs","title":"List of transaction error messages"},{"location":"hold/wallets/harmony-cli/list-of-transaction-error-messages/#list-of-transaction-error-messages","text":"Here is the list of failed transaction messages which can be checked by querying your transaction hash, checking the transaction hash on explorer or checking the blockchain pool transactions. Here is how with the hmy cli : ./hmy failures plain --node=\"https://api.s0.t.hmny.io\" {% hint style=\"info\" %} failed messages are network and shard specifics, please use the shard you were sending the transaction from and change the --node value accordingly Example above is for shard 1 in the test network. Mainnet example on shard 0 would be : https://api.s0.t.hmny.io {% endhint %} Message Notes transaction size is <tx size in Bytes>: oversized data A transaction cannot be more than 32KB to prevent DDOS attacks transaction value is <tx value>: negative value Transaction value is negative transaction gas is <tx gas-limit>: exceeds block gas limit Assumed to be hardcoded / config transaction sender is <tx from addr>: invalid sender Transaction sent from an invalid account transaction gas-price is <tx gas-price> ONE: transaction underpriced Too low transaction fee transaction nonce is <tx nonce>: nonce too low Occurs when the nonce associated with that transaction is too lower than the actual nonce insufficient funds for gas * price + value Usually when not enough holdings to pay for gas transaction gas is <tx gas-limit>: intrinsic gas too low Intrinsic gas is based on the size of the transaction including data transaction gas-price is <tx gas-price> ONE in full transaction pool: transaction underpriced Transactions can get dropped if tx pool is full and tx has lowest gas existing transaction price was not bumped enough: replacement transaction underpriced If a transaction attempts to replace another with less gas than the original, it will get dropped old transaction, nonce <tx nonce> is too low During promotion (from 'future' txs to pending txs in pool) the nonce is checked again unpayable transaction, out of gas or balance of <acc bal in ONE >cannot pay cost of <cost on ONE> During promotion (from 'future' txs to pending txs in pool) balance is checked again exceeds cap for queued transactions for account <one1... address> Each account has a limit in the number of txs it can put into the tx pool fairness-exceeding pending transaction If tx pool is full, txs from accounts with highest number of total transactions in pool will be dropped exceeds global cap for queued transactions Occurs when the tx can\u00b4t be queued because global cap for queued tx pool exceeds the max old transaction, nonce <tx nonce> is too low During demote (from pending txs in pool to 'future' txs) the nonce is checked again unpayable transaction, out of gas or balance of <acc bal in ONE > cannot pay cost of <cost in ONE> During demote (from pending txs in pool to 'future' txs) balance is checked again demoting pending transaction Tx was not added to the pool and move to queue of 'future' txs","title":"List of transaction error messages"},{"location":"hold/wallets/harmony-cli/other-cli-references/","text":"Other CLI references Generate Markdown Documentation if you want a full list of commands the hmy tool knows in markdown format, please run the following command: ./hmy docs Then in the same directory, hmy creates a directory named hmy-docs in which you can find all markdown files for the commands and subcommands. Delete Account Deletion of a one account is possible by issuing the below command ./hmy keys remove [ACCOUNT-NAME] {% hint style=\"danger\" %} Be sure to have saved your private keys before if you had fund in that account. Deleting the account without backing it up means you'll lose it forever. {% endhint %}","title":"Other CLI references"},{"location":"hold/wallets/harmony-cli/other-cli-references/#other-cli-references","text":"","title":"Other CLI references"},{"location":"hold/wallets/harmony-cli/other-cli-references/#generate-markdown-documentation","text":"if you want a full list of commands the hmy tool knows in markdown format, please run the following command: ./hmy docs Then in the same directory, hmy creates a directory named hmy-docs in which you can find all markdown files for the commands and subcommands.","title":"Generate Markdown Documentation"},{"location":"hold/wallets/harmony-cli/other-cli-references/#delete-account","text":"Deletion of a one account is possible by issuing the below command ./hmy keys remove [ACCOUNT-NAME] {% hint style=\"danger\" %} Be sure to have saved your private keys before if you had fund in that account. Deleting the account without backing it up means you'll lose it forever. {% endhint %}","title":"Delete Account"},{"location":"hold/wallets/harmony-cli/querying-balances/","text":"Querying balances Get JSON output of balances on all shards of a given ONE address with the balances subcommand: Using the Binary: ./hmy balances <ONE-address> --node=\"<endpoint-address>\" Using the Shell Wrapper: ./hmy.sh -- balances <ONE-address> --node=\"<endpoint-address>\" Example: ./hmy balances one1km7xg8e3xjys7azp9f4xp8hkw79vm2h3f2lade --node=\"https://api.s0.t.hmny.io\"","title":"Querying balances"},{"location":"hold/wallets/harmony-cli/querying-balances/#querying-balances","text":"Get JSON output of balances on all shards of a given ONE address with the balances subcommand:","title":"Querying balances"},{"location":"hold/wallets/harmony-cli/querying-balances/#using-the-binary","text":"./hmy balances <ONE-address> --node=\"<endpoint-address>\"","title":"Using the Binary:"},{"location":"hold/wallets/harmony-cli/querying-balances/#using-the-shell-wrapper","text":"./hmy.sh -- balances <ONE-address> --node=\"<endpoint-address>\"","title":"Using the Shell Wrapper:"},{"location":"hold/wallets/harmony-cli/querying-balances/#example","text":"./hmy balances one1km7xg8e3xjys7azp9f4xp8hkw79vm2h3f2lade --node=\"https://api.s0.t.hmny.io\"","title":"Example:"},{"location":"hold/wallets/harmony-cli/querying-the-blockchain/","text":"Querying the blockchain hmy provides several subcommands under the blockchain subcommand which let you query the blockchain. {% hint style=\"info\" %} The Harmony blockchain is a sharded blockchain, therefore some commands depend on which shard you target. The shard you target when querying is controlled by the --node flag. For example, if a transaction is made between shard 0 and shard 1, the transaction receipt must be queried from whichever shard sent the funds - in this case shard 0, so the --node flag would look like this: --node=\"https://api.s0.t.hmny.io\" For other shards, please replace the s0 with the appropriate shard number - eg. s1 for shard 1, s2 for shard 2 etc. {% endhint %} List of available commands By using ./hmy blockchain help command we can see that the following options are available: {% hint style=\"info\" %} * block-by-number - get a harmony blockchain block by block number * current-nonce - current nonce of an account delegation information about delegations * known-chains - print out the known chain-ids * latest-header - get the latest header * median-stake - median stake of top 320 validators with delegations applied stake (pre-epos processing) * protocol-version - the version of the Harmony Protocol * transaction-by-hash - get transaction by hash * transaction-receipt - get information about a finalized transaction validator information about validators * pool - get transaction pool information {% endhint %} Here are some examples of the above commands that you will use frequently: transaction-by-hash Checking the hash of your transaction to see the transaction data and if the transaction has been completed Using the Binary: ./hmy blockchain transaction-by-hash <transaction-hash> --node=\"<endpoint-address>\" Using the Shell Wrapper: ./hmy.sh -- blockchain transaction-by-hash <transaction-hash> --node=\"<endpoint-address>\" Example: ./hmy blockchain transaction-by-hash 0x75d91100734edcd1497200cb438f0864d2ed4a44a88bf8c87855cb2b3cc54001 --node=\"https://api.s0.t.hmny.io\" { \"id\": \"0\", \"jsonrpc\": \"2.0\", \"result\": { \"blockHash\": \"0xf9c7e165d5636c7dd8a06bf2c53c364d7597028d7e10a3c5256462adf97b1f73\", \"blockNumber\": \"0xa35\", \"from\": \"one1mrrq665uarrmfur6hptevx9furph4293a37zme\", \"gas\": \"0x5208\", \"gasPrice\": \"0x3b9aca00\", \"hash\": \"0x75d91100734edcd1497200cb438f0864d2ed4a44a88bf8c87855cb2b3cc54001\", \"input\": \"0x\", \"nonce\": \"0xe\", \"r\": \"0x4a17d89f7b1818fe72d480a64fecfede1d73bd7242fcaabf907204a7022be806\", \"s\": \"0x557be1b9c378ecbae972e71ec6fc5d484abfe8cb7961ccd87724865c3a7020bc\", \"shardID\": 0, \"timestamp\": \"0x5e1cfcc1\", \"to\": \"one1mrrq665uarrmfur6hptevx9furph4293a37zme\", \"toShardID\": 1, \"transactionIndex\": \"0x0\", \"v\": \"0x2a\", \"value\": \"0xde0b6b3a7640000\" } } transaction-receipt Get information about a finalized transaction: Using the Binary: ./hmy blockchain transaction-receipt <transaction-hash> --node=\"<endpoint-address>\" Using the Shell Wrapper: ./hmy.sh -- blockchain transaction-receipt <transaction-hash> --node=\"<endpoint-address>\" Example: ./hmy blockchain transaction-receipt 0x599793f313ee17566f8d09728b9d043b8e26135ddce86beeee13f98767d452f7 --node=\"https://api.s0.t.hmny.io\" { \"id\": \"0\", \"jsonrpc\": \"2.0\", \"result\": { \"blockHash\": \"0x52171a8f3af94f639f1e6044679c4189c3cd088ffe7f1c216ce3089212373af9\", \"blockNumber\": \"0x6177\", \"contractAddress\": null, \"cumulativeGasUsed\": \"0x5208\", \"from\": \"0x261fa45c6a09cd3faa277d829e91d9473973357c\", \"gasUsed\": \"0x5208\", \"logs\": [], \"logsBloom\": \"0x00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000\", \"shardID\": 0, \"status\": \"0x1\", \"to\": \"0x06916163a17f07ce70e3d43ed37395f05b5738ae\", \"transactionHash\": \"0x599793f313ee17566f8d09728b9d043b8e26135ddce86beeee13f98767d452f7\", \"transactionIndex\": \"0x0\" } } latest-header command Checking the network status, last block, epoch, leaders, based on the shard number: Using the Binary: ./hmy blockchain latest-header --node=\"<endpoint-address>\" Using the Shell Wrapper: ./hmy.sh -- blockchain latest-header --node=\"<endpoint-address>\" Example: {% tabs %} {% tab title=\"Shard 0\" %} ./hmy blockchain latest-header --node=\"https://api.s0.t.hmny.io\" { \"id\": \"0\", \"jsonrpc\": \"2.0\", \"result\": { \"blockHash\": \"0xae23db112d22062be6a0f065ecc3989d4e9559ad6a1f34fe4344d021907e8c2e\", \"blockNumber\": 415749, \"epoch\": 5543, \"lastCommitBitmap\": \"fffffffffffffffb0f00\", \"lastCommitSig\": \"06efa677bdd327d3d9602fd246c214edb35e447692dccc2219ef08ce2fa026b96f3826fcb5a2a3f724222ecef4af66029f3b5d677e54534519ad2a405ad3b336dd5145dcc083fc2330b9d0bb398affd1745cab274b5019f32cba0287bd5e5a17\", \"leader\": \"one18ahxsrk9g4h4gz5r8ema7nyw6g9zpun5hhp54d\", \"shardID\": 0, \"timestamp\": \"2019-12-11 12:18:21 +0000 UTC\", \"unixtime\": 1576066701, \"viewID\": 415745 } } {% endtab %} {% tab title=\"Shard 1\" %} ./hmy blockchain latest-header --node=\"https://api.s1.t.hmny.io\" { \"id\": \"0\", \"jsonrpc\": \"2.0\", \"result\": { \"blockHash\": \"0x65d528672301b1c086b4f2db89ce20f6977f7aeaa494073352e211ac29f55179\", \"blockNumber\": 456065, \"epoch\": 5543, \"lastCommitBitmap\": \"ffffffffffffffff0f00\", \"lastCommitSig\": \"c8e049810c1f649625259f684e99f4a9cfc51cf01b2dd032f884136c9922ebb8fe0929e366bbf8122e430402d04d4804362013302994d4924c2990bdffeacb4b79e075c1897947a7ec5be44eef6f1bd1e013b80008f28085c15e17aa49629a09\", \"leader\": \"one1vaqzxt50ltk9hq4d44lgxmj4pj2x533fsp2acx\", \"shardID\": 1, \"timestamp\": \"2019-12-11 12:21:52 +0000 UTC\", \"unixtime\": 1576066912, \"viewID\": 456065 } } {% endtab %} {% tab title=\"Shard 2\" %} ./hmy blockchain latest-header --node=\"https://api.s2.t.hmny.io\" { \"id\": \"0\", \"jsonrpc\": \"2.0\", \"result\": { \"blockHash\": \"0xd5775e720a9bcc5a88fd13aac27d72365f4724d6a513ecf39af53c1bb826823d\", \"blockNumber\": 453475, \"epoch\": 5543, \"lastCommitBitmap\": \"ffffffffffffffff0f4000\", \"lastCommitSig\": \"701bad22a95b7ee937446c3f614755d1729f19b5976f1230af6de65fd7ecc0d8b95795396a55d78994b5a8ecaed77d028721f76a58e9919ab01f4aba36a6f3a3dda3aaf39b313e5d623e73ca83d71fc1631ae964e1747826662652be85fada18\", \"leader\": \"one18vn4hpu8jpu8p9pql59m7p0x8dqrpsw0jzav9u\", \"shardID\": 2, \"timestamp\": \"2019-12-11 12:22:26 +0000 UTC\", \"unixtime\": 1576066946, \"viewID\": 453508 } } {% endtab %} {% tab title=\"Shard 3\" %} ./hmy blockchain latest-header --node=\"https://api.s3.t.hmny.io\" { \"id\": \"0\", \"jsonrpc\": \"2.0\", \"result\": { \"blockHash\": \"0xd5775e720a9bcc5a88fd13aac27d72365f4724d6a513ecf39af53c1bb826823d\", \"blockNumber\": 453475, \"epoch\": 5543, \"lastCommitBitmap\": \"ffffffffffffffff0f4000\", \"lastCommitSig\": \"701bad22a95b7ee937446c3f614755d1729f19b5976f1230af6de65fd7ecc0d8b95795396a55d78994b5a8ecaed77d028721f76a58e9919ab01f4aba36a6f3a3dda3aaf39b313e5d623e73ca83d71fc1631ae964e1747826662652be85fada18\", \"leader\": \"one188345hbsgdsgstw6eenjgxsgusgs\", \"shardID\": 2, \"timestamp\": \"2019-12-11 12:22:26 +0000 UTC\", \"unixtime\": 1576066946, \"viewID\": 453508 } } {% endtab %} {% endtabs %} block-by-number {% hint style=\"info\" %} Note the block-number provided must be in hex with a 0x prefix. For example if you call latest-header and get a result of 10657 you convert this to hex which is 29A1 and then use the value 0x29A1 for block-number. This can be done using printf '0x%x\\n' 10617 #0X29a1 {% endhint %} Using the Binary: ./hmy blockchain block-by-number <block-number> --node=\"<endpoint-address>\" Using the Shell Wrapper: ./hmy.sh -- blockchain block-by-number <block-number> --node=\"<endpoint-address>\" Example: ./hmy blockchain block-by-number 0x29A1 --node=\"https://api.s0.t.hmny.io\" { \"id\": \"0\", \"jsonrpc\": \"2.0\", \"result\": { \"difficulty\": 0, \"extraData\": \"0x\", \"gasLimit\": \"0x4c4b400\", \"gasUsed\": \"0x0\", \"hash\": \"0x5cb6e0752530cef5e25c52539feca22b8ad197cca60c04cf06f4ee05d6537096\", \"logsBloom\": \"0x00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000\", \"miner\": \"0x3f6e680ec5456f540a833e77df4c8ed20a20f274\", \"mixHash\": \"0x0000000000000000000000000000000000000000000000000000000000000000\", \"nonce\": 0, \"number\": \"0x29a1\", \"parentHash\": \"0x30d28fb69701f8348e0cd6a7abbacceb4286009fc43827dc243e79508da057d7\", \"receiptsRoot\": \"0x56e81f171bcc55a6ff8345e692c0f86e5b48e01b996cadc001622fb5e363b421\", \"size\": \"0x50c\", \"stakingTransactions\": [], \"stateRoot\": \"0x096fac171e818e54e611d3543fd43b1929a4468d17dcb8766d18eaf1e426749c\", \"timestamp\": \"0x5e755a56\", \"transactions\": [], \"transactionsRoot\": \"0x56e81f171bcc55a6ff8345e692c0f86e5b48e01b996cadc001622fb5e363b421\", \"uncles\": [] } }","title":"Querying the blockchain"},{"location":"hold/wallets/harmony-cli/querying-the-blockchain/#querying-the-blockchain","text":"hmy provides several subcommands under the blockchain subcommand which let you query the blockchain. {% hint style=\"info\" %} The Harmony blockchain is a sharded blockchain, therefore some commands depend on which shard you target. The shard you target when querying is controlled by the --node flag. For example, if a transaction is made between shard 0 and shard 1, the transaction receipt must be queried from whichever shard sent the funds - in this case shard 0, so the --node flag would look like this: --node=\"https://api.s0.t.hmny.io\" For other shards, please replace the s0 with the appropriate shard number - eg. s1 for shard 1, s2 for shard 2 etc. {% endhint %}","title":"Querying the blockchain"},{"location":"hold/wallets/harmony-cli/querying-the-blockchain/#list-of-available-commands","text":"By using ./hmy blockchain help command we can see that the following options are available: {% hint style=\"info\" %} * block-by-number - get a harmony blockchain block by block number * current-nonce - current nonce of an account delegation information about delegations * known-chains - print out the known chain-ids * latest-header - get the latest header * median-stake - median stake of top 320 validators with delegations applied stake (pre-epos processing) * protocol-version - the version of the Harmony Protocol * transaction-by-hash - get transaction by hash * transaction-receipt - get information about a finalized transaction validator information about validators * pool - get transaction pool information {% endhint %} Here are some examples of the above commands that you will use frequently:","title":"List of available commands"},{"location":"hold/wallets/harmony-cli/querying-the-blockchain/#transaction-by-hash","text":"Checking the hash of your transaction to see the transaction data and if the transaction has been completed","title":"transaction-by-hash"},{"location":"hold/wallets/harmony-cli/querying-the-blockchain/#using-the-binary","text":"./hmy blockchain transaction-by-hash <transaction-hash> --node=\"<endpoint-address>\"","title":"Using the Binary:"},{"location":"hold/wallets/harmony-cli/querying-the-blockchain/#using-the-shell-wrapper","text":"./hmy.sh -- blockchain transaction-by-hash <transaction-hash> --node=\"<endpoint-address>\"","title":"Using the Shell Wrapper:"},{"location":"hold/wallets/harmony-cli/querying-the-blockchain/#example","text":"./hmy blockchain transaction-by-hash 0x75d91100734edcd1497200cb438f0864d2ed4a44a88bf8c87855cb2b3cc54001 --node=\"https://api.s0.t.hmny.io\" { \"id\": \"0\", \"jsonrpc\": \"2.0\", \"result\": { \"blockHash\": \"0xf9c7e165d5636c7dd8a06bf2c53c364d7597028d7e10a3c5256462adf97b1f73\", \"blockNumber\": \"0xa35\", \"from\": \"one1mrrq665uarrmfur6hptevx9furph4293a37zme\", \"gas\": \"0x5208\", \"gasPrice\": \"0x3b9aca00\", \"hash\": \"0x75d91100734edcd1497200cb438f0864d2ed4a44a88bf8c87855cb2b3cc54001\", \"input\": \"0x\", \"nonce\": \"0xe\", \"r\": \"0x4a17d89f7b1818fe72d480a64fecfede1d73bd7242fcaabf907204a7022be806\", \"s\": \"0x557be1b9c378ecbae972e71ec6fc5d484abfe8cb7961ccd87724865c3a7020bc\", \"shardID\": 0, \"timestamp\": \"0x5e1cfcc1\", \"to\": \"one1mrrq665uarrmfur6hptevx9furph4293a37zme\", \"toShardID\": 1, \"transactionIndex\": \"0x0\", \"v\": \"0x2a\", \"value\": \"0xde0b6b3a7640000\" } }","title":"Example:"},{"location":"hold/wallets/harmony-cli/querying-the-blockchain/#transaction-receipt","text":"Get information about a finalized transaction:","title":"transaction-receipt"},{"location":"hold/wallets/harmony-cli/querying-the-blockchain/#using-the-binary_1","text":"./hmy blockchain transaction-receipt <transaction-hash> --node=\"<endpoint-address>\"","title":"Using the Binary:"},{"location":"hold/wallets/harmony-cli/querying-the-blockchain/#using-the-shell-wrapper_1","text":"./hmy.sh -- blockchain transaction-receipt <transaction-hash> --node=\"<endpoint-address>\"","title":"Using the Shell Wrapper:"},{"location":"hold/wallets/harmony-cli/querying-the-blockchain/#example_1","text":"./hmy blockchain transaction-receipt 0x599793f313ee17566f8d09728b9d043b8e26135ddce86beeee13f98767d452f7 --node=\"https://api.s0.t.hmny.io\" { \"id\": \"0\", \"jsonrpc\": \"2.0\", \"result\": { \"blockHash\": \"0x52171a8f3af94f639f1e6044679c4189c3cd088ffe7f1c216ce3089212373af9\", \"blockNumber\": \"0x6177\", \"contractAddress\": null, \"cumulativeGasUsed\": \"0x5208\", \"from\": \"0x261fa45c6a09cd3faa277d829e91d9473973357c\", \"gasUsed\": \"0x5208\", \"logs\": [], \"logsBloom\": \"0x00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000\", \"shardID\": 0, \"status\": \"0x1\", \"to\": \"0x06916163a17f07ce70e3d43ed37395f05b5738ae\", \"transactionHash\": \"0x599793f313ee17566f8d09728b9d043b8e26135ddce86beeee13f98767d452f7\", \"transactionIndex\": \"0x0\" } }","title":"Example:"},{"location":"hold/wallets/harmony-cli/querying-the-blockchain/#latest-header-command","text":"Checking the network status, last block, epoch, leaders, based on the shard number:","title":"latest-header command"},{"location":"hold/wallets/harmony-cli/querying-the-blockchain/#using-the-binary_2","text":"./hmy blockchain latest-header --node=\"<endpoint-address>\"","title":"Using the Binary:"},{"location":"hold/wallets/harmony-cli/querying-the-blockchain/#using-the-shell-wrapper_2","text":"./hmy.sh -- blockchain latest-header --node=\"<endpoint-address>\"","title":"Using the Shell Wrapper:"},{"location":"hold/wallets/harmony-cli/querying-the-blockchain/#example_2","text":"{% tabs %} {% tab title=\"Shard 0\" %} ./hmy blockchain latest-header --node=\"https://api.s0.t.hmny.io\" { \"id\": \"0\", \"jsonrpc\": \"2.0\", \"result\": { \"blockHash\": \"0xae23db112d22062be6a0f065ecc3989d4e9559ad6a1f34fe4344d021907e8c2e\", \"blockNumber\": 415749, \"epoch\": 5543, \"lastCommitBitmap\": \"fffffffffffffffb0f00\", \"lastCommitSig\": \"06efa677bdd327d3d9602fd246c214edb35e447692dccc2219ef08ce2fa026b96f3826fcb5a2a3f724222ecef4af66029f3b5d677e54534519ad2a405ad3b336dd5145dcc083fc2330b9d0bb398affd1745cab274b5019f32cba0287bd5e5a17\", \"leader\": \"one18ahxsrk9g4h4gz5r8ema7nyw6g9zpun5hhp54d\", \"shardID\": 0, \"timestamp\": \"2019-12-11 12:18:21 +0000 UTC\", \"unixtime\": 1576066701, \"viewID\": 415745 } } {% endtab %} {% tab title=\"Shard 1\" %} ./hmy blockchain latest-header --node=\"https://api.s1.t.hmny.io\" { \"id\": \"0\", \"jsonrpc\": \"2.0\", \"result\": { \"blockHash\": \"0x65d528672301b1c086b4f2db89ce20f6977f7aeaa494073352e211ac29f55179\", \"blockNumber\": 456065, \"epoch\": 5543, \"lastCommitBitmap\": \"ffffffffffffffff0f00\", \"lastCommitSig\": \"c8e049810c1f649625259f684e99f4a9cfc51cf01b2dd032f884136c9922ebb8fe0929e366bbf8122e430402d04d4804362013302994d4924c2990bdffeacb4b79e075c1897947a7ec5be44eef6f1bd1e013b80008f28085c15e17aa49629a09\", \"leader\": \"one1vaqzxt50ltk9hq4d44lgxmj4pj2x533fsp2acx\", \"shardID\": 1, \"timestamp\": \"2019-12-11 12:21:52 +0000 UTC\", \"unixtime\": 1576066912, \"viewID\": 456065 } } {% endtab %} {% tab title=\"Shard 2\" %} ./hmy blockchain latest-header --node=\"https://api.s2.t.hmny.io\" { \"id\": \"0\", \"jsonrpc\": \"2.0\", \"result\": { \"blockHash\": \"0xd5775e720a9bcc5a88fd13aac27d72365f4724d6a513ecf39af53c1bb826823d\", \"blockNumber\": 453475, \"epoch\": 5543, \"lastCommitBitmap\": \"ffffffffffffffff0f4000\", \"lastCommitSig\": \"701bad22a95b7ee937446c3f614755d1729f19b5976f1230af6de65fd7ecc0d8b95795396a55d78994b5a8ecaed77d028721f76a58e9919ab01f4aba36a6f3a3dda3aaf39b313e5d623e73ca83d71fc1631ae964e1747826662652be85fada18\", \"leader\": \"one18vn4hpu8jpu8p9pql59m7p0x8dqrpsw0jzav9u\", \"shardID\": 2, \"timestamp\": \"2019-12-11 12:22:26 +0000 UTC\", \"unixtime\": 1576066946, \"viewID\": 453508 } } {% endtab %} {% tab title=\"Shard 3\" %} ./hmy blockchain latest-header --node=\"https://api.s3.t.hmny.io\" { \"id\": \"0\", \"jsonrpc\": \"2.0\", \"result\": { \"blockHash\": \"0xd5775e720a9bcc5a88fd13aac27d72365f4724d6a513ecf39af53c1bb826823d\", \"blockNumber\": 453475, \"epoch\": 5543, \"lastCommitBitmap\": \"ffffffffffffffff0f4000\", \"lastCommitSig\": \"701bad22a95b7ee937446c3f614755d1729f19b5976f1230af6de65fd7ecc0d8b95795396a55d78994b5a8ecaed77d028721f76a58e9919ab01f4aba36a6f3a3dda3aaf39b313e5d623e73ca83d71fc1631ae964e1747826662652be85fada18\", \"leader\": \"one188345hbsgdsgstw6eenjgxsgusgs\", \"shardID\": 2, \"timestamp\": \"2019-12-11 12:22:26 +0000 UTC\", \"unixtime\": 1576066946, \"viewID\": 453508 } } {% endtab %} {% endtabs %}","title":"Example:"},{"location":"hold/wallets/harmony-cli/querying-the-blockchain/#block-by-number","text":"{% hint style=\"info\" %} Note the block-number provided must be in hex with a 0x prefix. For example if you call latest-header and get a result of 10657 you convert this to hex which is 29A1 and then use the value 0x29A1 for block-number. This can be done using printf '0x%x\\n' 10617 #0X29a1 {% endhint %}","title":"block-by-number"},{"location":"hold/wallets/harmony-cli/querying-the-blockchain/#using-the-binary_3","text":"./hmy blockchain block-by-number <block-number> --node=\"<endpoint-address>\"","title":"Using the Binary:"},{"location":"hold/wallets/harmony-cli/querying-the-blockchain/#using-the-shell-wrapper_3","text":"./hmy.sh -- blockchain block-by-number <block-number> --node=\"<endpoint-address>\"","title":"Using the Shell Wrapper:"},{"location":"hold/wallets/harmony-cli/querying-the-blockchain/#example_3","text":"./hmy blockchain block-by-number 0x29A1 --node=\"https://api.s0.t.hmny.io\" { \"id\": \"0\", \"jsonrpc\": \"2.0\", \"result\": { \"difficulty\": 0, \"extraData\": \"0x\", \"gasLimit\": \"0x4c4b400\", \"gasUsed\": \"0x0\", \"hash\": \"0x5cb6e0752530cef5e25c52539feca22b8ad197cca60c04cf06f4ee05d6537096\", \"logsBloom\": \"0x00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000\", \"miner\": \"0x3f6e680ec5456f540a833e77df4c8ed20a20f274\", \"mixHash\": \"0x0000000000000000000000000000000000000000000000000000000000000000\", \"nonce\": 0, \"number\": \"0x29a1\", \"parentHash\": \"0x30d28fb69701f8348e0cd6a7abbacceb4286009fc43827dc243e79508da057d7\", \"receiptsRoot\": \"0x56e81f171bcc55a6ff8345e692c0f86e5b48e01b996cadc001622fb5e363b421\", \"size\": \"0x50c\", \"stakingTransactions\": [], \"stateRoot\": \"0x096fac171e818e54e611d3543fd43b1929a4468d17dcb8766d18eaf1e426749c\", \"timestamp\": \"0x5e755a56\", \"transactions\": [], \"transactionsRoot\": \"0x56e81f171bcc55a6ff8345e692c0f86e5b48e01b996cadc001622fb5e363b421\", \"uncles\": [] } }","title":"Example:"},{"location":"hold/wallets/harmony-cli/send-tx/","text":"Sending transactions Perhaps the most important feature of the hmy CLI is the ability to create and send signed transactions to the Harmony blockchain. Overview Sending a transaction Using the Binary: ./hmy transfer --node=\"<endpoint-address>\" \\ --from <ONE_address> --to <ONE_address> \\ --from-shard <shard> --to-shard <shard> \\ --amount <amount> --chain-id <chain-id> --passphrase Using the Shell Script: ./hmy.sh -- transfer --node=\"<endpoint-address>\" \\ --from <ONE_address> --to <ONE_address> \\ --from-shard <shard> --to-shard <shard> \\ --amount <amount> --chain-id <chain-id> --passphrase Example: ./hmy --node=\"https://api.s0.t.hmny.io\" \\ transfer --from one1yc06ghr2p8xnl2380kpfayweguuhxdtupkhqzw \\ --to one1q6gkzcap0uruuu8r6sldxuu47pd4ww9w9t7tg6 \\ --from-shard 0 --to-shard 1 --amount 12.5 --chain-id mainnet --passphrase mypassword Checking the transaction hash Check for finality of the transaction by using the transaction hash like so: Using the Binary: ./hmy blockchain transaction-receipt <transaction_id> --node=\"<endpoint-address>\" Using the Shell Script: ./hmy.sh -- blockchain transaction-receipt <transaction_id> --node=\"<endpoint-address>\" Example: ./hmy --node=\"https://api.s0.t.hmny.io\" \\ blockchain transaction-receipt \\ 0x599793f313ee17566f8d09728b9d043b8e26135ddce86beeee13f98767d452f7 Detail ChainIDs Let's first check what chain-ids are available for us to use, we can do that easily with: Using the Binary: ./hmy blockchain known-chains Using the Shell Script: ./hmy.sh -- blockchain known-chains Example: ./hmy blockchain known-chains [ \"mainnet\", \"testnet\", \"devnet\" ] Notice that the output is pretty printed JSON , most outputs of hmy are JSON encoded and hmy defaults to showing it nicely indented. Sometimes though you might want to turn that off, you can do that for any command with the flag --no-pretty . By default, hmy assumes the testnet chain-id; override that with the --chain-id flag Our first transaction We'll use the transfer subcommand of hmy to send a transaction. ./hmy transfer Error: required flag(s) \"amount\", \"from\", \"from-shard\", \"to\", \"to-shard\" not set Notice that simply invoking the transfer subcommand gave us an error message about certain flags not being set. We'll need to provide legitimate values for these flags for our transaction to proceed successfully. Reading off the flags in the error message from left to right, the semantic meanings are as follows: amount : The quantity of Harmony One token to transfer from the senders to the receiver from : The sender's one address from-shard : Shard from which sender's balance will be drawn from to : Receiver's ONE address to-shard : Shard in which receiver will receive the amount sent by the sender passphrase: your wallet passphrase, which is prompted when you hit enter (or you can use a txt file with password and add it: --passphrase file.txt) A sharded blockchain is a new kind of blockchain architecture where the network is partitioned into sub-networks called shards. Sharding is one of the distinguishing features of Harmony and it is key to solving the traditional scalability problems encountered in other blockchain protocols. Note: The same ONE address will have a different balance in each shard. Currently Harmony mainnet has four shards while testnet has three shards. Sending a transaction from one shard to another is called a \"cross-shard transaction.\" Thus, a correct usage of transfer looks like: Using the Binary: ./hmy transfer --node=\"<endpoint-address>\" \\ --from <ONE_address> --to <ONE_address> \\ --from-shard <shard> --to-shard <shard> \\ --amount <amount> --chain-id <chain-id> --passphrase Using the Shell Wrapper: ./hmy.sh -- transfer --node=\"<endpoint-address>\" \\ --from <ONE_address> --to <ONE_address> \\ --from-shard <shard> --to-shard <shard> \\ --amount <amount> --chain-id <chain-id> --passphrase Example: ./hmy transfer --node=\"https://api.s0.t.hmny.io\" \\ --from one1yc06ghr2p8xnl2380kpfayweguuhxdtupkhqzw \\ --to one1q6gkzcap0uruuu8r6sldxuu47pd4ww9w9t7tg6 \\ --from-shard 0 --to-shard 1 --amount 10 --chain-id mainnet {\"transaction-receipt\":\"0x455f98a3aa11ef50ee5cc5ac8bbd79e04f2fe353180bb7e25fc6c921fc8fdc83\"} {% hint style=\"info\" %} hmy assumes that the private keys needed for signing the transaction on behalf of the sender ( one1yc06ghr2p8xnl2380kpfayweguuhxdtupkhqzw in this example) exist in the local keystore or in the hardware wallet if the --ledger flag was used. {% endhint %} {% hint style=\"info\" %} The sender's account must have enough of a balance on the from-shard to send a transaction. In our example, one1yc06ghr2p8xnl2380kpfayweguuhxdtupkhqzw must have an amount balance of at least 10 in shard 0. {% endhint %} Try out your transaction with the flag --dry-run , this flag tells hmy to create, cryptographically sign the transaction but not actually send it off. Sender's balances are checked and the output is a JSON dump of the signed transaction. Signing and sending a transaction is very quick, about 2 seconds maximum. The actual sending of the transaction is done via an RPC (Remote Procedure Call), you'll notice that we did not explicitly say where to send the transaction to. This is because the default destination of the RPC call goes to http://localhost:9500 , the default HTTP RPC server running when you start a local harmony blockchain. For real world usage though, you'll want a different location. You can control that with the --node flag (see the top of this page for an example). Result of the transaction Once an RPC machine receives a transaction, it sends you back a transaction hash. This transaction hash is the key identifier used when querying the blockchain for transactions. {% hint style=\"warning\" %} Simply having a transaction hash does NOT imply that the transaction was successfully accepted by the blockchain. A transaction is successfully accepted once it has been added to the blockchain. In the case of cross-shard transactions (when the from-shard, to-shard values are different), this means each shard has added the transaction to their blockchain. {% endhint %} We can pull down details of the finalized transaction with ./hmy blockchain transaction-receipt as well: Using the Binary: ./hmy blockchain transaction-receipt --node=\"<endpoint-address>\" <transaction-hash> Using the Shell Wrapper: ./hmy.sh -- blockchain transaction-receipt --node=\"<endpoint-address>\" <transaction-hash> Example: ./hmy blockchain transaction-receipt \\ --node=\"https://api.s0.t.hmny.io\" \\ 0x25dd32397b5a69146b2dc3bbdc8ef8aae271e9b12a36c6dff1eb8995cac9dcba { \"id\": \"0\", \"jsonrpc\": \"2.0\", \"result\": { \"blockHash\": \"0x67eb5d671af76814d9ab326f9ec36c5b889b872e0c34e8cbe484aea20f0611ea\", \"blockNumber\": \"0x21017f\", \"contractAddress\": null, \"cumulativeGasUsed\": \"0x5208\", \"from\": \"one1sp4q22r7cc78742mzrufu6xwcekqxjgq78jk3m\", \"gasUsed\": \"0x5208\", \"logs\": [], \"logsBloom\": \"0x00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000\", \"shardID\": 0, \"status\": \"0x1\", \"to\": \"one129r9pj3sk0re76f7zs3qz92rggmdgjhtwge62k\", \"transactionHash\": \"0x25dd32397b5a69146b2dc3bbdc8ef8aae271e9b12a36c6dff1eb8995cac9dcba\", \"transactionIndex\": \"0x0\" } } {% hint style=\"info\" %} If the transaction has not finalized then the \"result\" key in the JSON output will have value of null . {% endhint %} {% hint style=\"warning\" %} You should set the value of --node to the same shard that sent the transaction, notice that the URL we used, https://api.s0.t.hmny.io contained s0 , this means that this URL is targeting shard 0. For further information, see Querying the Blockchain . {% endhint %} You can tell hmy to wait until transaction confirmation by providing a positive integer value to flag --wait-for-confirm . For example, --wait-for-confirm=10 will try checking the receipt of the transaction for 10 seconds.","title":"Sending transactions"},{"location":"hold/wallets/harmony-cli/send-tx/#sending-transactions","text":"Perhaps the most important feature of the hmy CLI is the ability to create and send signed transactions to the Harmony blockchain.","title":"Sending transactions"},{"location":"hold/wallets/harmony-cli/send-tx/#overview","text":"","title":"Overview "},{"location":"hold/wallets/harmony-cli/send-tx/#sending-a-transaction","text":"","title":"Sending a transaction "},{"location":"hold/wallets/harmony-cli/send-tx/#using-the-binary","text":"./hmy transfer --node=\"<endpoint-address>\" \\ --from <ONE_address> --to <ONE_address> \\ --from-shard <shard> --to-shard <shard> \\ --amount <amount> --chain-id <chain-id> --passphrase","title":"Using the Binary:"},{"location":"hold/wallets/harmony-cli/send-tx/#using-the-shell-script","text":"./hmy.sh -- transfer --node=\"<endpoint-address>\" \\ --from <ONE_address> --to <ONE_address> \\ --from-shard <shard> --to-shard <shard> \\ --amount <amount> --chain-id <chain-id> --passphrase","title":"Using the Shell Script:"},{"location":"hold/wallets/harmony-cli/send-tx/#example","text":"./hmy --node=\"https://api.s0.t.hmny.io\" \\ transfer --from one1yc06ghr2p8xnl2380kpfayweguuhxdtupkhqzw \\ --to one1q6gkzcap0uruuu8r6sldxuu47pd4ww9w9t7tg6 \\ --from-shard 0 --to-shard 1 --amount 12.5 --chain-id mainnet --passphrase mypassword","title":"Example:"},{"location":"hold/wallets/harmony-cli/send-tx/#checking-the-transaction-hash","text":"Check for finality of the transaction by using the transaction hash like so:","title":"Checking the transaction hash "},{"location":"hold/wallets/harmony-cli/send-tx/#using-the-binary_1","text":"./hmy blockchain transaction-receipt <transaction_id> --node=\"<endpoint-address>\"","title":"Using the Binary:"},{"location":"hold/wallets/harmony-cli/send-tx/#using-the-shell-script_1","text":"./hmy.sh -- blockchain transaction-receipt <transaction_id> --node=\"<endpoint-address>\"","title":"Using the Shell Script:"},{"location":"hold/wallets/harmony-cli/send-tx/#example_1","text":"./hmy --node=\"https://api.s0.t.hmny.io\" \\ blockchain transaction-receipt \\ 0x599793f313ee17566f8d09728b9d043b8e26135ddce86beeee13f98767d452f7","title":"Example:"},{"location":"hold/wallets/harmony-cli/send-tx/#detail","text":"","title":"Detail "},{"location":"hold/wallets/harmony-cli/send-tx/#chainids","text":"Let's first check what chain-ids are available for us to use, we can do that easily with:","title":"ChainIDs "},{"location":"hold/wallets/harmony-cli/send-tx/#using-the-binary_2","text":"./hmy blockchain known-chains","title":"Using the Binary:"},{"location":"hold/wallets/harmony-cli/send-tx/#using-the-shell-script_2","text":"./hmy.sh -- blockchain known-chains","title":"Using the Shell Script:"},{"location":"hold/wallets/harmony-cli/send-tx/#example_2","text":"./hmy blockchain known-chains [ \"mainnet\", \"testnet\", \"devnet\" ] Notice that the output is pretty printed JSON , most outputs of hmy are JSON encoded and hmy defaults to showing it nicely indented. Sometimes though you might want to turn that off, you can do that for any command with the flag --no-pretty . By default, hmy assumes the testnet chain-id; override that with the --chain-id flag","title":"Example:"},{"location":"hold/wallets/harmony-cli/send-tx/#our-first-transaction","text":"We'll use the transfer subcommand of hmy to send a transaction. ./hmy transfer Error: required flag(s) \"amount\", \"from\", \"from-shard\", \"to\", \"to-shard\" not set Notice that simply invoking the transfer subcommand gave us an error message about certain flags not being set. We'll need to provide legitimate values for these flags for our transaction to proceed successfully. Reading off the flags in the error message from left to right, the semantic meanings are as follows: amount : The quantity of Harmony One token to transfer from the senders to the receiver from : The sender's one address from-shard : Shard from which sender's balance will be drawn from to : Receiver's ONE address to-shard : Shard in which receiver will receive the amount sent by the sender passphrase: your wallet passphrase, which is prompted when you hit enter (or you can use a txt file with password and add it: --passphrase file.txt) A sharded blockchain is a new kind of blockchain architecture where the network is partitioned into sub-networks called shards. Sharding is one of the distinguishing features of Harmony and it is key to solving the traditional scalability problems encountered in other blockchain protocols. Note: The same ONE address will have a different balance in each shard. Currently Harmony mainnet has four shards while testnet has three shards. Sending a transaction from one shard to another is called a \"cross-shard transaction.\" Thus, a correct usage of transfer looks like:","title":"Our first transaction "},{"location":"hold/wallets/harmony-cli/send-tx/#using-the-binary_3","text":"./hmy transfer --node=\"<endpoint-address>\" \\ --from <ONE_address> --to <ONE_address> \\ --from-shard <shard> --to-shard <shard> \\ --amount <amount> --chain-id <chain-id> --passphrase","title":"Using the Binary:"},{"location":"hold/wallets/harmony-cli/send-tx/#using-the-shell-wrapper","text":"./hmy.sh -- transfer --node=\"<endpoint-address>\" \\ --from <ONE_address> --to <ONE_address> \\ --from-shard <shard> --to-shard <shard> \\ --amount <amount> --chain-id <chain-id> --passphrase","title":"Using the Shell Wrapper:"},{"location":"hold/wallets/harmony-cli/send-tx/#example_3","text":"./hmy transfer --node=\"https://api.s0.t.hmny.io\" \\ --from one1yc06ghr2p8xnl2380kpfayweguuhxdtupkhqzw \\ --to one1q6gkzcap0uruuu8r6sldxuu47pd4ww9w9t7tg6 \\ --from-shard 0 --to-shard 1 --amount 10 --chain-id mainnet {\"transaction-receipt\":\"0x455f98a3aa11ef50ee5cc5ac8bbd79e04f2fe353180bb7e25fc6c921fc8fdc83\"} {% hint style=\"info\" %} hmy assumes that the private keys needed for signing the transaction on behalf of the sender ( one1yc06ghr2p8xnl2380kpfayweguuhxdtupkhqzw in this example) exist in the local keystore or in the hardware wallet if the --ledger flag was used. {% endhint %} {% hint style=\"info\" %} The sender's account must have enough of a balance on the from-shard to send a transaction. In our example, one1yc06ghr2p8xnl2380kpfayweguuhxdtupkhqzw must have an amount balance of at least 10 in shard 0. {% endhint %} Try out your transaction with the flag --dry-run , this flag tells hmy to create, cryptographically sign the transaction but not actually send it off. Sender's balances are checked and the output is a JSON dump of the signed transaction. Signing and sending a transaction is very quick, about 2 seconds maximum. The actual sending of the transaction is done via an RPC (Remote Procedure Call), you'll notice that we did not explicitly say where to send the transaction to. This is because the default destination of the RPC call goes to http://localhost:9500 , the default HTTP RPC server running when you start a local harmony blockchain. For real world usage though, you'll want a different location. You can control that with the --node flag (see the top of this page for an example).","title":"Example:"},{"location":"hold/wallets/harmony-cli/send-tx/#result-of-the-transaction","text":"Once an RPC machine receives a transaction, it sends you back a transaction hash. This transaction hash is the key identifier used when querying the blockchain for transactions. {% hint style=\"warning\" %} Simply having a transaction hash does NOT imply that the transaction was successfully accepted by the blockchain. A transaction is successfully accepted once it has been added to the blockchain. In the case of cross-shard transactions (when the from-shard, to-shard values are different), this means each shard has added the transaction to their blockchain. {% endhint %} We can pull down details of the finalized transaction with ./hmy blockchain transaction-receipt as well:","title":"Result of the transaction "},{"location":"hold/wallets/harmony-cli/send-tx/#using-the-binary_4","text":"./hmy blockchain transaction-receipt --node=\"<endpoint-address>\" <transaction-hash>","title":"Using the Binary:"},{"location":"hold/wallets/harmony-cli/send-tx/#using-the-shell-wrapper_1","text":"./hmy.sh -- blockchain transaction-receipt --node=\"<endpoint-address>\" <transaction-hash>","title":"Using the Shell Wrapper:"},{"location":"hold/wallets/harmony-cli/send-tx/#example_4","text":"./hmy blockchain transaction-receipt \\ --node=\"https://api.s0.t.hmny.io\" \\ 0x25dd32397b5a69146b2dc3bbdc8ef8aae271e9b12a36c6dff1eb8995cac9dcba { \"id\": \"0\", \"jsonrpc\": \"2.0\", \"result\": { \"blockHash\": \"0x67eb5d671af76814d9ab326f9ec36c5b889b872e0c34e8cbe484aea20f0611ea\", \"blockNumber\": \"0x21017f\", \"contractAddress\": null, \"cumulativeGasUsed\": \"0x5208\", \"from\": \"one1sp4q22r7cc78742mzrufu6xwcekqxjgq78jk3m\", \"gasUsed\": \"0x5208\", \"logs\": [], \"logsBloom\": \"0x00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000\", \"shardID\": 0, \"status\": \"0x1\", \"to\": \"one129r9pj3sk0re76f7zs3qz92rggmdgjhtwge62k\", \"transactionHash\": \"0x25dd32397b5a69146b2dc3bbdc8ef8aae271e9b12a36c6dff1eb8995cac9dcba\", \"transactionIndex\": \"0x0\" } } {% hint style=\"info\" %} If the transaction has not finalized then the \"result\" key in the JSON output will have value of null . {% endhint %} {% hint style=\"warning\" %} You should set the value of --node to the same shard that sent the transaction, notice that the URL we used, https://api.s0.t.hmny.io contained s0 , this means that this URL is targeting shard 0. For further information, see Querying the Blockchain . {% endhint %} You can tell hmy to wait until transaction confirmation by providing a positive integer value to flag --wait-for-confirm . For example, --wait-for-confirm=10 will try checking the receipt of the transaction for 10 seconds.","title":"Example:"},{"location":"hold/wallets/harmony-cli/staking-transactions/","text":"Staking Transactions Delegating to a Validator You can delegate tokens to a validator using the following command: ./hmy --node=\"https://api.s0.t.hmny.io\" staking delegate \\ --delegator-addr [ONE ADDRESS] --validator-addr [ONE ADDRESS] \\ --amount [AMOUNT] --passphrase The CLI will ask for the passphrase for the delegator-addr keystore file. --delegator-addr is the ONE address of the delegator (string) --validator-addr is the ONE address of the validator (string) --amount is the number of ONE tokens to delegate to the validator (float) {% hint style=\"info\" %} As a validator, if you want to increase your stake, you will have to delegate to yourself. For delegating to your own validator, delegator-addr and validator-addr will be the same. {% endhint %} Undelegating from a Validator You can un-delegate tokens from a validator using the following command: ./hmy --node=\"https://api.s0.t.hmny.io\" staking undelegate \\ --delegator-addr [ONE ADDRESS] --validator-addr [ONE ADDRESS] \\ --amount [AMOUNT] --passphrase The CLI will ask for the passphrase for the delegator-addr keystore file. --delegator-addr is the ONE address of the delegator (string) --validator-addr is the ONE address of the validator (string) --amount is the number of ONE tokens to un-delegate (float) {% hint style=\"info\" %} As a validator, for un-delegating from your own validator, delegator-addr and validator-addr will be the same. {% endhint %} Collecting Rewards You can collect your block rewards with the following command: ./hmy --node=\"https://api.s0.t.hmny.io\" staking collect-rewards \\ --delegator-addr [ONE ADDRESS] --passphrase The CLI will prompt your for the passphrase of the delegation account. --delegator-addr is the account to collect rewards for {% hint style=\"warning\" %} You can only collect ALL of your block rewards at once, not partially. {% endhint %}","title":"Staking Transactions"},{"location":"hold/wallets/harmony-cli/staking-transactions/#staking-transactions","text":"","title":"Staking Transactions"},{"location":"hold/wallets/harmony-cli/staking-transactions/#delegating-to-a-validator","text":"You can delegate tokens to a validator using the following command: ./hmy --node=\"https://api.s0.t.hmny.io\" staking delegate \\ --delegator-addr [ONE ADDRESS] --validator-addr [ONE ADDRESS] \\ --amount [AMOUNT] --passphrase The CLI will ask for the passphrase for the delegator-addr keystore file. --delegator-addr is the ONE address of the delegator (string) --validator-addr is the ONE address of the validator (string) --amount is the number of ONE tokens to delegate to the validator (float) {% hint style=\"info\" %} As a validator, if you want to increase your stake, you will have to delegate to yourself. For delegating to your own validator, delegator-addr and validator-addr will be the same. {% endhint %}","title":"Delegating to a Validator"},{"location":"hold/wallets/harmony-cli/staking-transactions/#undelegating-from-a-validator","text":"You can un-delegate tokens from a validator using the following command: ./hmy --node=\"https://api.s0.t.hmny.io\" staking undelegate \\ --delegator-addr [ONE ADDRESS] --validator-addr [ONE ADDRESS] \\ --amount [AMOUNT] --passphrase The CLI will ask for the passphrase for the delegator-addr keystore file. --delegator-addr is the ONE address of the delegator (string) --validator-addr is the ONE address of the validator (string) --amount is the number of ONE tokens to un-delegate (float) {% hint style=\"info\" %} As a validator, for un-delegating from your own validator, delegator-addr and validator-addr will be the same. {% endhint %}","title":"Undelegating from a Validator"},{"location":"hold/wallets/harmony-cli/staking-transactions/#collecting-rewards","text":"You can collect your block rewards with the following command: ./hmy --node=\"https://api.s0.t.hmny.io\" staking collect-rewards \\ --delegator-addr [ONE ADDRESS] --passphrase The CLI will prompt your for the passphrase of the delegation account. --delegator-addr is the account to collect rewards for {% hint style=\"warning\" %} You can only collect ALL of your block rewards at once, not partially. {% endhint %}","title":"Collecting Rewards"},{"location":"hold/wallets/ledger/download-and-setup/","text":"Download & Setup {% hint style=\"info\" %} Currently Harmony is available only on Ledger Nano S. {% endhint %} Step 1. Turn on Developer Download and install the latest Ledger Live version onto your computer. Ledger Live is the app you use to manage your Ledger device. Please follow the official installation instruction here . {% hint style=\"success\" %} Make sure to i nstall the latest firmware on your device. This ensures compatibility with the Harmony app. {% endhint %} Open Ledger Live, select Manager. Turn on Developer Mode in Manager: Settings -> Experimental Features -> Developer Mode, as shown below: Step 2. Search for the App in the Catalog Ledger live provides app catalog for different types of apps, as shown below: To find the Harmony app, type harmony in the search bar, as shown below: Step 3. Install/Remove the App There are two buttons associated with Harmony One app. The install button can be clicked to install Harmony One app to Ledger Nano. The app can be uninstalled by clicking the trash bin button. Step 4. Using the App To use Harmony One app, please check your Ledger Nano device and click both buttons to open the app.","title":"Download and setup"},{"location":"hold/wallets/ledger/download-and-setup/#download-setup","text":"{% hint style=\"info\" %} Currently Harmony is available only on Ledger Nano S. {% endhint %}","title":"Download &amp; Setup"},{"location":"hold/wallets/ledger/download-and-setup/#step-1-turn-on-developer","text":"Download and install the latest Ledger Live version onto your computer. Ledger Live is the app you use to manage your Ledger device. Please follow the official installation instruction here . {% hint style=\"success\" %} Make sure to i nstall the latest firmware on your device. This ensures compatibility with the Harmony app. {% endhint %} Open Ledger Live, select Manager. Turn on Developer Mode in Manager: Settings -> Experimental Features -> Developer Mode, as shown below:","title":"Step 1. Turn on Developer"},{"location":"hold/wallets/ledger/download-and-setup/#step-2-search-for-the-app-in-the-catalog","text":"Ledger live provides app catalog for different types of apps, as shown below: To find the Harmony app, type harmony in the search bar, as shown below:","title":"Step 2. Search for the App in the Catalog"},{"location":"hold/wallets/ledger/download-and-setup/#step-3-installremove-the-app","text":"There are two buttons associated with Harmony One app. The install button can be clicked to install Harmony One app to Ledger Nano. The app can be uninstalled by clicking the trash bin button.","title":"Step 3. Install/Remove the App"},{"location":"hold/wallets/ledger/download-and-setup/#step-4-using-the-app","text":"To use Harmony One app, please check your Ledger Nano device and click both buttons to open the app.","title":"Step 4. Using the App"},{"location":"hold/wallets/ledger/overview/","text":"Ledger Ledger Nano S The Nano S is a hardware wallet created by Ledger. A hardware wallet stores the private keys to Harmony tokens on a separate device, making it much harder for malicious parties to steal them. In fact, the private keys never leave the Nano S itself, so they will remain secure even if the device is connected to a compromised computer. As long as you follow best practices when using your Nano S, it is virtually impossible for an attacker to steal your funds.","title":"Overview"},{"location":"hold/wallets/ledger/overview/#ledger","text":"","title":"Ledger"},{"location":"hold/wallets/ledger/overview/#ledger-nano-s","text":"The Nano S is a hardware wallet created by Ledger. A hardware wallet stores the private keys to Harmony tokens on a separate device, making it much harder for malicious parties to steal them. In fact, the private keys never leave the Nano S itself, so they will remain secure even if the device is connected to a compromised computer. As long as you follow best practices when using your Nano S, it is virtually impossible for an attacker to steal your funds.","title":"Ledger Nano S"},{"location":"hold/wallets/ledger/using-with-hmy-cli/","text":"Ledger with HMY CLI Download & Setup HMY To interact with your Ledger device using the HMYC CLI, please click here to download and configure it first. Interacting with Ledger {% hint style=\"success\" %} When using Ledger with HMY CLI, the only difference here is that you have to add parameter --ledger on every command. {% endhint %} With that in mind, you can run any other command via HMY CLI using your Ledger. {% hint style=\"warning\" %} Make sure HMY CLI is being run with super user permissions when interacting with Ledger. {% endhint %} Below, are a few practical examples on how to interact with your Ledger device. 1. Displaying your Address For example, if you want to show your Ledger address you would simply run: Using the Binary: ./hmy keys list --ledger Using the Shell Wrapper: ./hmy.sh -- keys list --ledger 2. Displaying your Balance Using the Binary: ./hmy balances --node=\"<endpoint-address>\" <ONE-address> --ledger Using the Shell Wrapper: ./hmy.sh -- balances --node=\"<endpoint-address>\" <ONE-address> --ledger 3. Sending Transactions Using the Binary: ./hmy transfer --node=\"<endpoint_address>\" \\ --from <ONE_address> --to <ONE_address> \\ --from-shard <shard> --to-shard <shard> \\ --amount <amount> --chain-id <chain-id> --passphrase --ledger Using the Shell Script: ./hmy.sh -- transfer --node=\"<endpoint_address>\" \\ --from <ONE_address> --to <ONE_address> \\ --from-shard <shard> --to-shard <shard> \\ --amount <amount> --chain-id <chain-id> --passphrase --ledger For a complete reference of all commands available, please check the HMY CLI cookbook .","title":"Ledger with HMY CLI"},{"location":"hold/wallets/ledger/using-with-hmy-cli/#ledger-with-hmy-cli","text":"","title":"Ledger with HMY CLI"},{"location":"hold/wallets/ledger/using-with-hmy-cli/#download-setup-hmy","text":"To interact with your Ledger device using the HMYC CLI, please click here to download and configure it first.","title":"Download &amp; Setup HMY"},{"location":"hold/wallets/ledger/using-with-hmy-cli/#interacting-with-ledger","text":"{% hint style=\"success\" %} When using Ledger with HMY CLI, the only difference here is that you have to add parameter --ledger on every command. {% endhint %} With that in mind, you can run any other command via HMY CLI using your Ledger. {% hint style=\"warning\" %} Make sure HMY CLI is being run with super user permissions when interacting with Ledger. {% endhint %} Below, are a few practical examples on how to interact with your Ledger device.","title":"Interacting with Ledger"},{"location":"hold/wallets/ledger/using-with-hmy-cli/#1-displaying-your-address","text":"For example, if you want to show your Ledger address you would simply run:","title":"1. Displaying your Address"},{"location":"hold/wallets/ledger/using-with-hmy-cli/#using-the-binary","text":"./hmy keys list --ledger","title":"Using the Binary:"},{"location":"hold/wallets/ledger/using-with-hmy-cli/#using-the-shell-wrapper","text":"./hmy.sh -- keys list --ledger","title":"Using the Shell Wrapper:"},{"location":"hold/wallets/ledger/using-with-hmy-cli/#2-displaying-your-balance","text":"","title":"2. Displaying your Balance"},{"location":"hold/wallets/ledger/using-with-hmy-cli/#using-the-binary_1","text":"./hmy balances --node=\"<endpoint-address>\" <ONE-address> --ledger","title":"Using the Binary:"},{"location":"hold/wallets/ledger/using-with-hmy-cli/#using-the-shell-wrapper_1","text":"./hmy.sh -- balances --node=\"<endpoint-address>\" <ONE-address> --ledger","title":"Using the Shell Wrapper:"},{"location":"hold/wallets/ledger/using-with-hmy-cli/#3-sending-transactions","text":"","title":"3. Sending Transactions"},{"location":"hold/wallets/ledger/using-with-hmy-cli/#using-the-binary_2","text":"./hmy transfer --node=\"<endpoint_address>\" \\ --from <ONE_address> --to <ONE_address> \\ --from-shard <shard> --to-shard <shard> \\ --amount <amount> --chain-id <chain-id> --passphrase --ledger","title":"Using the Binary:"},{"location":"hold/wallets/ledger/using-with-hmy-cli/#using-the-shell-script","text":"./hmy.sh -- transfer --node=\"<endpoint_address>\" \\ --from <ONE_address> --to <ONE_address> \\ --from-shard <shard> --to-shard <shard> \\ --amount <amount> --chain-id <chain-id> --passphrase --ledger For a complete reference of all commands available, please check the HMY CLI cookbook .","title":"Using the Shell Script:"},{"location":"hold/wallets/ledger/staking/overview/","text":"Ledger with Staking Dashboard Using Harmony hardware wallet on the Ledger requires a few things. You will need: Your Ledger The Harmony app installed on your Ledger","title":"Overview"},{"location":"hold/wallets/ledger/staking/overview/#ledger-with-staking-dashboard","text":"Using Harmony hardware wallet on the Ledger requires a few things. You will need: Your Ledger The Harmony app installed on your Ledger","title":"Ledger with Staking Dashboard"},{"location":"hold/wallets/ledger/staking/send-tx/","text":"Sending transactions via Ledger {% hint style=\"info\" %} Note: staking dashboard only process transactions on shard 0. {% endhint %} To send ONE tokens to an address, click the \" Transfer funds\" button and the send window will pop-up. Input the amount of tokens to send and the destination address, then click the \"next\" buttons. Click the \"Confirm and Sign\" button to sign the transaction. Check your ledger Nano S, the LED display on Nano S is shown as below. Click on the right button to review transaction on Ledger. Check and confirm the destination address is correct. Check and confirm the amount is correct. Currently, staking dashboard only supports transaction on shard0. Click the right button to start signing the transaction: Once transaction is signed, Send window will pop-up on the staking dashboard and display the transaction status. It will display \"Successful Send\" once the transactions completes.","title":"Sending transactions"},{"location":"hold/wallets/ledger/staking/send-tx/#sending-transactions-via-ledger","text":"{% hint style=\"info\" %} Note: staking dashboard only process transactions on shard 0. {% endhint %} To send ONE tokens to an address, click the \" Transfer funds\" button and the send window will pop-up. Input the amount of tokens to send and the destination address, then click the \"next\" buttons. Click the \"Confirm and Sign\" button to sign the transaction. Check your ledger Nano S, the LED display on Nano S is shown as below. Click on the right button to review transaction on Ledger. Check and confirm the destination address is correct. Check and confirm the amount is correct. Currently, staking dashboard only supports transaction on shard0. Click the right button to start signing the transaction: Once transaction is signed, Send window will pop-up on the staking dashboard and display the transaction status. It will display \"Successful Send\" once the transactions completes.","title":"Sending transactions via Ledger"},{"location":"hold/wallets/ledger/staking/sign-delegation/","text":"Staking Transactions via Ledger Check the validators page to see list of validators. Click on desired validator logo to check validator details. Click on the \"Delegate\" button to delegate to this validator. Enter the desired delegation amount or scroll the percentage slider in the pop-up Delegate window. Delegation must be at least 1000 ONE. Click on \"Next\" and confirm the signature request. Check your Ledger, it will display \"Delegate Stake\" in the LED screen. Press the right button to start signing the transaction. Check the delegator address. Press the right button to show full address. If correct, press both left/right buttons to continue. Check the validator address. If correct, press both left/right buttons to continue. Check the delegation amount. If correct, press the right button to continue: Press right button for Sign Stake confirmation. The entire process is shown below: {% embed url=\"https://youtu.be/HWECABLQN0Q\" caption=\"\" %} Once transaction is signed, Delegate window will pop-up on the staking dashboard and display the transaction status.","title":"Staking transactions"},{"location":"hold/wallets/ledger/staking/sign-delegation/#staking-transactions-via-ledger","text":"Check the validators page to see list of validators. Click on desired validator logo to check validator details. Click on the \"Delegate\" button to delegate to this validator. Enter the desired delegation amount or scroll the percentage slider in the pop-up Delegate window. Delegation must be at least 1000 ONE. Click on \"Next\" and confirm the signature request. Check your Ledger, it will display \"Delegate Stake\" in the LED screen. Press the right button to start signing the transaction. Check the delegator address. Press the right button to show full address. If correct, press both left/right buttons to continue. Check the validator address. If correct, press both left/right buttons to continue. Check the delegation amount. If correct, press the right button to continue: Press right button for Sign Stake confirmation. The entire process is shown below: {% embed url=\"https://youtu.be/HWECABLQN0Q\" caption=\"\" %} Once transaction is signed, Delegate window will pop-up on the staking dashboard and display the transaction status.","title":"Staking Transactions via Ledger"},{"location":"hold/wallets/ledger/staking/sign-in-with-ledger/","text":"Sign In With Ledger Plug in your Ledger and open the Harmony Ledger App. Your device will be detected by your computer. Start from the staking dashboard: https://staking.harmony.one/ledger and click the \"sign-in\" button. You will be directed to the Validators page on the Staking Dashboard and a small trident logo will appear on the chrome tab. Your Ledger Nano will display \"waiting for commands\" before you click on any buttons. Click the \"Show on Ledger\" button to display your address on your Ledger device. Press the right button on Ledger to continue and confirm the address is correct.","title":"Signing in"},{"location":"hold/wallets/ledger/staking/sign-in-with-ledger/#sign-in-with-ledger","text":"Plug in your Ledger and open the Harmony Ledger App. Your device will be detected by your computer. Start from the staking dashboard: https://staking.harmony.one/ledger and click the \"sign-in\" button. You will be directed to the Validators page on the Staking Dashboard and a small trident logo will appear on the chrome tab. Your Ledger Nano will display \"waiting for commands\" before you click on any buttons. Click the \"Show on Ledger\" button to display your address on your Ledger device. Press the right button on Ledger to continue and confirm the address is correct.","title":"Sign In With Ledger"},{"location":"hold/wallets/mathwallet/create-import-wallet/","text":"Create/Import/Export Wallet You can choose to create a wallet through the extension or import your existing wallet using a mnemonic phrase or a private key. When you create a wallet, please write down your mnemonic correctly and keep in a safe place. You may also import your Harmony Account using your mnemonic or private key. You can also choose to export your keys in Settings. Your keys will be exported into a txt file with both private key and mnemonic.","title":"Key Management"},{"location":"hold/wallets/mathwallet/create-import-wallet/#createimportexport-wallet","text":"You can choose to create a wallet through the extension or import your existing wallet using a mnemonic phrase or a private key. When you create a wallet, please write down your mnemonic correctly and keep in a safe place. You may also import your Harmony Account using your mnemonic or private key. You can also choose to export your keys in Settings. Your keys will be exported into a txt file with both private key and mnemonic.","title":"Create/Import/Export Wallet"},{"location":"hold/wallets/mathwallet/download-and-setup/","text":"Download & Setup Installation Access the Google Chrome web store and install the Math Wallet extension . {% hint style=\"info\" %} Note : Ensure you use version 2.07 or later of MathWallet (2.1.9 is the latest version). Previous versions have a known bug and are not supported. {% endhint %} Open the extension in your browser and create new password. Select Harmony from the list of networks.","title":"Download and setup"},{"location":"hold/wallets/mathwallet/download-and-setup/#download-setup","text":"","title":"Download &amp; Setup"},{"location":"hold/wallets/mathwallet/download-and-setup/#installation","text":"Access the Google Chrome web store and install the Math Wallet extension . {% hint style=\"info\" %} Note : Ensure you use version 2.07 or later of MathWallet (2.1.9 is the latest version). Previous versions have a known bug and are not supported. {% endhint %} Open the extension in your browser and create new password. Select Harmony from the list of networks.","title":"Installation"},{"location":"hold/wallets/mathwallet/overview/","text":"Math Wallet Math Wallet is a browser extension and a mobile wallet for holding and transacting cryptocurrency.","title":"Overview"},{"location":"hold/wallets/mathwallet/overview/#math-wallet","text":"Math Wallet is a browser extension and a mobile wallet for holding and transacting cryptocurrency.","title":"Math Wallet"},{"location":"hold/wallets/mathwallet/send-tx/","text":"Sending Transactions via Math Wallet Make sure you've set up your Math Wallet extension according to the directions in Download & Setup . Opening Web Wallet You will need to open Web Wallet in order to view account details and perform transactions. Please select the wallet you want to open and click Web Wallet on the Math Wallet extension popover interface. After clicking Web Wallet, a new tab will open asking you to login into Math Wallet, click on login and you will enter the Web Wallet. Sending transactions Specify the shard you want to pull funds from using the Shard dropdown in the sidebar. Specify which account you want to send funds to using the To Address field. Specify which shard you want to send funds to using the Shard dropdown to the right. Specify the amount you wish to send in the Transfer Amount field. Specify the gas price you wish to pay using the Fee slider. Gas is a fee charged by the network for the computational work of mining a transaction into the blockchain. Click Transfer to complete the transaction! You will be shown a transaction receipt before finalizing the transaction.","title":"Sending transactions"},{"location":"hold/wallets/mathwallet/send-tx/#sending-transactions-via-math-wallet","text":"Make sure you've set up your Math Wallet extension according to the directions in Download & Setup .","title":"Sending Transactions via Math Wallet"},{"location":"hold/wallets/mathwallet/send-tx/#opening-web-wallet","text":"You will need to open Web Wallet in order to view account details and perform transactions. Please select the wallet you want to open and click Web Wallet on the Math Wallet extension popover interface. After clicking Web Wallet, a new tab will open asking you to login into Math Wallet, click on login and you will enter the Web Wallet.","title":"Opening Web Wallet"},{"location":"hold/wallets/mathwallet/send-tx/#sending-transactions","text":"Specify the shard you want to pull funds from using the Shard dropdown in the sidebar. Specify which account you want to send funds to using the To Address field. Specify which shard you want to send funds to using the Shard dropdown to the right. Specify the amount you wish to send in the Transfer Amount field. Specify the gas price you wish to pay using the Fee slider. Gas is a fee charged by the network for the computational work of mining a transaction into the blockchain. Click Transfer to complete the transaction! You will be shown a transaction receipt before finalizing the transaction.","title":"Sending transactions"},{"location":"hold/wallets/mathwallet/staking-transactions/","text":"Staking Transactions via Math Wallet Sign in from the staking dashboard https://staking.harmony.one/validators 1 for staking transactions. Sign in to your Math Wallet browser extension. You will see a Login Request pop up. Select your wallet and click Accept. You will be brought back to the Validator page of Staking Dashboard. You will be able to see your address on the top left corner under the Harmony logo which means you are now signed in to your account. Choose your preferred validator and click on Delegate button. Enter the desired amount of tokens you would like to delegate and click next. Confirm the signature request on the Math Wallet pop-up window. That\u2019s it! You have successfully delegated your tokens to a validator. Now you will also be able to see your wallet address in the list of delegates and the validator on your portfolio page.","title":"Staking"},{"location":"hold/wallets/mathwallet/staking-transactions/#staking-transactions-via-math-wallet","text":"Sign in from the staking dashboard https://staking.harmony.one/validators 1 for staking transactions. Sign in to your Math Wallet browser extension. You will see a Login Request pop up. Select your wallet and click Accept. You will be brought back to the Validator page of Staking Dashboard. You will be able to see your address on the top left corner under the Harmony logo which means you are now signed in to your account. Choose your preferred validator and click on Delegate button. Enter the desired amount of tokens you would like to delegate and click next. Confirm the signature request on the Math Wallet pop-up window. That\u2019s it! You have successfully delegated your tokens to a validator. Now you will also be able to see your wallet address in the list of delegates and the validator on your portfolio page.","title":"Staking Transactions via Math Wallet"},{"location":"hold/wallets/safepal/create-import-account/","text":"Create/import account Create New Wallet Import Wallet (Recover)","title":"Account Management"},{"location":"hold/wallets/safepal/create-import-account/#createimport-account","text":"","title":"Create/import account"},{"location":"hold/wallets/safepal/create-import-account/#create-new-wallet","text":"","title":"Create New Wallet"},{"location":"hold/wallets/safepal/create-import-account/#import-wallet-recover","text":"","title":"Import Wallet (Recover)"},{"location":"hold/wallets/safepal/download-and-setup/","text":"Download & setup Download SafePal Mobile Apps SafePal mobile apps can be downloaded from PlayStore and AppStore following the instructions here . Quick Start Please make sure your SafePal is the latest by following the instructions here . The SafePal general user's manual is here and the initial set up guide is here .","title":"Download and setup"},{"location":"hold/wallets/safepal/download-and-setup/#download-setup","text":"","title":"Download &amp; setup"},{"location":"hold/wallets/safepal/download-and-setup/#download-safepal-mobile-apps","text":"SafePal mobile apps can be downloaded from PlayStore and AppStore following the instructions here .","title":"Download SafePal Mobile Apps"},{"location":"hold/wallets/safepal/download-and-setup/#quick-start","text":"Please make sure your SafePal is the latest by following the instructions here . The SafePal general user's manual is here and the initial set up guide is here .","title":"Quick Start"},{"location":"hold/wallets/safepal/overview/","text":"Safepal SafePal Hardware Wallet SafePal is a secure and user-friendly hardware wallet designed for the masses. SafePal S1, its first flagship hardware wallet, adopts multiple layers of security schemes and intuitive user interfaces, enabling users to store, transfer and trade coins in the wallet in the easiest way.","title":"Overview.md"},{"location":"hold/wallets/safepal/overview/#safepal","text":"","title":"Safepal"},{"location":"hold/wallets/safepal/overview/#safepal-hardware-wallet","text":"SafePal is a secure and user-friendly hardware wallet designed for the masses. SafePal S1, its first flagship hardware wallet, adopts multiple layers of security schemes and intuitive user interfaces, enabling users to store, transfer and trade coins in the wallet in the easiest way.","title":"SafePal Hardware Wallet"},{"location":"hold/wallets/safepal/send-transaction/","text":"Send transaction How to send ONE in SafePal\uff1f Click on the 'Send' segment in SafePal App menu bar and select ONE. Input the destination address by pasting the address or scanning the QR code. Enter all transaction details - amount, fee and don't forget to select the shard number. Then clink \u201cSend\u201dto check the transaction details. Tips: If you don't know the exact shard number, don't worry, you can simply use Shard 0 as the default shard. Sign the order with your SafePal S1 hardware wallet. Confirm the payment.The transfer is broadcasted on chain. Don't forget to check transfer status later. {% embed url=\"https://www.dropbox.com/s/uo80rhxy0pnu9sa/SafePal%20Teaser.mp4?dl=0\" caption=\"\" %} How to receive ONE in SafePal? To receive ONE tokens you need to provide the sender your ONE address which can be found using the SafePal app or wallet. Using the SafePal App: Select ONE which gives you the option of receive and send, click on receive You can either copy your ONE address for the wallet, save the QR code, or have the other party scan the QR code from your phone Using the SafePal Wallet: Turn on the wallet Scroll to \"Asset Management\" in the main menu Select \"Harmony\" out of all the options Click on receive, and then enter your PIN code Your QR code, as well as the ONE address for the wallet will show for the other party to use","title":"Send Transaction"},{"location":"hold/wallets/safepal/send-transaction/#send-transaction","text":"","title":"Send transaction"},{"location":"hold/wallets/safepal/send-transaction/#how-to-send-one-in-safepal","text":"Click on the 'Send' segment in SafePal App menu bar and select ONE. Input the destination address by pasting the address or scanning the QR code. Enter all transaction details - amount, fee and don't forget to select the shard number. Then clink \u201cSend\u201dto check the transaction details. Tips: If you don't know the exact shard number, don't worry, you can simply use Shard 0 as the default shard. Sign the order with your SafePal S1 hardware wallet. Confirm the payment.The transfer is broadcasted on chain. Don't forget to check transfer status later. {% embed url=\"https://www.dropbox.com/s/uo80rhxy0pnu9sa/SafePal%20Teaser.mp4?dl=0\" caption=\"\" %}","title":"How to send ONE in SafePal\uff1f"},{"location":"hold/wallets/safepal/send-transaction/#how-to-receive-one-in-safepal","text":"To receive ONE tokens you need to provide the sender your ONE address which can be found using the SafePal app or wallet. Using the SafePal App: Select ONE which gives you the option of receive and send, click on receive You can either copy your ONE address for the wallet, save the QR code, or have the other party scan the QR code from your phone Using the SafePal Wallet: Turn on the wallet Scroll to \"Asset Management\" in the main menu Select \"Harmony\" out of all the options Click on receive, and then enter your PIN code Your QR code, as well as the ONE address for the wallet will show for the other party to use","title":"How to receive ONE in SafePal?"},{"location":"home/","text":"Welcome to Developer Playground Developer Playground Goals John created this site to capture the knowledge and share tools around blockchain ecoystems. The site has two main purposes A knowledge base for Layer 1 protocol ecoystems with a target audience of ecosystem architects and developers. A prototype for Harmony for a richer community engagement and ecosystem grant management process showcasing some very cool technology built by the Harmony Team (see the contribute section ). The audience is not just DApp and Smart Contract developers but the larger blockchain ecosystem developer community including core protocol developers, tooling (API, SDK, IDE, etc) developers and centralized applications that integrate with blockchains such as exchanges, oracles and fintech applications. Harmony Focus The initial version of the Developer Playground has a strong Harmony Focus which aligns with the last year of John's work at Harmony and his involvement with the community.one of the leaders in high performant, sharded, proof of stake layer 1 solutions. For other blockchain projects check the resources section to see the relevant guides and grants. As the community contributes and John's focus shifts to other layer 1 platforms, interoperability and defi solutions this site will evolve. DISCLAIMER: Developer Playground is a completely independent and open-source initiative founded by blockchain community members. Nothing contained in this Github repository should be considered financial or investment advice - it is for informational purposes only.","title":"Welcome"},{"location":"home/#welcome-to-developer-playground","text":"","title":"Welcome to Developer Playground"},{"location":"home/#developer-playground-goals","text":"John created this site to capture the knowledge and share tools around blockchain ecoystems. The site has two main purposes A knowledge base for Layer 1 protocol ecoystems with a target audience of ecosystem architects and developers. A prototype for Harmony for a richer community engagement and ecosystem grant management process showcasing some very cool technology built by the Harmony Team (see the contribute section ). The audience is not just DApp and Smart Contract developers but the larger blockchain ecosystem developer community including core protocol developers, tooling (API, SDK, IDE, etc) developers and centralized applications that integrate with blockchains such as exchanges, oracles and fintech applications.","title":"Developer Playground Goals"},{"location":"home/#harmony-focus","text":"The initial version of the Developer Playground has a strong Harmony Focus which aligns with the last year of John's work at Harmony and his involvement with the community.one of the leaders in high performant, sharded, proof of stake layer 1 solutions. For other blockchain projects check the resources section to see the relevant guides and grants. As the community contributes and John's focus shifts to other layer 1 platforms, interoperability and defi solutions this site will evolve. DISCLAIMER: Developer Playground is a completely independent and open-source initiative founded by blockchain community members. Nothing contained in this Github repository should be considered financial or investment advice - it is for informational purposes only.","title":"Harmony Focus"},{"location":"home/audience/","text":"Who is this Playground for? This playground has two intended audiences with sub audiences based on role. Those audiences are Blockchain Ecosystem Developers This site has deep technical information for all members of a layer 1 ecosystem including protocol developers, network operations, tool creators, DApp developers and Application developers. Whilst the majority of content has a Harmony focus the infrastructure will be similar for any layer 1 protocol. Audience Section Breakdown This site has headers for each section in the top navigation bar. Below is a breakdown of each section, it purpose and target audience. Section Audience Content home Blockchain Ecosytem Architects Overview of what components are typically required for a layer 1 ecosystem resources Blockchain Ecoystem Developers Links to Layer 1 protocol information Harmony Team and Community This site has a number of sections with a Harmony focus to illustrate how a more comprehensive engagement platform can be created. Audience Section Breakdown This site has headers for each section in the top navigation bar. Below is a breakdown of each section, it purpose and target audience. Section Audience Content learn Harmony Community Harmony educational material hold Harmony Token Holders Guides for holding, delegating, exchanging and staking Harmony Tokens develop Developers building on Harmony Harmony DApp and Smart Contract developer guides and tutorials validate Harmony Validators Hamonry Validator Guides integrate Application developers integrating with Harmony Integration use cases and approaches API Developers integrating with Harmony via APIs API guides and tools for Developers contribute Blockchain Ecosystem Builders Harmony Roadmap, Ecosystem Grants and ecosystem developer guides ecosystem Harmony Ecosystem Partners and Community Harmony ecosystem partners including wallets, exchanges and applications resources Blockchain Ecosystem Developers Blockchain reference guides as well as information about the contributors","title":"Audience"},{"location":"home/audience/#who-is-this-playground-for","text":"This playground has two intended audiences with sub audiences based on role. Those audiences are","title":"Who is this Playground for?"},{"location":"home/audience/#blockchain-ecosystem-developers","text":"This site has deep technical information for all members of a layer 1 ecosystem including protocol developers, network operations, tool creators, DApp developers and Application developers. Whilst the majority of content has a Harmony focus the infrastructure will be similar for any layer 1 protocol.","title":"Blockchain Ecosystem Developers"},{"location":"home/audience/#audience-section-breakdown","text":"This site has headers for each section in the top navigation bar. Below is a breakdown of each section, it purpose and target audience. Section Audience Content home Blockchain Ecosytem Architects Overview of what components are typically required for a layer 1 ecosystem resources Blockchain Ecoystem Developers Links to Layer 1 protocol information","title":"Audience Section Breakdown"},{"location":"home/audience/#harmony-team-and-community","text":"This site has a number of sections with a Harmony focus to illustrate how a more comprehensive engagement platform can be created.","title":"Harmony Team and Community"},{"location":"home/audience/#audience-section-breakdown_1","text":"This site has headers for each section in the top navigation bar. Below is a breakdown of each section, it purpose and target audience. Section Audience Content learn Harmony Community Harmony educational material hold Harmony Token Holders Guides for holding, delegating, exchanging and staking Harmony Tokens develop Developers building on Harmony Harmony DApp and Smart Contract developer guides and tutorials validate Harmony Validators Hamonry Validator Guides integrate Application developers integrating with Harmony Integration use cases and approaches API Developers integrating with Harmony via APIs API guides and tools for Developers contribute Blockchain Ecosystem Builders Harmony Roadmap, Ecosystem Grants and ecosystem developer guides ecosystem Harmony Ecosystem Partners and Community Harmony ecosystem partners including wallets, exchanges and applications resources Blockchain Ecosystem Developers Blockchain reference guides as well as information about the contributors","title":"Audience Section  Breakdown"},{"location":"home/contribute/","text":"Contributing to Developer Playground Docs How to make changes to Developer Playground pages Head on over to the Developer Playground repo . Create a new Github account or login into your existing account Follow this great guide to learn how to make your first pull request Contribution Guidelines In the interest of keeping the content on Developer Playground looking uniform, we have set up a template that you can use when adding your own pages to the github repo. You can find the template here . There are also some basic guidelines that need to be followed when contributing to EthHub: All pages should have links to supporting sources/documentation and additional resources No marketing or sponsored posts No promotion of ICOs/token sales No inappropriate content Donate on Harmony: one1zkg4uavu79xwemzywrqzyfx707ndqtcs9628kl DISCLAIMER: Developer Playground is a completely independent and open-source initiative founded by blockchain community members. Nothing contained in this Github repository should be considered financial or investment advice - it is for informational purposes only.","title":"Contribute"},{"location":"home/contribute/#contributing-to-developer-playground-docs","text":"","title":"Contributing to Developer Playground Docs"},{"location":"home/contribute/#how-to-make-changes-to-developer-playground-pages","text":"Head on over to the Developer Playground repo . Create a new Github account or login into your existing account Follow this great guide to learn how to make your first pull request","title":"How to make changes to Developer Playground pages"},{"location":"home/contribute/#contribution-guidelines","text":"In the interest of keeping the content on Developer Playground looking uniform, we have set up a template that you can use when adding your own pages to the github repo. You can find the template here . There are also some basic guidelines that need to be followed when contributing to EthHub: All pages should have links to supporting sources/documentation and additional resources No marketing or sponsored posts No promotion of ICOs/token sales No inappropriate content Donate on Harmony: one1zkg4uavu79xwemzywrqzyfx707ndqtcs9628kl DISCLAIMER: Developer Playground is a completely independent and open-source initiative founded by blockchain community members. Nothing contained in this Github repository should be considered financial or investment advice - it is for informational purposes only.","title":"Contribution Guidelines"},{"location":"home/sample/","text":"Sample Blockchain Ecosystem Layer 1 blockchain protocols need to evolve a complete ecosystem in order to drive adoption and be sucessful. Two years ago John was designing a layer 1 protocol which leveraged the quality work done by the Ethereum Enterprise Alliance . The following is a draft blockchain landscape called project-x which built upon that foundation, it may be somewhat outdated as 2 years is a very long time in the blockchain space. We show it here for reference as, although the technologies have evolved, it still provides a good overview of what a blockchain ecosystem requires to be succesful.","title":"Overview"},{"location":"home/sample/#sample-blockchain-ecosystem","text":"Layer 1 blockchain protocols need to evolve a complete ecosystem in order to drive adoption and be sucessful. Two years ago John was designing a layer 1 protocol which leveraged the quality work done by the Ethereum Enterprise Alliance . The following is a draft blockchain landscape called project-x which built upon that foundation, it may be somewhat outdated as 2 years is a very long time in the blockchain space. We show it here for reference as, although the technologies have evolved, it still provides a good overview of what a blockchain ecosystem requires to be succesful.","title":"Sample Blockchain Ecosystem"},{"location":"integrate/overview/","text":"Harmony Integration Overview Integration guide for exchanges, wallet and applications. Harmony provides a rich suite of tools to enable integrating with the Harmony Platform Integration Approaches and Tooling API Integration SDK Integration Hosting your own Harmony Endpoint Generating your own Harmony Custom Client Use Cases Wallet Integration Exchange Integration MarketPlace Integration Payment Integration Lending Integration Identity Management Industry Verticals Integration","title":"Overview"},{"location":"integrate/overview/#harmony-integration-overview","text":"Integration guide for exchanges, wallet and applications. Harmony provides a rich suite of tools to enable integrating with the Harmony Platform","title":"Harmony Integration Overview"},{"location":"integrate/overview/#integration-approaches-and-tooling","text":"","title":"Integration Approaches and Tooling"},{"location":"integrate/overview/#api-integration","text":"","title":"API Integration"},{"location":"integrate/overview/#sdk-integration","text":"","title":"SDK Integration"},{"location":"integrate/overview/#hosting-your-own-harmony-endpoint","text":"","title":"Hosting your own Harmony Endpoint"},{"location":"integrate/overview/#generating-your-own-harmony-custom-client","text":"","title":"Generating your own Harmony Custom Client"},{"location":"integrate/overview/#use-cases","text":"","title":"Use Cases"},{"location":"integrate/overview/#wallet-integration","text":"","title":"Wallet Integration"},{"location":"integrate/overview/#exchange-integration","text":"","title":"Exchange Integration"},{"location":"integrate/overview/#marketplace-integration","text":"","title":"MarketPlace Integration"},{"location":"integrate/overview/#payment-integration","text":"","title":"Payment Integration"},{"location":"integrate/overview/#lending-integration","text":"","title":"Lending Integration"},{"location":"integrate/overview/#identity-management","text":"","title":"Identity Management"},{"location":"integrate/overview/#industry-verticals-integration","text":"","title":"Industry Verticals Integration"},{"location":"learn/SUMMARY/","text":"Table of contents Welcome Guide Papers and Other Important links Intern's guide to blockchain Part 1 Part 2 COMMUNITY The $ONE token Binance Launchpad Gate.io Token Sale Utility Exchanges Staking Understanding Proof of Stake How to stake Harmony tokens Staking pools Everstake Honest Mining Cobo Harmony nodes Run a node Foundational Nodes Pangaea Social Mining Hummingbot Transparency Tuesday TGI TECH ZONE Technology Deep Dive Fast Byzantine Fault Tolerance Effective Proof-of-Stake (EPoS) Adaptive IDA Protocol Rateless Erasure Code Unbiasable Randomness Resharding Cross-shard Routing In depth with Near Protocol Competitor Overview Future Work dApps Harmony Puzzle PhotoBlock SDK Use Cases Data Marketplace for Scientists: A New Hope COMPANY Why build Harmony? Team & Advisors Partners & Clients FAQ's Milestones","title":"Table of contents"},{"location":"learn/SUMMARY/#table-of-contents","text":"Welcome Guide Papers and Other Important links Intern's guide to blockchain Part 1 Part 2","title":"Table of contents"},{"location":"learn/SUMMARY/#community","text":"The $ONE token Binance Launchpad Gate.io Token Sale Utility Exchanges Staking Understanding Proof of Stake How to stake Harmony tokens Staking pools Everstake Honest Mining Cobo Harmony nodes Run a node Foundational Nodes Pangaea Social Mining Hummingbot Transparency Tuesday TGI","title":"COMMUNITY"},{"location":"learn/SUMMARY/#tech-zone","text":"Technology Deep Dive Fast Byzantine Fault Tolerance Effective Proof-of-Stake (EPoS) Adaptive IDA Protocol Rateless Erasure Code Unbiasable Randomness Resharding Cross-shard Routing In depth with Near Protocol Competitor Overview Future Work dApps Harmony Puzzle PhotoBlock SDK Use Cases Data Marketplace for Scientists: A New Hope","title":"TECH ZONE"},{"location":"learn/SUMMARY/#company","text":"Why build Harmony? Team & Advisors Partners & Clients FAQ's Milestones","title":"COMPANY"},{"location":"learn/introduction/","text":"Introduction What is Harmony?\u200c \u200c Harmony is a fast and secure blockchain for decentralized applications. Our production mainnet supports 4 shards of 1000 nodes, producing blocks in 8 seconds with finality. Our Effective Proof-of-Stake (EPoS) reduces centralization while supporting stake delegation, reward compounding and double-sign slashing. Harmony aims to build an open network of nodes operated and governed by a large community. This node community is called Pangaea. Are we decentralized yet? There\u2019s no consensus without participation. There are now 1,000 Harmony nodes \u2013 so far 320 of them run by the community \u2013 in line with thousands of Bitcoin and Ethereum nodes. Pangaea consists of volunteers and validators from more than 100 countries and most of them have never run a node before. Secure, Random State Sharding Harmony has transcended the blockchain trilemma by bringing the best research to production. Sharding is proven to scale blockchains without compromising security and decentralization . We divide not only our network nodes but also the blockchain states into shards, scaling linearly in all three aspects of machines, transactions and storages. To prevent single shard attacks, we must have a sufficiently large number of nodes per shard and cryptographic randomness to re-shard regularly. Each shard has 250 nodes for strong security guarantee against Byzantine behaviors. We use Verifiable Random Function (VDF) for unbiasable and unpredictable shard membership. Fast Consensus w/ Instant Finality Harmony has innovated on the battle-tested Practical Byzantine Fault Tolerance (PBFT) for fast consensus of block transactions. Our Fast BFT (FBFT) leads to low transaction fees and 1-block-time finality in Harmony Mainnet. We use Boneh\u2013Lynn\u2013Shacham (BLS) constant-sized signatures to commit blocks in a single round of consensus messages. We achieve 8-second block time with view changes in production against adversarial or unavailable leaders. Harmony Mainnet was launched in June 2019. Our network has produced 10M+ blocks with 20k+ transactions in publicly traded, native ONE tokens. Effective PoS & Token Economics Harmony has designed a novel Proof-of-Stake (PoS) mechanism for network security and economics. Our Effective Proof-of-Stake (EPoS) reduces centralization and distributes rewards fairly to thousands of validators. Our staking mechanism supports delegation and reward compounding. To support 100% uptime but fully open participation, EPoS slashes validators who double-sign and it penalizes elected but unavailable nodes. Harmony Economics Model caps the annual insurance at 441 million tokens (about 3% rate in long term). Our model gives validators a simple and predictable return. All transaction fees are burnt to offset the insurance, naturally leading to zero inflation when our network usage becomes high.","title":"Introduction"},{"location":"learn/introduction/#introduction","text":"","title":"Introduction"},{"location":"learn/introduction/#what-is-harmony","text":"\u200c Harmony is a fast and secure blockchain for decentralized applications. Our production mainnet supports 4 shards of 1000 nodes, producing blocks in 8 seconds with finality. Our Effective Proof-of-Stake (EPoS) reduces centralization while supporting stake delegation, reward compounding and double-sign slashing. Harmony aims to build an open network of nodes operated and governed by a large community. This node community is called Pangaea. Are we decentralized yet? There\u2019s no consensus without participation. There are now 1,000 Harmony nodes \u2013 so far 320 of them run by the community \u2013 in line with thousands of Bitcoin and Ethereum nodes. Pangaea consists of volunteers and validators from more than 100 countries and most of them have never run a node before.","title":"What is Harmony?\u200c"},{"location":"learn/introduction/#secure-random-state-sharding","text":"Harmony has transcended the blockchain trilemma by bringing the best research to production. Sharding is proven to scale blockchains without compromising security and decentralization . We divide not only our network nodes but also the blockchain states into shards, scaling linearly in all three aspects of machines, transactions and storages. To prevent single shard attacks, we must have a sufficiently large number of nodes per shard and cryptographic randomness to re-shard regularly. Each shard has 250 nodes for strong security guarantee against Byzantine behaviors. We use Verifiable Random Function (VDF) for unbiasable and unpredictable shard membership.","title":"Secure, Random State Sharding"},{"location":"learn/introduction/#fast-consensus-w-instant-finality","text":"Harmony has innovated on the battle-tested Practical Byzantine Fault Tolerance (PBFT) for fast consensus of block transactions. Our Fast BFT (FBFT) leads to low transaction fees and 1-block-time finality in Harmony Mainnet. We use Boneh\u2013Lynn\u2013Shacham (BLS) constant-sized signatures to commit blocks in a single round of consensus messages. We achieve 8-second block time with view changes in production against adversarial or unavailable leaders. Harmony Mainnet was launched in June 2019. Our network has produced 10M+ blocks with 20k+ transactions in publicly traded, native ONE tokens.","title":"Fast Consensus w/ Instant Finality"},{"location":"learn/introduction/#effective-pos-token-economics","text":"Harmony has designed a novel Proof-of-Stake (PoS) mechanism for network security and economics. Our Effective Proof-of-Stake (EPoS) reduces centralization and distributes rewards fairly to thousands of validators. Our staking mechanism supports delegation and reward compounding. To support 100% uptime but fully open participation, EPoS slashes validators who double-sign and it penalizes elected but unavailable nodes. Harmony Economics Model caps the annual insurance at 441 million tokens (about 3% rate in long term). Our model gives validators a simple and predictable return. All transaction fees are burnt to offset the insurance, naturally leading to zero inflation when our network usage becomes high.","title":"Effective PoS &amp; Token Economics"},{"location":"learn/papers-and-social-links/","text":"Papers and Other Important links Wikis **** Node-runners **** Developers **** Papers Whitepaper: E nglish , Chinese Deck : English Official sources Social Links Language Chats We bsite \ud83c\uddfa\ud83c\uddf8 English Telegram C hat \ud83c\uddf0\ud83c\uddf7 Korean (telegram) Telegram News \ud83c\uddf0\ud83c\uddf7 Korean (KakaoTalk) Foundational Nodes \ud83c\udde8\ud83c\uddf3 Chinese Pangaea \ud83c\uddf5\ud83c\uddf9 Portuguese Discord \ud83c\uddf7\ud83c\uddfa Russian Twitter \ud83c\uddee\ud83c\uddf3 India Reddit \ud83c\uddf5\ud83c\udded Phillipines GitHub \ud83c\uddfb\ud83c\uddf3 Vietnamese Medium \ud83c\uddf9\ud83c\uddf7 Turkish Blockchain Explorer \ud83c\uddee\ud83c\udde9 Indonesia","title":"Papers and other important links"},{"location":"learn/papers-and-social-links/#papers-and-other-important-links","text":"","title":"Papers and Other Important links"},{"location":"learn/papers-and-social-links/#wikis","text":"**** Node-runners **** Developers ****","title":"Wikis"},{"location":"learn/papers-and-social-links/#papers","text":"Whitepaper: E nglish , Chinese Deck : English","title":"Papers"},{"location":"learn/papers-and-social-links/#official-sources","text":"Social Links Language Chats We bsite \ud83c\uddfa\ud83c\uddf8 English Telegram C hat \ud83c\uddf0\ud83c\uddf7 Korean (telegram) Telegram News \ud83c\uddf0\ud83c\uddf7 Korean (KakaoTalk) Foundational Nodes \ud83c\udde8\ud83c\uddf3 Chinese Pangaea \ud83c\uddf5\ud83c\uddf9 Portuguese Discord \ud83c\uddf7\ud83c\uddfa Russian Twitter \ud83c\uddee\ud83c\uddf3 India Reddit \ud83c\uddf5\ud83c\udded Phillipines GitHub \ud83c\uddfb\ud83c\uddf3 Vietnamese Medium \ud83c\uddf9\ud83c\uddf7 Turkish Blockchain Explorer \ud83c\uddee\ud83c\udde9 Indonesia","title":"Official sources"},{"location":"learn/welcome/","text":"Welcome Guide Hello human, welcome to the rabbithole... There is so much to learn about any blockchain project but Layer 1 protocols present a particularly broad landscape and everyone who comes to us has a different angle of attack. Our website is really just a front door for the project and rather than load it up with hundreds of pages of information we decided to offload that to Gitbook which offers a beautiful and elegant framework for all that detail. Here you'll be able to find everything you need about our team, our token, our technical innovations, who's building on us and how you can start building, staking and contributing as a valuable human on our network. What's the big deal about Harmony? Glad you asked. Ex Apple, Google, Amazon with multiple exits Sharding at network AND consensus level Highly attractive scaling solution for existing dApps Lightning fast execution -- zero to mainnet in 12 months Top tier market interest: Binance Labs, Coinbase shortlist Staking and node rewards via Effective PoS Community driven - add your power to the network by running a node, introducing clients or by building tools Core focus: Gaming, DeFi, Data Sharing {% hint style=\"info\" %} Harmony is a proof-of-stake blockchain meaning you can earn rewards for staking but there are so many other ways to get involved by participating in daily activities, introducing us to clients, building tools all while earning more $ONE. {% endhint %} Community Get up to speed with our token $ONE, where to buy it, how to stake it, how to run a node and how to earn for completing tasks for Harmony. Section Description The $ONE token All about the token that fuels the network Staking How to benefit from staking rewards Nodes Secure and validate transactions by running the Harmony protocol Social Mining Earn from completing tasks, creating content and building tools Transparency Tuesday Our weekly transparency update featuring our famous live document TGI Harmony's Xoogler weekly networking event Tech Zone There's a lot to learn about Harmony's technical foundation and it's always evolving. You can sink your teeth into the juicy nuggets of pure code by heading to the GitHub repo or follow the links to go deep on the key innovations that make Harmony so exciting as a blockchain platform. Section Description FBFT Our variation on BFT: Fast Byzantine Fault Tolerance EPoS Our adaptation of the classic PoS is called Effective proof of stake Adaptive IDA All about the IDA protocol Rateless Erasure Code Forward error correction, Harmony style Unbiasable Randomness Nobody messes with our randomness, great for games, voting etc. Resharding Re-re-shard and the crowd say... never mind, just read it Cross-shard Routing Shards. That speak to each other. Sounds easy, but is it? In-depth with Near Protocol Near protocol got really near to Harmony and this is what happened Competitor Overview Boo. Hiss. No, we love our competition. Good projects all. Future Work Here's where we're going next dApps The meat of blockchain value creation. Meet the dApps Company There's a lot to learn about Harmony's technical foundation and it's always evolving. You can sink your teeth into the juicy nuggets of pure code by heading to the GitHub repo or follow the links to go deep on the key innovations that make Harmony so exciting as a blockchain platform. Section Description Why build Harmony? Just another TPS party or is there more going on? Team & Advisors The people behind the power Partners & Clients You can't do this on your own, here's who's on the extended team FAQ's Fanatical About Quidditch? Milestones In Europe they use the metric system but we'll let it slide. (for now...)","title":"Welcome"},{"location":"learn/welcome/#welcome-guide","text":"","title":"Welcome Guide"},{"location":"learn/welcome/#hello-human-welcome-to-the-rabbithole","text":"There is so much to learn about any blockchain project but Layer 1 protocols present a particularly broad landscape and everyone who comes to us has a different angle of attack. Our website is really just a front door for the project and rather than load it up with hundreds of pages of information we decided to offload that to Gitbook which offers a beautiful and elegant framework for all that detail. Here you'll be able to find everything you need about our team, our token, our technical innovations, who's building on us and how you can start building, staking and contributing as a valuable human on our network.","title":"Hello human, welcome to the rabbithole..."},{"location":"learn/welcome/#whats-the-big-deal-about-harmony","text":"Glad you asked. Ex Apple, Google, Amazon with multiple exits Sharding at network AND consensus level Highly attractive scaling solution for existing dApps Lightning fast execution -- zero to mainnet in 12 months Top tier market interest: Binance Labs, Coinbase shortlist Staking and node rewards via Effective PoS Community driven - add your power to the network by running a node, introducing clients or by building tools Core focus: Gaming, DeFi, Data Sharing {% hint style=\"info\" %} Harmony is a proof-of-stake blockchain meaning you can earn rewards for staking but there are so many other ways to get involved by participating in daily activities, introducing us to clients, building tools all while earning more $ONE. {% endhint %}","title":"What's the big deal about Harmony?"},{"location":"learn/welcome/#community","text":"Get up to speed with our token $ONE, where to buy it, how to stake it, how to run a node and how to earn for completing tasks for Harmony. Section Description The $ONE token All about the token that fuels the network Staking How to benefit from staking rewards Nodes Secure and validate transactions by running the Harmony protocol Social Mining Earn from completing tasks, creating content and building tools Transparency Tuesday Our weekly transparency update featuring our famous live document TGI Harmony's Xoogler weekly networking event","title":"Community"},{"location":"learn/welcome/#tech-zone","text":"There's a lot to learn about Harmony's technical foundation and it's always evolving. You can sink your teeth into the juicy nuggets of pure code by heading to the GitHub repo or follow the links to go deep on the key innovations that make Harmony so exciting as a blockchain platform. Section Description FBFT Our variation on BFT: Fast Byzantine Fault Tolerance EPoS Our adaptation of the classic PoS is called Effective proof of stake Adaptive IDA All about the IDA protocol Rateless Erasure Code Forward error correction, Harmony style Unbiasable Randomness Nobody messes with our randomness, great for games, voting etc. Resharding Re-re-shard and the crowd say... never mind, just read it Cross-shard Routing Shards. That speak to each other. Sounds easy, but is it? In-depth with Near Protocol Near protocol got really near to Harmony and this is what happened Competitor Overview Boo. Hiss. No, we love our competition. Good projects all. Future Work Here's where we're going next dApps The meat of blockchain value creation. Meet the dApps","title":"Tech Zone"},{"location":"learn/welcome/#company","text":"There's a lot to learn about Harmony's technical foundation and it's always evolving. You can sink your teeth into the juicy nuggets of pure code by heading to the GitHub repo or follow the links to go deep on the key innovations that make Harmony so exciting as a blockchain platform. Section Description Why build Harmony? Just another TPS party or is there more going on? Team & Advisors The people behind the power Partners & Clients You can't do this on your own, here's who's on the extended team FAQ's Fanatical About Quidditch? Milestones In Europe they use the metric system but we'll let it slide. (for now...)","title":"Company"},{"location":"learn/community/hummingbot/","text":"Hummingbot What is Hummingbot Hummingbot can be considered like a Bitcoin mining node. A mining nodes is a software client that runs either locally or in the cloud. It continually runs the Proof-of-Work algorithm that generates value, but only if you provide it with enough electricity. Similarly, Hummingbot is a software client that also runs locally or in the cloud. Rather than a hashing algorithm, it runs a market making algorithm. Instead of electricity, it requires users to maintain inventory of tokens in different markets. What is Market Making Market making is simply providing continual offers to buy and sell an asset. In traditional markets, market making has been the exclusive province of investment banks, broker dealers, quant hedge funds, high frequency trading shops and other very specialized organizations because only those firms have the right to trade on the exchange directly. On the other hand, everyone has direct market access in crypto. Both individuals and funds are on a level playing field because they're accessing the same APIs. In addition, the highly competitive nature of crypto exchanges means that exchanges have to be open with their APIs in order to compete with one another. That opens up the possibility for anyone to run essentially a market making bot and profit from earning the bid-ask spread that exists on different exchanges. In fact, most of our engineering over the past months has really been focused there because even though exchanges have APIs, they're all different, they all have weird edge cases like rate limits, error conditions for you to handle. In addition, we initially built our stack on Python; we realized after a while it was just too slow, so we converted everything to Cython, which is basically Python-like code compiled into low-level C. It made our infrastructure about 1000x faster than where it was previously. What problem does Hummingbot solve? Basically, there are both large and small markets, but there are only large market makers currently. These are firms like Jump Trading and DRW Cumberland that focus on making markets in the top trading pairs, like BTC-USD on Coinbase or ETH-USDT on Binance. But once you start going to smaller token pairs and smaller exchanges, that liquidity drops off significantly. Large market makers have balance sheets in the billions of dollars, so allocating the inventory and technical integration needed to trade small-cap token pairs on decentralized exchanges simply isn't worthwhile when they can focus their efforts on on larger-volume higher-liquidity token pairs. For these smaller markets, individuals and smaller firms are better suited to be market makers. This problem also exists in traditional markets. US equities markets are facing a \"small cap liquidity crisis\" in the US because fragmentation of liquidity due to the rise of dark pools and alternative trading systems (ATS) has caused small-cap stocks to suffer from lack of attention by market makers. If you can market make for Apple, why are you bothering with some small penny stocks that are trading on different exchanges? This effect is even more exaggerated in crypto because instead of 13 exchanges, there are hundreds of exchanges around the world, each with dozens to hundreds of token pairs. Get started https://hummingbot.io/liquidity-bounties/harmony/ https://hummingbot.io/start/ {% embed url=\"https://t.co/72otPr56Fz\" %}","title":"Hummingbot"},{"location":"learn/community/hummingbot/#hummingbot","text":"","title":"Hummingbot"},{"location":"learn/community/hummingbot/#what-is-hummingbot","text":"Hummingbot can be considered like a Bitcoin mining node. A mining nodes is a software client that runs either locally or in the cloud. It continually runs the Proof-of-Work algorithm that generates value, but only if you provide it with enough electricity. Similarly, Hummingbot is a software client that also runs locally or in the cloud. Rather than a hashing algorithm, it runs a market making algorithm. Instead of electricity, it requires users to maintain inventory of tokens in different markets.","title":"What is Hummingbot"},{"location":"learn/community/hummingbot/#what-is-market-making","text":"Market making is simply providing continual offers to buy and sell an asset. In traditional markets, market making has been the exclusive province of investment banks, broker dealers, quant hedge funds, high frequency trading shops and other very specialized organizations because only those firms have the right to trade on the exchange directly. On the other hand, everyone has direct market access in crypto. Both individuals and funds are on a level playing field because they're accessing the same APIs. In addition, the highly competitive nature of crypto exchanges means that exchanges have to be open with their APIs in order to compete with one another. That opens up the possibility for anyone to run essentially a market making bot and profit from earning the bid-ask spread that exists on different exchanges. In fact, most of our engineering over the past months has really been focused there because even though exchanges have APIs, they're all different, they all have weird edge cases like rate limits, error conditions for you to handle. In addition, we initially built our stack on Python; we realized after a while it was just too slow, so we converted everything to Cython, which is basically Python-like code compiled into low-level C. It made our infrastructure about 1000x faster than where it was previously.","title":"What is Market Making"},{"location":"learn/community/hummingbot/#what-problem-does-hummingbot-solve","text":"Basically, there are both large and small markets, but there are only large market makers currently. These are firms like Jump Trading and DRW Cumberland that focus on making markets in the top trading pairs, like BTC-USD on Coinbase or ETH-USDT on Binance. But once you start going to smaller token pairs and smaller exchanges, that liquidity drops off significantly. Large market makers have balance sheets in the billions of dollars, so allocating the inventory and technical integration needed to trade small-cap token pairs on decentralized exchanges simply isn't worthwhile when they can focus their efforts on on larger-volume higher-liquidity token pairs. For these smaller markets, individuals and smaller firms are better suited to be market makers. This problem also exists in traditional markets. US equities markets are facing a \"small cap liquidity crisis\" in the US because fragmentation of liquidity due to the rise of dark pools and alternative trading systems (ATS) has caused small-cap stocks to suffer from lack of attention by market makers. If you can market make for Apple, why are you bothering with some small penny stocks that are trading on different exchanges? This effect is even more exaggerated in crypto because instead of 13 exchanges, there are hundreds of exchanges around the world, each with dozens to hundreds of token pairs.","title":"What problem does Hummingbot solve?"},{"location":"learn/community/hummingbot/#get-started","text":"https://hummingbot.io/liquidity-bounties/harmony/ https://hummingbot.io/start/ {% embed url=\"https://t.co/72otPr56Fz\" %}","title":"Get started"},{"location":"learn/community/social-mining/","text":"Social Mining What is Social Mining? Social Mining is the most advanced resource to convert any tokenized ecosystem into a Decentralized Autonomous Organization (DAO). Harmony uses the Daomaker platform to build out our extended community and create a dynamic network of useful humans. To participate in Social Mining, a project\u2019s stakeholders and community members sign-up on a designated community dashboard. After the simple onboarding process, each community member has the opportunity to add value to the project , whether it be through a simple retweet of the project\u2019s most recent announce or by creating a supplementary software that eases the use of the development, i.e. a blockchain scanner for a native token. Whenever a value-added task is done, it can be documented on the dashboard. The Social Mining dashboard pulls all reported work into a news feed that is presented to all members of a community, who validate the authenticity of each reported work and then decide on how much value said task generated. Subsequently, each reported work is paid project tokens based on the amount of points the reported work received in proportion to all the points given in a reward period. Start Earning $ONE To participate in Social Mining, think about how YOU can add value to Harmony and how you want the platform to evolve. And don't be shy about asking people what they think before you start. That's the point of a community. You might even find others who share your ideas and want to help you make them happen. The value you bring will be scored by the community so being an engaged contributor will only help your cause. Ultimately, the system is designed to self-organise and self-govern so patterns will begin to emerge in terms of what works and what doesn't. But we would always encourage bold and innovative thinking. By way of inspiration here are some examples of work that can be done through Social Mining: Social Media Outreach: Get the word out on social channels. Content: Do you have design skills, love making little movies or just have the knack of writing a great sentence. Strong content helps newcomers understand Harmony and what we are about. It's a proven strategy for building community. Business Development: Our focus is DeFi , Data Sharing and Gaming but that doesn't mean we can't look at other usecases. We're always open to new business leads and our key partnerships started out as casual conversations. Partnerships: Lympo was our first full migration but Harmony's promise is to assist developers struggling with scaling issues on Ethereum and provide a strong team to follow suit. Help us get the word out there and bring new partners to the table. Bugs: Nobody likes bugs. Some people just love the code. If that's you then help us improve the protocol and be rewarded Node Scripts: Running a node is a bewildering process for the first-timer. Fortunately the community boasts some experienced heads who've created hugely helpful tools to assist people. If you're one of those people compile your work and share it to help the community and earn rewards. This is just a short list of potential avenues to explore. Reach out, discuss, get feedback. This system is designed to benefit all and will give everybody a new avenue of utility.","title":"Social Mining"},{"location":"learn/community/social-mining/#social-mining","text":"","title":"Social Mining"},{"location":"learn/community/social-mining/#what-is-social-mining","text":"Social Mining is the most advanced resource to convert any tokenized ecosystem into a Decentralized Autonomous Organization (DAO). Harmony uses the Daomaker platform to build out our extended community and create a dynamic network of useful humans. To participate in Social Mining, a project\u2019s stakeholders and community members sign-up on a designated community dashboard. After the simple onboarding process, each community member has the opportunity to add value to the project , whether it be through a simple retweet of the project\u2019s most recent announce or by creating a supplementary software that eases the use of the development, i.e. a blockchain scanner for a native token. Whenever a value-added task is done, it can be documented on the dashboard. The Social Mining dashboard pulls all reported work into a news feed that is presented to all members of a community, who validate the authenticity of each reported work and then decide on how much value said task generated. Subsequently, each reported work is paid project tokens based on the amount of points the reported work received in proportion to all the points given in a reward period.","title":"What is Social Mining? "},{"location":"learn/community/social-mining/#start-earning-one","text":"To participate in Social Mining, think about how YOU can add value to Harmony and how you want the platform to evolve. And don't be shy about asking people what they think before you start. That's the point of a community. You might even find others who share your ideas and want to help you make them happen. The value you bring will be scored by the community so being an engaged contributor will only help your cause. Ultimately, the system is designed to self-organise and self-govern so patterns will begin to emerge in terms of what works and what doesn't. But we would always encourage bold and innovative thinking. By way of inspiration here are some examples of work that can be done through Social Mining: Social Media Outreach: Get the word out on social channels. Content: Do you have design skills, love making little movies or just have the knack of writing a great sentence. Strong content helps newcomers understand Harmony and what we are about. It's a proven strategy for building community. Business Development: Our focus is DeFi , Data Sharing and Gaming but that doesn't mean we can't look at other usecases. We're always open to new business leads and our key partnerships started out as casual conversations. Partnerships: Lympo was our first full migration but Harmony's promise is to assist developers struggling with scaling issues on Ethereum and provide a strong team to follow suit. Help us get the word out there and bring new partners to the table. Bugs: Nobody likes bugs. Some people just love the code. If that's you then help us improve the protocol and be rewarded Node Scripts: Running a node is a bewildering process for the first-timer. Fortunately the community boasts some experienced heads who've created hugely helpful tools to assist people. If you're one of those people compile your work and share it to help the community and earn rewards. This is just a short list of potential avenues to explore. Reach out, discuss, get feedback. This system is designed to benefit all and will give everybody a new avenue of utility.","title":"Start Earning $ONE "},{"location":"learn/community/tgi/","text":"TGI TGI is Harmony's weekly networking event inspired by the founders' experience at Google. It's about sharing ideas, challenges and staying curious about what's being created by others. The event is also the source of the infamous Harmony BBQcoin meme, a selection of which you can see below (we love memes...) Harmony TGI: Blockchain over BBQWho: Ex-Googlers & friends interested in blockchain + machine learning + startups Time / place: By invitation only, every Saturday 12pm-4pm, near Google headquarter in Mountain View Organizers: Stephen Tse ( linkedin.com/in/tsestephen ), Zi Wang ( linkedin.com/in/ziwang0315 ) This private gathering is for staying in touch with fellow entrepreneurs and offering help to each other. You may learn more about Harmony at https://harmony.one/newsletter or https://harmony.one/deck . Call Li 312-659-9987 or Sahil 617-909-1681 for directions. Join our https://harmony.one/tgi-telegram and https://harmony.one/wechat . Fill in this form to join us any Saturday.","title":"TGI"},{"location":"learn/community/tgi/#tgi","text":"TGI is Harmony's weekly networking event inspired by the founders' experience at Google. It's about sharing ideas, challenges and staying curious about what's being created by others. The event is also the source of the infamous Harmony BBQcoin meme, a selection of which you can see below (we love memes...) Harmony TGI: Blockchain over BBQWho: Ex-Googlers & friends interested in blockchain + machine learning + startups Time / place: By invitation only, every Saturday 12pm-4pm, near Google headquarter in Mountain View Organizers: Stephen Tse ( linkedin.com/in/tsestephen ), Zi Wang ( linkedin.com/in/ziwang0315 ) This private gathering is for staying in touch with fellow entrepreneurs and offering help to each other. You may learn more about Harmony at https://harmony.one/newsletter or https://harmony.one/deck . Call Li 312-659-9987 or Sahil 617-909-1681 for directions. Join our https://harmony.one/tgi-telegram and https://harmony.one/wechat . Fill in this form to join us any Saturday.","title":"TGI"},{"location":"learn/community/transparency-tuesday/","text":"Transparency Tuesday We strongly believe in being fully open source and our code has been since Jan 2019. But we took it one further with Transparency Tuesday where we share our development progress documents each week in the cloud. We are the first project to do this and hope to become leaders in transparency through our live document updates. Anyone is also welcome to comment on this document. Our team will see your feedback live and provide answers. It is a unique opportunity to dig into what Harmony is doing week by week. Find all the latest Transparency posts on our Medium {% embed url=\"https://medium.com/harmony-one/tagged/community\" %}","title":"Transparency Tuesday"},{"location":"learn/community/transparency-tuesday/#transparency-tuesday","text":"We strongly believe in being fully open source and our code has been since Jan 2019. But we took it one further with Transparency Tuesday where we share our development progress documents each week in the cloud. We are the first project to do this and hope to become leaders in transparency through our live document updates. Anyone is also welcome to comment on this document. Our team will see your feedback live and provide answers. It is a unique opportunity to dig into what Harmony is doing week by week. Find all the latest Transparency posts on our Medium {% embed url=\"https://medium.com/harmony-one/tagged/community\" %}","title":"Transparency Tuesday"},{"location":"learn/community/run-a-harmony-node/","text":"Harmony nodes In a Proof of Stake blockchain network nodes are run by users who are deliberately distributed across computers across the world. There is no central authority as the network aims to achieve full decentralisation. Running a node means running the protocol on a local or remote machine and conforming to the rules of the protocol. Nodes compete with each other to complete blocks of verified transactions for the network. In return, they receive a block reward of newly minted coins. For instance, if you\u2019re running an Ethereum node, you earn ETH. On Harmony you earn ONE But in order for participants to help the network and earn, they must \u2018stake\u2019 coins. This means holding them in a special wallet and keeping them there as long as they are running a node. This incentivises participants to act in the best interests of the network. By having these nodes set up in a decentralized manner as described above, and by providing incentivization to keep the network operating smoothly and safely, PoS systems take the best of game theory and automation and combine them with a digital currency that can also be saved, spent or traded. If you wish to learn more about nodes in general nodes.com is an excellent resource.","title":"Harmony nodes"},{"location":"learn/community/run-a-harmony-node/#harmony-nodes","text":"In a Proof of Stake blockchain network nodes are run by users who are deliberately distributed across computers across the world. There is no central authority as the network aims to achieve full decentralisation. Running a node means running the protocol on a local or remote machine and conforming to the rules of the protocol. Nodes compete with each other to complete blocks of verified transactions for the network. In return, they receive a block reward of newly minted coins. For instance, if you\u2019re running an Ethereum node, you earn ETH. On Harmony you earn ONE But in order for participants to help the network and earn, they must \u2018stake\u2019 coins. This means holding them in a special wallet and keeping them there as long as they are running a node. This incentivises participants to act in the best interests of the network. By having these nodes set up in a decentralized manner as described above, and by providing incentivization to keep the network operating smoothly and safely, PoS systems take the best of game theory and automation and combine them with a digital currency that can also be saved, spent or traded. If you wish to learn more about nodes in general nodes.com is an excellent resource.","title":"Harmony nodes"},{"location":"learn/community/run-a-harmony-node/foundational-nodes/","text":"Foundational Nodes Harmony is a permissionless protocol \u2014 anyone can join, leave and contribute to the network. That said, it is equally important and pragmatic to ensure that the protocol is secure from Day 1, and hence the validator pool needs to keep the protocol secure and stable. Therefore, we started the Foundational node operator program to make sure we would have an early community of external nodes/validators to help bootstrap the network. We have kept geographic diversity as an important criterion in welcoming some of the early node/validator community. Some of the regions are Foundational node operators come from include: USA, UK, Thailand, Russia, Taiwan, Canada, Czech Republic, China, Korea. After the security of the protocol is proven, we will voluntarily limit our role in driving and facilitating the validator community. We\u2019re looking for global strategic partners who are interested in running a Harmony node and in contributing to our next strategic investment round. This initiative is key to the long-term success of our protocol for three reasons. Since we use a sharded architecture, our throughput increases with an increase in the number of nodes and shards in our network. This means that in order for our blockchain to scale, we need the number of node operators to scale as well. Decentralization is critical to the security and resilience of any blockchain network. And while many projects run a majority of nodes themselves, or rely on a small number of firms to do so, we seek to have an organic and globally distributed network of node operators to ensure that our network is decentralized from the start. This is a key step towards bootstrapping a robust decentralized network that is spread across the world. Our protocol is only as strong as our community is. The sophisticated technology we are building is crucial, but equally important are the people that believe in and support the Harmony network. This initiative will drive Harmony\u2019s success as a whole, by bringing scale and decentralization to the network, while broadening and strengthening our community. Details about running Foundational Nodes The partners who sign up to run Foundational nodes will be participating in the Proof-of-Stake (PoS) validating network on our mainnet. Each node operator will be entitled to staking rewards. Requirements Complete KYC/AML via Coinlist (US) or OpenToken (Non-US) $10,000+ in investment US participants must be accredited Introduce yourself on our forum and discord !","title":"Foundational Nodes"},{"location":"learn/community/run-a-harmony-node/foundational-nodes/#foundational-nodes","text":"Harmony is a permissionless protocol \u2014 anyone can join, leave and contribute to the network. That said, it is equally important and pragmatic to ensure that the protocol is secure from Day 1, and hence the validator pool needs to keep the protocol secure and stable. Therefore, we started the Foundational node operator program to make sure we would have an early community of external nodes/validators to help bootstrap the network. We have kept geographic diversity as an important criterion in welcoming some of the early node/validator community. Some of the regions are Foundational node operators come from include: USA, UK, Thailand, Russia, Taiwan, Canada, Czech Republic, China, Korea. After the security of the protocol is proven, we will voluntarily limit our role in driving and facilitating the validator community. We\u2019re looking for global strategic partners who are interested in running a Harmony node and in contributing to our next strategic investment round. This initiative is key to the long-term success of our protocol for three reasons. Since we use a sharded architecture, our throughput increases with an increase in the number of nodes and shards in our network. This means that in order for our blockchain to scale, we need the number of node operators to scale as well. Decentralization is critical to the security and resilience of any blockchain network. And while many projects run a majority of nodes themselves, or rely on a small number of firms to do so, we seek to have an organic and globally distributed network of node operators to ensure that our network is decentralized from the start. This is a key step towards bootstrapping a robust decentralized network that is spread across the world. Our protocol is only as strong as our community is. The sophisticated technology we are building is crucial, but equally important are the people that believe in and support the Harmony network. This initiative will drive Harmony\u2019s success as a whole, by bringing scale and decentralization to the network, while broadening and strengthening our community.","title":"Foundational Nodes"},{"location":"learn/community/run-a-harmony-node/foundational-nodes/#details-about-running-foundational-nodes","text":"The partners who sign up to run Foundational nodes will be participating in the Proof-of-Stake (PoS) validating network on our mainnet. Each node operator will be entitled to staking rewards.","title":"Details about running Foundational Nodes "},{"location":"learn/community/run-a-harmony-node/foundational-nodes/#requirements","text":"Complete KYC/AML via Coinlist (US) or OpenToken (Non-US) $10,000+ in investment US participants must be accredited Introduce yourself on our forum and discord !","title":"Requirements "},{"location":"learn/community/run-a-harmony-node/pangaea/","text":"Pangaea Pangaea is the name given to Earth\u2019s first and best-known super continent, long before tectonic plates did all their shuffling around to create the planet we live on today. You could say that Pangaea is the ultimate example of a \u2018borderless\u2019 environment and evidence that we were all ONE in the beginning. We are launching Pangaea \u2014 an experimental game for thousands of people to interact with the Harmony network, test the limitations of our technology and have lots of fun while earning rewards. Pangaea is created purely for experimental purposes. It will have its own currency for playing and bookkeeping. The goals of Pangaea: Test Harmony\u2019s upcoming core protocol milestones and updates such as staking smart contracts and resharding, on a network of all external nodes Set-up and onboard a vast number of nodes, ready to jump into the mainnet, through collective knowledge building and competitions Identify and award community members who help secure Harmony network and are willing to go the extra mile by taking on leadership roles in our validator community Who can participate? EveryONE \u2014 the more the merrier! To create a fully secure, permission less, and sharded blockchain we need lots and lots of nodes. If you\u2019ve previously thought running a node was too technical or expensive, this is a great opportunity to give it a go. If you want to get your hands dirty and play with the network, this is the way to go! Become a node, learn on the go, secure Pangaea and get the chance to become a node in Mainnet with its stake sponsored by Harmony. In addition, you will win prizes for maintaining superior network performance during the game. Technical requirements: Minimum of 2 cores, 2G RAM, 30G hard drive AWS t3.small or equivalent from other cloud provider Get Involved To join Pangaea and find out all about our incentivised testnet games you can explore the dedicated Gitbook or join the Telegram discussion Gitbook Telegram","title":"Pangaea"},{"location":"learn/community/run-a-harmony-node/pangaea/#pangaea","text":"Pangaea is the name given to Earth\u2019s first and best-known super continent, long before tectonic plates did all their shuffling around to create the planet we live on today. You could say that Pangaea is the ultimate example of a \u2018borderless\u2019 environment and evidence that we were all ONE in the beginning. We are launching Pangaea \u2014 an experimental game for thousands of people to interact with the Harmony network, test the limitations of our technology and have lots of fun while earning rewards. Pangaea is created purely for experimental purposes. It will have its own currency for playing and bookkeeping.","title":"Pangaea"},{"location":"learn/community/run-a-harmony-node/pangaea/#the-goals-of-pangaea","text":"Test Harmony\u2019s upcoming core protocol milestones and updates such as staking smart contracts and resharding, on a network of all external nodes Set-up and onboard a vast number of nodes, ready to jump into the mainnet, through collective knowledge building and competitions Identify and award community members who help secure Harmony network and are willing to go the extra mile by taking on leadership roles in our validator community","title":"The goals of Pangaea:"},{"location":"learn/community/run-a-harmony-node/pangaea/#who-can-participate","text":"EveryONE \u2014 the more the merrier! To create a fully secure, permission less, and sharded blockchain we need lots and lots of nodes. If you\u2019ve previously thought running a node was too technical or expensive, this is a great opportunity to give it a go. If you want to get your hands dirty and play with the network, this is the way to go! Become a node, learn on the go, secure Pangaea and get the chance to become a node in Mainnet with its stake sponsored by Harmony. In addition, you will win prizes for maintaining superior network performance during the game. Technical requirements: Minimum of 2 cores, 2G RAM, 30G hard drive AWS t3.small or equivalent from other cloud provider","title":"Who can participate?"},{"location":"learn/community/run-a-harmony-node/pangaea/#get-involved","text":"To join Pangaea and find out all about our incentivised testnet games you can explore the dedicated Gitbook or join the Telegram discussion Gitbook Telegram","title":"Get Involved"},{"location":"learn/community/run-a-harmony-node/run-a-node/","text":"Run a node The Harmony node set-up is now a very painless one-click process that can be completed in around 5 minutes. We've set up a node playbook with its own documention which you can find here . Alternatively select from the appropriate chapter below: Setting up your node Node setup quick reference Key management guide Node operator mainnet launch prep Frequently asked questions Token transfers on Mainnet Non-validating Nodes Fast State Syncing using DB Snapshot Upgrading your Disk Space to 100GB Betanet Mainnet Monitoring and Reporting Tools Community Join our Discord to connect with the team directly","title":"Run a node"},{"location":"learn/community/run-a-harmony-node/run-a-node/#run-a-node","text":"The Harmony node set-up is now a very painless one-click process that can be completed in around 5 minutes. We've set up a node playbook with its own documention which you can find here . Alternatively select from the appropriate chapter below: Setting up your node Node setup quick reference Key management guide Node operator mainnet launch prep Frequently asked questions Token transfers on Mainnet Non-validating Nodes Fast State Syncing using DB Snapshot Upgrading your Disk Space to 100GB Betanet Mainnet Monitoring and Reporting Tools Community Join our Discord to connect with the team directly","title":"Run a node"},{"location":"learn/community/staking/how-to-stake-harmony-tokens/","text":"How to stake Harmony tokens","title":"How to stake Harmony Tokens"},{"location":"learn/community/staking/how-to-stake-harmony-tokens/#how-to-stake-harmony-tokens","text":"","title":"How to stake Harmony tokens"},{"location":"learn/community/staking/staking/","text":"Staking Do more with your tokens Proof-of-Stake is a more democratic way of validating transactions and providing security to a blockchain. It means anyone with skin in the game can compound their holdings by simply... holding. The fun thing is there are lots of different ways to do this and we've even seen major players like Binance and Coinbase launching Staking as a Service so it's becoming ever easier to stake tokens in secure, reliable tech from partners with a proper track record. There's a few things you're going to need in order to stake. Some tokens An approved wallet or a Staking pool","title":"Overview"},{"location":"learn/community/staking/staking/#staking","text":"","title":"Staking"},{"location":"learn/community/staking/staking/#do-more-with-your-tokens","text":"Proof-of-Stake is a more democratic way of validating transactions and providing security to a blockchain. It means anyone with skin in the game can compound their holdings by simply... holding. The fun thing is there are lots of different ways to do this and we've even seen major players like Binance and Coinbase launching Staking as a Service so it's becoming ever easier to stake tokens in secure, reliable tech from partners with a proper track record. There's a few things you're going to need in order to stake. Some tokens An approved wallet or a Staking pool","title":"Do more with your tokens"},{"location":"learn/community/staking/understanding-proof-of-stake/","text":"Understanding Proof of Stake What is it and how is it different from PoW? The Proof-of-stake consensus mechanism was created as an alternative to Proof-of-Work (PoW), to tackle inherent issues in the latter. When a transaction is initiated, the transaction data is fitted into a block with a maximum capacity of 1 megabyte, and then duplicated across multiple computers or nodes on the network. The nodes are the administrative body of the blockchain and verify the legitimacy of the transactions in each block. To carry out the verification step, the nodes or miners would need to solve a computational puzzle, known as the proof of work problem. The first miner to decrypt each block transaction problem gets rewarded with coin. Once a block of transactions has been verified, it is added to the blockchain, a public transparent ledger. Mining requires a great deal of computing power to run different cryptographic calculations to unlock the computational challenges. The computing power translates into a high amount of electricity and power needed for the proof of work. In 2015, it was estimated that one Bitcoin transaction required the amount of electricity needed to power up 1.57 American households per day. To foot the electricity bill, miners would usually sell their awarded coins for fiat money, which would lead to a downward movement in the price of the cryptocurrency. Proof-of-stake (PoS) seeks to address this issue by attributing mining power to the proportion of coins held by a miner. This way, instead of utilizing energy to answer PoW puzzles, a PoS miner is limited to mining a percentage of transactions that is reflective of his or her ownership stake. For instance, a miner who owns 3% of the Bitcoin available can theoretically mine only 3% of the blocks.","title":"Understanding Proof of Stake"},{"location":"learn/community/staking/understanding-proof-of-stake/#understanding-proof-of-stake","text":"","title":"Understanding Proof of Stake"},{"location":"learn/community/staking/understanding-proof-of-stake/#what-is-it-and-how-is-it-different-from-pow","text":"The Proof-of-stake consensus mechanism was created as an alternative to Proof-of-Work (PoW), to tackle inherent issues in the latter. When a transaction is initiated, the transaction data is fitted into a block with a maximum capacity of 1 megabyte, and then duplicated across multiple computers or nodes on the network. The nodes are the administrative body of the blockchain and verify the legitimacy of the transactions in each block. To carry out the verification step, the nodes or miners would need to solve a computational puzzle, known as the proof of work problem. The first miner to decrypt each block transaction problem gets rewarded with coin. Once a block of transactions has been verified, it is added to the blockchain, a public transparent ledger. Mining requires a great deal of computing power to run different cryptographic calculations to unlock the computational challenges. The computing power translates into a high amount of electricity and power needed for the proof of work. In 2015, it was estimated that one Bitcoin transaction required the amount of electricity needed to power up 1.57 American households per day. To foot the electricity bill, miners would usually sell their awarded coins for fiat money, which would lead to a downward movement in the price of the cryptocurrency. Proof-of-stake (PoS) seeks to address this issue by attributing mining power to the proportion of coins held by a miner. This way, instead of utilizing energy to answer PoW puzzles, a PoS miner is limited to mining a percentage of transactions that is reflective of his or her ownership stake. For instance, a miner who owns 3% of the Bitcoin available can theoretically mine only 3% of the blocks.","title":"What is it and how is it different from PoW?"},{"location":"learn/community/staking/staking-pools/cobo/","text":"Cobo Cobo is the first leading wallet company in the world to offer Staking and masternode rewards on user holdings, making it easy for users to grow their digital assets effortlessly. As a company, they emphasize long-term security, reliability, and convenience. Cobo offers a secure mobile wallet (Cobo Wallet), high-end cold storage wallet for advanced users (Cobo Vault), and custodial services for institutional investors. They offer a number of options to stake $ONE, either delegating to a node or staking within the Cobo Wallet. Visit the Cobo site here for more information https://cobo.com/","title":"Cobo"},{"location":"learn/community/staking/staking-pools/cobo/#cobo","text":"Cobo is the first leading wallet company in the world to offer Staking and masternode rewards on user holdings, making it easy for users to grow their digital assets effortlessly. As a company, they emphasize long-term security, reliability, and convenience. Cobo offers a secure mobile wallet (Cobo Wallet), high-end cold storage wallet for advanced users (Cobo Vault), and custodial services for institutional investors. They offer a number of options to stake $ONE, either delegating to a node or staking within the Cobo Wallet. Visit the Cobo site here for more information https://cobo.com/","title":"Cobo"},{"location":"learn/community/staking/staking-pools/everstake/","text":"Everstake About Everstake Everstake is a team of experienced developers, financial experts and blockchain enthusiasts. The company was founded by Attic Lab, an EOS block producer from Ukraine. They run highly secure and reliable nodes for PoS protocols using enterprise-level hardware to ensure maximum efficiency and security. Everstake helps institutional investors and regular token holders to profit off their crypto assets. They operate in a wide range of Proof of Stake blockchains, providing customers with numerous options to choose from. Pick the most promising projects, delegate with Everstake and make 5%-20% annually. A team built for success Everstake Validation Stats speak for themselves: As of today the digital asset staked worth exceeds $630.5 Million, more than 4.3 M blocks produced, while the rewards distributed are close to $250k. Since Harmony\u2019s network\u2019s launch earlier this year, Everstake team has been operating two validator nodes achieving the top staking provider status. Sergii Vasylchuk, CEO & Founder of Everstake: We believe that Harmony is capable of solving all current challenges the modern blockchain technology is facing, and we will continue supporting the platform. Moreover, we are planning to launch the development of several projects for Harmony, that will improve the usability and comfort of the platform, starting from its early adopters. Nick White, Co-Founder of Harmony Protocol \u201cWe are looking forward to having Everstake be part of the Harmony ecosystem. They will bring to Harmony their deep experience in staking systems and as a leading validator for top blockchain projects\u201d Institutions need a trusted partner to help them actively, safely, and easily delegate in Harmony\u2019s Proof of Stake network \u2014 in which participants are incentivized to secure our blockchain by staking. This partnership with Everstake will allow institutions and crypto holders to earn passive income by delegating their $ONE tokens to a trusted validator and proportionally share in the block rewards. Everstake runs already Harmony nodes sharing the same security and infrastructure standards as one of the top EOS validators. Among the most important elements of this partnership is the ease of use, since clients enjoy a simple deposit and withdrawal experience, along with detailed reporting features. If you are interested to stake your ONE tokens through the Everstake you can enquire here for additional information in regard to the provided services and current enrollment opportunities. To know more about Everstake, visit their Website or Medium , or engage directly with their team through their Telegram community.","title":"Everstake"},{"location":"learn/community/staking/staking-pools/everstake/#everstake","text":"","title":"Everstake"},{"location":"learn/community/staking/staking-pools/everstake/#about-everstake","text":"Everstake is a team of experienced developers, financial experts and blockchain enthusiasts. The company was founded by Attic Lab, an EOS block producer from Ukraine. They run highly secure and reliable nodes for PoS protocols using enterprise-level hardware to ensure maximum efficiency and security. Everstake helps institutional investors and regular token holders to profit off their crypto assets. They operate in a wide range of Proof of Stake blockchains, providing customers with numerous options to choose from. Pick the most promising projects, delegate with Everstake and make 5%-20% annually.","title":"About Everstake"},{"location":"learn/community/staking/staking-pools/everstake/#a-team-built-for-success","text":"Everstake Validation Stats speak for themselves: As of today the digital asset staked worth exceeds $630.5 Million, more than 4.3 M blocks produced, while the rewards distributed are close to $250k. Since Harmony\u2019s network\u2019s launch earlier this year, Everstake team has been operating two validator nodes achieving the top staking provider status. Sergii Vasylchuk, CEO & Founder of Everstake: We believe that Harmony is capable of solving all current challenges the modern blockchain technology is facing, and we will continue supporting the platform. Moreover, we are planning to launch the development of several projects for Harmony, that will improve the usability and comfort of the platform, starting from its early adopters. Nick White, Co-Founder of Harmony Protocol \u201cWe are looking forward to having Everstake be part of the Harmony ecosystem. They will bring to Harmony their deep experience in staking systems and as a leading validator for top blockchain projects\u201d Institutions need a trusted partner to help them actively, safely, and easily delegate in Harmony\u2019s Proof of Stake network \u2014 in which participants are incentivized to secure our blockchain by staking. This partnership with Everstake will allow institutions and crypto holders to earn passive income by delegating their $ONE tokens to a trusted validator and proportionally share in the block rewards. Everstake runs already Harmony nodes sharing the same security and infrastructure standards as one of the top EOS validators. Among the most important elements of this partnership is the ease of use, since clients enjoy a simple deposit and withdrawal experience, along with detailed reporting features. If you are interested to stake your ONE tokens through the Everstake you can enquire here for additional information in regard to the provided services and current enrollment opportunities. To know more about Everstake, visit their Website or Medium , or engage directly with their team through their Telegram community.","title":"A team built for success"},{"location":"learn/community/staking/staking-pools/honest-mining/","text":"Honest Mining About Honest Mining Honest Mining serves as Staking-as-a-Service (SaaS) platform that makes staking in Proof-of-Stake protocols easy and accessible for everybody. Carrying the name that reflects virtuous morality, we commit to provide full transparency and security to our users. They enable people to grow their crypto-asset over time by distributing staking yield of average 7\u201315% annually. As the largest Staking as a Service platform in South East Asia, Honest Mining opens up a whole new market for Harmony (ONE) node in the region. Honest Mining will open shared nodes service of Harmony (ONE) for users to stake in and to earn rewards at ease. \u201c Honest Mining is happy to support Harmony ONE goal, building a blockchain for 10 billion people. ONE ambitious sharding & EPoS infrastructure needs a lot of validators, and with Honest Mining, everyone can be part of the network and enjoy the staking rewards. \u201d Lawrence Samantha, CEO of Honest Mining honestmining.com Join Honest Mining Community on Telegram: Channel @HonestMining English Community @HonestMiningEN Indonesian Community @HonestMiningID","title":"Honest Mining"},{"location":"learn/community/staking/staking-pools/honest-mining/#honest-mining","text":"","title":"Honest Mining"},{"location":"learn/community/staking/staking-pools/honest-mining/#about-honest-mining","text":"Honest Mining serves as Staking-as-a-Service (SaaS) platform that makes staking in Proof-of-Stake protocols easy and accessible for everybody. Carrying the name that reflects virtuous morality, we commit to provide full transparency and security to our users. They enable people to grow their crypto-asset over time by distributing staking yield of average 7\u201315% annually. As the largest Staking as a Service platform in South East Asia, Honest Mining opens up a whole new market for Harmony (ONE) node in the region. Honest Mining will open shared nodes service of Harmony (ONE) for users to stake in and to earn rewards at ease. \u201c Honest Mining is happy to support Harmony ONE goal, building a blockchain for 10 billion people. ONE ambitious sharding & EPoS infrastructure needs a lot of validators, and with Honest Mining, everyone can be part of the network and enjoy the staking rewards. \u201d Lawrence Samantha, CEO of Honest Mining honestmining.com","title":"About Honest Mining"},{"location":"learn/community/staking/staking-pools/honest-mining/#join-honest-mining-community-on-telegram","text":"Channel @HonestMining English Community @HonestMiningEN Indonesian Community @HonestMiningID","title":"Join Honest Mining Community on Telegram: "},{"location":"learn/community/staking/staking-pools/staking-pools/","text":"Staking pools NB: This content has been reproduced verbatim from Binance Academy Credit: Tanwa Arpornthip A staking pool allows multiple stakeholders to combine their computational resources as a way to increase their chances of being rewarded. In other words, they unite their staking power in the process of verifying and validating new blocks , so they have a higher probability of earning the block rewards . The overall idea of the staking pool model is quite similar to the traditional mining pool, which involves the pooling of hash rate in a Proof of Work (PoW) blockchain. However, the staking pool setup is only available on blockchains that employ the Proof of Stake (PoS) model or, in non-POS systems through protocol design features. Typically, a staking pool is managed by a pool operator and the stakeholders that decide to join the pool have to lock their coins in a specific blockchain address (or wallet). While some pools require users to stake their coins with a third party, there are many other alternatives that allow stakeholders to contribute with their staking power while still holding their coins in a personal wallet . For instance, the so-called cold staking pools enable a more secure model, as users can participate in the staking process while keeping their funds on a hardware wallet. Compared to solo staking, a staking pool will give smaller rewards because each successful block forging (validation) will split the rewards among the many participants of the pool. In addition, most pools will charge fees, which will reduce even more the final payout. On the other hand, staking pools provide more predictable and frequent staking rewards. Other than that, they allow stakeholders to make a passive income without having to worry about the technical implementation and maintenance of setting up and running a validating node. Harmony currently has relationships with the following staking pools: Everstake Honest mining Cobo Click the links to learn more about each company's approach.","title":"Overview"},{"location":"learn/community/staking/staking-pools/staking-pools/#staking-pools","text":"NB: This content has been reproduced verbatim from Binance Academy Credit: Tanwa Arpornthip A staking pool allows multiple stakeholders to combine their computational resources as a way to increase their chances of being rewarded. In other words, they unite their staking power in the process of verifying and validating new blocks , so they have a higher probability of earning the block rewards . The overall idea of the staking pool model is quite similar to the traditional mining pool, which involves the pooling of hash rate in a Proof of Work (PoW) blockchain. However, the staking pool setup is only available on blockchains that employ the Proof of Stake (PoS) model or, in non-POS systems through protocol design features. Typically, a staking pool is managed by a pool operator and the stakeholders that decide to join the pool have to lock their coins in a specific blockchain address (or wallet). While some pools require users to stake their coins with a third party, there are many other alternatives that allow stakeholders to contribute with their staking power while still holding their coins in a personal wallet . For instance, the so-called cold staking pools enable a more secure model, as users can participate in the staking process while keeping their funds on a hardware wallet. Compared to solo staking, a staking pool will give smaller rewards because each successful block forging (validation) will split the rewards among the many participants of the pool. In addition, most pools will charge fees, which will reduce even more the final payout. On the other hand, staking pools provide more predictable and frequent staking rewards. Other than that, they allow stakeholders to make a passive income without having to worry about the technical implementation and maintenance of setting up and running a validating node. Harmony currently has relationships with the following staking pools: Everstake Honest mining Cobo Click the links to learn more about each company's approach.","title":"Staking pools"},{"location":"learn/community/token-utility-and-economics/binance-launchpad/","text":"Binance Launchpad Harmony was the fifth Launchpad project announced by Binance in 2019 and our tokens went on sale May 28th with hard cap of $5m USD. Binance Research compiled a thorough report on our project which involved weeks of intense due diligence. You can find the report here . Token sale and economics Launchpad Hard Cap 5,000,000 USD Total Token Supply 12,600,000,000 ONE Initial Circulating Supply 24.3% of Total Token Supply Public Sale Token Price 0.003175 USD (price in BNB will be determined on the lottery draw date) Launchpad Allocation 1,575,000,000 ONE (12.5% of Total Token Supply) Max Number of Winning Lottery Tickets 16,666 Allocation Per Winning Ticket 300 USD (94503.78 ONE) Public Sale Vesting Period No lockup Seed Sale Token Price 1 ONE = 0.0065USD Seed Sale 22.4% of Total Token Supply Seed Sale Vesting Period 25% unlocked at TGE, remaining 75% unlocks at 25% every 6 months afterwards Token Type BEP2 Token Distribution Within 15 days after end of token sale","title":"Binance Launchpad"},{"location":"learn/community/token-utility-and-economics/binance-launchpad/#binance-launchpad","text":"Harmony was the fifth Launchpad project announced by Binance in 2019 and our tokens went on sale May 28th with hard cap of $5m USD. Binance Research compiled a thorough report on our project which involved weeks of intense due diligence. You can find the report here .","title":"Binance Launchpad"},{"location":"learn/community/token-utility-and-economics/binance-launchpad/#token-sale-and-economics","text":"Launchpad Hard Cap 5,000,000 USD Total Token Supply 12,600,000,000 ONE Initial Circulating Supply 24.3% of Total Token Supply Public Sale Token Price 0.003175 USD (price in BNB will be determined on the lottery draw date) Launchpad Allocation 1,575,000,000 ONE (12.5% of Total Token Supply) Max Number of Winning Lottery Tickets 16,666 Allocation Per Winning Ticket 300 USD (94503.78 ONE) Public Sale Vesting Period No lockup Seed Sale Token Price 1 ONE = 0.0065USD Seed Sale 22.4% of Total Token Supply Seed Sale Vesting Period 25% unlocked at TGE, remaining 75% unlocks at 25% every 6 months afterwards Token Type BEP2 Token Distribution Within 15 days after end of token sale","title":"Token sale and economics"},{"location":"learn/community/token-utility-and-economics/exchanges/","text":"Exchanges Where can I buy Harmony ONE tokens? Binance online exchange Bitmax online exchange Kucoin online exchange Gate.io online exchange TrustWallet with credit cards Crypto.com with credit cards Bitladon (EUR) online exchange Coinmerce (EUR) online exchange Coinspot (AUD) online exchange For US Token Holders As of September 12 2019 US based token holders will no longer be able to deposit funds or make trades on Binance.com. As stated by the exchange \"Binance is unable to provide services to any U.S. person\". As a Launchpad project Binance was our first exchange and continues to be the primary platform for those wishing to purchase our token. BAM Trading Services has announced that it will be partnering with Binance to launch Binance.US which will provide secure and reliable cryptocurrency trading to users in the United States. Harmony is not currently listed on Binance.US but we are now listed on Kucoin so US token holders now have more options available to them. Coinbase August 5th 2019 Coinbase announced it was exploring the addition of 8 new assets to its exchange. Harmony was listed as one of those assets. Coinbase's goal is to offer support for all assets that meet our technical standards and which comply with applicable laws.","title":"Exchanges"},{"location":"learn/community/token-utility-and-economics/exchanges/#exchanges","text":"","title":"Exchanges"},{"location":"learn/community/token-utility-and-economics/exchanges/#where-can-i-buy-harmony-one-tokens","text":"Binance online exchange Bitmax online exchange Kucoin online exchange Gate.io online exchange TrustWallet with credit cards Crypto.com with credit cards Bitladon (EUR) online exchange Coinmerce (EUR) online exchange Coinspot (AUD) online exchange","title":"Where can I buy Harmony ONE tokens?"},{"location":"learn/community/token-utility-and-economics/exchanges/#for-us-token-holders","text":"As of September 12 2019 US based token holders will no longer be able to deposit funds or make trades on Binance.com. As stated by the exchange \"Binance is unable to provide services to any U.S. person\". As a Launchpad project Binance was our first exchange and continues to be the primary platform for those wishing to purchase our token. BAM Trading Services has announced that it will be partnering with Binance to launch Binance.US which will provide secure and reliable cryptocurrency trading to users in the United States. Harmony is not currently listed on Binance.US but we are now listed on Kucoin so US token holders now have more options available to them.","title":"For US Token Holders"},{"location":"learn/community/token-utility-and-economics/exchanges/#coinbase","text":"August 5th 2019 Coinbase announced it was exploring the addition of 8 new assets to its exchange. Harmony was listed as one of those assets. Coinbase's goal is to offer support for all assets that meet our technical standards and which comply with applicable laws.","title":"Coinbase"},{"location":"learn/community/token-utility-and-economics/gate.io-token-sale/","text":"Gate.io Token Sale Gate.io Startup Discount Offer On 19th August 2019 Gate.io launched Startup , a platform that aims to present projects with potential that are already listed on other exchanges. To thank their users and to provide a fast track for project listing, they offer Startup token sales with a discount on the platform. Harmony(ONE) Token Sale Result The Gate.io Startup Discount Offer Harmony(ONE) token sale result is as follows: ONE Startup Sale Amount: 46,125,461.2338 ONE Total value of orders (in USDT): 31,917,342.3420842 Total value of qualified orders (in USDT): 31,881,531.531273678 Number of orders: 4, 924 Number of Qualified orders: 4, 911 Percentage of qualified orders: 99.735987002437 % Percentage of succeeded purchases: 99.887801401424 % Number of participants: 4,924 Number of qualified participants: 4, 911 Average qualified order value per user (in USDT): 6,491.8614398847 Average distribution value per user (in GT): 58.622906529431 Average distributed ONE per user: 9,392.27473708 F (distribution ratio with GT) = 0.0078327323534186","title":"Gate.io Token Sale"},{"location":"learn/community/token-utility-and-economics/gate.io-token-sale/#gateio-token-sale","text":"","title":"Gate.io Token Sale"},{"location":"learn/community/token-utility-and-economics/gate.io-token-sale/#gateio-startup-discount-offer","text":"On 19th August 2019 Gate.io launched Startup , a platform that aims to present projects with potential that are already listed on other exchanges. To thank their users and to provide a fast track for project listing, they offer Startup token sales with a discount on the platform.","title":"Gate.io Startup Discount Offer"},{"location":"learn/community/token-utility-and-economics/gate.io-token-sale/#harmonyone-token-sale-result","text":"The Gate.io Startup Discount Offer Harmony(ONE) token sale result is as follows: ONE Startup Sale Amount: 46,125,461.2338 ONE Total value of orders (in USDT): 31,917,342.3420842 Total value of qualified orders (in USDT): 31,881,531.531273678 Number of orders: 4, 924 Number of Qualified orders: 4, 911 Percentage of qualified orders: 99.735987002437 % Percentage of succeeded purchases: 99.887801401424 % Number of participants: 4,924 Number of qualified participants: 4, 911 Average qualified order value per user (in USDT): 6,491.8614398847 Average distribution value per user (in GT): 58.622906529431 Average distributed ONE per user: 9,392.27473708 F (distribution ratio with GT) = 0.0078327323534186","title":"Harmony(ONE) Token Sale Result"},{"location":"learn/community/token-utility-and-economics/onetoken/","text":"The $ONE token BEP2 Tokens The Harmony token $ONE was officially brought into the world on Binance Chain as a BEP2 token on May 28th coinciding with the launch of Mainnet Phase 1. This was supported with a major push from Binance to bring new projects into its eco-system via the decentralised Binance DEX. Sharding is still in its infancy and we prioritised building our pool of external validators gradually to ensure security and up-time before migrating the BEP2 tokens to full mainnet. Unlock Schedule A full breakdown of the $ONE unlock schedule can be found here Key Metrics Ticker ONE Issuing Price $0.003175 USD Initial Circ. Supply 3,061,800,000 ONE (24.3%) Total Supply 12,600,000,000 ONE What\u2019s the purpose of Harmony\u2019s native token? The Harmony token is a protocol token used for a number of purposes on the network. The token is used to stake in order to become a validator on the network to earn block rewards and transaction fees. We use Proof of Stake (POS) as our sybil resistance mechanism in the protocol. The token is used to pay fees on the network, both transaction fees, gas and storage fees. The token is used in voting for on-chain governance of the protocol. Without the token, the protocol could not function. Where to buy Utility Staking Social Mining Run a node Hummingbot","title":"Overview"},{"location":"learn/community/token-utility-and-economics/onetoken/#the-one-token","text":"","title":"The $ONE token"},{"location":"learn/community/token-utility-and-economics/onetoken/#bep2-tokens","text":"The Harmony token $ONE was officially brought into the world on Binance Chain as a BEP2 token on May 28th coinciding with the launch of Mainnet Phase 1. This was supported with a major push from Binance to bring new projects into its eco-system via the decentralised Binance DEX. Sharding is still in its infancy and we prioritised building our pool of external validators gradually to ensure security and up-time before migrating the BEP2 tokens to full mainnet.","title":"BEP2 Tokens"},{"location":"learn/community/token-utility-and-economics/onetoken/#unlock-schedule","text":"A full breakdown of the $ONE unlock schedule can be found here","title":"Unlock Schedule"},{"location":"learn/community/token-utility-and-economics/onetoken/#key-metrics","text":"Ticker ONE Issuing Price $0.003175 USD Initial Circ. Supply 3,061,800,000 ONE (24.3%) Total Supply 12,600,000,000 ONE","title":"Key Metrics"},{"location":"learn/community/token-utility-and-economics/onetoken/#whats-the-purpose-of-harmonys-native-token","text":"The Harmony token is a protocol token used for a number of purposes on the network. The token is used to stake in order to become a validator on the network to earn block rewards and transaction fees. We use Proof of Stake (POS) as our sybil resistance mechanism in the protocol. The token is used to pay fees on the network, both transaction fees, gas and storage fees. The token is used in voting for on-chain governance of the protocol. Without the token, the protocol could not function. Where to buy Utility Staking Social Mining Run a node Hummingbot","title":"What\u2019s the purpose of Harmony\u2019s native token?"},{"location":"learn/community/token-utility-and-economics/utility/","text":"Utility You got some tokens... now what? Okay, you were brave, you took the plunge. We said 'Be the ONE' and you said 'Yeah, that's me, I'm the ONE...' and you bought tokens. And we know that you aren't the kind of person to just sit and HODL and turn a blind eye to everything else you could be doing. But... the market is going crazy and you're not entirely sure what the next step is. You probably bought tokens speculatively at this stage and that's okay. Everybody's gotta start somewhere. The crypto public markets can be savage and soul-crushing in their volatility and we understand the nasty effect this can have on you, the token-holder. One way we mitigate this is to develop and bolster the fundamentals, creating . If this were real money you'd be able to do something with it, like buy groceries, stick it in the bank for that epic interest rate you've been promised (see below), or just plain give it away to charity because you're a good person. Yes you are. {% hint style=\"info\" %} According to the FDIC, the national average interest rate on savings accounts currently stands at 0.09% APY. {% endhint %} Well tokens, when they're really cooking, can do all that and a lot more besides. As we continue to develop the protocol more utility will open up but here are some ways in which you can do more with your $ONE. Stake your tokens in an official wallet and benefit from a much higher rate of turn than that offered by your bank Delegate your stake to one of our recognised staking partners such as Everstake or Honest Mining As collateral to run a node and earn validator rewards Earn rewards by completing tasks for the community through Social Mining To power decentralised market-making services using Hummingbot Go deeper... there's so much more you can do. We look forward to you being able to pay for your groceries through the likes of Crypto.com's debit card, or take advantage of decentralised financial services like MakerDAO. Those will come in time.","title":"Utility"},{"location":"learn/community/token-utility-and-economics/utility/#utility","text":"","title":"Utility"},{"location":"learn/community/token-utility-and-economics/utility/#you-got-some-tokens-now-what","text":"Okay, you were brave, you took the plunge. We said 'Be the ONE' and you said 'Yeah, that's me, I'm the ONE...' and you bought tokens. And we know that you aren't the kind of person to just sit and HODL and turn a blind eye to everything else you could be doing. But... the market is going crazy and you're not entirely sure what the next step is. You probably bought tokens speculatively at this stage and that's okay. Everybody's gotta start somewhere. The crypto public markets can be savage and soul-crushing in their volatility and we understand the nasty effect this can have on you, the token-holder. One way we mitigate this is to develop and bolster the fundamentals, creating . If this were real money you'd be able to do something with it, like buy groceries, stick it in the bank for that epic interest rate you've been promised (see below), or just plain give it away to charity because you're a good person. Yes you are. {% hint style=\"info\" %} According to the FDIC, the national average interest rate on savings accounts currently stands at 0.09% APY. {% endhint %} Well tokens, when they're really cooking, can do all that and a lot more besides. As we continue to develop the protocol more utility will open up but here are some ways in which you can do more with your $ONE. Stake your tokens in an official wallet and benefit from a much higher rate of turn than that offered by your bank Delegate your stake to one of our recognised staking partners such as Everstake or Honest Mining As collateral to run a node and earn validator rewards Earn rewards by completing tasks for the community through Social Mining To power decentralised market-making services using Hummingbot Go deeper... there's so much more you can do. We look forward to you being able to pay for your groceries through the likes of Crypto.com's debit card, or take advantage of decentralised financial services like MakerDAO. Those will come in time.","title":"You got some tokens... now what? "},{"location":"learn/company/adoption-partners-and-clients/","text":"Partners & Clients {% embed url=\"https://cointelegraph.com/news/animoca-and-harmony-acquire-quidd-to-expand-sale-of-crypto-collectibles\" %} {% embed url=\"https://medium.com/harmony-one/harmony-partners-with-gaming-industry-leader-animoca-e29f4624c055?source=---------17-----------------------\" %} {% embed url=\"https://medium.com/harmony-one/harmony-partners-with-everstake-to-expand-staking-as-a-service-to-institutional-investors-cd3e9ddb86c2?source=---------1-----------------------\" %} {% embed url=\"https://medium.com/harmony-one/harmony-partners-with-photoblock-to-simplify-login-for-dapps-f4126f30e7f6?source=---------0-----------------------\" %} {% embed url=\"https://medium.com/harmony-one/one-maker-initiative-stronger-one-by-every-one-429ab7bfcacd?source=---------7-----------------------\" %} {% embed url=\"https://medium.com/harmony-one/harmony-and-matic-team-up-to-set-new-industry-standards-in-blockchain-scalability-and-dapp-b2e60a4aff68\" %} {% embed url=\"https://medium.com/harmony-one/harmony-partnership-series-harmony-x-hyperion-d5338a054c8e?source=---------14-----------------------\" %} {% embed url=\"https://medium.com/harmony-one/partnership-series-harmony-x-hydro-protocol-1d07c26d72b0?source=---------6-----------------------\" %} {% embed url=\"https://medium.com/harmony-one/partnership-series-harmony-x-swyft-network-9cc678b84a74?source=---------5-----------------------\" %} {% embed url=\"https://medium.com/harmony-one/buidling-the-next-stage-of-harmony-stably-partnership-a72448404c28?source=---------4-----------------------\" %} {% embed url=\"https://medium.com/harmony-one/harmony-and-ankr-partnering-to-grow-dapps-on-distributed-cloud-9f9ffc063043?source=---------11-----------------------\" %} {% embed url=\"https://medium.com/harmony-one/harmony-to-partner-with-chainlink-for-off-chain-connectivity-fc0372819aca?source=---------10-----------------------\" %} {% embed url=\"https://medium.com/harmony-one/harmony-partnership-series-harmony-x-contentos-6bb85cffe756?source=---------9-----------------------\" %} {% embed url=\"https://medium.com/harmony-one/harmony-and-taxa-collaborate-towards-the-holistic-development-of-blockchain-infrastructure-b0131eadb8da?source=---------2-----------------------\" %}","title":"Partners & Clients"},{"location":"learn/company/adoption-partners-and-clients/#partners-clients","text":"{% embed url=\"https://cointelegraph.com/news/animoca-and-harmony-acquire-quidd-to-expand-sale-of-crypto-collectibles\" %} {% embed url=\"https://medium.com/harmony-one/harmony-partners-with-gaming-industry-leader-animoca-e29f4624c055?source=---------17-----------------------\" %} {% embed url=\"https://medium.com/harmony-one/harmony-partners-with-everstake-to-expand-staking-as-a-service-to-institutional-investors-cd3e9ddb86c2?source=---------1-----------------------\" %} {% embed url=\"https://medium.com/harmony-one/harmony-partners-with-photoblock-to-simplify-login-for-dapps-f4126f30e7f6?source=---------0-----------------------\" %} {% embed url=\"https://medium.com/harmony-one/one-maker-initiative-stronger-one-by-every-one-429ab7bfcacd?source=---------7-----------------------\" %} {% embed url=\"https://medium.com/harmony-one/harmony-and-matic-team-up-to-set-new-industry-standards-in-blockchain-scalability-and-dapp-b2e60a4aff68\" %} {% embed url=\"https://medium.com/harmony-one/harmony-partnership-series-harmony-x-hyperion-d5338a054c8e?source=---------14-----------------------\" %} {% embed url=\"https://medium.com/harmony-one/partnership-series-harmony-x-hydro-protocol-1d07c26d72b0?source=---------6-----------------------\" %} {% embed url=\"https://medium.com/harmony-one/partnership-series-harmony-x-swyft-network-9cc678b84a74?source=---------5-----------------------\" %} {% embed url=\"https://medium.com/harmony-one/buidling-the-next-stage-of-harmony-stably-partnership-a72448404c28?source=---------4-----------------------\" %} {% embed url=\"https://medium.com/harmony-one/harmony-and-ankr-partnering-to-grow-dapps-on-distributed-cloud-9f9ffc063043?source=---------11-----------------------\" %} {% embed url=\"https://medium.com/harmony-one/harmony-to-partner-with-chainlink-for-off-chain-connectivity-fc0372819aca?source=---------10-----------------------\" %} {% embed url=\"https://medium.com/harmony-one/harmony-partnership-series-harmony-x-contentos-6bb85cffe756?source=---------9-----------------------\" %} {% embed url=\"https://medium.com/harmony-one/harmony-and-taxa-collaborate-towards-the-holistic-development-of-blockchain-infrastructure-b0131eadb8da?source=---------2-----------------------\" %}","title":"Partners &amp; Clients"},{"location":"learn/company/company-team-and-advisors/","text":"Team & Advisors Harmony\u2019s core team Stephen Tse: Google engineer, startup founder (acquired by Apple), UPenn CS Phd ( telegram ) Rongjian Lan: Google Search engineer, Maryland PhD candidate ( linkedin ) Minh Doan: Google Voice AI engineer, Olympiad champion, UC PhD candidate ( linkedin ) Nick White: Zeroth AI specialist, Stanford EE BS & MSc ( telegram ) Sahil Dewan: Edtech startup founder, Draper Dragon, Harvard MBA, CS BS ( telegram ) Eugene Kim: Amazon/Blizzard/NTT network engineer, CS BS ( linkedin ) Leo Chen: Amazon AWS & Kindle engineer & manager of 8, CS BS & MSc ( linkedin ) Chao Ma: Amazon NLP & fraud engineer, Math PhD ( linkedin ) John Whitton: SAP Engineer, Tooling and Protocols, University of Queensland BS CS ( linkedin ) Andy Wu: DevOps Engineer, Simon Fraser, MBA M.A.Sc (linkedin) Edgar Aroutiounian : Software Engineer, Columbia MA ( linkedin ) Dennis Won: Facebook, Microsoft, Software Engineer, Stanford CS ( linkedin ) Ganesha Upadhyaya : Software Engineer SAP, Amazon Iowa State CS PhD ( linkedin ) Li Jiang: logistics startup founder, Global Tech/Education Summit organizer, GSV Capital ( telegram ) Mary Dansker: blockchain agency founder, Draper University mentor, business innovation MSc ( telegram ) Garlam Won: ICONIZ global partnership, Deloitte consultant, featured in Forbes ( telegram ) Robin Schmidt: Award-winning filmmaker and creative director, Oxford BA ( linkedin ) Nikos Kostopoulos: Business and community management, Athens University MSc ( linkedin ) See the full team profiles , our Ex-Googler community and founding story . Select collaborators Hakwan Lau (professor of neuroscience and machine learning at UCLA) \u2014 working with Harmony on healthcare blockchain use cases and human episodic memory. Link Ka-yuet Liu (professor of medical data and network analysis at UCLA) \u2014 working with Prof. Lau on data marketplace models in science. Link Zi Wang (9 years at Google, founder of Google X lab on retail) \u2014 partnering with Harmony on developing the early use cases and product strategy. Bruce Huang (8 years at Microsoft, director at Alibaba Cloud and CreditEase) \u2014 helping with China developer community engagement and tooling initiatives.","title":"Team & Advisors"},{"location":"learn/company/company-team-and-advisors/#team-advisors","text":"","title":"Team &amp; Advisors"},{"location":"learn/company/company-team-and-advisors/#harmonys-core-team","text":"Stephen Tse: Google engineer, startup founder (acquired by Apple), UPenn CS Phd ( telegram ) Rongjian Lan: Google Search engineer, Maryland PhD candidate ( linkedin ) Minh Doan: Google Voice AI engineer, Olympiad champion, UC PhD candidate ( linkedin ) Nick White: Zeroth AI specialist, Stanford EE BS & MSc ( telegram ) Sahil Dewan: Edtech startup founder, Draper Dragon, Harvard MBA, CS BS ( telegram ) Eugene Kim: Amazon/Blizzard/NTT network engineer, CS BS ( linkedin ) Leo Chen: Amazon AWS & Kindle engineer & manager of 8, CS BS & MSc ( linkedin ) Chao Ma: Amazon NLP & fraud engineer, Math PhD ( linkedin ) John Whitton: SAP Engineer, Tooling and Protocols, University of Queensland BS CS ( linkedin ) Andy Wu: DevOps Engineer, Simon Fraser, MBA M.A.Sc (linkedin) Edgar Aroutiounian : Software Engineer, Columbia MA ( linkedin ) Dennis Won: Facebook, Microsoft, Software Engineer, Stanford CS ( linkedin ) Ganesha Upadhyaya : Software Engineer SAP, Amazon Iowa State CS PhD ( linkedin ) Li Jiang: logistics startup founder, Global Tech/Education Summit organizer, GSV Capital ( telegram ) Mary Dansker: blockchain agency founder, Draper University mentor, business innovation MSc ( telegram ) Garlam Won: ICONIZ global partnership, Deloitte consultant, featured in Forbes ( telegram ) Robin Schmidt: Award-winning filmmaker and creative director, Oxford BA ( linkedin ) Nikos Kostopoulos: Business and community management, Athens University MSc ( linkedin ) See the full team profiles , our Ex-Googler community and founding story .","title":"Harmony\u2019s core team "},{"location":"learn/company/company-team-and-advisors/#select-collaborators","text":"Hakwan Lau (professor of neuroscience and machine learning at UCLA) \u2014 working with Harmony on healthcare blockchain use cases and human episodic memory. Link Ka-yuet Liu (professor of medical data and network analysis at UCLA) \u2014 working with Prof. Lau on data marketplace models in science. Link Zi Wang (9 years at Google, founder of Google X lab on retail) \u2014 partnering with Harmony on developing the early use cases and product strategy. Bruce Huang (8 years at Microsoft, director at Alibaba Cloud and CreditEase) \u2014 helping with China developer community engagement and tooling initiatives.","title":"Select collaborators "},{"location":"learn/company/faqs/","text":"FAQ's What is Harmony? Harmony is a fast and secure blockchain built by a 20-person team in Silicon Valley with 7 engineers from Google/Apple/Amazon and 2 PhDs. Our public network is operational and fully open source. Our key innovations have been realised in state sharding (secure staking & resharding with decentralized randomness) and in peer-to-peer networking (optimal cross-shard routing, fast block propagation). Our mission is to harness the power of technology to expand human potential without sacrificing the fundamental rights of those we are building it for. We believe the biggest tech companies in twenty years will be the ones that recognised how rapidly our very humanity was being eroded and did everything they could to respect and preserve it. To empower the way we live, love, gather, play and learn. Harmony is the Blockchain for Humans. Why is the project called \u201cHarmony\u201d? Harmony is the beautiful music when we sing in different notes but resonate. It\u2019s analogous to our high-performance protocol of multiple shards but reaching consensus. Why is the token called \u201cONE\u201d? One describes the individual, the single human at the core of everything we aim to do as a technology company. It describes the kind of world we are trying to create. And it describes a state of being where we are in balance. It's the core element of our most important value 'Be the one...' Stand up and be counted, be the one, take responsibility, take ownership and take a risk. What's behind the logo design? Harmony\u2019s community is built on \u201cHandshake & Embrace.\u201d All Is Fair in Love and War. (Euphues [Euphuism]: The Anatomy of Wit, 1579). Well, also, in vino veritas ! Read the \u201c Xoogler Interview\u201d on our founding story. What is the real world value of Harmony? Harmony helps businesses build marketplaces of fungible tokens (energy credits, security offerings) and non-fungible assets (game collectibles, real estate). We\u2019re applying zero-knowledge proofs for data sharing (ad exchanges, credit ratings) while preserving the consumer\u2019s privacy. What is the long-term vision for Harmony? Today, only hundreds of thousands of people are participating in the decentralized marketplaces. We want to help millions participate in a radically fair economy. We believe that a scalable architecture and design of a public blockchain is crucial for mainstream adoption and high value use cases. Through a combination of research-proven innovations in transport networks, consensus protocol, and system tooling, we think Harmony\u2019s scalable blockchain protocol can eventually support markets for billions of users. What percentage of your team/company tokens have you sold? We sold 22.4% of the 12.6 Billion token supply in our seed round.","title":"FAQ's"},{"location":"learn/company/faqs/#faqs","text":"","title":"FAQ's"},{"location":"learn/company/faqs/#what-is-harmony","text":"Harmony is a fast and secure blockchain built by a 20-person team in Silicon Valley with 7 engineers from Google/Apple/Amazon and 2 PhDs. Our public network is operational and fully open source. Our key innovations have been realised in state sharding (secure staking & resharding with decentralized randomness) and in peer-to-peer networking (optimal cross-shard routing, fast block propagation). Our mission is to harness the power of technology to expand human potential without sacrificing the fundamental rights of those we are building it for. We believe the biggest tech companies in twenty years will be the ones that recognised how rapidly our very humanity was being eroded and did everything they could to respect and preserve it. To empower the way we live, love, gather, play and learn. Harmony is the Blockchain for Humans.","title":"What is Harmony? "},{"location":"learn/company/faqs/#why-is-the-project-called-harmony","text":"Harmony is the beautiful music when we sing in different notes but resonate. It\u2019s analogous to our high-performance protocol of multiple shards but reaching consensus.","title":"Why is the project called \u201cHarmony\u201d? "},{"location":"learn/company/faqs/#why-is-the-token-called-one","text":"One describes the individual, the single human at the core of everything we aim to do as a technology company. It describes the kind of world we are trying to create. And it describes a state of being where we are in balance. It's the core element of our most important value 'Be the one...' Stand up and be counted, be the one, take responsibility, take ownership and take a risk.","title":"Why is the token called \u201cONE\u201d? "},{"location":"learn/company/faqs/#whats-behind-the-logo-design","text":"Harmony\u2019s community is built on \u201cHandshake & Embrace.\u201d All Is Fair in Love and War. (Euphues [Euphuism]: The Anatomy of Wit, 1579). Well, also, in vino veritas ! Read the \u201c Xoogler Interview\u201d on our founding story.","title":"What's behind the logo design? "},{"location":"learn/company/faqs/#what-is-the-real-world-value-of-harmony","text":"Harmony helps businesses build marketplaces of fungible tokens (energy credits, security offerings) and non-fungible assets (game collectibles, real estate). We\u2019re applying zero-knowledge proofs for data sharing (ad exchanges, credit ratings) while preserving the consumer\u2019s privacy.","title":"What is the real world value of Harmony? "},{"location":"learn/company/faqs/#what-is-the-long-term-vision-for-harmony","text":"Today, only hundreds of thousands of people are participating in the decentralized marketplaces. We want to help millions participate in a radically fair economy. We believe that a scalable architecture and design of a public blockchain is crucial for mainstream adoption and high value use cases. Through a combination of research-proven innovations in transport networks, consensus protocol, and system tooling, we think Harmony\u2019s scalable blockchain protocol can eventually support markets for billions of users.","title":"What is the long-term vision for Harmony? "},{"location":"learn/company/faqs/#what-percentage-of-your-teamcompany-tokens-have-you-sold","text":"We sold 22.4% of the 12.6 Billion token supply in our seed round.","title":"What percentage of your team/company tokens have you sold? "},{"location":"learn/company/milestones/","text":"Milestones COMING SOON....","title":"Milestones"},{"location":"learn/company/milestones/#milestones","text":"COMING SOON....","title":"Milestones"},{"location":"learn/company/why-build-harmony/","text":"Why build Harmony? The following is an edited transcript of a fireside chat with Harmony founder, Stephen Tse, led by Zi Wang on August 8, 2018. Zi Wang was a Creative Director at Android and founded a research lab at Google with a $20M budget. In February 2017, Zi, Chris Fong and Stephen Tse started TGI-ML, a weekly gathering of ex-Google entrepreneurs, that quickly turned into TGI-Blockchain . Below is the edited transcript of their firechat on Aug 8 with the Xoogler.co community on the founding story and vision of Harmony . Introduction Zi: Let\u2019s start with your story, your journey. Why are you building a public blockchain with the aspiration of impacting billions of people? Stephen: After Google, Apple, and my first startup exit, looking for the next journey is not any easier! I\u2019m really grateful to find this group of ex-Google founders to support each other along the way. So many false starts, wrong turns, walking about into the deep, playing the young man\u2019s game of obsession, paralysis by over-learning, failure being the only option \u2026 it\u2019s been you (and many beers and ramen together) that keep me going. I\u2019ll remember the unreasonably high trust and the bone-shaking generosity you all bestowed along the way. Pitching to many of you, I\u2019ve learnt a lot on selling yourself and asking for help . But the key is product-market fit \u2014 What is the biggest market opportunity now? Which product can capture the most value in the market right away? To me, the answer is platform infrastructure for the decentralized economy . Internet technologies impacted millions of people and mobile technologies impacted hundreds of millions of people; now, we have a technology that can have a direct impact on 10 billion people in the future. Z: Can you talk a bit about what are the major engineering efforts at layer 0 \u2014 trusted execution environment, PoW/PoS consensus, scaling via sharding? S: It\u2019s all about scalability . Decentralization is already proven to be worth hundreds of billions. Very much like Dropbox, Slack, Google Docs when arguing Internet vs Intranet , permissionless protocols will win over permissioned or consortium chains very soon. For security, we don\u2019t want to go back to trusting hardware from a few vendors. Secure enclaves cannot be verified independently . To protect against Sybil attacks , it\u2019s very important to find alternatives to Proof of Work but there are no proven techniques that are well studied or deployed to large scale yet. Sharding is the proven way to scale when communication gets expensive. Sharding is commonly used for large-scale memory database and distributed systems. Z: Are we in a bubble? S: Not if you look far enough. Many crypto projects without products will pop, but decentralization and scaling by technology will stay for the next few decades. Eight trillion dollars of gold and hundreds of trillion dollars of financial instruments will be replaced before we see the boundary of a bubble. Harmony & Protocol Z: What is Harmony? S: Harmony is an open infrastructure for 10B people in the future. Harmony builds a high-performance consensus protocol . We provide a Google-scale marketplace and decentralized economy for everyone. Z: You recently announced a benchmark of 10,184 transactions per second with 10,000 nodes and 25 shards\u2026 can you put this into context of what it means? S: Other than Bitcoin and Ethereum, most protocols have tested with very few nodes. Scaling to tens or hundreds of nodes is easy to build but is not decentralized enough . We have the ambition to scale to hundreds of thousands of nodes for everyone to participate equally on our platform. Z: There are a lot of protocol projects out there \u2014 Ethereum, EOS, NEO, Dfinity \u2014 and there are new ones popping up every day, what differentiates Harmony? S: Others only focus on throughput performance in terms of transactions per seconds. Harmony sets the standard to benchmark both TPS and the number of nodes . Very few teams have the combined expertise in academic research, engineering large-scale systems , and building a long-term company. Very few people take the integrated, end-to-end approach like Google. It\u2019s not just about the PageRank algorithm. Google optimizes their own kernels and tailor-makes their compilers. Harmony is also taking the full stack approach of applying 10x innovations in networking , systems , and algorithms . Z: Can you talk more about OmniLedger? S: OmniLedger is the most promising scaling architecture I found after months of research. The lead author Bryan Ford __is a top researcher in the fields of decentralized systems and scalability. Actually, he and I published in the same conference when he was still a Master\u2019s student at MIT! Harmony builds on top of OmniLedger because it is a proven research result that we want to bring to production scale. The research covers many important implementation details such as O(log n) for block distribution with multicast trees , and signed back-pointers for 100x smaller checkpoints. Z: What is a conceptual model to think about the decentralized world? What is the \u201cbusiness model\u201d of the decentralized world? (speculation, metered electricity \u2014 charging per transaction, or based on net positive value you deliver?) S: This is an open question for blockchain companies. Given our approach of open source, open research, and open platform, how do we make money? Transaction fees are for miners, not for the platform foundation. We see ourselves as platform developers and foundation directors . Once our community is formed, it\u2019s of utmost importance to hand off the development to open governance. The team holds Harmony tokens and we benefit from a continued success of the platform. We may manage an ecosystem fund and nurture long-term research ****as a business. Z: Other than Harmony, what other protocols do you value highly? S: Zillqa has a strong academic background and an active open source community. Its smart contract language Scilla __is written in OCaml, which I coded in for more than 15 years. Z: You guys raised $18M earlier this year. Why do you think there\u2019s so much capital coming into the space? What are the key insights you learned in the process? S: The answer is scale. This space has 1000x bigger potential and more global audience. Once you\u2019ve found your product-market fit, the market moves with you! Instead of 2 or 3 investor meetings per day, I had 20 asynchronous pitches on WeChat and Telegram. I was very glad that I went on the China tour you organized earlier this year. The speed of innovation , market opportunities , and _entrepreneurial spirit_there deeply impressed me. The power of decentralization finally hit me during the final week of our fundraising. Everyday, millions of dollars were transferred to Harmony in a few minutes after signing a contract! Learn, Team & Culture Z: What kind of people are suited to a career in blockchain? What kind of skill do they need to prepare themselves with? S: We are still very early in decentralizing everything . So this opportunity is prime for pioneers and innovators. Go deep into the latest research from the top conferences, go broad on innovations from emerging markets like China and India. But most of all, find your core group of dreamers to kindle the fire. There\u2019s too much noise online or even in meetups. You need fellow founders to dare to disagree with you every week, every day! Z: What languages should I learn if I want to be a blockchain engineer? S: My language min-lang.com ! You will learn a lot of beautiful syntax and minimal abstraction there for the charm and delight of programming. OCaml is the best if you want to learn about building a compiler for smart contracts. Coq is the state of art for formal verification and security. We use Go and Rust for Harmony. Go is great for distributed systems, while Rust is optimal for parallel processing with safe memory management . Z: How much cryptography is it necessary to learn? S: If you know math or computer science, you can pick up most concepts to apply along the way. It is far more fun and lasting to go deep into topics you\u2019re most interested in. Z: Can you recommend any resources for learning the fundamental technical concepts of blockchain? S: Definitely \u2014 Bitcoin and Cryptocurrency Technologies __by Narayanan at Princeton and others. I have cited many resources and top conferences in Harmony\u2019s technical whitepaper . For business and product, the Token Economy newsletter is a must read. Z: How about Harmony\u2019s hiring/team culture? What types of folks are you looking for to join the team? S: They must be Hungry and Foolish ! We are spending lots of effort on hiring the best people. Our candidates self-score on our 3x3 cultural interview questions and spend two days working onsite before they\u2019re hired. Everyone wants to work with the A players in his field. We have a high bar of excellence ; our team are from Google, Apple, Stanford, Harvard, CMU\u2026 But we\u2019ve found empathy and passion even more critical. For example, we value conversation turn taking , being optimistic about flying off a cliff , and people over process . Z: What is your view of where we are in 5 years? How much of what we experience everyday will be decentralized? S: Billions of dollars for funding startups are already transferring in Ethereum. I expect many more financial services and digital assets will be decentralized. In particular, AI data marketplaces are going to be a big direction for decentralized technology. These open marketplaces will democratize machine learning . Bitcoin is mostly for one-to-one transfers and store of value; Ethereum tokenizes your assets on contracts, so the transactions are one-to-many . Harmony is going to be a marketplace for many-to-many transactions. Imagine for your health data . There\u2019s very little value in the sleep or diet data of one person; there\u2019s also very little impact in exercise or meditation advice from one health expert. But there is huge value with many millions of users and thousands of experts \u2014 that\u2019ll be the impact of an open platform! Z: How do I connect with you or team? S: My team in the crowd can stand up! We\u2019re hiring \u2014 we have a few first edition of Harmony t-shirts for those who are ready to join the team!","title":"Why build Harmony?"},{"location":"learn/company/why-build-harmony/#why-build-harmony","text":"The following is an edited transcript of a fireside chat with Harmony founder, Stephen Tse, led by Zi Wang on August 8, 2018. Zi Wang was a Creative Director at Android and founded a research lab at Google with a $20M budget. In February 2017, Zi, Chris Fong and Stephen Tse started TGI-ML, a weekly gathering of ex-Google entrepreneurs, that quickly turned into TGI-Blockchain . Below is the edited transcript of their firechat on Aug 8 with the Xoogler.co community on the founding story and vision of Harmony .","title":"Why build Harmony?"},{"location":"learn/company/why-build-harmony/#introduction","text":"Zi: Let\u2019s start with your story, your journey. Why are you building a public blockchain with the aspiration of impacting billions of people? Stephen: After Google, Apple, and my first startup exit, looking for the next journey is not any easier! I\u2019m really grateful to find this group of ex-Google founders to support each other along the way. So many false starts, wrong turns, walking about into the deep, playing the young man\u2019s game of obsession, paralysis by over-learning, failure being the only option \u2026 it\u2019s been you (and many beers and ramen together) that keep me going. I\u2019ll remember the unreasonably high trust and the bone-shaking generosity you all bestowed along the way. Pitching to many of you, I\u2019ve learnt a lot on selling yourself and asking for help . But the key is product-market fit \u2014 What is the biggest market opportunity now? Which product can capture the most value in the market right away? To me, the answer is platform infrastructure for the decentralized economy . Internet technologies impacted millions of people and mobile technologies impacted hundreds of millions of people; now, we have a technology that can have a direct impact on 10 billion people in the future. Z: Can you talk a bit about what are the major engineering efforts at layer 0 \u2014 trusted execution environment, PoW/PoS consensus, scaling via sharding? S: It\u2019s all about scalability . Decentralization is already proven to be worth hundreds of billions. Very much like Dropbox, Slack, Google Docs when arguing Internet vs Intranet , permissionless protocols will win over permissioned or consortium chains very soon. For security, we don\u2019t want to go back to trusting hardware from a few vendors. Secure enclaves cannot be verified independently . To protect against Sybil attacks , it\u2019s very important to find alternatives to Proof of Work but there are no proven techniques that are well studied or deployed to large scale yet. Sharding is the proven way to scale when communication gets expensive. Sharding is commonly used for large-scale memory database and distributed systems. Z: Are we in a bubble? S: Not if you look far enough. Many crypto projects without products will pop, but decentralization and scaling by technology will stay for the next few decades. Eight trillion dollars of gold and hundreds of trillion dollars of financial instruments will be replaced before we see the boundary of a bubble.","title":"Introduction "},{"location":"learn/company/why-build-harmony/#harmony-protocol","text":"Z: What is Harmony? S: Harmony is an open infrastructure for 10B people in the future. Harmony builds a high-performance consensus protocol . We provide a Google-scale marketplace and decentralized economy for everyone. Z: You recently announced a benchmark of 10,184 transactions per second with 10,000 nodes and 25 shards\u2026 can you put this into context of what it means? S: Other than Bitcoin and Ethereum, most protocols have tested with very few nodes. Scaling to tens or hundreds of nodes is easy to build but is not decentralized enough . We have the ambition to scale to hundreds of thousands of nodes for everyone to participate equally on our platform. Z: There are a lot of protocol projects out there \u2014 Ethereum, EOS, NEO, Dfinity \u2014 and there are new ones popping up every day, what differentiates Harmony? S: Others only focus on throughput performance in terms of transactions per seconds. Harmony sets the standard to benchmark both TPS and the number of nodes . Very few teams have the combined expertise in academic research, engineering large-scale systems , and building a long-term company. Very few people take the integrated, end-to-end approach like Google. It\u2019s not just about the PageRank algorithm. Google optimizes their own kernels and tailor-makes their compilers. Harmony is also taking the full stack approach of applying 10x innovations in networking , systems , and algorithms . Z: Can you talk more about OmniLedger? S: OmniLedger is the most promising scaling architecture I found after months of research. The lead author Bryan Ford __is a top researcher in the fields of decentralized systems and scalability. Actually, he and I published in the same conference when he was still a Master\u2019s student at MIT! Harmony builds on top of OmniLedger because it is a proven research result that we want to bring to production scale. The research covers many important implementation details such as O(log n) for block distribution with multicast trees , and signed back-pointers for 100x smaller checkpoints. Z: What is a conceptual model to think about the decentralized world? What is the \u201cbusiness model\u201d of the decentralized world? (speculation, metered electricity \u2014 charging per transaction, or based on net positive value you deliver?) S: This is an open question for blockchain companies. Given our approach of open source, open research, and open platform, how do we make money? Transaction fees are for miners, not for the platform foundation. We see ourselves as platform developers and foundation directors . Once our community is formed, it\u2019s of utmost importance to hand off the development to open governance. The team holds Harmony tokens and we benefit from a continued success of the platform. We may manage an ecosystem fund and nurture long-term research ****as a business. Z: Other than Harmony, what other protocols do you value highly? S: Zillqa has a strong academic background and an active open source community. Its smart contract language Scilla __is written in OCaml, which I coded in for more than 15 years. Z: You guys raised $18M earlier this year. Why do you think there\u2019s so much capital coming into the space? What are the key insights you learned in the process? S: The answer is scale. This space has 1000x bigger potential and more global audience. Once you\u2019ve found your product-market fit, the market moves with you! Instead of 2 or 3 investor meetings per day, I had 20 asynchronous pitches on WeChat and Telegram. I was very glad that I went on the China tour you organized earlier this year. The speed of innovation , market opportunities , and _entrepreneurial spirit_there deeply impressed me. The power of decentralization finally hit me during the final week of our fundraising. Everyday, millions of dollars were transferred to Harmony in a few minutes after signing a contract!","title":"Harmony &amp; Protocol "},{"location":"learn/company/why-build-harmony/#learn-team-culture","text":"Z: What kind of people are suited to a career in blockchain? What kind of skill do they need to prepare themselves with? S: We are still very early in decentralizing everything . So this opportunity is prime for pioneers and innovators. Go deep into the latest research from the top conferences, go broad on innovations from emerging markets like China and India. But most of all, find your core group of dreamers to kindle the fire. There\u2019s too much noise online or even in meetups. You need fellow founders to dare to disagree with you every week, every day! Z: What languages should I learn if I want to be a blockchain engineer? S: My language min-lang.com ! You will learn a lot of beautiful syntax and minimal abstraction there for the charm and delight of programming. OCaml is the best if you want to learn about building a compiler for smart contracts. Coq is the state of art for formal verification and security. We use Go and Rust for Harmony. Go is great for distributed systems, while Rust is optimal for parallel processing with safe memory management . Z: How much cryptography is it necessary to learn? S: If you know math or computer science, you can pick up most concepts to apply along the way. It is far more fun and lasting to go deep into topics you\u2019re most interested in. Z: Can you recommend any resources for learning the fundamental technical concepts of blockchain? S: Definitely \u2014 Bitcoin and Cryptocurrency Technologies __by Narayanan at Princeton and others. I have cited many resources and top conferences in Harmony\u2019s technical whitepaper . For business and product, the Token Economy newsletter is a must read. Z: How about Harmony\u2019s hiring/team culture? What types of folks are you looking for to join the team? S: They must be Hungry and Foolish ! We are spending lots of effort on hiring the best people. Our candidates self-score on our 3x3 cultural interview questions and spend two days working onsite before they\u2019re hired. Everyone wants to work with the A players in his field. We have a high bar of excellence ; our team are from Google, Apple, Stanford, Harvard, CMU\u2026 But we\u2019ve found empathy and passion even more critical. For example, we value conversation turn taking , being optimistic about flying off a cliff , and people over process . Z: What is your view of where we are in 5 years? How much of what we experience everyday will be decentralized? S: Billions of dollars for funding startups are already transferring in Ethereum. I expect many more financial services and digital assets will be decentralized. In particular, AI data marketplaces are going to be a big direction for decentralized technology. These open marketplaces will democratize machine learning . Bitcoin is mostly for one-to-one transfers and store of value; Ethereum tokenizes your assets on contracts, so the transactions are one-to-many . Harmony is going to be a marketplace for many-to-many transactions. Imagine for your health data . There\u2019s very little value in the sleep or diet data of one person; there\u2019s also very little impact in exercise or meditation advice from one health expert. But there is huge value with many millions of users and thousands of experts \u2014 that\u2019ll be the impact of an open platform! Z: How do I connect with you or team? S: My team in the crowd can stand up! We\u2019re hiring \u2014 we have a few first edition of Harmony t-shirts for those who are ready to join the team!","title":"Learn, Team &amp; Culture "},{"location":"learn/developer-area/untitled/","text":"Untitled","title":"Untitled"},{"location":"learn/developer-area/untitled/#untitled","text":"","title":"Untitled"},{"location":"learn/interns-guide-to-blockchain/","text":"Intern's guide to blockchain Over the Summer of 2019 one of our interns, Larissa Bitterli wrote a beautifully considered Intern's guide to blockchain. It's in two parts and it's just a lovely account of working at Harmony and understanding what this strange world of ours is really like. {% page-ref page=\"part-1.md\" %} {% page-ref page=\"part-2.md\" %}","title":"Intern's guide to blockchain"},{"location":"learn/interns-guide-to-blockchain/#interns-guide-to-blockchain","text":"Over the Summer of 2019 one of our interns, Larissa Bitterli wrote a beautifully considered Intern's guide to blockchain. It's in two parts and it's just a lovely account of working at Harmony and understanding what this strange world of ours is really like. {% page-ref page=\"part-1.md\" %} {% page-ref page=\"part-2.md\" %}","title":"Intern's guide to blockchain"},{"location":"learn/interns-guide-to-blockchain/part-1/","text":"Part 1 At the start of the summer I assumed I would be a camp counselor at a STEM summer camp, sharing my passion for science with kids, coming up with games to keep them entertained, and getting blasted by water guns. Never would I have guessed I would find myself spending my summer interning at a blockchain startup.\u200c During the first week of work at Harmony I was introduced to the world of cryptocurrency and with it, a torrent of blockchain concepts. I had difficulty figuring out how concepts connected to others and even struggled to understand which were abstract or applied models; I remember being unable to wrap my head around how the abstract model, State Machine Replication (SMR), relates to the applied rules of blockchain. This would have been similar to learning about bonds between protons and electrons before learning the basic two-dimensional model of an atom and then, struggling to connect the two.\u200c In my second week of work, I had the opportunity to attend a team research talk on Facebook\u2019s own take on both cryptocurrency and blockchain \u2014 Libra. I was so intrigued with everything I was able to grasp out of that talk and so determined to understand the blockchain concepts in that presentation that I found myself asking questions, surprising both myself and the engineers at the talk with how interested I was in the material.\u200c I continued engaging my teammate who presented on Libra after the talk was over. I learned the differences between our project\u2019s protocols and others, and another one of our engineers walked me through Harmony\u2019s protocol in detail.\u200c From those talks onward, I ended up spending late nights at work sifting through whitepapers, and discussing blockchain concepts with my coworkers to gain an understanding of what blockchain is and how it works.\u200c In this post I am presenting my understanding of blockchain in a way that would have made sense to me during my first day interning at Harmony. As a biochemistry undergraduate I have a very basic background in computer science; I know that searching up cryptography related terms and general blockchain concepts can be confusing \u2014 and not everyone has a room full of doctorate brains to pick. I am writing this guide as an introduction to blockchain for those interested in learning more.\u200c Let\u2019s start off with bitcoin. Bitcoin is a coin with real market value. You can trade it and buy it as currency. Bitcoin increases in value as new blocks are mined and added to an existing blockchain. However, bitcoin is just one application of blockchain \u2014 there are numerous use cases ranging from securing new apps to patenting ideas with timestamps. Blockchain is only limited to what we can imagine it to be. So What is Blockchain? Say I want to drive from my house to yours, and I take a road to get to your house. This road is viewed by everyone as a secure method of travel and everyone, you and me included, holds a map of that road. Maybe we are all using Google Maps or Apple Maps or Waze but the point is, everyone\u2019s map is identical. With this identical map anyone can view how to drive from my house to yours \u2014 if they know our addresses.\u200c Blockchain is that road and houses are nodes . Secure transactions can be sent from one node to another within the blockchain as the blockchain is a trusted network to do so.\u200c The map that is shared by all users is the entire history of transactions in the blockchain \u2014 known as a distributed ledger that all nodes share. This map or ledger is copied across the blockchain network so that each node will have its own copy. There is no single node with a master map sending out copies to each new node. Instead the network is decentralized \u2014 nodes replicate the ledger and save identical copies, updating their own copy independently as the network grows.\u200c Why is Blockchain Useful? The answer to why blockchain can be adopted by numerous platforms lies in decentralization \u2014 in a public blockchain no one authority has control over validation of user transactions, how the network grows, or who earns rewards.\u200c In the current banking system, a third party is used when money is sent from one account to another, but in blockchain there is no third party. This means anyone can use blockchain in international transactions to speed up their validation processes. In addition, transactions are permanently time stamped and logged into blocks within the network; open source projects can be patented through these timestamps to give creators acknowledgement when their work is used later on. With such a variety of use cases, blockchain is a powerful tool for those who can apply it.\u200c \u200b Next : how blockchain eliminates the use of a third party through cryptography and will begin introducing and explaining the terminology needed to understand how a blockchain functions and how users can earn rewards.","title":"Part 1"},{"location":"learn/interns-guide-to-blockchain/part-1/#part-1","text":"At the start of the summer I assumed I would be a camp counselor at a STEM summer camp, sharing my passion for science with kids, coming up with games to keep them entertained, and getting blasted by water guns. Never would I have guessed I would find myself spending my summer interning at a blockchain startup.\u200c During the first week of work at Harmony I was introduced to the world of cryptocurrency and with it, a torrent of blockchain concepts. I had difficulty figuring out how concepts connected to others and even struggled to understand which were abstract or applied models; I remember being unable to wrap my head around how the abstract model, State Machine Replication (SMR), relates to the applied rules of blockchain. This would have been similar to learning about bonds between protons and electrons before learning the basic two-dimensional model of an atom and then, struggling to connect the two.\u200c In my second week of work, I had the opportunity to attend a team research talk on Facebook\u2019s own take on both cryptocurrency and blockchain \u2014 Libra. I was so intrigued with everything I was able to grasp out of that talk and so determined to understand the blockchain concepts in that presentation that I found myself asking questions, surprising both myself and the engineers at the talk with how interested I was in the material.\u200c I continued engaging my teammate who presented on Libra after the talk was over. I learned the differences between our project\u2019s protocols and others, and another one of our engineers walked me through Harmony\u2019s protocol in detail.\u200c From those talks onward, I ended up spending late nights at work sifting through whitepapers, and discussing blockchain concepts with my coworkers to gain an understanding of what blockchain is and how it works.\u200c In this post I am presenting my understanding of blockchain in a way that would have made sense to me during my first day interning at Harmony. As a biochemistry undergraduate I have a very basic background in computer science; I know that searching up cryptography related terms and general blockchain concepts can be confusing \u2014 and not everyone has a room full of doctorate brains to pick. I am writing this guide as an introduction to blockchain for those interested in learning more.\u200c Let\u2019s start off with bitcoin. Bitcoin is a coin with real market value. You can trade it and buy it as currency. Bitcoin increases in value as new blocks are mined and added to an existing blockchain. However, bitcoin is just one application of blockchain \u2014 there are numerous use cases ranging from securing new apps to patenting ideas with timestamps. Blockchain is only limited to what we can imagine it to be.","title":"Part 1"},{"location":"learn/interns-guide-to-blockchain/part-1/#so-what-is-blockchain","text":"Say I want to drive from my house to yours, and I take a road to get to your house. This road is viewed by everyone as a secure method of travel and everyone, you and me included, holds a map of that road. Maybe we are all using Google Maps or Apple Maps or Waze but the point is, everyone\u2019s map is identical. With this identical map anyone can view how to drive from my house to yours \u2014 if they know our addresses.\u200c Blockchain is that road and houses are nodes . Secure transactions can be sent from one node to another within the blockchain as the blockchain is a trusted network to do so.\u200c The map that is shared by all users is the entire history of transactions in the blockchain \u2014 known as a distributed ledger that all nodes share. This map or ledger is copied across the blockchain network so that each node will have its own copy. There is no single node with a master map sending out copies to each new node. Instead the network is decentralized \u2014 nodes replicate the ledger and save identical copies, updating their own copy independently as the network grows.\u200c","title":"So What is Blockchain? "},{"location":"learn/interns-guide-to-blockchain/part-1/#why-is-blockchain-useful","text":"The answer to why blockchain can be adopted by numerous platforms lies in decentralization \u2014 in a public blockchain no one authority has control over validation of user transactions, how the network grows, or who earns rewards.\u200c In the current banking system, a third party is used when money is sent from one account to another, but in blockchain there is no third party. This means anyone can use blockchain in international transactions to speed up their validation processes. In addition, transactions are permanently time stamped and logged into blocks within the network; open source projects can be patented through these timestamps to give creators acknowledgement when their work is used later on. With such a variety of use cases, blockchain is a powerful tool for those who can apply it.\u200c \u200b Next : how blockchain eliminates the use of a third party through cryptography and will begin introducing and explaining the terminology needed to understand how a blockchain functions and how users can earn rewards.","title":"Why is Blockchain Useful? "},{"location":"learn/interns-guide-to-blockchain/part-2/","text":"Part 2 How Cryptography Eliminates The Need For A Third Party Users in a blockchain network hold their coins or tokens in a wallet that contains a public key and a private key. The public key is, well, public to everyone in the blockchain network and the private key is only known to you, the user. The two keys are generated through cryptographic means \u2014 the private key is a very large and very random number, while the public key is generated from the private key through an equation known as a trap-door . This means that it is easy to generate the public key, but tremendously difficult to figure out the private key from the public key. Just as it is easy to fall through a trap door but nearly impossible to go back through it. So the two keys are a pair: if a message is encrypted with a public key only the corresponding private key can unlock or decrypt that message. What are the two keys for? Private keys can be used to sign documents or in the case of blockchain, transactions. Only you know your private key and therefore only you can use your private key to sign a transaction. On the other end, everyone else has access to your public key so they can use it to verify that it was you who signed the transaction due to the two keys being linked. If I send you five bitcoin, my private key is used to encrypt that transaction message, which is then broad-casted to all the other nodes in the blockchain network. The other nodes check the source of my transaction message by decrypting it with my public key. This combination of keys and nodes allows for transactions to be verified without any third party such that the entire process is decentralized . In addition, transactions and blocks are both validated and time stamped throughout the entire blockchain, meaning that transactions cannot be altered or tampered with. How are new blocks added to the blockchain? Let\u2019s use an extended analogy to describe the relationship among nodes during the process of validating a new block to the blockchain. You can read through the story leaving out the technical terms and come back to swap out the common terms with their technical counter parts. You (the user) work as a journalist for an online publication (blockchain) and want to publish an article (new transaction) . You send copies of the final draft of your article to each of the editors (nodes) in your publication. The editors individually review the article and approve or disapprove the article by signing their signatures. If they approve of the article, they sign. If they do not approve, they do not sign. The editors sign with magic ink that automatically updates every copy of the article so that each editor can see all the signatures. Every editor knows who has signed the article and who has not signed. It is company policy that 2/3 of the editors must sign (reach consensus) before the article can be published. You manage to collect 2/3 of the editors signatures in your company before the deadline (transaction time limit) to publish your article has passed. You successfully publish your article (new block) and it is now a part of the online publication (blockchain) . All the editors in your company know that your article has been published, your article is permanently a part of the publication, and your article cannot be erased. What if there are Malicious Writers? Sometimes there will be malicious writers (malicious nodes) or journalists who do not follow the rules of the company (rules of the blockchain code) . Maybe these journalists are accepting bribes to present a certain angle on a story. When a writer like this sends out copies of their article, editors will not sign the article as long as they themselves are not scheming with the malicious writer. Even if there is more than one malicious editor there will not be enough to sign the article. The company policy of having 2/3 editors reach a consensus on an article before publication prevents articles like these from being published. What does this have to do with how users earn rewards? When an editor signs an article they receive a reward if that article gets published. In blockchain terms, when a node sends in its digital signature approving of a transaction, and a new block is validated into existence, the user will earn rewards in the form of coins or tokens. An Ending and a Beginning This concludes my introduction to blockchain from my understanding as an intern. It was incredible to have the opportunity to deep dive into blockchain and its community \u2014 Harmony connects so many brilliant and passionate people that it was an amazing space to be a part of, if even just for a couple months. I know that writing these two posts helped me to organize the influx of information I gained in my past months working at Harmony; connecting the concepts I learned to previous experiences allowed me to retain the information such that I can continue exploring blockchain on my own, even as I go back to school.","title":"Part 2"},{"location":"learn/interns-guide-to-blockchain/part-2/#part-2","text":"","title":"Part 2"},{"location":"learn/interns-guide-to-blockchain/part-2/#how-cryptography-eliminates-the-need-for-a-third-party","text":"Users in a blockchain network hold their coins or tokens in a wallet that contains a public key and a private key. The public key is, well, public to everyone in the blockchain network and the private key is only known to you, the user. The two keys are generated through cryptographic means \u2014 the private key is a very large and very random number, while the public key is generated from the private key through an equation known as a trap-door . This means that it is easy to generate the public key, but tremendously difficult to figure out the private key from the public key. Just as it is easy to fall through a trap door but nearly impossible to go back through it. So the two keys are a pair: if a message is encrypted with a public key only the corresponding private key can unlock or decrypt that message.","title":"How Cryptography Eliminates The Need For A Third Party "},{"location":"learn/interns-guide-to-blockchain/part-2/#what-are-the-two-keys-for","text":"Private keys can be used to sign documents or in the case of blockchain, transactions. Only you know your private key and therefore only you can use your private key to sign a transaction. On the other end, everyone else has access to your public key so they can use it to verify that it was you who signed the transaction due to the two keys being linked. If I send you five bitcoin, my private key is used to encrypt that transaction message, which is then broad-casted to all the other nodes in the blockchain network. The other nodes check the source of my transaction message by decrypting it with my public key. This combination of keys and nodes allows for transactions to be verified without any third party such that the entire process is decentralized . In addition, transactions and blocks are both validated and time stamped throughout the entire blockchain, meaning that transactions cannot be altered or tampered with.","title":"What are the two keys for? "},{"location":"learn/interns-guide-to-blockchain/part-2/#how-are-new-blocks-added-to-the-blockchain","text":"Let\u2019s use an extended analogy to describe the relationship among nodes during the process of validating a new block to the blockchain. You can read through the story leaving out the technical terms and come back to swap out the common terms with their technical counter parts. You (the user) work as a journalist for an online publication (blockchain) and want to publish an article (new transaction) . You send copies of the final draft of your article to each of the editors (nodes) in your publication. The editors individually review the article and approve or disapprove the article by signing their signatures. If they approve of the article, they sign. If they do not approve, they do not sign. The editors sign with magic ink that automatically updates every copy of the article so that each editor can see all the signatures. Every editor knows who has signed the article and who has not signed. It is company policy that 2/3 of the editors must sign (reach consensus) before the article can be published. You manage to collect 2/3 of the editors signatures in your company before the deadline (transaction time limit) to publish your article has passed. You successfully publish your article (new block) and it is now a part of the online publication (blockchain) . All the editors in your company know that your article has been published, your article is permanently a part of the publication, and your article cannot be erased.","title":"How are new blocks added to the blockchain? "},{"location":"learn/interns-guide-to-blockchain/part-2/#what-if-there-are-malicious-writers","text":"Sometimes there will be malicious writers (malicious nodes) or journalists who do not follow the rules of the company (rules of the blockchain code) . Maybe these journalists are accepting bribes to present a certain angle on a story. When a writer like this sends out copies of their article, editors will not sign the article as long as they themselves are not scheming with the malicious writer. Even if there is more than one malicious editor there will not be enough to sign the article. The company policy of having 2/3 editors reach a consensus on an article before publication prevents articles like these from being published.","title":"What if there are Malicious Writers? "},{"location":"learn/interns-guide-to-blockchain/part-2/#what-does-this-have-to-do-with-how-users-earn-rewards","text":"When an editor signs an article they receive a reward if that article gets published. In blockchain terms, when a node sends in its digital signature approving of a transaction, and a new block is validated into existence, the user will earn rewards in the form of coins or tokens.","title":"What does this have to do with how users earn rewards? "},{"location":"learn/interns-guide-to-blockchain/part-2/#an-ending-and-a-beginning","text":"This concludes my introduction to blockchain from my understanding as an intern. It was incredible to have the opportunity to deep dive into blockchain and its community \u2014 Harmony connects so many brilliant and passionate people that it was an amazing space to be a part of, if even just for a couple months. I know that writing these two posts helped me to organize the influx of information I gained in my past months working at Harmony; connecting the concepts I learned to previous experiences allowed me to retain the information such that I can continue exploring blockchain on my own, even as I go back to school.","title":"An Ending and a Beginning "},{"location":"learn/tech-zone/sdk/","text":"SDK Find the full SDK wiki here . Or jump to a section: Developers Local Harmony Blockchain Configuring your local node Updating your codebase to the latest Running a local Node Local Harmony Web Wallet Account information Running the Web Wallet Setting up your accounts Funding your wallet Transferring funds Smart Contract Development Smart contracts development using Truffle Deploying contracts using dApp examples Interacting with Deployed Contracts using dApp examples Troubleshooting Basic troubleshooting Betanet Betanet essentials API Developers Guide Introduction Sample code Sample nodejs CLI Application Account Methods Transaction Related Methods Contract Related Methods Protocol Related Methods Explorer Methods Test Command Line Interface Using the Harmony CLI tool Blockchain Keys Wallet Developers Guide Ledger Nano S Firmware Usage Manual","title":"SDK"},{"location":"learn/tech-zone/sdk/#sdk","text":"Find the full SDK wiki here . Or jump to a section:","title":"SDK"},{"location":"learn/tech-zone/sdk/#developers","text":"","title":"Developers"},{"location":"learn/tech-zone/sdk/#local-harmony-blockchain","text":"Configuring your local node Updating your codebase to the latest Running a local Node","title":"Local Harmony Blockchain"},{"location":"learn/tech-zone/sdk/#local-harmony-web-wallet","text":"Account information Running the Web Wallet Setting up your accounts Funding your wallet Transferring funds","title":"Local Harmony Web Wallet"},{"location":"learn/tech-zone/sdk/#smart-contract-development","text":"Smart contracts development using Truffle Deploying contracts using dApp examples Interacting with Deployed Contracts using dApp examples","title":"Smart Contract Development"},{"location":"learn/tech-zone/sdk/#troubleshooting","text":"Basic troubleshooting","title":"Troubleshooting"},{"location":"learn/tech-zone/sdk/#betanet","text":"Betanet essentials","title":"Betanet"},{"location":"learn/tech-zone/sdk/#api-developers-guide","text":"","title":"API Developers Guide"},{"location":"learn/tech-zone/sdk/#introduction","text":"Sample code Sample nodejs CLI Application Account Methods Transaction Related Methods Contract Related Methods Protocol Related Methods Explorer Methods","title":"Introduction"},{"location":"learn/tech-zone/sdk/#test","text":"","title":"Test"},{"location":"learn/tech-zone/sdk/#command-line-interface","text":"","title":"Command Line Interface"},{"location":"learn/tech-zone/sdk/#using-the-harmony-cli-tool","text":"Blockchain Keys","title":"Using the Harmony CLI tool"},{"location":"learn/tech-zone/sdk/#wallet-developers-guide","text":"","title":"Wallet Developers Guide"},{"location":"learn/tech-zone/sdk/#ledger-nano-s-firmware-usage-manual","text":"","title":"Ledger Nano S Firmware Usage Manual"},{"location":"learn/tech-zone/dapps/","text":"dApps","title":"dApps"},{"location":"learn/tech-zone/dapps/#dapps","text":"","title":"dApps"},{"location":"learn/tech-zone/dapps/harmony-puzzle/","text":"Harmony Puzzle {% embed url=\"https://www.youtube.com/watch?v=zU_LhrDcQyM\" %} You can play the game here ! The game is simple to play: use your arrow keys (or W,A,S,D for game nerds/H,J,K,L for vim nerds) to move the cursor to adjacent blocks. Once a cursor moves to a block, the number in the block increases by one. The goal is to make the numbers on all 9 blocks equal, so that they are in harmony. Harmony Puzzle highlights several blockchain features. Before you play, the blockchain needs to ascertain that you have actually bet your tokens. For this, The transaction needs to be legitimate \u2014 your account needs to have the balance to make the transaction. We ensure this by giving you 100 tokens initially. Your betting transaction needs to be accepted \u2014 it needs to be included in a block in the blockchain by a leader in a shard. The block carrying your transaction needs to be \u201cfinalized\u201d. Let\u2019s look into what that means. In Proof-of-Work chains (like Bitcoin, Ethereum) the miners keep attaching blocks to the blockchain as soon as they can be mined. With their large networks, competing blockchains may emerge where nodes are attaching blocks to multiple different chains. The longest chain is supposed to have \u201cwon\u201d and is considered the canonical \u201cfinal\u201d truth. Finality means that the well-formed blocks won\u2019t be revoked once committed to the blockchain and so the transactions in them cannot be reversed.Longest Chain Rule in Bitcoin So while your transaction is legitimate and accepted and is part of a block, it might not end up on the chain considered the real/canonical chain. In general, in Proof-of-Work networks finality is never 100%. The probability that your transaction will be on the canonical chain increases as the transactions gets deeper in the blockchain. It\u2019s generally accepted that waiting for 6 block confirmations is advisable, as it would guarantee a 99.8% chance that your transaction will be in the canonical chain. In Bitcoin this would mean 6 blocks*10 mins block time ~ 1 hour of waiting for confirmation. Even for Ethereum, that would mean 6 blocks *15 secs block time ~ 1.5 minutes. ( Vitalik and others recommend 10\u201312 confirmations ~ 3 mins). Now imagine you are playing the game and have to wait 1.5 minutes to actually start! That won\u2019t make for a fun experience. The good thing about Harmony is we use FBFT for consensus, an improvement on the Practical Byzantine Fault Tolerance (PBFT) algorithm. We guarantee instant finality, i.e. just wait for the next block and your transaction is finalized. By utilizing fast finality we have been able to make the game play smooth. As you play the game, you are rewarded for finishing a level. The fast finality of Harmony Blockchain lets you go through the levels of the game quickly as well \u2014 as you are finishing levels an account created in your name is getting awarded this transactions. Once again if we waited for many blocks to make sure your tokens have actually increased, it won\u2019t make for a smooth game play. We are very excited as we keep adding features to our Puzzle game and demonstrate the features of our blockchain. We store the moves you made to win a level in the puzzle on our blockchain. This proof is stored in the transaction we rewarded you tokens with!Transaction Snapshot from Harmony\u2019s blockchain explorer See the above snap of a transaction from our blockchain explorer .Level 1 of Harmony Puzzle. RRDD is the winning move! If you see the \u201c Sequence \u201d field above, it stores the configuration of the first level (\u201c00010..\u201d) and \u201cRRDD\u201d (\u201cRight, Right, Down, Down\u201d) the moves someone did to win the first level! In future we will let you rewatch your own level-play using this stored information.","title":"Harmony Puzzle"},{"location":"learn/tech-zone/dapps/harmony-puzzle/#harmony-puzzle","text":"{% embed url=\"https://www.youtube.com/watch?v=zU_LhrDcQyM\" %} You can play the game here ! The game is simple to play: use your arrow keys (or W,A,S,D for game nerds/H,J,K,L for vim nerds) to move the cursor to adjacent blocks. Once a cursor moves to a block, the number in the block increases by one. The goal is to make the numbers on all 9 blocks equal, so that they are in harmony. Harmony Puzzle highlights several blockchain features. Before you play, the blockchain needs to ascertain that you have actually bet your tokens. For this, The transaction needs to be legitimate \u2014 your account needs to have the balance to make the transaction. We ensure this by giving you 100 tokens initially. Your betting transaction needs to be accepted \u2014 it needs to be included in a block in the blockchain by a leader in a shard. The block carrying your transaction needs to be \u201cfinalized\u201d. Let\u2019s look into what that means. In Proof-of-Work chains (like Bitcoin, Ethereum) the miners keep attaching blocks to the blockchain as soon as they can be mined. With their large networks, competing blockchains may emerge where nodes are attaching blocks to multiple different chains. The longest chain is supposed to have \u201cwon\u201d and is considered the canonical \u201cfinal\u201d truth. Finality means that the well-formed blocks won\u2019t be revoked once committed to the blockchain and so the transactions in them cannot be reversed.Longest Chain Rule in Bitcoin So while your transaction is legitimate and accepted and is part of a block, it might not end up on the chain considered the real/canonical chain. In general, in Proof-of-Work networks finality is never 100%. The probability that your transaction will be on the canonical chain increases as the transactions gets deeper in the blockchain. It\u2019s generally accepted that waiting for 6 block confirmations is advisable, as it would guarantee a 99.8% chance that your transaction will be in the canonical chain. In Bitcoin this would mean 6 blocks*10 mins block time ~ 1 hour of waiting for confirmation. Even for Ethereum, that would mean 6 blocks *15 secs block time ~ 1.5 minutes. ( Vitalik and others recommend 10\u201312 confirmations ~ 3 mins). Now imagine you are playing the game and have to wait 1.5 minutes to actually start! That won\u2019t make for a fun experience. The good thing about Harmony is we use FBFT for consensus, an improvement on the Practical Byzantine Fault Tolerance (PBFT) algorithm. We guarantee instant finality, i.e. just wait for the next block and your transaction is finalized. By utilizing fast finality we have been able to make the game play smooth. As you play the game, you are rewarded for finishing a level. The fast finality of Harmony Blockchain lets you go through the levels of the game quickly as well \u2014 as you are finishing levels an account created in your name is getting awarded this transactions. Once again if we waited for many blocks to make sure your tokens have actually increased, it won\u2019t make for a smooth game play. We are very excited as we keep adding features to our Puzzle game and demonstrate the features of our blockchain. We store the moves you made to win a level in the puzzle on our blockchain. This proof is stored in the transaction we rewarded you tokens with!Transaction Snapshot from Harmony\u2019s blockchain explorer See the above snap of a transaction from our blockchain explorer .Level 1 of Harmony Puzzle. RRDD is the winning move! If you see the \u201c Sequence \u201d field above, it stores the configuration of the first level (\u201c00010..\u201d) and \u201cRRDD\u201d (\u201cRight, Right, Down, Down\u201d) the moves someone did to win the first level! In future we will let you rewatch your own level-play using this stored information.","title":"Harmony Puzzle"},{"location":"learn/tech-zone/dapps/photoblock/","text":"PhotoBlock 3 Phases of Usability: Harmony x TryCrypto PhotoBlock \u2014 Login using just a photo and emojis Phase 2 \u2014 (Releasing payment application on Harmony) Phase 3 \u2014 (Allowing everyONE to easily create their own DAPPS) Harmony is partnered with PhotoBlock , an Open Source library for decentralized authentication that allows users to login to dapps using a photo and emojis. Decentralized applications built on Harmony can provide PhotoBlock as an authentication option for users, combining the power of Harmony\u2019s scalable blockchain with PhotoBlock\u2019s simple interface. {% embed url=\"https://twitter.com/harmonyprotocol/status/1169726186257297409\" %} Dapp adoption is lacking In a survey of dapp developers , 67% listed overall lack of users their biggest pain point, attributing the lack of engagement to scalability and usability issues. Current infrastructure is slow and difficult to use, requiring users to be both patient and technically savvy. A partnership between Harmony and PhotoBlock attacks the problem from both sides, creating usable decentralized solutions that scale, allowing users to login to Harmony-powered dapps on the web without wallet downloads or extensions. Scalability with Harmony Harmony is developing a high-throughput, low-latency and low-fee consensus platform, improving scalability and speed of decentralized applications. Innovating on both the protocol and network layers, Harmony is paving the way for fast decentralized applications handling transactions for billions of people for applications in gaming, finance, ecommerce, and more. Usability with PhotoBlock PhotoBlock makes logging into every blockchain simple, allowing users to use one login for every blockchain without worrying about private keys, downloads, or installations. Creating an account with PhotoBlock is as simple as uploading a photo and choosing emojis. Developed by the team at TryCrypto, PhotoBlock also supports customized settings for users, allowing dapps to create a personalized experience for each user while respecting anonymity and privacy. Together, PhotoBlock and Harmony provide necessary infrastructure to build decentralized applications that are usable, scalable, and made for everyONE. Nik Kalyani, Co-Founder of TryCrypto (company behind PhotoBlock): We are excited about Harmony\u2019s innovations in terms of scalability and speed but we also recognize the need for usability. We have incorporated support for Harmony in PhotoBlock to improve usability and fully leverage the speed of their network. We look forward to continuing to work with Harmony on other usability initiatives to fully unlock the power of this technology. Support for authentication on Harmony is built and deployed in PhotoBlock Beta . To learn more about PhotoBlock and how it works: Technical Details Website Twitter Github","title":"PhotoBlock"},{"location":"learn/tech-zone/dapps/photoblock/#photoblock","text":"","title":"PhotoBlock"},{"location":"learn/tech-zone/dapps/photoblock/#3-phases-of-usability-harmony-x-trycrypto","text":"PhotoBlock \u2014 Login using just a photo and emojis Phase 2 \u2014 (Releasing payment application on Harmony) Phase 3 \u2014 (Allowing everyONE to easily create their own DAPPS) Harmony is partnered with PhotoBlock , an Open Source library for decentralized authentication that allows users to login to dapps using a photo and emojis. Decentralized applications built on Harmony can provide PhotoBlock as an authentication option for users, combining the power of Harmony\u2019s scalable blockchain with PhotoBlock\u2019s simple interface. {% embed url=\"https://twitter.com/harmonyprotocol/status/1169726186257297409\" %}","title":"3 Phases of Usability: Harmony x TryCrypto"},{"location":"learn/tech-zone/dapps/photoblock/#dapp-adoption-is-lacking","text":"In a survey of dapp developers , 67% listed overall lack of users their biggest pain point, attributing the lack of engagement to scalability and usability issues. Current infrastructure is slow and difficult to use, requiring users to be both patient and technically savvy. A partnership between Harmony and PhotoBlock attacks the problem from both sides, creating usable decentralized solutions that scale, allowing users to login to Harmony-powered dapps on the web without wallet downloads or extensions.","title":"Dapp adoption is lacking "},{"location":"learn/tech-zone/dapps/photoblock/#scalability-with-harmony","text":"Harmony is developing a high-throughput, low-latency and low-fee consensus platform, improving scalability and speed of decentralized applications. Innovating on both the protocol and network layers, Harmony is paving the way for fast decentralized applications handling transactions for billions of people for applications in gaming, finance, ecommerce, and more.","title":"Scalability with Harmony "},{"location":"learn/tech-zone/dapps/photoblock/#usability-with-photoblock","text":"PhotoBlock makes logging into every blockchain simple, allowing users to use one login for every blockchain without worrying about private keys, downloads, or installations. Creating an account with PhotoBlock is as simple as uploading a photo and choosing emojis. Developed by the team at TryCrypto, PhotoBlock also supports customized settings for users, allowing dapps to create a personalized experience for each user while respecting anonymity and privacy. Together, PhotoBlock and Harmony provide necessary infrastructure to build decentralized applications that are usable, scalable, and made for everyONE. Nik Kalyani, Co-Founder of TryCrypto (company behind PhotoBlock): We are excited about Harmony\u2019s innovations in terms of scalability and speed but we also recognize the need for usability. We have incorporated support for Harmony in PhotoBlock to improve usability and fully leverage the speed of their network. We look forward to continuing to work with Harmony on other usability initiatives to fully unlock the power of this technology. Support for authentication on Harmony is built and deployed in PhotoBlock Beta . To learn more about PhotoBlock and how it works: Technical Details Website Twitter Github","title":"Usability with PhotoBlock "},{"location":"learn/tech-zone/tech-deep-sharding/","text":"Technology Deep Dive Our Approach Harmony's technical architecture implements a full & secure sharding scheme, with an efficient consensus (EPoS), and scalable networking infrastructure. Harmony relies on a secure sharding process, where validators are distributed into shards based on a randomness that is both unpredictable and unbiasable. Harmony is a Proof-of-Stake blockchain, where validators needs to stake a certain amount of tokens to be eligible for block validation. Harmony integrates an efficient consensus protocol called FBFT that combines BLS multi-signature and view change protocol to achieve high robustness and low latency. With the adoption of networking technology including RaptorQ fountain code and Kademlia routing, Harmony is able to achieve cross-shard transactions that scale sub linearly by the number of shards. By innovating on each layer, Harmony aims to provide a scalable, secure, and decentralized system that supports economic activities, including data marketplaces, gaming, and financial transactions, for billions of people. To participate in our research and technical discussions, join our Research forum on talk.harmony.one Core technical innovations Harmony is the highly scalable, minimal-fee and provably secure blockchain that will serves as the backbone of next-generation decentralized applications. Harmony innovates on both protocol and networking layers of blockchain by introducing: Highly scalable BFT consensus using BLS multi-signature Secure distributed randomness generation protocol using VDF (Verifiable Delay Function) Adaptive PoS-based sharding mechanism guaranteeing the network security Kademlia routing and erasure encoding for optimal network usage Technical differentiation compared to existing projects Harmony is a POS-based state-sharding protocol, while existing protocol projects are mostly POW-based. Harmony\u2019s consensus is a fast BFT algorithm which uses BLS multi-sig and scales linearly with the number of nodes, while many existing projects uses the old single chain-based consensus (same as Bitcoin). Harmony\u2019s consensus doesn\u2019t have forks and has instant finality, while existing chains have forks and no instant finality. Harmony provides a provably secure source of randomness with the latest technology Verifiable Delay Functions (VDF), which guarantees the security of the shards and provides fair randomness to applications. However, most existing protocols sharding security is not guarded by randomness, so it\u2019s prone to single-shard takeover attacks, and there is no fair randomness for Dapps (such as gambling games etc.). Harmony\u2019s cross-shard communication is sublinearly efficient because we use Kademlia routing and Erasure Encoding. What is Kademlia routing and how does Harmony apply it? We currently use gossiping and Kademlia in a mutually complementary arrangement: Kademlia handles baseline peer discovery as well as topic mesh forming, and pub\u2013sub gossiping for topical broadcast routing over the topical mesh discovered by Kademlia. Our cross-shard communication will also rely on Kademlia routing technology. For cross-shard communication, we will use Kademlia routing table to minimize network cost. The tradeoffs of doing so as opposed to using gossip are: Gossip (pros): The message delivery is mostly guaranteed because all nodes are involved in relaying the message to the destination. Gossip (cons): A single message incurs network cost for every node, which can easily lead to network congestion. Kademlia (pros): Only a subset of the nodes on the short path to destination needs to relay the message. Overall network cost is low. Less chance of network congestion. Open Source We\u2019re proud of what we\u2019ve built and our implementation of Adaptive IDA is open source for anyone to use. Please head over to our github and dig around in the code! This is one part of our larger effort to release a full P2P, E2E networking library called libunison. We hope that our our open-source networking software contributions will drive the entire blockchain ecosystem forward. SDK The Harmony SDK is now built and ready to use. Find all the documentation here . Discord If you want to get in touch with us, we are very active on Discord and welcome you to join our channel and get to know us. You can watch our open development in progress! Research Forum If you found this interesting, please check out our research forum where we talk about many more ideas like these.","title":"Technology Deep Dive"},{"location":"learn/tech-zone/tech-deep-sharding/#technology-deep-dive","text":"","title":"Technology Deep Dive"},{"location":"learn/tech-zone/tech-deep-sharding/#our-approach","text":"Harmony's technical architecture implements a full & secure sharding scheme, with an efficient consensus (EPoS), and scalable networking infrastructure. Harmony relies on a secure sharding process, where validators are distributed into shards based on a randomness that is both unpredictable and unbiasable. Harmony is a Proof-of-Stake blockchain, where validators needs to stake a certain amount of tokens to be eligible for block validation. Harmony integrates an efficient consensus protocol called FBFT that combines BLS multi-signature and view change protocol to achieve high robustness and low latency. With the adoption of networking technology including RaptorQ fountain code and Kademlia routing, Harmony is able to achieve cross-shard transactions that scale sub linearly by the number of shards. By innovating on each layer, Harmony aims to provide a scalable, secure, and decentralized system that supports economic activities, including data marketplaces, gaming, and financial transactions, for billions of people. To participate in our research and technical discussions, join our Research forum on talk.harmony.one","title":"Our Approach"},{"location":"learn/tech-zone/tech-deep-sharding/#core-technical-innovations","text":"Harmony is the highly scalable, minimal-fee and provably secure blockchain that will serves as the backbone of next-generation decentralized applications. Harmony innovates on both protocol and networking layers of blockchain by introducing: Highly scalable BFT consensus using BLS multi-signature Secure distributed randomness generation protocol using VDF (Verifiable Delay Function) Adaptive PoS-based sharding mechanism guaranteeing the network security Kademlia routing and erasure encoding for optimal network usage","title":"Core technical innovations"},{"location":"learn/tech-zone/tech-deep-sharding/#technical-differentiation-compared-to-existing-projects","text":"Harmony is a POS-based state-sharding protocol, while existing protocol projects are mostly POW-based. Harmony\u2019s consensus is a fast BFT algorithm which uses BLS multi-sig and scales linearly with the number of nodes, while many existing projects uses the old single chain-based consensus (same as Bitcoin). Harmony\u2019s consensus doesn\u2019t have forks and has instant finality, while existing chains have forks and no instant finality. Harmony provides a provably secure source of randomness with the latest technology Verifiable Delay Functions (VDF), which guarantees the security of the shards and provides fair randomness to applications. However, most existing protocols sharding security is not guarded by randomness, so it\u2019s prone to single-shard takeover attacks, and there is no fair randomness for Dapps (such as gambling games etc.). Harmony\u2019s cross-shard communication is sublinearly efficient because we use Kademlia routing and Erasure Encoding.","title":"Technical differentiation compared to existing projects "},{"location":"learn/tech-zone/tech-deep-sharding/#what-is-kademlia-routing-and-how-does-harmony-apply-it","text":"We currently use gossiping and Kademlia in a mutually complementary arrangement: Kademlia handles baseline peer discovery as well as topic mesh forming, and pub\u2013sub gossiping for topical broadcast routing over the topical mesh discovered by Kademlia. Our cross-shard communication will also rely on Kademlia routing technology. For cross-shard communication, we will use Kademlia routing table to minimize network cost. The tradeoffs of doing so as opposed to using gossip are: Gossip (pros): The message delivery is mostly guaranteed because all nodes are involved in relaying the message to the destination. Gossip (cons): A single message incurs network cost for every node, which can easily lead to network congestion. Kademlia (pros): Only a subset of the nodes on the short path to destination needs to relay the message. Overall network cost is low. Less chance of network congestion.","title":"What is Kademlia routing and how does Harmony apply it? "},{"location":"learn/tech-zone/tech-deep-sharding/#open-source","text":"We\u2019re proud of what we\u2019ve built and our implementation of Adaptive IDA is open source for anyone to use. Please head over to our github and dig around in the code! This is one part of our larger effort to release a full P2P, E2E networking library called libunison. We hope that our our open-source networking software contributions will drive the entire blockchain ecosystem forward.","title":"Open Source "},{"location":"learn/tech-zone/tech-deep-sharding/#sdk","text":"The Harmony SDK is now built and ready to use. Find all the documentation here .","title":"SDK"},{"location":"learn/tech-zone/tech-deep-sharding/#discord","text":"If you want to get in touch with us, we are very active on Discord and welcome you to join our channel and get to know us. You can watch our open development in progress!","title":"Discord "},{"location":"learn/tech-zone/tech-deep-sharding/#research-forum","text":"If you found this interesting, please check out our research forum where we talk about many more ideas like these.","title":"Research Forum "},{"location":"learn/tech-zone/tech-deep-sharding/adaptive-ida-protocol/","text":"Adaptive IDA Protocol The results from our first networking benchmark are out! Eugene and Chao, two of our Amazon veterans turned Harmony networking specialists, have delivered a core component of our networking stack called Adaptive Information Dispersal Algorithm (IDA). Our Adaptive IDA tackles a challenge central to any blockchain protocol \u2014 propagating blocks across a faulty, byzantine network \u2014 with stunning speed. Equally exciting, we will open-source this component as part of our larger peer-to-peer, end-to-end networking library \u201c libunison \u201d.A code snippet from a core function in our Adaptive IDA library. A bit of background At Harmony, our goal is to build a high-performance blockchain protocol to power the next generation of decentralized applications. Our approach to achieving scalability is to build a sharded blockchain, which is optimized over all layers of the technology stack, from consensus mechanisms to systems and most important for this post, networking . To date, the networking layer has not received the attention that it deserves in discussions around blockchain scaling. This oversight represents a huge opportunity for improvement over current protocol implementations. That\u2019s why our team of senior engineers is eager to bring the latest techniques from the networking industry to Harmony. The remainder of this post will focus on one specific component of our networking design (IDA) but if you are interested to learn more about our general networking vision, you are encouraged to read our previous post \u201c Harmony\u2019s Networking Story \u201d. What makes networking important to blockchain? A blockchain is in essence a replicated database that is coordinated across a network of computers over the Internet. As simple as this sounds, doing this in a permissionless and trustless manner is an enormous challenge. It is not sufficient to simply send all the transactions around to all the nodes in the network, the nodes must also come to consensus on the order of these transactions so that everyone is on the same page. This last part requires a lot of communication, and that\u2019s where networking comes in. One of the major bottlenecks of coming to consensus is propagating the latest block of transactions from the block proposer to all network participants. Assuming a block size of 1MB and 500 participants, you are faced with the task of sending a total of 500MB of data around the network so everyone has a copy of the block. This is the fundamental problem of information dispersal and depending on how you solve it, this process can take a long time . The longer it takes to disseminate the block, the longer the delay between blocks which in turn means slower transaction latency and less throughput. Block propagation techniques Let\u2019s explore the most naive approach to block propagation called manycast. In manycast, the block proposer sends the 1MB block to each node in the network one by one. Since the proposer has to send all 500MB himself, if he has an average broadband internet speed of 64Mbps, this would take roughly 62.5 seconds. That\u2019s faster than Bitcoin\u2019s average 10 minute inter-block time, but it still isn\u2019t nearly fast enough for a high-performance blockchain like Harmony. As you can probably guess, manycast is not very practical and not widely used for a number of reasons. More popular approaches include gossiping and multicast trees. In gossiping schemes, as new nodes hear about the block, they pass it on to others in the network. This offloads some of the communication burden from the proposer to his peers and reduces the bottleneck. In multicast schemes, the network is arranged in a branching tree structure originating from the proposer. When each node receives the block it passes the message down to its children until everyone has received it. Whereas manycast\u2019s time for block propagation is linear in the number of nodes in the network or O(n) , gossiping and multicast approaches take time that is only logarithmic in the number of nodes in the network or O(log(n)) . This is a significant improvement, but we can do even better. The origin of IDA A proposal for a better block propagation scheme appeared in a 2018 paper titled Rapidchain by Zamani, Movahedi, and Raykova [1]. Among other improvements to sharded blockchain protocols, the authors propose a novel technique called \u2014 you guessed it \u2014 IDA, to disseminate a block amongst a network running a BFT consensus. The core concept behind IDA is to use erasure coding to break up a block into encoded chunks so that it can be quickly and securely spread throughout network. To understand how IDA works, you first have to know a bit about erasure coding . Erasure coding allows you to take a piece of data and expand it into a larger encoded file. Even if portions of that encoded file are lost, the original file can still be recovered. Erasure coding schemes have rates which determine the amount of the encoded file that can be lost without losing the original. These rates also dictate the amount of excess data or overhead that must be encoded over the original file\u2019s size. In IDA, the proposer takes the 1MB block and expands it into an erasure-encoded file of 1.5MB. The proposer then chops this 1.5MB file into 500 chunks of 3kB each. Next the proposer sends one 3kB chunk to each of the 500 nodes in the network. Finally, each node in the network sends their 3kB chunk to everyone else. Then each node has the chunk it received from the proposer as well as the other 499 chunks it received from its peers. As soon as it has more than 1MB worth of 3kB chunks, that node can decode those chunks into the original block and voila we\u2019re done! The difference between manycast and an IDA broadcast using erasure coding. Notice in the above example that the block proposer only sends 500 chunks of 3kB for a total 1.5MB, far less than the 500MB in the manycast example. However, each other node in the network also sends its 3kB chunk 500 times for a total of 1.5MB, making the total data transmitted 750MB. On the surface this may appear worse than manycast. The advantage of IDA is that even though more data is sent in aggregate, the sending of the data is perfectly parallelized between all the nodes. This removes the bottleneck of any single node needing to send a majority of data and allows us to best utilize the aggregate bandwidth of every node in the network. You might ask why we can\u2019t just split up the original 1MB block without encoding it? Good question! The answer is that in any permissionless blockchain context we cannot assume that every node will cooperate. By erasure-coding the block first, we are ensured against any malicious nodes who choose not to share their piece of data. In fact, in the above example we can tolerate up to 33% of nodes not sharing and still the rest of the nodes will be able to recover the original block. Without encoding, just one malicious node would stop every other node from recovering the entire block. Adaptive IDA The benefits of IDA are astonishing. By parallelizing the communication load, IDA completes in the amount of time it takes for one node to send an amount of data as large as the block plus some overhead. This further reduces the problem from logarithmic complexity to constant complexity or O(1). The benefits of IDA for block propagation were immediately clear to us, but as we continued to ponder the problem, an even better solution came to our minds. Having spent 15 years working on networking protocols at NTT (Japan\u2019s largest telco), Eugene is up to date on the latest and greatest in the networking field. The idea came from a novel application of erasure coding called RaptorQ Forward Error Correction which Eugene had designated as part of our peer-to-peer, end-to-end networking stack. While contemplating IDA and RaptorQ FEC side by side, it dawned on us that we could use RaptorQ coding to improve IDA. RaptorQ code is a special type of erasure coding scheme called a fountain code . Fountain codes are rateless meaning that the encoded file has no fixed size. They are useful because they enable the person sending the original file to keep generating new encoded chunks on demand, indefinitely. The sender can act as a fountain of new encoded chunks, hence the name. What does this have to do with IDA? In normal IDA, the code rate must be set in advance. So, assuming a 33% threat model as in PBFT, the encoded block must be at least 1.5MB to guarantee that all the honest nodes will receive the original. This implies a 50% fixed communication overhead regardless of the actual proportion of malicious nodes in the network. Anything less than 50% and block propagation could be stalled, forcing the proposer to start over. RaptorQ\u2019s rateless coding allows us to overcome this fixed overhead and instead adapt our code rate to actual network conditions. To see how this would work, let\u2019s imagine the block proposer felt optimistic about his peers and only made 1.2MB worth of chunks. This 1.2MB was split into 500 chunks and sent around the network as in normal IDA. If more than 5/6th of the network is honest, then each of the honest nodes will receive the enough chunks to make up 1MB and recover the original block. Everyone is okay and in fact the proposer has saved 0.3MB of excess overhead! However, if more than 1/6th are malicious then no honest node will be able to recover the block. In such a situation, if we had used normal erasure coding, we could figure out which chunks had not been propagated by malicious nodes and rebroadcast them but to do so would be time consuming. Or we could restart the whole process with a higher code-rate to protect against the bad guys. Either way, consensus would get stuck and we would lose precious time. With a rateless code, the solution is much more elegant. The proposer can simply begin broadcasting entirely new chunks out of his fountain until honest nodes have received enough chunks to recover the original block. Then having learned that the initial code rate was too low, the proposer would adapt the code rate to be higher for the next round, hence the name Adaptive IDA. Eugene\u2019s diagram of Adaptive IDA at work. When not enough chunks reach two of the honest participants, the leader begins generating and sending new chunks until they have received enough to recover the block. So, Adaptive IDA actually protects against more than just malicious nodes \u2014 it also protects against faulty network conditions. The Internet is unpredictable. Connections drop from time to time. You\u2019ve no doubt experienced this frustration yourself. But no matter how unreliable the underlying Internet is, Harmony needs to be 100% reliable. Adaptive IDA handles situations in which connections between honest nodes are dropped. Therefore, as opposed to normal IDA with fixed rate codes, Adaptive IDA can optimize the code rate for the given malicious ratio and underlying network conditions. This reduces the communication overhead and provides for quick recovery from adverse situations, making the IDA process even faster and more resilient. Bonus: For those network geeks out there, you could consider Adaptive IDA as a block propagation analog of adaptive window connections in TCP. Open Source We\u2019re proud of what we\u2019ve built and our implementation of Adaptive IDA is open source for anyone to use. Please head over to our github and dig around in the code! This is one part of our larger effort to release a full P2P, E2E networking library called libunison. We hope that our our open-source networking software contributions will drive the entire blockchain ecosystem forward. Discord If you want to get in touch with us, we are very active on Discord and welcome you to join our channel and get to know us. You can watch our open development in progress! Research Forum If you found this interesting, please check out our research forum where we talk about many more ideas like these. If you want a more mathematical and technical explanation of Adaptive IDA, make a new topic in the networking category of the forum. Come discuss! Special thanks to Arunesh Mishra from Picolo Labs for his feedback on this post. [1] M. Zamani, M. Movahedi, and M. Raykova, \u201cRapidChain: A Fast Blockchain Protocol via Full Sharding.\u201d Cryptology ePrint Archive, Report 2018/460, 2018. https://eprint.iacr.org/2018/460 .","title":"Adaptive IDA Protocol"},{"location":"learn/tech-zone/tech-deep-sharding/adaptive-ida-protocol/#adaptive-ida-protocol","text":"The results from our first networking benchmark are out! Eugene and Chao, two of our Amazon veterans turned Harmony networking specialists, have delivered a core component of our networking stack called Adaptive Information Dispersal Algorithm (IDA). Our Adaptive IDA tackles a challenge central to any blockchain protocol \u2014 propagating blocks across a faulty, byzantine network \u2014 with stunning speed. Equally exciting, we will open-source this component as part of our larger peer-to-peer, end-to-end networking library \u201c libunison \u201d.A code snippet from a core function in our Adaptive IDA library.","title":"Adaptive IDA Protocol"},{"location":"learn/tech-zone/tech-deep-sharding/adaptive-ida-protocol/#a-bit-of-background","text":"At Harmony, our goal is to build a high-performance blockchain protocol to power the next generation of decentralized applications. Our approach to achieving scalability is to build a sharded blockchain, which is optimized over all layers of the technology stack, from consensus mechanisms to systems and most important for this post, networking . To date, the networking layer has not received the attention that it deserves in discussions around blockchain scaling. This oversight represents a huge opportunity for improvement over current protocol implementations. That\u2019s why our team of senior engineers is eager to bring the latest techniques from the networking industry to Harmony. The remainder of this post will focus on one specific component of our networking design (IDA) but if you are interested to learn more about our general networking vision, you are encouraged to read our previous post \u201c Harmony\u2019s Networking Story \u201d.","title":"A bit of background "},{"location":"learn/tech-zone/tech-deep-sharding/adaptive-ida-protocol/#what-makes-networking-important-to-blockchain","text":"A blockchain is in essence a replicated database that is coordinated across a network of computers over the Internet. As simple as this sounds, doing this in a permissionless and trustless manner is an enormous challenge. It is not sufficient to simply send all the transactions around to all the nodes in the network, the nodes must also come to consensus on the order of these transactions so that everyone is on the same page. This last part requires a lot of communication, and that\u2019s where networking comes in. One of the major bottlenecks of coming to consensus is propagating the latest block of transactions from the block proposer to all network participants. Assuming a block size of 1MB and 500 participants, you are faced with the task of sending a total of 500MB of data around the network so everyone has a copy of the block. This is the fundamental problem of information dispersal and depending on how you solve it, this process can take a long time . The longer it takes to disseminate the block, the longer the delay between blocks which in turn means slower transaction latency and less throughput.","title":"What makes networking important to blockchain? "},{"location":"learn/tech-zone/tech-deep-sharding/adaptive-ida-protocol/#block-propagation-techniques","text":"Let\u2019s explore the most naive approach to block propagation called manycast. In manycast, the block proposer sends the 1MB block to each node in the network one by one. Since the proposer has to send all 500MB himself, if he has an average broadband internet speed of 64Mbps, this would take roughly 62.5 seconds. That\u2019s faster than Bitcoin\u2019s average 10 minute inter-block time, but it still isn\u2019t nearly fast enough for a high-performance blockchain like Harmony. As you can probably guess, manycast is not very practical and not widely used for a number of reasons. More popular approaches include gossiping and multicast trees. In gossiping schemes, as new nodes hear about the block, they pass it on to others in the network. This offloads some of the communication burden from the proposer to his peers and reduces the bottleneck. In multicast schemes, the network is arranged in a branching tree structure originating from the proposer. When each node receives the block it passes the message down to its children until everyone has received it. Whereas manycast\u2019s time for block propagation is linear in the number of nodes in the network or O(n) , gossiping and multicast approaches take time that is only logarithmic in the number of nodes in the network or O(log(n)) . This is a significant improvement, but we can do even better.","title":"Block propagation techniques "},{"location":"learn/tech-zone/tech-deep-sharding/adaptive-ida-protocol/#the-origin-of-ida","text":"A proposal for a better block propagation scheme appeared in a 2018 paper titled Rapidchain by Zamani, Movahedi, and Raykova [1]. Among other improvements to sharded blockchain protocols, the authors propose a novel technique called \u2014 you guessed it \u2014 IDA, to disseminate a block amongst a network running a BFT consensus. The core concept behind IDA is to use erasure coding to break up a block into encoded chunks so that it can be quickly and securely spread throughout network. To understand how IDA works, you first have to know a bit about erasure coding . Erasure coding allows you to take a piece of data and expand it into a larger encoded file. Even if portions of that encoded file are lost, the original file can still be recovered. Erasure coding schemes have rates which determine the amount of the encoded file that can be lost without losing the original. These rates also dictate the amount of excess data or overhead that must be encoded over the original file\u2019s size. In IDA, the proposer takes the 1MB block and expands it into an erasure-encoded file of 1.5MB. The proposer then chops this 1.5MB file into 500 chunks of 3kB each. Next the proposer sends one 3kB chunk to each of the 500 nodes in the network. Finally, each node in the network sends their 3kB chunk to everyone else. Then each node has the chunk it received from the proposer as well as the other 499 chunks it received from its peers. As soon as it has more than 1MB worth of 3kB chunks, that node can decode those chunks into the original block and voila we\u2019re done! The difference between manycast and an IDA broadcast using erasure coding. Notice in the above example that the block proposer only sends 500 chunks of 3kB for a total 1.5MB, far less than the 500MB in the manycast example. However, each other node in the network also sends its 3kB chunk 500 times for a total of 1.5MB, making the total data transmitted 750MB. On the surface this may appear worse than manycast. The advantage of IDA is that even though more data is sent in aggregate, the sending of the data is perfectly parallelized between all the nodes. This removes the bottleneck of any single node needing to send a majority of data and allows us to best utilize the aggregate bandwidth of every node in the network. You might ask why we can\u2019t just split up the original 1MB block without encoding it? Good question! The answer is that in any permissionless blockchain context we cannot assume that every node will cooperate. By erasure-coding the block first, we are ensured against any malicious nodes who choose not to share their piece of data. In fact, in the above example we can tolerate up to 33% of nodes not sharing and still the rest of the nodes will be able to recover the original block. Without encoding, just one malicious node would stop every other node from recovering the entire block.","title":"The origin of IDA "},{"location":"learn/tech-zone/tech-deep-sharding/adaptive-ida-protocol/#adaptive-ida","text":"The benefits of IDA are astonishing. By parallelizing the communication load, IDA completes in the amount of time it takes for one node to send an amount of data as large as the block plus some overhead. This further reduces the problem from logarithmic complexity to constant complexity or O(1). The benefits of IDA for block propagation were immediately clear to us, but as we continued to ponder the problem, an even better solution came to our minds. Having spent 15 years working on networking protocols at NTT (Japan\u2019s largest telco), Eugene is up to date on the latest and greatest in the networking field. The idea came from a novel application of erasure coding called RaptorQ Forward Error Correction which Eugene had designated as part of our peer-to-peer, end-to-end networking stack. While contemplating IDA and RaptorQ FEC side by side, it dawned on us that we could use RaptorQ coding to improve IDA. RaptorQ code is a special type of erasure coding scheme called a fountain code . Fountain codes are rateless meaning that the encoded file has no fixed size. They are useful because they enable the person sending the original file to keep generating new encoded chunks on demand, indefinitely. The sender can act as a fountain of new encoded chunks, hence the name. What does this have to do with IDA? In normal IDA, the code rate must be set in advance. So, assuming a 33% threat model as in PBFT, the encoded block must be at least 1.5MB to guarantee that all the honest nodes will receive the original. This implies a 50% fixed communication overhead regardless of the actual proportion of malicious nodes in the network. Anything less than 50% and block propagation could be stalled, forcing the proposer to start over. RaptorQ\u2019s rateless coding allows us to overcome this fixed overhead and instead adapt our code rate to actual network conditions. To see how this would work, let\u2019s imagine the block proposer felt optimistic about his peers and only made 1.2MB worth of chunks. This 1.2MB was split into 500 chunks and sent around the network as in normal IDA. If more than 5/6th of the network is honest, then each of the honest nodes will receive the enough chunks to make up 1MB and recover the original block. Everyone is okay and in fact the proposer has saved 0.3MB of excess overhead! However, if more than 1/6th are malicious then no honest node will be able to recover the block. In such a situation, if we had used normal erasure coding, we could figure out which chunks had not been propagated by malicious nodes and rebroadcast them but to do so would be time consuming. Or we could restart the whole process with a higher code-rate to protect against the bad guys. Either way, consensus would get stuck and we would lose precious time. With a rateless code, the solution is much more elegant. The proposer can simply begin broadcasting entirely new chunks out of his fountain until honest nodes have received enough chunks to recover the original block. Then having learned that the initial code rate was too low, the proposer would adapt the code rate to be higher for the next round, hence the name Adaptive IDA. Eugene\u2019s diagram of Adaptive IDA at work. When not enough chunks reach two of the honest participants, the leader begins generating and sending new chunks until they have received enough to recover the block. So, Adaptive IDA actually protects against more than just malicious nodes \u2014 it also protects against faulty network conditions. The Internet is unpredictable. Connections drop from time to time. You\u2019ve no doubt experienced this frustration yourself. But no matter how unreliable the underlying Internet is, Harmony needs to be 100% reliable. Adaptive IDA handles situations in which connections between honest nodes are dropped. Therefore, as opposed to normal IDA with fixed rate codes, Adaptive IDA can optimize the code rate for the given malicious ratio and underlying network conditions. This reduces the communication overhead and provides for quick recovery from adverse situations, making the IDA process even faster and more resilient. Bonus: For those network geeks out there, you could consider Adaptive IDA as a block propagation analog of adaptive window connections in TCP.","title":"Adaptive IDA "},{"location":"learn/tech-zone/tech-deep-sharding/adaptive-ida-protocol/#open-source","text":"We\u2019re proud of what we\u2019ve built and our implementation of Adaptive IDA is open source for anyone to use. Please head over to our github and dig around in the code! This is one part of our larger effort to release a full P2P, E2E networking library called libunison. We hope that our our open-source networking software contributions will drive the entire blockchain ecosystem forward.","title":"Open Source "},{"location":"learn/tech-zone/tech-deep-sharding/adaptive-ida-protocol/#discord","text":"If you want to get in touch with us, we are very active on Discord and welcome you to join our channel and get to know us. You can watch our open development in progress!","title":"Discord "},{"location":"learn/tech-zone/tech-deep-sharding/adaptive-ida-protocol/#research-forum","text":"If you found this interesting, please check out our research forum where we talk about many more ideas like these. If you want a more mathematical and technical explanation of Adaptive IDA, make a new topic in the networking category of the forum. Come discuss! Special thanks to Arunesh Mishra from Picolo Labs for his feedback on this post. [1] M. Zamani, M. Movahedi, and M. Raykova, \u201cRapidChain: A Fast Blockchain Protocol via Full Sharding.\u201d Cryptology ePrint Archive, Report 2018/460, 2018. https://eprint.iacr.org/2018/460 .","title":"Research Forum "},{"location":"learn/tech-zone/tech-deep-sharding/competitor-overview/","text":"Competitor Overview","title":"Competitor Overview"},{"location":"learn/tech-zone/tech-deep-sharding/competitor-overview/#competitor-overview","text":"","title":"Competitor Overview"},{"location":"learn/tech-zone/tech-deep-sharding/cross-shard-routing/","text":"Cross-shard Routing Transactions can be processed in a committee or in multiple committee\u2019s in a blockchain. Either the co-ordination across shards could be client driven or driven by the network itself. If the network drives the committee where a transaction needs to be executed then we need good committee routing methods. Prior inter-committee routing methods have included a strawman scheme \u2013 which is a fully connected network where every nodes knows the IP of every other node. This scheme has obvious privacy concerns as all IPs are known, it\u2019s easier to do a DoS attack. Such a scheme is not scalable since all nodes must know and broadcast to every other node, especially when the network has tens of thousands of nodes. Another structure is using reference committee for transaction routing, this creates centralized hub within the network and creates bottlenecks for the overall network. In Harmony, and as discussed in RapidChain 1 , we use Kademlia routing 3 which allows each committee or shard to maintain a routing table of logN records, where N is the number of committees. Each routing will take up to logN steps. For example, in a network with 2^5 committees, each committee needs to route a message 5 times to reach the desired/destination committee. In this scheme, each node stores info about all nodes in the same committee and an additional log(logN) nodes info of other logN committee. In a network of 2^8 committees, each node stores info about log 8, or 3 nodes, from each neighbor logN number of committee. Thus, for inter-committee transactions, all nodes in the sender committee try to send messages to the receiver committee (where they will be processed) via Kademlia routing with no neccessity of central leader. Nodes in the receiver committee broadcast messages to other members in the committee using information dispersal algorithm (IDA)-gossip protocol to speed up the block propagation in the receiver committee.","title":"Cross-shard Routing"},{"location":"learn/tech-zone/tech-deep-sharding/cross-shard-routing/#cross-shard-routing","text":"Transactions can be processed in a committee or in multiple committee\u2019s in a blockchain. Either the co-ordination across shards could be client driven or driven by the network itself. If the network drives the committee where a transaction needs to be executed then we need good committee routing methods. Prior inter-committee routing methods have included a strawman scheme \u2013 which is a fully connected network where every nodes knows the IP of every other node. This scheme has obvious privacy concerns as all IPs are known, it\u2019s easier to do a DoS attack. Such a scheme is not scalable since all nodes must know and broadcast to every other node, especially when the network has tens of thousands of nodes. Another structure is using reference committee for transaction routing, this creates centralized hub within the network and creates bottlenecks for the overall network. In Harmony, and as discussed in RapidChain 1 , we use Kademlia routing 3 which allows each committee or shard to maintain a routing table of logN records, where N is the number of committees. Each routing will take up to logN steps. For example, in a network with 2^5 committees, each committee needs to route a message 5 times to reach the desired/destination committee. In this scheme, each node stores info about all nodes in the same committee and an additional log(logN) nodes info of other logN committee. In a network of 2^8 committees, each node stores info about log 8, or 3 nodes, from each neighbor logN number of committee. Thus, for inter-committee transactions, all nodes in the sender committee try to send messages to the receiver committee (where they will be processed) via Kademlia routing with no neccessity of central leader. Nodes in the receiver committee broadcast messages to other members in the committee using information dispersal algorithm (IDA)-gossip protocol to speed up the block propagation in the receiver committee.","title":"Cross-shard Routing"},{"location":"learn/tech-zone/tech-deep-sharding/effective-proof-of-stake-epos/","text":"Effective Proof-of-Stake (EPoS) How to Elect Validators Most of the current PoS blockchains have a concept of committee which is a group of validators (a.k.a. block producers, endorsers etc.) who have the right to produce and validate blocks. Usually, the committee has a limited number of seats (e.g. 21 for EOS and 100 for Cosmos). The question of validator election is basically \u2014 how to decide who gets the seats in the committee? This is theoretically the same question of how to distribute limited resources in real world economy. In our economy, the way to distribute limited resources can be, but not limited to, 1) by pricing or bidding , meaning whoever pays the highest price will get it; 2) by social criteria , such as title and reputation; 3) by time , as in the time spent in the line for a limited edition product; 4) or by random selection , as in a lottery. In fact, the way to select the validators in the committee is being solved by similar solutions. Let\u2019s take a look at some of the common approaches in PoS blockchains: By the amount of stake (Cosmos, Polkadot): In this model, the validators who stake the most get the limited seats. This is very similar to bidding in real world. Our initial bidding-based design also falls in this category. By random selection among stake holders (Ethereum 2.0, Tezos): This model requires the potential validators to stake a minimum amount to be considered in the random selection. For example, Ethereum 2.0 requires a minimum of 32 ETH (10,000XTZ for Tezos) to be eligible for random selection into the committee. This model is basically a combination of pricing and random selection. By social reputation and voting (EOS, Tron): In EOS, the limited 21 block producers are determined by the amount of votes the validators get from token holders, which is an off-chain social reputational criteria. The ways to elect validators are not limited to the above and other factors such as the token age ( time ), as in Peercoin, were also used before. Generally, we believe using staked tokens as criteria is the most efficient and economically secure way for validator election, as the stakes closely ties the validators incentives with the well-being of the blockchain itself. We decided to go with the first option for its simplicity and effectiveness. Option 2 gives fair chance to all stakers, but the issue is that for a good amount of time the potential validators are just idling there, waiting to be selected, which comes at a considerable opportunity cost for potential validators. Preventing Centralization with Effective Proof-of-Stake We introduce Effective Proof-of-Stake, an efficient staking mechanism that avoids stake centralization while still supporting stake compounding and delegation. Validator Election As mentioned above, we will adopt the mechanism that elect the highest ranked validators based on stake as the committee. Specifically, for every epoch (~ 1 day), the top 1600 stakers will obtain the 1600 seats (4 shards * 400 seats) and become the validators across the shards. Once the epoch changes, the new rank of stakes will determine the validators for the next epoch. Block Rewards based on Effective Stake We\u2019ve shared above that neither pro-rata rewards nor equal rewards is an optimal and fair choice for our design goals (specifically the even distribution of stakes and the ability to compound stake and returns). In EPoS, the validators will be rewarded in proportion to their effective stake , which is defined in the formula below. We use median_stake to denote the amount of stake at median in the ranked list of top 1600 stakers, and actual_stake is the actual stake hold by the validator. Here, c is a protocol parameter (for example, c = 0.15). The effective stake of a validator is basically its actual stake bounded by the upper limit of (1 + c) * median_stake and the lower limit of (1 \u2014 c) * median_stake. Besides the block reward, the voting power of each validator in the consensus is also determined proportionally by the validator\u2019s effective stake.Validator\u2019s Effective Stake and the Curve of Actual Stake With the introduction of effective stake, the higher ranked validators are actually economically punished to stake too much in a single validator and the lower-ranked validators are enjoying extra reward for their stake. The effective stake is acting as an equalizer that pushes for a more evenly distributed stake among validators, thus avoiding stake centralization. For compounding, the validators in the yellow area are economically incentivized to spin up new validator machines to \u201ccompound\u201d their rewards. In terms of staking pool, this design is forcing the staking pools to decentralize themselves and avoid single point of failure. The nodes in the blue and green area can directly compound by re-staking their reward in the same validator. In terms of delegation, token holders can freely choose one of more validators to delegate their tokens based on their commission rate, uptime and their position in the rank. The block rewards will be distributed to delegators pro-rata after the commission fee set by the validator is deducted. For delegators, It\u2019s economically more rewarding to delegate to the validators in the green area as the return to stake ratio is higher, thus avoiding the stake centralization too. With these design features, we can achieve our goals of supporting delegation, compounding stake while preserving decentralization. Slashing Mechanism In addition to the block rewards used to incentivize good behavior, the slashing mechanism is equally important as it can deter misbehavior and potential attacks. In EPoS, we will employ the following slashing rules. Double Signing Minimum 2% slashing on the stake. The slashing increases linearly as the number of validators being slashed at the same time (e.g. 33% slashing if 1/3 of the validators double signing ) Note: the staking mechanism\u2019s push for big stakers to decentralize themselves comes in handy with the slashing rule. If the big staker initiates attack with all of their nodes together, more slashing will be applied on their stake. Unavailability For every 3 hours of unavailability, the validator\u2019s voting power will be leaked by 25% . After 12 hours of continuously being offline, the validator will have no voting power to participate in the consensus and become inactive . Inactive validators will take 0.1% slashing on their stake. If the validator goes online again, its voting power will be fully restored. For those validators with no voting power, they won\u2019t be considered in validator election until they send a rejoin transaction Finally Staking mechanisms and incentive models are core components of PoS blockchains. To some degree, they are as important as the blockchain protocol. The information about staking mechanism and incentive models of current PoS blockchains are scattered in many places and it\u2019s hard to have a clear picture of how these systems compare. In that regard, we compiled a comparison chart of PoS designs among a few major projects. You can also find more details about Harmony\u2019s staking workflow there.","title":"Effective Proof-of-Stake \\(EPoS\\)"},{"location":"learn/tech-zone/tech-deep-sharding/effective-proof-of-stake-epos/#effective-proof-of-stake-epos","text":"","title":"Effective Proof-of-Stake (EPoS)"},{"location":"learn/tech-zone/tech-deep-sharding/effective-proof-of-stake-epos/#how-to-elect-validators","text":"Most of the current PoS blockchains have a concept of committee which is a group of validators (a.k.a. block producers, endorsers etc.) who have the right to produce and validate blocks. Usually, the committee has a limited number of seats (e.g. 21 for EOS and 100 for Cosmos). The question of validator election is basically \u2014 how to decide who gets the seats in the committee? This is theoretically the same question of how to distribute limited resources in real world economy. In our economy, the way to distribute limited resources can be, but not limited to, 1) by pricing or bidding , meaning whoever pays the highest price will get it; 2) by social criteria , such as title and reputation; 3) by time , as in the time spent in the line for a limited edition product; 4) or by random selection , as in a lottery. In fact, the way to select the validators in the committee is being solved by similar solutions. Let\u2019s take a look at some of the common approaches in PoS blockchains: By the amount of stake (Cosmos, Polkadot): In this model, the validators who stake the most get the limited seats. This is very similar to bidding in real world. Our initial bidding-based design also falls in this category. By random selection among stake holders (Ethereum 2.0, Tezos): This model requires the potential validators to stake a minimum amount to be considered in the random selection. For example, Ethereum 2.0 requires a minimum of 32 ETH (10,000XTZ for Tezos) to be eligible for random selection into the committee. This model is basically a combination of pricing and random selection. By social reputation and voting (EOS, Tron): In EOS, the limited 21 block producers are determined by the amount of votes the validators get from token holders, which is an off-chain social reputational criteria. The ways to elect validators are not limited to the above and other factors such as the token age ( time ), as in Peercoin, were also used before. Generally, we believe using staked tokens as criteria is the most efficient and economically secure way for validator election, as the stakes closely ties the validators incentives with the well-being of the blockchain itself. We decided to go with the first option for its simplicity and effectiveness. Option 2 gives fair chance to all stakers, but the issue is that for a good amount of time the potential validators are just idling there, waiting to be selected, which comes at a considerable opportunity cost for potential validators.","title":"How to Elect Validators "},{"location":"learn/tech-zone/tech-deep-sharding/effective-proof-of-stake-epos/#preventing-centralization-with-effective-proof-of-stake","text":"We introduce Effective Proof-of-Stake, an efficient staking mechanism that avoids stake centralization while still supporting stake compounding and delegation.","title":"Preventing Centralization with Effective Proof-of-Stake "},{"location":"learn/tech-zone/tech-deep-sharding/effective-proof-of-stake-epos/#validator-election","text":"As mentioned above, we will adopt the mechanism that elect the highest ranked validators based on stake as the committee. Specifically, for every epoch (~ 1 day), the top 1600 stakers will obtain the 1600 seats (4 shards * 400 seats) and become the validators across the shards. Once the epoch changes, the new rank of stakes will determine the validators for the next epoch.","title":"Validator Election "},{"location":"learn/tech-zone/tech-deep-sharding/effective-proof-of-stake-epos/#block-rewards-based-on-effective-stake","text":"We\u2019ve shared above that neither pro-rata rewards nor equal rewards is an optimal and fair choice for our design goals (specifically the even distribution of stakes and the ability to compound stake and returns). In EPoS, the validators will be rewarded in proportion to their effective stake , which is defined in the formula below. We use median_stake to denote the amount of stake at median in the ranked list of top 1600 stakers, and actual_stake is the actual stake hold by the validator. Here, c is a protocol parameter (for example, c = 0.15). The effective stake of a validator is basically its actual stake bounded by the upper limit of (1 + c) * median_stake and the lower limit of (1 \u2014 c) * median_stake. Besides the block reward, the voting power of each validator in the consensus is also determined proportionally by the validator\u2019s effective stake.Validator\u2019s Effective Stake and the Curve of Actual Stake With the introduction of effective stake, the higher ranked validators are actually economically punished to stake too much in a single validator and the lower-ranked validators are enjoying extra reward for their stake. The effective stake is acting as an equalizer that pushes for a more evenly distributed stake among validators, thus avoiding stake centralization. For compounding, the validators in the yellow area are economically incentivized to spin up new validator machines to \u201ccompound\u201d their rewards. In terms of staking pool, this design is forcing the staking pools to decentralize themselves and avoid single point of failure. The nodes in the blue and green area can directly compound by re-staking their reward in the same validator. In terms of delegation, token holders can freely choose one of more validators to delegate their tokens based on their commission rate, uptime and their position in the rank. The block rewards will be distributed to delegators pro-rata after the commission fee set by the validator is deducted. For delegators, It\u2019s economically more rewarding to delegate to the validators in the green area as the return to stake ratio is higher, thus avoiding the stake centralization too. With these design features, we can achieve our goals of supporting delegation, compounding stake while preserving decentralization.","title":"Block Rewards based on Effective Stake "},{"location":"learn/tech-zone/tech-deep-sharding/effective-proof-of-stake-epos/#slashing-mechanism","text":"In addition to the block rewards used to incentivize good behavior, the slashing mechanism is equally important as it can deter misbehavior and potential attacks. In EPoS, we will employ the following slashing rules. Double Signing Minimum 2% slashing on the stake. The slashing increases linearly as the number of validators being slashed at the same time (e.g. 33% slashing if 1/3 of the validators double signing ) Note: the staking mechanism\u2019s push for big stakers to decentralize themselves comes in handy with the slashing rule. If the big staker initiates attack with all of their nodes together, more slashing will be applied on their stake. Unavailability For every 3 hours of unavailability, the validator\u2019s voting power will be leaked by 25% . After 12 hours of continuously being offline, the validator will have no voting power to participate in the consensus and become inactive . Inactive validators will take 0.1% slashing on their stake. If the validator goes online again, its voting power will be fully restored. For those validators with no voting power, they won\u2019t be considered in validator election until they send a rejoin transaction","title":"Slashing Mechanism "},{"location":"learn/tech-zone/tech-deep-sharding/effective-proof-of-stake-epos/#finally","text":"Staking mechanisms and incentive models are core components of PoS blockchains. To some degree, they are as important as the blockchain protocol. The information about staking mechanism and incentive models of current PoS blockchains are scattered in many places and it\u2019s hard to have a clear picture of how these systems compare. In that regard, we compiled a comparison chart of PoS designs among a few major projects. You can also find more details about Harmony\u2019s staking workflow there.","title":"Finally "},{"location":"learn/tech-zone/tech-deep-sharding/fast-byzantine-fault-tolerance/","text":"Fast Byzantine Fault Tolerance Harmony\u2019s Fast Byzantine Fault Tolerance The view change protocol is a core part in any blockchain from which we can tell whether a protocol is permissioned or permissionless and how decentralized it is. The code is here: harmony/consensus We launched our Day ONE Mainnet with a total of 600 nodes on 4 shards on June 28th. In our previous tests, we observed view change (i.e. leader change) happened in some shards due to bad network condition. We also manually triggered view change by killing the leader node as well as other kinds of attacks. The view change happened after the attack and the network keeps going as expected \u2014heck yeah! In the following, we will first explain the basic concepts of byzantine fault tolerance, then second how we improve it to handle large number of nodes in practice, and finally the overall code structure and some implementation details. What is Byzantine Fault Tolerance? A distributed system consists of multiple nodes where each node is an independent server. They communicate with each other by sending messages over the network and perform some tasks according to the protocol they conform to. There are many types of faults, but they can basically be classified into two major categories. The first kind of faults are node crash, network down, packet loss, etc., where the node had no malicious intention. These are non-byzantine faults. The second type is where a node can be malicious. It can act arbitrarily and not follow the rules of the protocol. For example, a validator can delay or refuse to relay the messages in the network, the leader can propose invalid block, or a node can send different messages to different peers. At worst, malicious nodes may collaborate with each other. These are called Byzantine faults. With these two kinds of faults in mind, there are two properties we want the system to maintain: consistency and liveness . In blockchain terminology, consistency means honest nodes must commit the same block for any given block number/height; liveness means the chain height must keep growing without being stuck. In a permissioned network, where we only have the first type of faults (non-byzantine), this is easier to achieve. For example, we can pick one powerful node as leader and all the other nodes will just listen to what the leader broadcasts and trust any block the leader proposes. Even in this case, we need to watch out for the first kind of faults, especially when it happens to the leader. For a fully decentralized network, we cannot trust any single node and assume the second kind of faults can happen in any node. There is only one fundamental assumption, which is a malicious node cannot forge the signatures other nodes signed. This is guaranteed by cryptography theory, where the difficulty of forging a signature is so high that no computer today can break in any practical time. Things might change when the quantum computer is ready. But at that time, we will use quantum-resistant cryptographic algorithm instead. A Byzantine Fault Tolerant protocol is a protocol that can guarantee the consistency and liveness of the distributed system even when there are malicious nodes in the system. All such protocols have the basic assumption that the number of malicious node is less than some threshold. This is easy to understand, if there are over 50% malicious nodes, then the network is fully controlled by the malicious nodes. In the case of prove of work (PoW) in Bitcoin, the requirement is less than 50% of nodes (in the computation power sense) are malicious. However, the selfish mining lowers the basic assumption to 25%. i.e. the system of PoW will be safe only if less than 25% of nodes (in the sense of computation power) are malicious. There is deep research on Byzantine Fault Tolerance protocol in traditional distributed systems. It is proven that malicious nodes should be less than 33% of a network in the classical paper of Lamport . Later on, the famous practical byzantine fault tolerance paper PBFT makes such system practical. There are still two remaining issues. First, such a system is permissioned, which not allow arbitrary nodes to join and leave. Second, it is not scalable to more than hundreds of nodes. The first issue is due to Sybil Attack, where a malicious user can easily create many fake identities and take over the majority of the network. It is first solved in Satoshi Nakamoto\u2019s Bitcoin whitepaper, where the economic effect is taken into consideration. After proof of work (PoW), there are many new designs such as proof of stake (PoS), proof of authority (PoA) etc. Instead of counting the number of nodes, we counting the amount of voting power. In PoS, the voting power of a node is proportional to its staking amount. The second issue is solved by aggregated signatures using BLS signature scheme which is explained in the FBFT section. Practical Byzantine Fault Tolerance For protocols like Raft and Paxos, they are used to deal with the first kind of system faults. Practical Byzantine Fault Tolerance (PBFT) is one of the first Byzantine fault tolerance protocols used in the real world to deal with the both first and second kinds of faults. We will always assume there are N nodes with at most f malicious nodes, where N=3f+1. There are two modes in the PBFT, the normal consensus (normal in short) mode and the view change mode. The normal mode looks like this (in blockchain, the client request and reply can be ignored): In one view (one view is a similar concept of one round), there are 3 steps/phases: pre-prepare (announce), prepare and commit. In pre-prepare(announce) phase, the leader will broadcast announce message (e.g. the proposal block) to other nodes (called validators). When a validator receives announce message, it enters prepare phase. In prepare phase, after a validator receives announce message, it will broadcast prepare message (e.g. signature on blockhash) to every node. When a validator (including the leader) receives enough (i.e. \u22652f+1 ) prepare messages, it will enter commit phase. In commit phase, a validator (including the leader) will send commit message (e.g. signature on |blockNum|blockHash|) When a validator receives enough (\u22652f+1) commit messages. It can safely commit the block. This ends one round of normal consensus process. Notice that there are some differences between general PBFT and blockchain PBFT. The major difference is that the blockchain is \u201csynchronized\u201d between two blocks, i.e. we cannot proceed to commit block h+1 before commit h. In the traditional PBFT, we can commit client request h+1 before request h. The PBFT will guarantee consistency across all the nodes. In this sense, the blockchain makes consensus process simpler. To be precise, there is a process in PBFT called checkpoint process. A checkpoint is a certificate that all the information with sequence number (in blockchain, it is the block number) less or equal than checkpoint\u2019s sequence number are finalized. In blockchain, each committed block is finalized and can be viewed as a checkpoint. When a validator cannot commit a new block before consensus timeout (\u0394T\u2265T0), the validators will start view change (v\u2192v+1), the new leader is uniquely determined in a predetermined way. If the view change cannot finish before timeout (\u0394T\u2265T1), the validator will propose another view change (v+1\u2192v+2, with view change timeout increases to 2*T1). There are 2 steps/phases in view change mode: A validator starts view change by sending view change message containing \u22652f+1prepare messages to new leader. If it doesn\u2019t receive enough prepare messages, it just send view change message without any prepare message to the new leader. The new leader collects enough (\u22652f+1) view change messages and broadcast new view message containing view change messages it receives. Then the new leader switches to normal mode. A validator switches to normal mode when it receives new view message from the new leader, at the same time, it stops the view change timer and start consensus timer. If the validator doesn\u2019t receive new view message before view change timeout, it will increase viewID by one and start another view change. View change guarantees liveness of the network. During the view change process, we need to make sure the block committed is consistency across view change as well. Simply speaking, the receiving of 2f+1 prepare messages only ensure the consistency in the same view. The receiving of 2f+1 commit messages ensure consistency across different views. When a node receives 2f+1 commit message, it can safely commit the block into the blockchain. The PBFT protocol ensures the same block will be committed by any honest nodes even in the case of view change. CONSISTENCY AND LIVENESS The key concept in PBFT is the quorum. A quorum is any subset with at least 2f+1 nodes. Since there are a total of 3f+1nodes, any two quorums will intersect at least f+1nodes. Based on the assumption that there are at most f malicious nodes, there will be at least one honest node in the intersection of two quorums. This is the reason why we need a quorum to take any action. Consistency in one view: Suppose a node received 2f+1 prepare message, these 2f+1 nodes form a quorum. Notice any two quorums will have at least one honest node in common, it means any two such quorums cannot contain different block hashes in their prepare messages, otherwise the honest node in common admits two different blocks of the same height which contradicts the fact it\u2019s honest. Consistency across different views: Suppose a node received 2f+1 commit message, these 2f+1 nodes form a quorum, denote it as Q1. When an honest node starts view change, it will send its prepared message (contains 2f+1 prepare messages) to new leader. The new leader needs to collect 2f+1 view change messages (denote as quorum Q2) in order to send new view message. Again Q1 and Q2 contains at least one honest node. This node contains 2f+1 prepare messages because it received enough prepare messages before it sent out its commit message. This ensures the same block will be committed by honest nodes across different views. Liveness: Each node has a timer for normal consensus process (with T0 timeout) and a timer for view change process (with k*T1 timeout, where k is how many view changes happened before a validator can switch back to normal mode). When the timer timeout, the node will start view change by increase view by one. In the case of consecutive leaders fail to send correct new view messages, the timeout period of view change timer will be increased to avoid frequently view changes and to make sure eventually enough honest nodes will have same viewID with honest new leader. Fast Byzantine Fault Tolerance As an improvement on PBFT, Harmony\u2019s consensus protocol is linearly scalable in terms of communication complexity, and thus we call it Fast Byzantine Fault Tolerance (FBFT). In FBFT, instead of asking all validators to broadcast their votes, the leader runs a multi-signature signing process to collect the validators\u2019 votes in a O (1) -sized multi-signature and then broadcast it. So instead of receiving O ( N ) signatures, each validator receives only one multi-signature, thus reducing the communication complexity from O(N\u00b2) to O ( N ) . With some modifications in view change message, the view change complexity can also be reduced to O(N). BLS SIGNATURE SCHEME Here we give a very brief and mathematical introduction to Boneh\u2013Lynn\u2013Shacham (BLS) signature scheme which is main distinguisher between FBFT and PBFT. The BLS signature scheme is based on elliptic curve pairing. Let E(Fp) to be the elliptic curve over finite field Fp where p is a large prime number. We pick a basic reference point g on this curve. The private BLS key is a random number \u03b1 sampled from Fp and the public key is \u03b1\u22c5g which is a point on E. Given a message m, the signature is calculated as \u03c3=\u03b1\u22c5H(m) which is a point on E, where H is a hash function to E. A bilinear map on two elliptic curves E1 and E2 is a pairing if e(\u03b1\u22c5g1,g2)=e(g1,\u03b1\u22c5g2),g1\u2208E1,g2\u2208E2 e(g0+g1,g2)=e(g0,g2)+e(g1,g2),g0,g1\u2208E1,g2\u2208E2 e(g1,g2+g3)=e(g1,g2)+e(g1,g3),g1\u2208E1,g2,g3\u2208E2 Now we can see how the k signatures are aggregated and verified by aggregated public key. e(g1,\u03c31+\u22ef+\u03c3k)=e(g1,\u03b11\u22c5H(m)+\u22ef+\u03b1k\u22c5H(m)) =e(\u03b11\u22c5g1+\u22ef+\u03b1k\u22c5g1,H(m)) Notice the aggregated signature looks like normal signature which is a point on elliptic curve, the aggregated public key looks like normal public key which is also a point on elliptic curve. This reduces the 2f+1 signatures into just 1 aggregated signature which is critical to reduce network traffic in consensus protocol. NORMAL MODE In traditional PBFT, the total message size a node sends or receives in each round of consensus O(N\u00b2). This is because in prepare and commit phases, every node need collect 2f+1=O(N) signatures and broadcast them to every node (i.e. O(N) nodes) in the network. By using BLS signature scheme, we aggregate the 2f+1 signatures into one signature, this way the message size in prepare and commit phases are O(1), which reduces the total size from O(N\u00b2) to O(N) in one round. To benefit from BLS scheme, every validator will send prepare and commit message to leader only and the leader is responsible to collect enough >=2f+1 signatures and aggregated them into one aggregated signature, after that the leader send the prepared/committed message in prepare/commit phase respectively. From the leader\u2019s perspective, the three phases are synchronized, but from validators\u2019 point of view, they can still receive messages out of order, e.g. a validator can receive prepared message before announce message, however in this case, its prepare signature will not be included in the prepared message. There are three phases in the normal mode: In announce phase, the leader will broadcast announce message (e.g. the proposal block) to validators. When a validator receives announce message, it enters prepare phase In prepare phase, the validator sends prepare message (e.g. signature on blockhash) to leader. When leader receives enough (i.e. \u22652f+1) prepare messages, it aggregates signatures of prepare messages received from validators and sends out prepared message contains aggregated prepare signatures. Then the leader enters commit phase. A validator enters commit phase when it receives prepared message from the leader. In commit phase, the validator sends commit message (e.g. signature on |blockNum|blockHash|) to leader. When the leader receives enough (i.e. \u22652f+1) commit messages, it aggregates signatures of commit messages received from validators and sends out committed message contains aggregated commit signatures. Then the leader finishes one view/round. A validator finishes one view/round after it receives committed message. When the leader or validator finishes one round, it will restart the consensus timer. In step 3 commit phase, the validator sends commit message with signature on blockNumber and blockHash. This is convenient for the node to quickly determine whether it is out of sync without tricked by the malicious leader. How the consensus process interacts with state syncing is explained in the state syncing mode section. LEADER ELECTION There are two causes for validators to start view change process. One cause is when a validator detects the leader proposed two different announce messages in one view, it will immediately start view change. The other cause is a validator doesn\u2019t make any progress after timeout. There are two kinds of timeouts: timeout in normal consensus mode and timeout in view change mode. In our blockchain, we have the concept of epoch. Each epoch contains X Blocks (e.g. X=1000). In the beginning of each epoch, the committee members are determined by who has staked for this epoch in the beaconchain. The order of the committee members is uniquely determined by the VDF randomness of this epoch. During one epoch, the committee will always stay the same. Suppose the order list is [v0,\u2026,vn]. Then in the beginning of epoch, the leader is v0. If view change happens, the next leader is v1, and so on. Here we assume each validator has equal voting power. VIEW CHANGE MODE The view change process is as follows: When the consensus timer timeouts, a node starts view change by sending view change message including viewID and prepared message (containing \u22652f+1 aggregated signatures) to new leader. If it doesn\u2019t receive prepared message, it just sends view change message including signature on viewID but without prepared message. When the new leader receives enough (\u22652f+1) view change messages, it aggregates signatures of viewID and just pick one prepared message from view change messages. It broadcasts new view message including aggregated signatures as well as the picked prepared message. Then the new leader switches to normal consensus mode. A validator switches to normal consensus node when it receives new view message from the new leader, at the same time, it stops the view change timer and start the consensus timer. If the validator doesn\u2019t receive new view message before view change timeout, it will increase viewID by one and start another view change. The second step requires each validator to send signature on viewID, the purpose is to reduce the size of new view message from O(N) to O(1) when the previous leader is malicious. To be precise, the previous leader can send different aggregated signatures to different validators in prepared phase. As long as the aggregated signature is valid, the validator will accept it and propose it when view change happens. In this scenario, the size of new view message is O(N), because the new leader has to prove the receiving of enough valid view change messages. With everyone signed on viewID, it\u2019s easy for new leader to aggregate the signatures to reduce new view message size to O(1) again. Only this way, we can scale up the number of nodes in the network in the case of view change. STATE SYNCING MODE We allow a node to join and leave freely in blockchain. When a new node joins consensus, it has to do state syncing before it can validate consensus messages. Also, there are situations when a node gets stuck in view change mode. e.g. When a validator has slow network connection, it may not be able to make any progress before timeout. In this case, it will start view change. However, there is no way it can escape from view change mode because all the other nodes are moving forward and the view change will fail. In this case, this node needs to do state syncing to catch up. The basic process is simple. When a node detects it\u2019s out of sync by comparing its current block height with the latest block height in committed message, it will switch to state syncing mode and start doing state syncing. After it finishes state syncing, it switches to normal mode. In order to join the consensus after state syncing finished, a node needs to know who is the current leader and what is the current viewID. One solution is to blindly accept whatever the leader and viewID from the consensus message. This approach gives the malicious leader the chance to send a large viewID along the consensus message to make every validator starts doing consensus. A better way is only accept the leader and viewID information when the node receives the committed message from the network. In this case, the malicious leader cannot trick the new node. But it slows down the process of new node joining consensus because it cannot verify announce and prepared messages until leader and viewID updated. The approach we choose is to add leader and viewID information into the block header. When a node finished state syncing, it can read the information from the latest block header. If during the state syncing, the view change happened, the information from the latest block is outdated. In this case, a new node can still update the leader and viewID information when it receives committed message. STATE TRANSITION The following drawing is the state transition graph of a validator. The state transition graph of a leader is simpler and omitted here. There are 5 modes: 3 normal modes (A: Announce, P: Prepare, C: Commit), view change mode (VC) and state syncing mode (S). The transitions between modes are triggered by different conditions such as receives a specific type of message or meet some conditions like timeout. Condition list: a.m (announce message), p.m (prepared message), c.m (committed message), t.c (try catchup success), t.o (timeout), n.v (new view message), i.s (in sync), o.s (out of sync).","title":"Fast Byzantine Fault Tolerance"},{"location":"learn/tech-zone/tech-deep-sharding/fast-byzantine-fault-tolerance/#fast-byzantine-fault-tolerance","text":"","title":"Fast Byzantine Fault Tolerance"},{"location":"learn/tech-zone/tech-deep-sharding/fast-byzantine-fault-tolerance/#harmonys-fast-byzantine-fault-tolerance","text":"The view change protocol is a core part in any blockchain from which we can tell whether a protocol is permissioned or permissionless and how decentralized it is. The code is here: harmony/consensus We launched our Day ONE Mainnet with a total of 600 nodes on 4 shards on June 28th. In our previous tests, we observed view change (i.e. leader change) happened in some shards due to bad network condition. We also manually triggered view change by killing the leader node as well as other kinds of attacks. The view change happened after the attack and the network keeps going as expected \u2014heck yeah! In the following, we will first explain the basic concepts of byzantine fault tolerance, then second how we improve it to handle large number of nodes in practice, and finally the overall code structure and some implementation details.","title":"Harmony\u2019s Fast Byzantine Fault Tolerance"},{"location":"learn/tech-zone/tech-deep-sharding/fast-byzantine-fault-tolerance/#what-is-byzantine-fault-tolerance","text":"A distributed system consists of multiple nodes where each node is an independent server. They communicate with each other by sending messages over the network and perform some tasks according to the protocol they conform to. There are many types of faults, but they can basically be classified into two major categories. The first kind of faults are node crash, network down, packet loss, etc., where the node had no malicious intention. These are non-byzantine faults. The second type is where a node can be malicious. It can act arbitrarily and not follow the rules of the protocol. For example, a validator can delay or refuse to relay the messages in the network, the leader can propose invalid block, or a node can send different messages to different peers. At worst, malicious nodes may collaborate with each other. These are called Byzantine faults. With these two kinds of faults in mind, there are two properties we want the system to maintain: consistency and liveness . In blockchain terminology, consistency means honest nodes must commit the same block for any given block number/height; liveness means the chain height must keep growing without being stuck. In a permissioned network, where we only have the first type of faults (non-byzantine), this is easier to achieve. For example, we can pick one powerful node as leader and all the other nodes will just listen to what the leader broadcasts and trust any block the leader proposes. Even in this case, we need to watch out for the first kind of faults, especially when it happens to the leader. For a fully decentralized network, we cannot trust any single node and assume the second kind of faults can happen in any node. There is only one fundamental assumption, which is a malicious node cannot forge the signatures other nodes signed. This is guaranteed by cryptography theory, where the difficulty of forging a signature is so high that no computer today can break in any practical time. Things might change when the quantum computer is ready. But at that time, we will use quantum-resistant cryptographic algorithm instead. A Byzantine Fault Tolerant protocol is a protocol that can guarantee the consistency and liveness of the distributed system even when there are malicious nodes in the system. All such protocols have the basic assumption that the number of malicious node is less than some threshold. This is easy to understand, if there are over 50% malicious nodes, then the network is fully controlled by the malicious nodes. In the case of prove of work (PoW) in Bitcoin, the requirement is less than 50% of nodes (in the computation power sense) are malicious. However, the selfish mining lowers the basic assumption to 25%. i.e. the system of PoW will be safe only if less than 25% of nodes (in the sense of computation power) are malicious. There is deep research on Byzantine Fault Tolerance protocol in traditional distributed systems. It is proven that malicious nodes should be less than 33% of a network in the classical paper of Lamport . Later on, the famous practical byzantine fault tolerance paper PBFT makes such system practical. There are still two remaining issues. First, such a system is permissioned, which not allow arbitrary nodes to join and leave. Second, it is not scalable to more than hundreds of nodes. The first issue is due to Sybil Attack, where a malicious user can easily create many fake identities and take over the majority of the network. It is first solved in Satoshi Nakamoto\u2019s Bitcoin whitepaper, where the economic effect is taken into consideration. After proof of work (PoW), there are many new designs such as proof of stake (PoS), proof of authority (PoA) etc. Instead of counting the number of nodes, we counting the amount of voting power. In PoS, the voting power of a node is proportional to its staking amount. The second issue is solved by aggregated signatures using BLS signature scheme which is explained in the FBFT section.","title":"What is Byzantine Fault Tolerance? "},{"location":"learn/tech-zone/tech-deep-sharding/fast-byzantine-fault-tolerance/#practical-byzantine-fault-tolerance","text":"For protocols like Raft and Paxos, they are used to deal with the first kind of system faults. Practical Byzantine Fault Tolerance (PBFT) is one of the first Byzantine fault tolerance protocols used in the real world to deal with the both first and second kinds of faults. We will always assume there are N nodes with at most f malicious nodes, where N=3f+1. There are two modes in the PBFT, the normal consensus (normal in short) mode and the view change mode. The normal mode looks like this (in blockchain, the client request and reply can be ignored): In one view (one view is a similar concept of one round), there are 3 steps/phases: pre-prepare (announce), prepare and commit. In pre-prepare(announce) phase, the leader will broadcast announce message (e.g. the proposal block) to other nodes (called validators). When a validator receives announce message, it enters prepare phase. In prepare phase, after a validator receives announce message, it will broadcast prepare message (e.g. signature on blockhash) to every node. When a validator (including the leader) receives enough (i.e. \u22652f+1 ) prepare messages, it will enter commit phase. In commit phase, a validator (including the leader) will send commit message (e.g. signature on |blockNum|blockHash|) When a validator receives enough (\u22652f+1) commit messages. It can safely commit the block. This ends one round of normal consensus process. Notice that there are some differences between general PBFT and blockchain PBFT. The major difference is that the blockchain is \u201csynchronized\u201d between two blocks, i.e. we cannot proceed to commit block h+1 before commit h. In the traditional PBFT, we can commit client request h+1 before request h. The PBFT will guarantee consistency across all the nodes. In this sense, the blockchain makes consensus process simpler. To be precise, there is a process in PBFT called checkpoint process. A checkpoint is a certificate that all the information with sequence number (in blockchain, it is the block number) less or equal than checkpoint\u2019s sequence number are finalized. In blockchain, each committed block is finalized and can be viewed as a checkpoint. When a validator cannot commit a new block before consensus timeout (\u0394T\u2265T0), the validators will start view change (v\u2192v+1), the new leader is uniquely determined in a predetermined way. If the view change cannot finish before timeout (\u0394T\u2265T1), the validator will propose another view change (v+1\u2192v+2, with view change timeout increases to 2*T1). There are 2 steps/phases in view change mode: A validator starts view change by sending view change message containing \u22652f+1prepare messages to new leader. If it doesn\u2019t receive enough prepare messages, it just send view change message without any prepare message to the new leader. The new leader collects enough (\u22652f+1) view change messages and broadcast new view message containing view change messages it receives. Then the new leader switches to normal mode. A validator switches to normal mode when it receives new view message from the new leader, at the same time, it stops the view change timer and start consensus timer. If the validator doesn\u2019t receive new view message before view change timeout, it will increase viewID by one and start another view change. View change guarantees liveness of the network. During the view change process, we need to make sure the block committed is consistency across view change as well. Simply speaking, the receiving of 2f+1 prepare messages only ensure the consistency in the same view. The receiving of 2f+1 commit messages ensure consistency across different views. When a node receives 2f+1 commit message, it can safely commit the block into the blockchain. The PBFT protocol ensures the same block will be committed by any honest nodes even in the case of view change.","title":"Practical Byzantine Fault Tolerance "},{"location":"learn/tech-zone/tech-deep-sharding/fast-byzantine-fault-tolerance/#consistency-and-liveness","text":"The key concept in PBFT is the quorum. A quorum is any subset with at least 2f+1 nodes. Since there are a total of 3f+1nodes, any two quorums will intersect at least f+1nodes. Based on the assumption that there are at most f malicious nodes, there will be at least one honest node in the intersection of two quorums. This is the reason why we need a quorum to take any action. Consistency in one view: Suppose a node received 2f+1 prepare message, these 2f+1 nodes form a quorum. Notice any two quorums will have at least one honest node in common, it means any two such quorums cannot contain different block hashes in their prepare messages, otherwise the honest node in common admits two different blocks of the same height which contradicts the fact it\u2019s honest. Consistency across different views: Suppose a node received 2f+1 commit message, these 2f+1 nodes form a quorum, denote it as Q1. When an honest node starts view change, it will send its prepared message (contains 2f+1 prepare messages) to new leader. The new leader needs to collect 2f+1 view change messages (denote as quorum Q2) in order to send new view message. Again Q1 and Q2 contains at least one honest node. This node contains 2f+1 prepare messages because it received enough prepare messages before it sent out its commit message. This ensures the same block will be committed by honest nodes across different views. Liveness: Each node has a timer for normal consensus process (with T0 timeout) and a timer for view change process (with k*T1 timeout, where k is how many view changes happened before a validator can switch back to normal mode). When the timer timeout, the node will start view change by increase view by one. In the case of consecutive leaders fail to send correct new view messages, the timeout period of view change timer will be increased to avoid frequently view changes and to make sure eventually enough honest nodes will have same viewID with honest new leader.","title":"CONSISTENCY AND LIVENESS "},{"location":"learn/tech-zone/tech-deep-sharding/fast-byzantine-fault-tolerance/#fast-byzantine-fault-tolerance_1","text":"As an improvement on PBFT, Harmony\u2019s consensus protocol is linearly scalable in terms of communication complexity, and thus we call it Fast Byzantine Fault Tolerance (FBFT). In FBFT, instead of asking all validators to broadcast their votes, the leader runs a multi-signature signing process to collect the validators\u2019 votes in a O (1) -sized multi-signature and then broadcast it. So instead of receiving O ( N ) signatures, each validator receives only one multi-signature, thus reducing the communication complexity from O(N\u00b2) to O ( N ) . With some modifications in view change message, the view change complexity can also be reduced to O(N).","title":"Fast Byzantine Fault Tolerance "},{"location":"learn/tech-zone/tech-deep-sharding/fast-byzantine-fault-tolerance/#bls-signature-scheme","text":"Here we give a very brief and mathematical introduction to Boneh\u2013Lynn\u2013Shacham (BLS) signature scheme which is main distinguisher between FBFT and PBFT. The BLS signature scheme is based on elliptic curve pairing. Let E(Fp) to be the elliptic curve over finite field Fp where p is a large prime number. We pick a basic reference point g on this curve. The private BLS key is a random number \u03b1 sampled from Fp and the public key is \u03b1\u22c5g which is a point on E. Given a message m, the signature is calculated as \u03c3=\u03b1\u22c5H(m) which is a point on E, where H is a hash function to E. A bilinear map on two elliptic curves E1 and E2 is a pairing if e(\u03b1\u22c5g1,g2)=e(g1,\u03b1\u22c5g2),g1\u2208E1,g2\u2208E2 e(g0+g1,g2)=e(g0,g2)+e(g1,g2),g0,g1\u2208E1,g2\u2208E2 e(g1,g2+g3)=e(g1,g2)+e(g1,g3),g1\u2208E1,g2,g3\u2208E2 Now we can see how the k signatures are aggregated and verified by aggregated public key. e(g1,\u03c31+\u22ef+\u03c3k)=e(g1,\u03b11\u22c5H(m)+\u22ef+\u03b1k\u22c5H(m)) =e(\u03b11\u22c5g1+\u22ef+\u03b1k\u22c5g1,H(m)) Notice the aggregated signature looks like normal signature which is a point on elliptic curve, the aggregated public key looks like normal public key which is also a point on elliptic curve. This reduces the 2f+1 signatures into just 1 aggregated signature which is critical to reduce network traffic in consensus protocol.","title":"BLS SIGNATURE SCHEME "},{"location":"learn/tech-zone/tech-deep-sharding/fast-byzantine-fault-tolerance/#normal-mode","text":"In traditional PBFT, the total message size a node sends or receives in each round of consensus O(N\u00b2). This is because in prepare and commit phases, every node need collect 2f+1=O(N) signatures and broadcast them to every node (i.e. O(N) nodes) in the network. By using BLS signature scheme, we aggregate the 2f+1 signatures into one signature, this way the message size in prepare and commit phases are O(1), which reduces the total size from O(N\u00b2) to O(N) in one round. To benefit from BLS scheme, every validator will send prepare and commit message to leader only and the leader is responsible to collect enough >=2f+1 signatures and aggregated them into one aggregated signature, after that the leader send the prepared/committed message in prepare/commit phase respectively. From the leader\u2019s perspective, the three phases are synchronized, but from validators\u2019 point of view, they can still receive messages out of order, e.g. a validator can receive prepared message before announce message, however in this case, its prepare signature will not be included in the prepared message. There are three phases in the normal mode: In announce phase, the leader will broadcast announce message (e.g. the proposal block) to validators. When a validator receives announce message, it enters prepare phase In prepare phase, the validator sends prepare message (e.g. signature on blockhash) to leader. When leader receives enough (i.e. \u22652f+1) prepare messages, it aggregates signatures of prepare messages received from validators and sends out prepared message contains aggregated prepare signatures. Then the leader enters commit phase. A validator enters commit phase when it receives prepared message from the leader. In commit phase, the validator sends commit message (e.g. signature on |blockNum|blockHash|) to leader. When the leader receives enough (i.e. \u22652f+1) commit messages, it aggregates signatures of commit messages received from validators and sends out committed message contains aggregated commit signatures. Then the leader finishes one view/round. A validator finishes one view/round after it receives committed message. When the leader or validator finishes one round, it will restart the consensus timer. In step 3 commit phase, the validator sends commit message with signature on blockNumber and blockHash. This is convenient for the node to quickly determine whether it is out of sync without tricked by the malicious leader. How the consensus process interacts with state syncing is explained in the state syncing mode section.","title":"NORMAL MODE "},{"location":"learn/tech-zone/tech-deep-sharding/fast-byzantine-fault-tolerance/#leader-election","text":"There are two causes for validators to start view change process. One cause is when a validator detects the leader proposed two different announce messages in one view, it will immediately start view change. The other cause is a validator doesn\u2019t make any progress after timeout. There are two kinds of timeouts: timeout in normal consensus mode and timeout in view change mode. In our blockchain, we have the concept of epoch. Each epoch contains X Blocks (e.g. X=1000). In the beginning of each epoch, the committee members are determined by who has staked for this epoch in the beaconchain. The order of the committee members is uniquely determined by the VDF randomness of this epoch. During one epoch, the committee will always stay the same. Suppose the order list is [v0,\u2026,vn]. Then in the beginning of epoch, the leader is v0. If view change happens, the next leader is v1, and so on. Here we assume each validator has equal voting power.","title":"LEADER ELECTION "},{"location":"learn/tech-zone/tech-deep-sharding/fast-byzantine-fault-tolerance/#view-change-mode","text":"The view change process is as follows: When the consensus timer timeouts, a node starts view change by sending view change message including viewID and prepared message (containing \u22652f+1 aggregated signatures) to new leader. If it doesn\u2019t receive prepared message, it just sends view change message including signature on viewID but without prepared message. When the new leader receives enough (\u22652f+1) view change messages, it aggregates signatures of viewID and just pick one prepared message from view change messages. It broadcasts new view message including aggregated signatures as well as the picked prepared message. Then the new leader switches to normal consensus mode. A validator switches to normal consensus node when it receives new view message from the new leader, at the same time, it stops the view change timer and start the consensus timer. If the validator doesn\u2019t receive new view message before view change timeout, it will increase viewID by one and start another view change. The second step requires each validator to send signature on viewID, the purpose is to reduce the size of new view message from O(N) to O(1) when the previous leader is malicious. To be precise, the previous leader can send different aggregated signatures to different validators in prepared phase. As long as the aggregated signature is valid, the validator will accept it and propose it when view change happens. In this scenario, the size of new view message is O(N), because the new leader has to prove the receiving of enough valid view change messages. With everyone signed on viewID, it\u2019s easy for new leader to aggregate the signatures to reduce new view message size to O(1) again. Only this way, we can scale up the number of nodes in the network in the case of view change.","title":"VIEW CHANGE MODE "},{"location":"learn/tech-zone/tech-deep-sharding/fast-byzantine-fault-tolerance/#state-syncing-mode","text":"We allow a node to join and leave freely in blockchain. When a new node joins consensus, it has to do state syncing before it can validate consensus messages. Also, there are situations when a node gets stuck in view change mode. e.g. When a validator has slow network connection, it may not be able to make any progress before timeout. In this case, it will start view change. However, there is no way it can escape from view change mode because all the other nodes are moving forward and the view change will fail. In this case, this node needs to do state syncing to catch up. The basic process is simple. When a node detects it\u2019s out of sync by comparing its current block height with the latest block height in committed message, it will switch to state syncing mode and start doing state syncing. After it finishes state syncing, it switches to normal mode. In order to join the consensus after state syncing finished, a node needs to know who is the current leader and what is the current viewID. One solution is to blindly accept whatever the leader and viewID from the consensus message. This approach gives the malicious leader the chance to send a large viewID along the consensus message to make every validator starts doing consensus. A better way is only accept the leader and viewID information when the node receives the committed message from the network. In this case, the malicious leader cannot trick the new node. But it slows down the process of new node joining consensus because it cannot verify announce and prepared messages until leader and viewID updated. The approach we choose is to add leader and viewID information into the block header. When a node finished state syncing, it can read the information from the latest block header. If during the state syncing, the view change happened, the information from the latest block is outdated. In this case, a new node can still update the leader and viewID information when it receives committed message.","title":"STATE SYNCING MODE "},{"location":"learn/tech-zone/tech-deep-sharding/fast-byzantine-fault-tolerance/#state-transition","text":"The following drawing is the state transition graph of a validator. The state transition graph of a leader is simpler and omitted here. There are 5 modes: 3 normal modes (A: Announce, P: Prepare, C: Commit), view change mode (VC) and state syncing mode (S). The transitions between modes are triggered by different conditions such as receives a specific type of message or meet some conditions like timeout. Condition list: a.m (announce message), p.m (prepared message), c.m (committed message), t.c (try catchup success), t.o (timeout), n.v (new view message), i.s (in sync), o.s (out of sync).","title":"STATE TRANSITION "},{"location":"learn/tech-zone/tech-deep-sharding/future-work/","text":"Future Work Availability Harmony\u2019s architecture centers around the problem of data availability . The key questions are: How fast can the network send data to update states? How small can the updates be encoded to minimize bandwidth? How final can transactions be guaranteed by a subset of the network? Our insight is using fraud proofs and erasure coding to guarantee the efficiency and the security of transactions across shards. Fraud proofs, with a long history in Bitcoin and Ethereum, are used to alert about invalid blocks to all nodes, including clients across shards or clients without the full states. Erasure encoding, also used in Information Dispersion Algorithm (IDA) and RaptorQ multicast protocol, makes optimal tradeoff between liveness and redundancy against attacks. You can read more about our experiments that have implemented IDA in our core protocol here[Insert Link of medium blog on IDA]. Research Ideas We are studying the tradeoffs of Proof-of-Stake. In particular, using checkpoints as in Capser FFG versus instant finality with BFT requires some deeper comparison. Mining incentives and storage rents are the main cryptoeconomics issues for Harmony (or any next-generation base protocols) to design. Also, without a PoW base layer, we are exploring the resilience of PoS against nothing-at-stake and long-range attacks. Some research advances today help privacy and scaling computation, but seemingly not transaction performance for current applications. For example, separating computation from verification and specializing virtual machines for O(log n) verification are groundbreaking results. However, few applications are compute-bound or verification-bound. Networks, in terms of making gigabytes of data available daily to many thousands of nodes, are the bottleneck. There are also well-known techniques that awaits good engineering: WebAssembly backends, language designs with OCaml compilers, and HIPv2 + QUIC. Our long-term goals include using Coq to formally verify our consensus algorithm. We will also investigate many promising results from cryptography research, including stateless clients and proof systems for generalized domains. Cross-shard transactions Cross-shard communication is a key component of any sharding-based blockchains. Cross-shard capability breaks the barrier between shards and extend the utility of a single shard beyond itself. Typically, there are three categories of cross-shard communication: Beacon chain-driven: Some blockchains rely on a beacon chain to achieve transactions across shards. Client-driven: In a client-driven cross-shard transaction, the messages are collected and sent across different shards by the client. This adds an extra burden on the client and is not desirable for adhoc light clients. Shard-driven: In this method, the messages are directly sent by the nodes in one shard to the nodes in another shard, without any external help. Harmony adopts the shard-driven approach for its simplicity and the absence of burden on clients. We believe the benefits of shard-driven communication outweights its drawback. The cost on overall network for shard-driven communication is significant because every cross-shard message is a network-level broadcast which incurs a O(N) network cost. To solve this problem, Harmony use Kademlia routing protocol to reduce the communication complexity to O(logN) . In addition, the data being communicated is encoded with erasure code to ensure the security of cross-shard communication. More details on this in the Networking section. For cross-shard smart contract, we are actively doing research on causal consistency between shards in the cross-shard smart contract execution. We have some preliminary result published in our research forum .","title":"Future Work"},{"location":"learn/tech-zone/tech-deep-sharding/future-work/#future-work","text":"","title":"Future Work"},{"location":"learn/tech-zone/tech-deep-sharding/future-work/#availability","text":"Harmony\u2019s architecture centers around the problem of data availability . The key questions are: How fast can the network send data to update states? How small can the updates be encoded to minimize bandwidth? How final can transactions be guaranteed by a subset of the network? Our insight is using fraud proofs and erasure coding to guarantee the efficiency and the security of transactions across shards. Fraud proofs, with a long history in Bitcoin and Ethereum, are used to alert about invalid blocks to all nodes, including clients across shards or clients without the full states. Erasure encoding, also used in Information Dispersion Algorithm (IDA) and RaptorQ multicast protocol, makes optimal tradeoff between liveness and redundancy against attacks. You can read more about our experiments that have implemented IDA in our core protocol here[Insert Link of medium blog on IDA].","title":"Availability"},{"location":"learn/tech-zone/tech-deep-sharding/future-work/#research-ideas","text":"We are studying the tradeoffs of Proof-of-Stake. In particular, using checkpoints as in Capser FFG versus instant finality with BFT requires some deeper comparison. Mining incentives and storage rents are the main cryptoeconomics issues for Harmony (or any next-generation base protocols) to design. Also, without a PoW base layer, we are exploring the resilience of PoS against nothing-at-stake and long-range attacks. Some research advances today help privacy and scaling computation, but seemingly not transaction performance for current applications. For example, separating computation from verification and specializing virtual machines for O(log n) verification are groundbreaking results. However, few applications are compute-bound or verification-bound. Networks, in terms of making gigabytes of data available daily to many thousands of nodes, are the bottleneck. There are also well-known techniques that awaits good engineering: WebAssembly backends, language designs with OCaml compilers, and HIPv2 + QUIC. Our long-term goals include using Coq to formally verify our consensus algorithm. We will also investigate many promising results from cryptography research, including stateless clients and proof systems for generalized domains.","title":"Research Ideas"},{"location":"learn/tech-zone/tech-deep-sharding/future-work/#cross-shard-transactions","text":"Cross-shard communication is a key component of any sharding-based blockchains. Cross-shard capability breaks the barrier between shards and extend the utility of a single shard beyond itself. Typically, there are three categories of cross-shard communication: Beacon chain-driven: Some blockchains rely on a beacon chain to achieve transactions across shards. Client-driven: In a client-driven cross-shard transaction, the messages are collected and sent across different shards by the client. This adds an extra burden on the client and is not desirable for adhoc light clients. Shard-driven: In this method, the messages are directly sent by the nodes in one shard to the nodes in another shard, without any external help. Harmony adopts the shard-driven approach for its simplicity and the absence of burden on clients. We believe the benefits of shard-driven communication outweights its drawback. The cost on overall network for shard-driven communication is significant because every cross-shard message is a network-level broadcast which incurs a O(N) network cost. To solve this problem, Harmony use Kademlia routing protocol to reduce the communication complexity to O(logN) . In addition, the data being communicated is encoded with erasure code to ensure the security of cross-shard communication. More details on this in the Networking section. For cross-shard smart contract, we are actively doing research on causal consistency between shards in the cross-shard smart contract execution. We have some preliminary result published in our research forum .","title":"Cross-shard transactions"},{"location":"learn/tech-zone/tech-deep-sharding/in-depth-with-near-protocol/","text":"In depth with Near Protocol {% embed url=\"https://youtu.be/dgr1GLV1gzM\" caption=\" Special thanks to Alex Skidanov and Rongjian (RJ) Lan\" %} Topic Overview Beacon chain [ 2:56 ] generates secure randomness stores cross-link hashes from the other shards Attacks on a single shard [ 7:52 ] Cross-shard transactions [ 20:22 ] Consensus [ 24:25 ] Randomness [ 45:04 ] Networking [ 56:56 ] Non-technical [ 1:01:42 ] Mainnet around June/July 2019 Testnet around two months from mid February Questions (paraphrased) 1. a) How many shards will there be when the network launches? ~10 to start (under 100). [ 2:32 ] b) What is the max number of shards supported? The network should support 1000 or 2000 shards, depending on beacon chain\u2019s processing power to verify shard headers and BLS signatures at 500kb or 1mb per block. [ 5:11 ] 2. a) Does the beacon chain produce blocks as frequently as the shard chains? Yes, because it\u2019s running the exact same consensus. b) Can you send transactions to the beacon chain? Yes. 3. Why do you need to cross-link? How does it help? [ 6:37 ] The cross-links on the beacon chain help ensure there is only one canonical chain for a shard. This is to prevent the rare case of a shard being attacked with forking. 4. a) What is the max percentage of malicious actors in the global pool? [ 7:55 ] 25% [ explanation & calculation at 8:50 ] b) Why do we need to cross-link? [1 3:08 ] (Context: given the assumptions/parameters, it seems like the probability of having 33% malicious actors is next to zero. It seems like forking is impossible.) Over time, a single shard can be overtaken or corrupted adaptively after the sharding happens. c) Can someone can adaptively corrupt more than two thirds? Yes, with our resharding mechanism, we periodically shuffle the voting power of validators in each shard, and frequently enough to have a low probability of a single shard being corrupted. [ 14:18 ] 6. How do you prevent 2/3 of a shard being corrupted and creating a fork? [ 15:22 ] We will make sure that this will never happen with a high enough frequency of resharding. [ 17:00 ] 7. How is the beacon chain made more secure than the shard chains? [ 18:30 ] The beacon chain will be assigned more staking eg. two times more. 8. How often are blocks produced? Every few seconds via BFT consensus optimized to scale linearly. 9. How does Alice send money to Bob if Bob is on more than one shard? [ 20:22 ] Create a transaction specifying the source address and destination address. The source shard will debit your balance, generate a proof (eg. a receipt) and send it to the destination shard. This shard will verify that the proof is valid and credit the destination address. 10. a) How do smart contracts express cross-shard invocations? [ 22:00 ] Most of the work is done by a single shard, whereas for cross-shard smart contracts, we are only supporting the \u2018read\u2019 operation, and not the update. b) How does reading work? [ 23:00 ] It\u2019s more like pubsub mechanism. If your smart contract will be reading fields in your other smart contract, you would specify that. Validators in the other shard will publish the field data of interest whenever the data changes. Your shard will listen to that, and execution of your smart contract won\u2019t be blocked. 11. a) How is the reward distributed? [ 27:56 ] Equally, including those that did not participate. b) What is the motivation to participate? Why even be online once I\u2019m assigned? [ 28:04 ] For those too slow to sign, it can be okay, but we\u2019ll drain the voting power of those that continuously fail to sign. [ 29:30 ] c) Does the leader rotate? [ 29:58 ] At first we\u2019ll keep it stable if the leader performs honestly. d) So if the leader wants to punish a validator, could they not include their signature? A filtered validator broadcasts proof that they signed (though the other validators don\u2019t rebroadcast the message). e) How is a leader re-elected and when does that happen? [ 31:42 ] We\u2019ll have a timeout counter based on the normal consensus speed. If the leader doesn\u2019t reach consensus by timeout, everyone is free to initiate the leader change protocol, which will be the same as the traditional PBFT algorithm. f) How is this timeout chosen? What is the process? [ 42:00 ] It\u2019s based on the previous performance, adjusted according to the history and network conditions. g) Why do we need any BFT consensus when we have the cross-link? It would be more efficient. [ 38:02 ] The BFT consensus is the main security safeguard, while the cross-link is another layer of security guarantee. The BFT consensus is a must-have and the cross-link is good to have, in terms of security. 12. If you\u2019re committed to using a partial synchronous algorithm, why not use Tendermint, which does not have a view change? [ 39:20 ] 13. What if the leader just produces empty blocks? [ 40:18 ] 14. Isn\u2019t it a problem that the leader has the sole power to include or exclude transactions? Censoring transactions with the excuse that the block is full. [ 41:12 ] 15. Harmony uses a gossip network. [ 44:15 ] Randomness [45:04] At the start of the epoch, the leader announce to other validators using the previous block hash. Every validator uses the VRF to sign this message back to the leader. Leader waits for F+1 VRF results and aggregates this into a pre-image of the randomness (pRnd) and then run the same PBFT consensus so that it gets committed to the next block. The pre-image is input into the VDF to generate the true randomness (Rnd). The VDF is configured so it\u2019s more than one block time eg. 10. Then you run consensus again and then commit Rnd to block. 1. a) Which VDF will you use? [ 48:26 ] Likely the Ethereum one. b) Ethereum\u2019s VDF will use an ASIC \u2014 do you expect the leader to use this ASIC? No, we can adjust the VDF time to make it longer if the leader doesn\u2019t have the ASIC. 2. Will smart contracts have access to the randomness? [ 51:17 ] We haven\u2019t decided that yet, because there isn\u2019t a defined period for randomness, so you may not have randomness for that block. It\u2019s a question we\u2019re still researching. 3. Theoretical beacon fork situation discussion [ 52:00 ] 4. The security assumption is that the beacon chain will never fork [ 54:50 ] 5. Alex argues that either 1) forks are possible or 2) you don\u2019t need cross-links [ 55:15 ] We\u2019ll guarantee with high probability that the beacon chain won\u2019t have forks by using more staking. We haven\u2019t decided, but before the mainnet, we\u2019ll have a clear analysis of how much the stake should be. Networking [56:56] We\u2019re optimizing the technology at the networking layer. Let\u2019s assume the sender is broadcasting block of size \u2018m\u2019. If we have \u2018d\u2019 neighbours, then we have m*d network load on the sender. When the block is large (eg. 1mb), it will be a bottleneck for the sender. We\u2019re using erasure coding to encode the block with extra erasure code, and then cut it into chunks and equally send to \u2018d\u2019 neighbours. So each neighbour only has a part of the encoded block, incurring a significantly reduced load compared with the sender. 1. How do they recover the (partitioned) block? [ 59:05 ] Nodes communicate among themselves to re-encode the chunks into the block, even if 1/3 of the blocks are malicious and not participating. 2. Why are you using fountain codes? [ 1:00:12 ] Erasure coding is traditionally based on Reed Solomon encoding, which is a fixed parameter. Instead, we\u2019re using RaptorQ fountain code, which is continuous and adaptive eg. at first you can have 30% and then generate additional pieces, bit by bit, which can be part of the reconstruction. This increases the probability of the receiver receiving the whole block. Non-technical [1:01:42] 1. When is the mainnet launch? Around June/July 2019. 2. Testnet? Around two months from mid February.","title":"In depth with Near Protocol"},{"location":"learn/tech-zone/tech-deep-sharding/in-depth-with-near-protocol/#in-depth-with-near-protocol","text":"{% embed url=\"https://youtu.be/dgr1GLV1gzM\" caption=\" Special thanks to Alex Skidanov and Rongjian (RJ) Lan\" %}","title":"In depth with Near Protocol"},{"location":"learn/tech-zone/tech-deep-sharding/in-depth-with-near-protocol/#topic-overview","text":"","title":"Topic Overview"},{"location":"learn/tech-zone/tech-deep-sharding/in-depth-with-near-protocol/#beacon-chain-256","text":"generates secure randomness stores cross-link hashes from the other shards","title":"Beacon chain [2:56] "},{"location":"learn/tech-zone/tech-deep-sharding/in-depth-with-near-protocol/#attacks-on-a-single-shard-752","text":"","title":"Attacks on a single shard [7:52] "},{"location":"learn/tech-zone/tech-deep-sharding/in-depth-with-near-protocol/#cross-shard-transactions-2022","text":"","title":"Cross-shard transactions [20:22] "},{"location":"learn/tech-zone/tech-deep-sharding/in-depth-with-near-protocol/#consensus-2425","text":"","title":"Consensus [24:25] "},{"location":"learn/tech-zone/tech-deep-sharding/in-depth-with-near-protocol/#randomness-4504","text":"","title":"Randomness [45:04] "},{"location":"learn/tech-zone/tech-deep-sharding/in-depth-with-near-protocol/#networking-5656","text":"","title":"Networking [56:56] "},{"location":"learn/tech-zone/tech-deep-sharding/in-depth-with-near-protocol/#non-technical-10142","text":"Mainnet around June/July 2019 Testnet around two months from mid February","title":"Non-technical [1:01:42] "},{"location":"learn/tech-zone/tech-deep-sharding/in-depth-with-near-protocol/#questions-paraphrased","text":"1. a) How many shards will there be when the network launches? ~10 to start (under 100). [ 2:32 ] b) What is the max number of shards supported? The network should support 1000 or 2000 shards, depending on beacon chain\u2019s processing power to verify shard headers and BLS signatures at 500kb or 1mb per block. [ 5:11 ] 2. a) Does the beacon chain produce blocks as frequently as the shard chains? Yes, because it\u2019s running the exact same consensus. b) Can you send transactions to the beacon chain? Yes. 3. Why do you need to cross-link? How does it help? [ 6:37 ] The cross-links on the beacon chain help ensure there is only one canonical chain for a shard. This is to prevent the rare case of a shard being attacked with forking. 4. a) What is the max percentage of malicious actors in the global pool? [ 7:55 ] 25% [ explanation & calculation at 8:50 ] b) Why do we need to cross-link? [1 3:08 ] (Context: given the assumptions/parameters, it seems like the probability of having 33% malicious actors is next to zero. It seems like forking is impossible.) Over time, a single shard can be overtaken or corrupted adaptively after the sharding happens. c) Can someone can adaptively corrupt more than two thirds? Yes, with our resharding mechanism, we periodically shuffle the voting power of validators in each shard, and frequently enough to have a low probability of a single shard being corrupted. [ 14:18 ] 6. How do you prevent 2/3 of a shard being corrupted and creating a fork? [ 15:22 ] We will make sure that this will never happen with a high enough frequency of resharding. [ 17:00 ] 7. How is the beacon chain made more secure than the shard chains? [ 18:30 ] The beacon chain will be assigned more staking eg. two times more. 8. How often are blocks produced? Every few seconds via BFT consensus optimized to scale linearly. 9. How does Alice send money to Bob if Bob is on more than one shard? [ 20:22 ] Create a transaction specifying the source address and destination address. The source shard will debit your balance, generate a proof (eg. a receipt) and send it to the destination shard. This shard will verify that the proof is valid and credit the destination address. 10. a) How do smart contracts express cross-shard invocations? [ 22:00 ] Most of the work is done by a single shard, whereas for cross-shard smart contracts, we are only supporting the \u2018read\u2019 operation, and not the update. b) How does reading work? [ 23:00 ] It\u2019s more like pubsub mechanism. If your smart contract will be reading fields in your other smart contract, you would specify that. Validators in the other shard will publish the field data of interest whenever the data changes. Your shard will listen to that, and execution of your smart contract won\u2019t be blocked. 11. a) How is the reward distributed? [ 27:56 ] Equally, including those that did not participate. b) What is the motivation to participate? Why even be online once I\u2019m assigned? [ 28:04 ] For those too slow to sign, it can be okay, but we\u2019ll drain the voting power of those that continuously fail to sign. [ 29:30 ] c) Does the leader rotate? [ 29:58 ] At first we\u2019ll keep it stable if the leader performs honestly. d) So if the leader wants to punish a validator, could they not include their signature? A filtered validator broadcasts proof that they signed (though the other validators don\u2019t rebroadcast the message). e) How is a leader re-elected and when does that happen? [ 31:42 ] We\u2019ll have a timeout counter based on the normal consensus speed. If the leader doesn\u2019t reach consensus by timeout, everyone is free to initiate the leader change protocol, which will be the same as the traditional PBFT algorithm. f) How is this timeout chosen? What is the process? [ 42:00 ] It\u2019s based on the previous performance, adjusted according to the history and network conditions. g) Why do we need any BFT consensus when we have the cross-link? It would be more efficient. [ 38:02 ] The BFT consensus is the main security safeguard, while the cross-link is another layer of security guarantee. The BFT consensus is a must-have and the cross-link is good to have, in terms of security. 12. If you\u2019re committed to using a partial synchronous algorithm, why not use Tendermint, which does not have a view change? [ 39:20 ] 13. What if the leader just produces empty blocks? [ 40:18 ] 14. Isn\u2019t it a problem that the leader has the sole power to include or exclude transactions? Censoring transactions with the excuse that the block is full. [ 41:12 ] 15. Harmony uses a gossip network. [ 44:15 ]","title":"Questions (paraphrased) "},{"location":"learn/tech-zone/tech-deep-sharding/in-depth-with-near-protocol/#randomness-4504_1","text":"At the start of the epoch, the leader announce to other validators using the previous block hash. Every validator uses the VRF to sign this message back to the leader. Leader waits for F+1 VRF results and aggregates this into a pre-image of the randomness (pRnd) and then run the same PBFT consensus so that it gets committed to the next block. The pre-image is input into the VDF to generate the true randomness (Rnd). The VDF is configured so it\u2019s more than one block time eg. 10. Then you run consensus again and then commit Rnd to block. 1. a) Which VDF will you use? [ 48:26 ] Likely the Ethereum one. b) Ethereum\u2019s VDF will use an ASIC \u2014 do you expect the leader to use this ASIC? No, we can adjust the VDF time to make it longer if the leader doesn\u2019t have the ASIC. 2. Will smart contracts have access to the randomness? [ 51:17 ] We haven\u2019t decided that yet, because there isn\u2019t a defined period for randomness, so you may not have randomness for that block. It\u2019s a question we\u2019re still researching. 3. Theoretical beacon fork situation discussion [ 52:00 ] 4. The security assumption is that the beacon chain will never fork [ 54:50 ] 5. Alex argues that either 1) forks are possible or 2) you don\u2019t need cross-links [ 55:15 ] We\u2019ll guarantee with high probability that the beacon chain won\u2019t have forks by using more staking. We haven\u2019t decided, but before the mainnet, we\u2019ll have a clear analysis of how much the stake should be.","title":"Randomness [45:04] "},{"location":"learn/tech-zone/tech-deep-sharding/in-depth-with-near-protocol/#networking-5656_1","text":"We\u2019re optimizing the technology at the networking layer. Let\u2019s assume the sender is broadcasting block of size \u2018m\u2019. If we have \u2018d\u2019 neighbours, then we have m*d network load on the sender. When the block is large (eg. 1mb), it will be a bottleneck for the sender. We\u2019re using erasure coding to encode the block with extra erasure code, and then cut it into chunks and equally send to \u2018d\u2019 neighbours. So each neighbour only has a part of the encoded block, incurring a significantly reduced load compared with the sender. 1. How do they recover the (partitioned) block? [ 59:05 ] Nodes communicate among themselves to re-encode the chunks into the block, even if 1/3 of the blocks are malicious and not participating. 2. Why are you using fountain codes? [ 1:00:12 ] Erasure coding is traditionally based on Reed Solomon encoding, which is a fixed parameter. Instead, we\u2019re using RaptorQ fountain code, which is continuous and adaptive eg. at first you can have 30% and then generate additional pieces, bit by bit, which can be part of the reconstruction. This increases the probability of the receiver receiving the whole block.","title":"Networking [56:56] "},{"location":"learn/tech-zone/tech-deep-sharding/in-depth-with-near-protocol/#non-technical-10142_1","text":"1. When is the mainnet launch? Around June/July 2019. 2. Testnet? Around two months from mid February.","title":"Non-technical [1:01:42] "},{"location":"learn/tech-zone/tech-deep-sharding/rateless-erasure-code/","text":"Rateless Erasure Code At Harmony, we don\u2019t just look at what is needed to get the job done today \u2014 we want to build something that will get the job done even years from now. This goes for all layers of our technology stack, not just the higher layers closer to our key deliverables\u2014such as smart contracts and consensus\u2014but also lower-level, \u201cmundane\u201d areas such as systems and networking that others tend to take for granted. We do this because we have a strong conviction that the key attributes of our protocol and implementation are driven not just by key components but the entire vertical stack of technologies that integrate together to enable the key deliverable at different levels. If any technology layer leaves much to be desired, the overall result suffers from that. Moreover, the lower level a suboptimal component resides, the wider its blast radius is, the greater its setback becomes, and the more difficult it is to work around or mask the failure. In this post, we are going to talk about one such low-level but critical component: Networking . We will try to keep things simple and more approachable, so if you are already a seasoned networking expert, please bear with our networking-101-style explanations. Please note: These are our current best approaches, but as with any bleeding-edge technological front, what we end up releasing or deploying in production may significantly differ from what we are about to discuss here. End-to-end Communication Preferred Harmony is built upon the end-to-end principle , which recommends that as much of the key logic of an application protocol as possible be pushed toward the end nodes that talk to one another. Nodes are self-contained and do not use middleboxes to communicate messages to other nodes, except in a few cases. Specifically, a node does not send a unicast message to another node over a multi-hop path on an overlay network of other nodes. Why? Because we assume that nodes may be corrupt with a relatively high probability: In the blockchain space, we routinely talk about as few as 67% or even 50% of nodes being honest! Let\u2019s call this probability p . Then if a message gets sent to another node h hops away, the overall probability the unicast message reaching an honest recipient p ^ h . For one-hop, direct end-to-end transmission, the probability of a node reaching the honest node is 67% or 50%; for two hops, 44% or 25%; for three hops; 30% or 12.5%. The probability diminishes exponentially! Unicast messaging over multi-hop P2P overlay with adversaries The exceptions to this principle include: When discovering other nodes; When multicasting a message; and When the limitation in the network topology prohibits direct communication between the sender and the recipient, e.g. due to network address translators (NAT) or network firewalls. HIPv2: Id/Loc, Discovery, Mobility, Multi-homing, NAT Traversal Under the end-to-end model, one major problem needs to be solved: If node A needs to talk directly to another node B without having a default go-to node, how can A discover B and find out where B lives? Let\u2019s examine this problem deeper and see how we solve it. Each networking entity, such as a host or a node, has two kinds of information associated with it : An identifier is a unique piece of information that distinguishes the associated entity from other entities on the network; A locator is a piece of information that the network can use to direct traffic to the associated entity. The early Internet consisted of relatively stable, long-running hosts each holding one statically assigned IP address, which served both as the identifier and as the locator of the host, and many application protocols were built upon this assumption of one-to-one mapping between hosts and IP addresses. However, mobile and multi-homed networking, as well as the exhaustion of IPv4 address space and the resulting need to allocate IP address dynamically broke this one-to-one assumption on the global Internet, and brought the need for separation of identifiers from locators and for a protocol that manages the mapping between the two. The end-to-end principle requires separation of who the sender/receiver are versus where they can be reached. In the Internet Engineering Task Force (IETF) , protocols such as HIPv2 , ILNP , and LISP \u2014no, not the functional programming language\u2014have been proposed to separate the identifier and locator space, each proposal with different characteristics and use cases. Of these, HIPv2, or Host Identity Protocol Version 2, comes the closest to the use case of end nodes identified by cryptographic public-private key pairs, which directly fits the node model of the vast majority of blockchain technologies, including Harmony. As an identifier/locator separation protocol, HIPv2 also provides support for mobility and multi-homing . Mobility support makes it possible to maintain an existing communication channel binding between two nodes despite IP address changes on one or both sides, which happens frequently for mobile nodes which can hop frequently between WiFi and cellular data. Multi-homing support makes it possible for a node to be reachable at and use more than one IP address, which can aid IPv4/IPv6 dual-stacked deployments. HIPv2 also provides an extension for basic NAT traversal , based upon another standards-track technology named Interactive Connectivity Establishment , in order to enable most nodes hidden behind NAT to establish communication channels to each other, further supporting our end-to-end principle. Harmony uses HIPv2 for id/loc, discovery, mobility, multihoming, and NAT traversal. HIPv2 acts as a layer-3.5 protocol, and presents the transport layer with pseudo IP addresses named Host Identity Tags (HITs) . Applications use HITs to communicate to each other, then HIPv2 handles translation between HITs and their underlying IP addresses using DNS and rendezvous mechanisms. We are also developing a DHT-based discovery mechanism on top of HIPv2, which will primarily be used to locate nodes that are unpublished and do not trust any rendezvous mechanisms.Host Identity Tags (HITs) versus IP addresses, in HIPv2 Use of HIPv2 keeps the Harmony protocol lean, obviating the need to resolve node identifier (public key) into IP addresses. RaptorQ: Reliable, Efficient Multicast/Unicast Now that we have solved the who and where problems of communication, we shift our discussion to the what problem \u2014 the messages themselves. Notably, let\u2019s examine these two real problems: How do we fight packet drops and corruptions so as to deliver a message reliably? How do we reliably deliver a multi-recipient message to its N recipients, without having its sender bear the cost of sending messages N times? The first problem is typically solved by incorporating NAKs (negative acknowledgements, or \u201cI didn\u2019t get that, say it again?\u201d signals) into the protocol. This model has two issues: 1) Such NAKs and resulting retransmissions introduce additional delays on the order of round-trip times (RTT) between the sender and the recipient, and 2) it is not easily scalable in the case of one-to-many messaging. The second problem is typically solved by gossiping: Sending not the entire message but a chunk of it to each recipient, and requiring the recipient to relay the chunk to all the other recipients. This way, the overall cost of \u201csharing\u201d such a message is evenly distributed among the sender and all the recipients. Since the gossiping model deviates from the end-to-end principle, a new problem arises: What if some of the recipients could be faulty? What if they are uncooperative and instead keep the received chunk to themselves? RapidChain proposes an information dispersal algorithm (IDA) inspired by earlier research . It uses a combination of Reed-Solomon error correction and Merkle trees to implement secure, reliable multicasting of a large message among at least all cooperative peers, if not all peers. Error correction codes are useful not just for the second multicast problem, but also for the first faulty path problem, such as combatting network-layer failures like packet losses. Error correction codes can fight both problems of packet loss and load-balanced multicast. However, Reed-Solomon code has a fixed code rate, which makes it harder to use for random packet drops. This means that if a message fragment is lost, the sender has no way of knowing which one was lost unless the receiver tells the sender. Again, such receiver-to-sender NAKs and retransmit requests slow down the protocol, especially over a high-latency, low-bandwidth connection (such as on a cellular network) where packet drops are more frequently seen. The IP broadcast industry recognized this problem from early on. In fact, in some cases, the reverse channel for NAK transmission may not even be available, or if it is, it may be much slower, in cases such as satellite broadcasting. So they turned their attention to a strategy combining forward error correction with rateless erasure codes . Unlike a fixed-rate code where there can be only a finite number of error recovery blocks, a rateless erasure code makes it possible for the sender to generate an infinite number of error recovery blocks. (This infinite generation of recovery blocks also gives rateless erasure code another name: \u201c Fountain code .\u201d) Because of this, when the sender of a message does not have confirmation that all necessary recipients\u2014such as a consensus quorum\u2014received and processed the message, it does not have to worry about which of the packets it has sent out was lost: It can simply generate more recovery blocks from the fountain and send it out, until it receives the necessary confirmation (or until it hits a protocol timeout, in the case of a synchronous protocol). Fountain code: Infinitely many carrier pigeons born out of a \u201cfountain\u201d After receiving enough error recovery blocks encoded using a rateless erasure code, regardless which blocks they are, the recipient can reconstruct the original message with very high probability. A rateless erasure code can be constructed with specific target threshold of the number of messages. Good rateless erasure codes also exhibit a phenomenon called cliff effect, which renders the probability of recovering the original message close to 1 when the recipient receives over the target threshold of error recovery blocks. Most rateless erasure codes\u2014such as this , this , this , and this \u2014are similar in relying upon encoding using an XOR-based bipartite graph and belief propagation decoding, and achieve near-optimal coding efficiency. Of these, Harmony uses the state-of-the-art RaptorQ code. This IETF- standardized code has been authored by prominent engineers from companies such as Qualcomm (hi wireless) and Netflix (hi IPTV), which attests to its practical nature. Harmony uses the RaptorQ fountain code, for reliable and load-balanced message passing. Given n overall destination nodes of which k may be corrupt, we construct a code of a target rate such that receiving n - k - Cp encoded blocks of the message is sufficient to recover the original message. (We talk about Cp below.) Then, we send out n encoded blocks using this code, each block to each of the n peers. Peers gossip the encoded block that they receive to other peers, same as in the RapidChain IDA. Assuming k nodes are uncooperative and do not gossip their recovery blocks to other peers, honest nodes will still receive n - k recovery blocks, which are sufficient to reconstruct the original message. After sending the initial burst of n encoded blocks, the sender sporadically generates additional encoded blocks and distributes them to random peers. The recommended delay is half the average round-trip time among nodes (RTT), which can be either configured statically or measured dynamically, with exponential backoff with a low base. The sender can stop generating and sending additional blocks once it confirms that all the necessary recipients (e.g. the quorum of n - k ) have reconstructed and processed the original message. The pessimist constant Cp, a small positive integer, deals with the tiny but non-zero probability that, after receiving the exact threshold number of encoded blocks, the receivers cannot still reconstruct the original message. It can also account for the baseline packet loss. The sender signs the encoded blocks that it generates and sends. This is used in place of a Merkle tree, so that a recipient can validate the block before gossiping it to other peers. We do not use a Merkle tree here because it is hard to use for a potentially unbounded number of nodes\u2014encoded blocks out of the \u201cfountain\u201d\u2014in the tree without sacrificing its security properties. The unicast case is similar to multicast, except: The number of encoded blocks and the target code rate are not governed by the consensus parameter but only by the anticipated packet loss rate; All encoded blocks are directly sent to the recipient; Encoded blocks need not be signed by the sender, because the ESP transport employed in the underlying HIPv2 layer already offers integrity protection of the end-to-end unicast between the sender and the recipient, and the received message, being a unicast message, does not need to be relayed to other peers. UDP Transport, With DCCP/QUIC-inspired Congestion Control Many, if not most, blockchain protocols use TCP as their transport. However, the fully-serialized, byte-oriented nature of TCP suffers from head-of-line blocking problems and other undesirable performance drawbacks. Moreover, we realize a lot of benefits offered by TCP via other means: Forward error correction by RaptorQ already provides a means of reliable transmission with little latency jitter. Error correction block reordering is a non-issue in rateless erasure codes. The consensus layer protocol messages already contain generation markers such as block numbers, so reordering of protocol messages can be detected and handled by the consensus layer. The ESP data plane embedded in the HIPv2 layer handles packet corruption by HMAC . Together, these mostly obviate the need for TCP. Therefore, Harmony departs from using TCP, and uses plain UDP as the base transport, on top of HIPv2 and ESP. Harmony uses UDP as the base transport. Use of plain datagram such as UDP leaves one issue still open: Congestion control. The Internet is a shared resource, and our traffic is multiplexed with countless other network flows on the same link. If the sender can detect that the path to the destination is congested (and packets are getting dropped), the sender would better back off and slow down the rate of transmission, so as to achieve good throughput economy. In other words, the ratio of effective bandwidth to the actual transmission rate should be close to 1. Congestion control is also important in guaranteeing fair use of a shared link. In fact, the IETF FEC Building Block standard, which underlies RaptorQ, requires that a protocol that uses an FEC building block employ a congestion control mechanism, so that the content distribution protocol that uses FEC building blocks may remain a good citizen by not spamming the shared link with an unnecessarily high number of encoded blocks. There have been multiple attempts to implement congestion control over plain datagram protocols such as UDP. Datagram Congestion Control Protocol (DCCP) , a long-time IETF proposed standard, offers a means of congestion control. It has a few modes, named TCP-like and TCP-friendly, with different backoff characteristics. It is implemented in both Linux and FreeBSD. QUIC , another transport protocol based upon UDP developed by Google and implemented in Chrome, also takes congestion control into its own hands, and implements a modern congestion control. It offers much better tolerance against lost packets in terms of bandwidth, but tends to disadvantage (\u201cstarve\u201d) TCP sessions on the same link. We are actively evaluating these different congestion control approaches, and will likely use one of them in the base Harmony protocol. Harmony will implement DCCP or QUIC congestion control. Conclusion This concludes a brief tour around the networking technologies upon which we base our Harmony protocol. Many of you would have noticed by now that this overview does not present a novel, six-page invention complete with fancy mathematical formula or in-depth reasoning, but is rather a combination of existing technologies, some of which even a decade or more old. Not so exciting, one might say. That is a correct observation, and actually there is a reason: Here at Harmony, we believe in pragmatism. We believe in standing on the shoulders of giants, just as most others in the world of blockchain and consensus protocols do. The most practical solution need not be the most novel ones. In fact, it is quite the opposite. At Harmony we believe in pragmatism and past wisdom. Take Google\u2019s datacenter networking fabric as an example. It is a novel application of this thing called Clos network , whose root extends all the way back to the days where telephone network consisted of a criss-cross jungle of clunky electromechanical switches . As those giant monstrosities fell out of favor, so did Clos network as well. However, Google rediscovered Clos network when it was looking for a viable datacenter network design in order to handle a huge amount of east-west network traffic; lo and behold, Clos network lives again, this time in the field of modern, packet-switched networks. The Internet is not exactly a \u201cnew thing\u201d either. Since its inception in mid-70s, a great deal of research and development has gone into it in order to make it one of the most successful innovations of the last 50 years. Not all of those R&D results saw their heyday. Some failed to gain meaningful momentum or traction; others had their application limited to a fairly narrow field. Despite those outcomes, however, the brilliance, novelty, and elegance of these older inventions still persist, waiting to be discovered by people with matching needs. At Harmony, we believe in this too, and aim to find promising building blocks\u2014not just in the present day, but also in the historical archive of Internet technologies, just as Google discovered this French telephone engineer and his 70-year-old invention.","title":"Rateless Erasure Code"},{"location":"learn/tech-zone/tech-deep-sharding/rateless-erasure-code/#rateless-erasure-code","text":"At Harmony, we don\u2019t just look at what is needed to get the job done today \u2014 we want to build something that will get the job done even years from now. This goes for all layers of our technology stack, not just the higher layers closer to our key deliverables\u2014such as smart contracts and consensus\u2014but also lower-level, \u201cmundane\u201d areas such as systems and networking that others tend to take for granted. We do this because we have a strong conviction that the key attributes of our protocol and implementation are driven not just by key components but the entire vertical stack of technologies that integrate together to enable the key deliverable at different levels. If any technology layer leaves much to be desired, the overall result suffers from that. Moreover, the lower level a suboptimal component resides, the wider its blast radius is, the greater its setback becomes, and the more difficult it is to work around or mask the failure. In this post, we are going to talk about one such low-level but critical component: Networking . We will try to keep things simple and more approachable, so if you are already a seasoned networking expert, please bear with our networking-101-style explanations. Please note: These are our current best approaches, but as with any bleeding-edge technological front, what we end up releasing or deploying in production may significantly differ from what we are about to discuss here.","title":"Rateless Erasure Code"},{"location":"learn/tech-zone/tech-deep-sharding/rateless-erasure-code/#end-to-end-communication-preferred","text":"Harmony is built upon the end-to-end principle , which recommends that as much of the key logic of an application protocol as possible be pushed toward the end nodes that talk to one another. Nodes are self-contained and do not use middleboxes to communicate messages to other nodes, except in a few cases. Specifically, a node does not send a unicast message to another node over a multi-hop path on an overlay network of other nodes. Why? Because we assume that nodes may be corrupt with a relatively high probability: In the blockchain space, we routinely talk about as few as 67% or even 50% of nodes being honest! Let\u2019s call this probability p . Then if a message gets sent to another node h hops away, the overall probability the unicast message reaching an honest recipient p ^ h . For one-hop, direct end-to-end transmission, the probability of a node reaching the honest node is 67% or 50%; for two hops, 44% or 25%; for three hops; 30% or 12.5%. The probability diminishes exponentially! Unicast messaging over multi-hop P2P overlay with adversaries The exceptions to this principle include: When discovering other nodes; When multicasting a message; and When the limitation in the network topology prohibits direct communication between the sender and the recipient, e.g. due to network address translators (NAT) or network firewalls.","title":"End-to-end Communication Preferred "},{"location":"learn/tech-zone/tech-deep-sharding/rateless-erasure-code/#hipv2-idloc-discovery-mobility-multi-homing-nat-traversal","text":"Under the end-to-end model, one major problem needs to be solved: If node A needs to talk directly to another node B without having a default go-to node, how can A discover B and find out where B lives? Let\u2019s examine this problem deeper and see how we solve it. Each networking entity, such as a host or a node, has two kinds of information associated with it : An identifier is a unique piece of information that distinguishes the associated entity from other entities on the network; A locator is a piece of information that the network can use to direct traffic to the associated entity. The early Internet consisted of relatively stable, long-running hosts each holding one statically assigned IP address, which served both as the identifier and as the locator of the host, and many application protocols were built upon this assumption of one-to-one mapping between hosts and IP addresses. However, mobile and multi-homed networking, as well as the exhaustion of IPv4 address space and the resulting need to allocate IP address dynamically broke this one-to-one assumption on the global Internet, and brought the need for separation of identifiers from locators and for a protocol that manages the mapping between the two. The end-to-end principle requires separation of who the sender/receiver are versus where they can be reached. In the Internet Engineering Task Force (IETF) , protocols such as HIPv2 , ILNP , and LISP \u2014no, not the functional programming language\u2014have been proposed to separate the identifier and locator space, each proposal with different characteristics and use cases. Of these, HIPv2, or Host Identity Protocol Version 2, comes the closest to the use case of end nodes identified by cryptographic public-private key pairs, which directly fits the node model of the vast majority of blockchain technologies, including Harmony. As an identifier/locator separation protocol, HIPv2 also provides support for mobility and multi-homing . Mobility support makes it possible to maintain an existing communication channel binding between two nodes despite IP address changes on one or both sides, which happens frequently for mobile nodes which can hop frequently between WiFi and cellular data. Multi-homing support makes it possible for a node to be reachable at and use more than one IP address, which can aid IPv4/IPv6 dual-stacked deployments. HIPv2 also provides an extension for basic NAT traversal , based upon another standards-track technology named Interactive Connectivity Establishment , in order to enable most nodes hidden behind NAT to establish communication channels to each other, further supporting our end-to-end principle. Harmony uses HIPv2 for id/loc, discovery, mobility, multihoming, and NAT traversal. HIPv2 acts as a layer-3.5 protocol, and presents the transport layer with pseudo IP addresses named Host Identity Tags (HITs) . Applications use HITs to communicate to each other, then HIPv2 handles translation between HITs and their underlying IP addresses using DNS and rendezvous mechanisms. We are also developing a DHT-based discovery mechanism on top of HIPv2, which will primarily be used to locate nodes that are unpublished and do not trust any rendezvous mechanisms.Host Identity Tags (HITs) versus IP addresses, in HIPv2 Use of HIPv2 keeps the Harmony protocol lean, obviating the need to resolve node identifier (public key) into IP addresses.","title":"HIPv2: Id/Loc, Discovery, Mobility, Multi-homing, NAT Traversal "},{"location":"learn/tech-zone/tech-deep-sharding/rateless-erasure-code/#raptorq-reliable-efficient-multicastunicast","text":"Now that we have solved the who and where problems of communication, we shift our discussion to the what problem \u2014 the messages themselves. Notably, let\u2019s examine these two real problems: How do we fight packet drops and corruptions so as to deliver a message reliably? How do we reliably deliver a multi-recipient message to its N recipients, without having its sender bear the cost of sending messages N times? The first problem is typically solved by incorporating NAKs (negative acknowledgements, or \u201cI didn\u2019t get that, say it again?\u201d signals) into the protocol. This model has two issues: 1) Such NAKs and resulting retransmissions introduce additional delays on the order of round-trip times (RTT) between the sender and the recipient, and 2) it is not easily scalable in the case of one-to-many messaging. The second problem is typically solved by gossiping: Sending not the entire message but a chunk of it to each recipient, and requiring the recipient to relay the chunk to all the other recipients. This way, the overall cost of \u201csharing\u201d such a message is evenly distributed among the sender and all the recipients. Since the gossiping model deviates from the end-to-end principle, a new problem arises: What if some of the recipients could be faulty? What if they are uncooperative and instead keep the received chunk to themselves? RapidChain proposes an information dispersal algorithm (IDA) inspired by earlier research . It uses a combination of Reed-Solomon error correction and Merkle trees to implement secure, reliable multicasting of a large message among at least all cooperative peers, if not all peers. Error correction codes are useful not just for the second multicast problem, but also for the first faulty path problem, such as combatting network-layer failures like packet losses. Error correction codes can fight both problems of packet loss and load-balanced multicast. However, Reed-Solomon code has a fixed code rate, which makes it harder to use for random packet drops. This means that if a message fragment is lost, the sender has no way of knowing which one was lost unless the receiver tells the sender. Again, such receiver-to-sender NAKs and retransmit requests slow down the protocol, especially over a high-latency, low-bandwidth connection (such as on a cellular network) where packet drops are more frequently seen. The IP broadcast industry recognized this problem from early on. In fact, in some cases, the reverse channel for NAK transmission may not even be available, or if it is, it may be much slower, in cases such as satellite broadcasting. So they turned their attention to a strategy combining forward error correction with rateless erasure codes . Unlike a fixed-rate code where there can be only a finite number of error recovery blocks, a rateless erasure code makes it possible for the sender to generate an infinite number of error recovery blocks. (This infinite generation of recovery blocks also gives rateless erasure code another name: \u201c Fountain code .\u201d) Because of this, when the sender of a message does not have confirmation that all necessary recipients\u2014such as a consensus quorum\u2014received and processed the message, it does not have to worry about which of the packets it has sent out was lost: It can simply generate more recovery blocks from the fountain and send it out, until it receives the necessary confirmation (or until it hits a protocol timeout, in the case of a synchronous protocol). Fountain code: Infinitely many carrier pigeons born out of a \u201cfountain\u201d After receiving enough error recovery blocks encoded using a rateless erasure code, regardless which blocks they are, the recipient can reconstruct the original message with very high probability. A rateless erasure code can be constructed with specific target threshold of the number of messages. Good rateless erasure codes also exhibit a phenomenon called cliff effect, which renders the probability of recovering the original message close to 1 when the recipient receives over the target threshold of error recovery blocks. Most rateless erasure codes\u2014such as this , this , this , and this \u2014are similar in relying upon encoding using an XOR-based bipartite graph and belief propagation decoding, and achieve near-optimal coding efficiency. Of these, Harmony uses the state-of-the-art RaptorQ code. This IETF- standardized code has been authored by prominent engineers from companies such as Qualcomm (hi wireless) and Netflix (hi IPTV), which attests to its practical nature. Harmony uses the RaptorQ fountain code, for reliable and load-balanced message passing. Given n overall destination nodes of which k may be corrupt, we construct a code of a target rate such that receiving n - k - Cp encoded blocks of the message is sufficient to recover the original message. (We talk about Cp below.) Then, we send out n encoded blocks using this code, each block to each of the n peers. Peers gossip the encoded block that they receive to other peers, same as in the RapidChain IDA. Assuming k nodes are uncooperative and do not gossip their recovery blocks to other peers, honest nodes will still receive n - k recovery blocks, which are sufficient to reconstruct the original message. After sending the initial burst of n encoded blocks, the sender sporadically generates additional encoded blocks and distributes them to random peers. The recommended delay is half the average round-trip time among nodes (RTT), which can be either configured statically or measured dynamically, with exponential backoff with a low base. The sender can stop generating and sending additional blocks once it confirms that all the necessary recipients (e.g. the quorum of n - k ) have reconstructed and processed the original message. The pessimist constant Cp, a small positive integer, deals with the tiny but non-zero probability that, after receiving the exact threshold number of encoded blocks, the receivers cannot still reconstruct the original message. It can also account for the baseline packet loss. The sender signs the encoded blocks that it generates and sends. This is used in place of a Merkle tree, so that a recipient can validate the block before gossiping it to other peers. We do not use a Merkle tree here because it is hard to use for a potentially unbounded number of nodes\u2014encoded blocks out of the \u201cfountain\u201d\u2014in the tree without sacrificing its security properties. The unicast case is similar to multicast, except: The number of encoded blocks and the target code rate are not governed by the consensus parameter but only by the anticipated packet loss rate; All encoded blocks are directly sent to the recipient; Encoded blocks need not be signed by the sender, because the ESP transport employed in the underlying HIPv2 layer already offers integrity protection of the end-to-end unicast between the sender and the recipient, and the received message, being a unicast message, does not need to be relayed to other peers.","title":"RaptorQ: Reliable, Efficient Multicast/Unicast "},{"location":"learn/tech-zone/tech-deep-sharding/rateless-erasure-code/#udp-transport-with-dccpquic-inspired-congestion-control","text":"Many, if not most, blockchain protocols use TCP as their transport. However, the fully-serialized, byte-oriented nature of TCP suffers from head-of-line blocking problems and other undesirable performance drawbacks. Moreover, we realize a lot of benefits offered by TCP via other means: Forward error correction by RaptorQ already provides a means of reliable transmission with little latency jitter. Error correction block reordering is a non-issue in rateless erasure codes. The consensus layer protocol messages already contain generation markers such as block numbers, so reordering of protocol messages can be detected and handled by the consensus layer. The ESP data plane embedded in the HIPv2 layer handles packet corruption by HMAC . Together, these mostly obviate the need for TCP. Therefore, Harmony departs from using TCP, and uses plain UDP as the base transport, on top of HIPv2 and ESP. Harmony uses UDP as the base transport. Use of plain datagram such as UDP leaves one issue still open: Congestion control. The Internet is a shared resource, and our traffic is multiplexed with countless other network flows on the same link. If the sender can detect that the path to the destination is congested (and packets are getting dropped), the sender would better back off and slow down the rate of transmission, so as to achieve good throughput economy. In other words, the ratio of effective bandwidth to the actual transmission rate should be close to 1. Congestion control is also important in guaranteeing fair use of a shared link. In fact, the IETF FEC Building Block standard, which underlies RaptorQ, requires that a protocol that uses an FEC building block employ a congestion control mechanism, so that the content distribution protocol that uses FEC building blocks may remain a good citizen by not spamming the shared link with an unnecessarily high number of encoded blocks. There have been multiple attempts to implement congestion control over plain datagram protocols such as UDP. Datagram Congestion Control Protocol (DCCP) , a long-time IETF proposed standard, offers a means of congestion control. It has a few modes, named TCP-like and TCP-friendly, with different backoff characteristics. It is implemented in both Linux and FreeBSD. QUIC , another transport protocol based upon UDP developed by Google and implemented in Chrome, also takes congestion control into its own hands, and implements a modern congestion control. It offers much better tolerance against lost packets in terms of bandwidth, but tends to disadvantage (\u201cstarve\u201d) TCP sessions on the same link. We are actively evaluating these different congestion control approaches, and will likely use one of them in the base Harmony protocol. Harmony will implement DCCP or QUIC congestion control.","title":"UDP Transport, With DCCP/QUIC-inspired Congestion Control "},{"location":"learn/tech-zone/tech-deep-sharding/rateless-erasure-code/#conclusion","text":"This concludes a brief tour around the networking technologies upon which we base our Harmony protocol. Many of you would have noticed by now that this overview does not present a novel, six-page invention complete with fancy mathematical formula or in-depth reasoning, but is rather a combination of existing technologies, some of which even a decade or more old. Not so exciting, one might say. That is a correct observation, and actually there is a reason: Here at Harmony, we believe in pragmatism. We believe in standing on the shoulders of giants, just as most others in the world of blockchain and consensus protocols do. The most practical solution need not be the most novel ones. In fact, it is quite the opposite. At Harmony we believe in pragmatism and past wisdom. Take Google\u2019s datacenter networking fabric as an example. It is a novel application of this thing called Clos network , whose root extends all the way back to the days where telephone network consisted of a criss-cross jungle of clunky electromechanical switches . As those giant monstrosities fell out of favor, so did Clos network as well. However, Google rediscovered Clos network when it was looking for a viable datacenter network design in order to handle a huge amount of east-west network traffic; lo and behold, Clos network lives again, this time in the field of modern, packet-switched networks. The Internet is not exactly a \u201cnew thing\u201d either. Since its inception in mid-70s, a great deal of research and development has gone into it in order to make it one of the most successful innovations of the last 50 years. Not all of those R&D results saw their heyday. Some failed to gain meaningful momentum or traction; others had their application limited to a fairly narrow field. Despite those outcomes, however, the brilliance, novelty, and elegance of these older inventions still persist, waiting to be discovered by people with matching needs. At Harmony, we believe in this too, and aim to find promising building blocks\u2014not just in the present day, but also in the historical archive of Internet technologies, just as Google discovered this French telephone engineer and his 70-year-old invention.","title":"Conclusion "},{"location":"learn/tech-zone/tech-deep-sharding/resharding/","text":"Resharding Harmony is a fully sharded chain. It shards transactions validation and network communication but also blockchain state. The sharded nature of our chain allows us to be scalable, parallel processing transactions across all our shards. Though sharding for scalability has its benefits it introduces security challenges for a decentralized network. In a sharded decentralized network, nodes come, stay and may go as they please. This openness may be used by an adversary to formulate join-leave attacks: The adversary operates a large number of nodes, and makes each node systematically leave and re-join the network until the network assigns the node to the specific shard that the adversary wants to take over. Also, if shards remain static, adversary has greater chance of corrupting the shard over time. Thus it is crucial to change node\u2013shard membership over time. To this end, the Harmony network binds node\u2013shard membership to a regular period of time called an epoch, at the end of which the network changes the voting share configuration of its shards. However, as a fully-sharded chain, where every shard maintains its own state, such a reshuffle could incur a tremendous communication overhead. To illustrate this, suppose that, at the end of an epoch, every node is reassigned to a random shard for the next epoch, and all shards share the same probability to be chosen. If there are 100 shards, the chance of a node staying in the same shard is only 1%, so 99% of the nodes in the network are expected to move to another shard and download the shard state from the 1% of the nodes staying in the same shard. Moreover, would such a reshuffle maintain equal shard sizes? To counter these problems, Harmony employs the bounded cuckoo rule to do this efficiently. The name comes from the parasitic behavior of some species of cuckoo, which lays eggs in another bird\u2019s nest, evicting an existing egg from the nest in order to make room for its own egg. Before we get into it, let\u2019s quickly look at the evolution of cuckoo rule, first proposed by Awerbuch and Schneider Awerbuch and Schneider, were then looking at building scalable and robust distributed hash table wanted to handle the presence of adversarial nodes. Cuckoo rule: Cuckoo Rule: A new node is assigned a random number, falling within a interval corresponding to s shard For a new node that wants to join the network, assign a random real number, say between 0 and 1 to a new node. If you imagine, numbers between 0 and 1 divided into n equal length spaces, then node lies in a unique space. The \u201c n \u201d stands for number of shards. Say it lies in the \u201c s \u201d th space from 0. Then node would belong to the \u201c s \u201d shard. Now, consider previous nodes that lie in the s shard. Assign each of them new random numbers. The random numbers fall in other unique spaces from 0 to 1 and get assigned corresponding new shards. (The nodes have been cuckoo-d !) The new intervals that the nodes fall into would correspond to their new shards. Simply put, cuckoo assign a random number to a new node that wants to join the network, the position of that random number indicates the shard number for the node and then cuckoo (move) nodes that are \u201cclose\u201d to that random number (\u201cexisting eggs\u201d), to new random numbers which give them new shards. Thus new nodes can join the network and cause minimum reconfiguration \u2014 change only a few nodes that are in the same space as the new node. Awerbuch and Schneider proved (under some constraints), the resulting shards will be balanced and would each shard contain less than 1/3rd faulty nodes. This type of resharding is also robust to join-leave attack. (There is a bit of mathematics and technical nomenclature we are avoiding here, but this simplification is good to give us the right intuition.) Seems simple, secure and easy to implement! However, a few years later, Sen and Freedman found an adversarial strategy that is able to thwart the cuckoo rule \u2014 the shards no longer remained secure. They found that cuckoo rule may fail because of \u201cbad luck\u201d: adversarial nodes may repeatedly join to the same shard with non-negligible probability, thus increasing the proportion of faulty/adversarial nodes in a shard beyond a fraction for it to be secure. They proposed the following adversarial strategy to make it happen: at the beginning of each round, the adversary would sort all shards by increasing fraction of faulty nodes, and should have a faulty node belonging to the shard with the lowest fraction attempt to rejoin the system. This is to keep the adversary\u2019s existing advantage (corruption ratio). For example, let\u2019s say there are 3 shards with equal size, and an adversary controls 5 corrupt nodes \u2014 2 in the first and second shards, and 1 in the last. If the adversary could afford to let one of them leave/re-join, the most sensible thing would be to move the lone node in the last shard, rather than move a node out of the first or second shard where there are already two corrupt nodes. With the cuckoo rule it has non-negligible probability of succeeding. Sen and Freedman\u2019s approach was to partially modify the cuckoo rule by 1) ensuring the number of nodes cuckoo-d during a join deterministically matches the expected amount, and 2) allowing shards to reject join attempts if they have not received sufficient new nodes since the last join. Using this commensal cuckoo, their fault tolerance for fraction of faulty nodes is 35x larger than that of the cuckoo rule. Commensal Cuckoo Rule Just like the cuckoo rule above a new node attempts to join a shard chosen randomly. Its joining attempt is rejected if that shard has not received sufficient number of cuckoo-ed nodes. If rejected, the node tries again. Once the node joins a shard, c_uckoo_ k nodes chosen randomly from that shard, instead of all nodes in that shard earlier. The Bounded Cuckoo rule that Harmony builds on is even simpler. Note that with Harmony we deal in voting shares and not nodes. The voting share for a node is proportional to the tokens they have staked. Hence cuckoo rule for Harmony is concerned with dividing the voting shares among all the shards. Here is how we do it: Bounded Cuckoo Rule The new node (voting share) joins the shards with larger than median stake and evicts random voting shares (nodes corresponding to them) to shards with less than median stake. [Image Credits: https://cbr.stanford.edu/seminarTalks/zamani.pdf ] The nodes who withdrew their stake before the beginning of the epoch are evicted from the network, while those who keep their stakes stay. The new nodes who staked during this epoch get new voting shares. These voting shares will be randomly assigned to the shards that have more than the median of the total voting shares. Next, a constant number of voting shares from all shards will be randomly re-distributed to the other half of the shards who have less than the median of total voting shares. Our scheme above (based on work by Zamani and Mohavedi ), moves only a constant fraction of shares between shards while provably guaranteeing security under reasonable constraints. We are excited to tell you that the first version of our resharding is already ready \u2014 we are able to now shard new nodes joining into 4 shards (1 beaconchain + 3 regular shards). Take a look at our implementation on GitHub , and try it by downloading our wallet and playing with it on our cello testnet! Let us know if you have questions or want to know more on our forum !","title":"Resharding"},{"location":"learn/tech-zone/tech-deep-sharding/resharding/#resharding","text":"Harmony is a fully sharded chain. It shards transactions validation and network communication but also blockchain state. The sharded nature of our chain allows us to be scalable, parallel processing transactions across all our shards. Though sharding for scalability has its benefits it introduces security challenges for a decentralized network. In a sharded decentralized network, nodes come, stay and may go as they please. This openness may be used by an adversary to formulate join-leave attacks: The adversary operates a large number of nodes, and makes each node systematically leave and re-join the network until the network assigns the node to the specific shard that the adversary wants to take over. Also, if shards remain static, adversary has greater chance of corrupting the shard over time. Thus it is crucial to change node\u2013shard membership over time. To this end, the Harmony network binds node\u2013shard membership to a regular period of time called an epoch, at the end of which the network changes the voting share configuration of its shards. However, as a fully-sharded chain, where every shard maintains its own state, such a reshuffle could incur a tremendous communication overhead. To illustrate this, suppose that, at the end of an epoch, every node is reassigned to a random shard for the next epoch, and all shards share the same probability to be chosen. If there are 100 shards, the chance of a node staying in the same shard is only 1%, so 99% of the nodes in the network are expected to move to another shard and download the shard state from the 1% of the nodes staying in the same shard. Moreover, would such a reshuffle maintain equal shard sizes? To counter these problems, Harmony employs the bounded cuckoo rule to do this efficiently. The name comes from the parasitic behavior of some species of cuckoo, which lays eggs in another bird\u2019s nest, evicting an existing egg from the nest in order to make room for its own egg. Before we get into it, let\u2019s quickly look at the evolution of cuckoo rule, first proposed by Awerbuch and Schneider Awerbuch and Schneider, were then looking at building scalable and robust distributed hash table wanted to handle the presence of adversarial nodes.","title":"Resharding"},{"location":"learn/tech-zone/tech-deep-sharding/resharding/#cuckoo-rule","text":"Cuckoo Rule: A new node is assigned a random number, falling within a interval corresponding to s shard For a new node that wants to join the network, assign a random real number, say between 0 and 1 to a new node. If you imagine, numbers between 0 and 1 divided into n equal length spaces, then node lies in a unique space. The \u201c n \u201d stands for number of shards. Say it lies in the \u201c s \u201d th space from 0. Then node would belong to the \u201c s \u201d shard. Now, consider previous nodes that lie in the s shard. Assign each of them new random numbers. The random numbers fall in other unique spaces from 0 to 1 and get assigned corresponding new shards. (The nodes have been cuckoo-d !) The new intervals that the nodes fall into would correspond to their new shards. Simply put, cuckoo assign a random number to a new node that wants to join the network, the position of that random number indicates the shard number for the node and then cuckoo (move) nodes that are \u201cclose\u201d to that random number (\u201cexisting eggs\u201d), to new random numbers which give them new shards. Thus new nodes can join the network and cause minimum reconfiguration \u2014 change only a few nodes that are in the same space as the new node. Awerbuch and Schneider proved (under some constraints), the resulting shards will be balanced and would each shard contain less than 1/3rd faulty nodes. This type of resharding is also robust to join-leave attack. (There is a bit of mathematics and technical nomenclature we are avoiding here, but this simplification is good to give us the right intuition.) Seems simple, secure and easy to implement! However, a few years later, Sen and Freedman found an adversarial strategy that is able to thwart the cuckoo rule \u2014 the shards no longer remained secure. They found that cuckoo rule may fail because of \u201cbad luck\u201d: adversarial nodes may repeatedly join to the same shard with non-negligible probability, thus increasing the proportion of faulty/adversarial nodes in a shard beyond a fraction for it to be secure. They proposed the following adversarial strategy to make it happen: at the beginning of each round, the adversary would sort all shards by increasing fraction of faulty nodes, and should have a faulty node belonging to the shard with the lowest fraction attempt to rejoin the system. This is to keep the adversary\u2019s existing advantage (corruption ratio). For example, let\u2019s say there are 3 shards with equal size, and an adversary controls 5 corrupt nodes \u2014 2 in the first and second shards, and 1 in the last. If the adversary could afford to let one of them leave/re-join, the most sensible thing would be to move the lone node in the last shard, rather than move a node out of the first or second shard where there are already two corrupt nodes. With the cuckoo rule it has non-negligible probability of succeeding. Sen and Freedman\u2019s approach was to partially modify the cuckoo rule by 1) ensuring the number of nodes cuckoo-d during a join deterministically matches the expected amount, and 2) allowing shards to reject join attempts if they have not received sufficient new nodes since the last join. Using this commensal cuckoo, their fault tolerance for fraction of faulty nodes is 35x larger than that of the cuckoo rule.","title":"Cuckoo rule: "},{"location":"learn/tech-zone/tech-deep-sharding/resharding/#commensal-cuckoo-rule","text":"Just like the cuckoo rule above a new node attempts to join a shard chosen randomly. Its joining attempt is rejected if that shard has not received sufficient number of cuckoo-ed nodes. If rejected, the node tries again. Once the node joins a shard, c_uckoo_ k nodes chosen randomly from that shard, instead of all nodes in that shard earlier. The Bounded Cuckoo rule that Harmony builds on is even simpler. Note that with Harmony we deal in voting shares and not nodes. The voting share for a node is proportional to the tokens they have staked. Hence cuckoo rule for Harmony is concerned with dividing the voting shares among all the shards. Here is how we do it:","title":"Commensal Cuckoo Rule "},{"location":"learn/tech-zone/tech-deep-sharding/resharding/#bounded-cuckoo-rule","text":"The new node (voting share) joins the shards with larger than median stake and evicts random voting shares (nodes corresponding to them) to shards with less than median stake. [Image Credits: https://cbr.stanford.edu/seminarTalks/zamani.pdf ] The nodes who withdrew their stake before the beginning of the epoch are evicted from the network, while those who keep their stakes stay. The new nodes who staked during this epoch get new voting shares. These voting shares will be randomly assigned to the shards that have more than the median of the total voting shares. Next, a constant number of voting shares from all shards will be randomly re-distributed to the other half of the shards who have less than the median of total voting shares. Our scheme above (based on work by Zamani and Mohavedi ), moves only a constant fraction of shares between shards while provably guaranteeing security under reasonable constraints. We are excited to tell you that the first version of our resharding is already ready \u2014 we are able to now shard new nodes joining into 4 shards (1 beaconchain + 3 regular shards). Take a look at our implementation on GitHub , and try it by downloading our wallet and playing with it on our cello testnet! Let us know if you have questions or want to know more on our forum !","title":"Bounded Cuckoo Rule "},{"location":"learn/tech-zone/tech-deep-sharding/unbiasable-randomness/","text":"Unbiasable Randomness Sharding in blockchain involves the methodology of assigning nodes into different shards. Nodes within the same shards forms a committee and run consensus in parallel. Various approaches have been proposed to assign nodes into shards such as randomness-based sharding in Omniledger and RapidChain [1,2], location-based sharding, and centrally-controlled sharding. Out of all the approaches, randomness-based sharding has been recognized as the most secure solution. In randomness-based sharding, a mutually agreed random number is used to determine the sharding assignment for each node. The random number must have the following properties: Unpredictable: No one should be able to predict the random number before it\u2019s generated. Unbiasable: The process of generating the random number should not be bias-able by the participants. Verifiable: The validity of the generated random number should be verifiable. Scalable: The algorithm of randomness generation should scale to large number of participants. Omniledger uses the RandHound [3] protocol, which is a leader-driven distributed randomness generation (DRG) process that involves PVSS (Publicly Verifiable Secret Sharing) and Byzantine Agreement. RandHound is a O(n*c2) complex protocol that divides participant nodes into multiple groups of size c. It achieves the first three properties above but is impractically slow to qualify as scalable. RapidChain [2] takes an easier and faster approach by letting each participant do VSS (Verifiable Secret Sharing) and using the combined secret shares as the resulting randomness. Unfortunately, this protocol is not secure because the malicious nodes can send inconsistent shares to different nodes [3]. Besides, RapidChain [2] does not describe how the nodes reach consensus on the multiple versions of reconstructed randomness. In addition, Algorand relies on the VRF-based (Verifiable Random Function) cryptographic sortition to select the group of consensus validators. The Ethereum 2.0 design proposed the use of VDF (Verifiable Delay Function) [4] to delay the revelation of the actual random number so as to prevent last-revealer attack. VDF [4] is a recently studied cryptographic primitive which takes an adjustable minimum amount of time to compute and the result can be verified immediately. Harmony\u2019s approach borrows elements from the above works, but differs from them in the following ways. First, Harmony\u2019s DRG protocol is O(n) complex, which is at least an order of magnitude faster than RandHound. Second, unlike RapidChain\u2019s simple VSS-based approach, ours is unbiasable and verifiable. Third, compared to Ethereum 2.0\u2019s solution, our approach uses BFT consensus to provide finality to the random number. Besides, the DRG protocol runs naturally with the shard committee of a leader and many validators. Specifically, the protocol contains the following steps: A leader sends an init message with the hash of the last block H(Bn-1) to all the validators to start the DRG protocol. For each validator i, after receiving the init message, a VRF is computed to create a random number ri and a proof pi: (ri, pi)=VRF(ski, H(Bn-1), v) , where ski is the secret key of validator i and v is the current view number of consensus. Then, each validator sends back (ri, pi) to the leader. The leader waits until it receives f+1 valid random numbers and combine them with XOR operation to get the random number preimage pRnd. The leader runs BFT (discussed in \u00a72) among all the validators to reach consensus on the pRnd and commit it in block Bn. After pRnd is committed, the leader starts computing the actual randomness Rnd=VDF(pRnd, T), where T is the VDF difficulty and is set algorithmically such that the randomness can only be computed after k blocks. Once Rnd is computed, the leader initiates a BFT among all validators to agree on the validity of Rnd and finally commit the randomness into the blockchain. The use of VDF here is to provably delay the revelation of Rnd and avoid malicious leader biasing the randomness by specifically selecting a subset of the VRF random numbers. With VDF, the leader won\u2019t be able to know what\u2019s the actual randomness before the pRnd is committed into the blockchain. Therefore, the best a malicious leader can do is either blindly commiting the randomness pRnd, or stalling the protocol by not committing the pRnd. The former is the same as the honest behavior. The latter won\u2019t cause much damage as the same timeout mechanism in PBFT will be used to switch the leader and restart the protocol. [1] E. Kokoris-Kogias, P. Jovanovic, L. Gasser, N. Gailly, E. Syta, and B. Ford, \u201cOmniledger: A secure, scale-out, decentralized ledger via sharding,\u201d in 2018 IEEE Symposium on Security and Privacy (SP), pp. 19\u201334, 2018. https://eprint.iacr.org/2017/406.pdf 2 [2] M. Zamani, M. Movahedi, and M. Raykova, \u201cRapidChain: A Fast Blockchain Protocol via Full Sharding.\u201d Cryptology ePrint Archive, Report 2018/460, 2018. https://eprint.iacr.org/2018/460 . [3] E. Syta, P. Jovanovic, E. Kokoris-Kogias, N. Gailly, L. Gasser, I. Khoffi, M. J. Fischer, and B. Ford. Scalable Bias-Resistant Distributed Randomness. In 38th IEEE Symposium on Security and Privacy, May 2017. https://eprint.iacr.org/2016/1067.pdf 1 [4] Dan Boneh, Joseph Bonneau, Benedikt B\u00fcnz, and Ben Fisch. Verifiable delay functions. In CRYPTO 2018, 2018. https://eprint.iacr.org/2018/601.pdf 3 __","title":"Unbiasable Randomness"},{"location":"learn/tech-zone/tech-deep-sharding/unbiasable-randomness/#unbiasable-randomness","text":"Sharding in blockchain involves the methodology of assigning nodes into different shards. Nodes within the same shards forms a committee and run consensus in parallel. Various approaches have been proposed to assign nodes into shards such as randomness-based sharding in Omniledger and RapidChain [1,2], location-based sharding, and centrally-controlled sharding. Out of all the approaches, randomness-based sharding has been recognized as the most secure solution. In randomness-based sharding, a mutually agreed random number is used to determine the sharding assignment for each node. The random number must have the following properties: Unpredictable: No one should be able to predict the random number before it\u2019s generated. Unbiasable: The process of generating the random number should not be bias-able by the participants. Verifiable: The validity of the generated random number should be verifiable. Scalable: The algorithm of randomness generation should scale to large number of participants. Omniledger uses the RandHound [3] protocol, which is a leader-driven distributed randomness generation (DRG) process that involves PVSS (Publicly Verifiable Secret Sharing) and Byzantine Agreement. RandHound is a O(n*c2) complex protocol that divides participant nodes into multiple groups of size c. It achieves the first three properties above but is impractically slow to qualify as scalable. RapidChain [2] takes an easier and faster approach by letting each participant do VSS (Verifiable Secret Sharing) and using the combined secret shares as the resulting randomness. Unfortunately, this protocol is not secure because the malicious nodes can send inconsistent shares to different nodes [3]. Besides, RapidChain [2] does not describe how the nodes reach consensus on the multiple versions of reconstructed randomness. In addition, Algorand relies on the VRF-based (Verifiable Random Function) cryptographic sortition to select the group of consensus validators. The Ethereum 2.0 design proposed the use of VDF (Verifiable Delay Function) [4] to delay the revelation of the actual random number so as to prevent last-revealer attack. VDF [4] is a recently studied cryptographic primitive which takes an adjustable minimum amount of time to compute and the result can be verified immediately. Harmony\u2019s approach borrows elements from the above works, but differs from them in the following ways. First, Harmony\u2019s DRG protocol is O(n) complex, which is at least an order of magnitude faster than RandHound. Second, unlike RapidChain\u2019s simple VSS-based approach, ours is unbiasable and verifiable. Third, compared to Ethereum 2.0\u2019s solution, our approach uses BFT consensus to provide finality to the random number. Besides, the DRG protocol runs naturally with the shard committee of a leader and many validators. Specifically, the protocol contains the following steps: A leader sends an init message with the hash of the last block H(Bn-1) to all the validators to start the DRG protocol. For each validator i, after receiving the init message, a VRF is computed to create a random number ri and a proof pi: (ri, pi)=VRF(ski, H(Bn-1), v) , where ski is the secret key of validator i and v is the current view number of consensus. Then, each validator sends back (ri, pi) to the leader. The leader waits until it receives f+1 valid random numbers and combine them with XOR operation to get the random number preimage pRnd. The leader runs BFT (discussed in \u00a72) among all the validators to reach consensus on the pRnd and commit it in block Bn. After pRnd is committed, the leader starts computing the actual randomness Rnd=VDF(pRnd, T), where T is the VDF difficulty and is set algorithmically such that the randomness can only be computed after k blocks. Once Rnd is computed, the leader initiates a BFT among all validators to agree on the validity of Rnd and finally commit the randomness into the blockchain. The use of VDF here is to provably delay the revelation of Rnd and avoid malicious leader biasing the randomness by specifically selecting a subset of the VRF random numbers. With VDF, the leader won\u2019t be able to know what\u2019s the actual randomness before the pRnd is committed into the blockchain. Therefore, the best a malicious leader can do is either blindly commiting the randomness pRnd, or stalling the protocol by not committing the pRnd. The former is the same as the honest behavior. The latter won\u2019t cause much damage as the same timeout mechanism in PBFT will be used to switch the leader and restart the protocol. [1] E. Kokoris-Kogias, P. Jovanovic, L. Gasser, N. Gailly, E. Syta, and B. Ford, \u201cOmniledger: A secure, scale-out, decentralized ledger via sharding,\u201d in 2018 IEEE Symposium on Security and Privacy (SP), pp. 19\u201334, 2018. https://eprint.iacr.org/2017/406.pdf 2 [2] M. Zamani, M. Movahedi, and M. Raykova, \u201cRapidChain: A Fast Blockchain Protocol via Full Sharding.\u201d Cryptology ePrint Archive, Report 2018/460, 2018. https://eprint.iacr.org/2018/460 . [3] E. Syta, P. Jovanovic, E. Kokoris-Kogias, N. Gailly, L. Gasser, I. Khoffi, M. J. Fischer, and B. Ford. Scalable Bias-Resistant Distributed Randomness. In 38th IEEE Symposium on Security and Privacy, May 2017. https://eprint.iacr.org/2016/1067.pdf 1 [4] Dan Boneh, Joseph Bonneau, Benedikt B\u00fcnz, and Ben Fisch. Verifiable delay functions. In CRYPTO 2018, 2018. https://eprint.iacr.org/2018/601.pdf 3 __","title":"Unbiasable Randomness"},{"location":"learn/tech-zone/use-cases/","text":"Use Cases","title":"Use Cases"},{"location":"learn/tech-zone/use-cases/#use-cases","text":"","title":"Use Cases"},{"location":"learn/tech-zone/use-cases/data-marketplace-for-scientists-a-new-hope/","text":"Data Marketplace for Scientists: A New Hope Decentralized ledger technology promises to make data open and immutable. In explaining what \u201cblockchain\u201d is to colleagues outside of the tech industry, we sometimes say it is like putting a ledger up in the sky \u2014 everybody can see the content, and nobody can tamper with it unilaterally. Paradoxically, by putting the data out in the open via this promising new technology, we can also preserve data privacy . This is because we can encrypt the data before we put it up on an open blockchain. By giving the keys only to the people we want, and recording the access history on key usage (on blockchain too, no less), the promise is eventually we will have the best of both worlds \u2014 data that are at once open and transparent, and yet they go only where they are supposed to go. In the past months, numerous projects have come into existence to tackle the issue of health and medical records (such as these and these ). The selling point has mostly been from the perspective of a patient: how does one share one\u2019s medical records, to just the right people (doctors treating one for a particular disease), and the right people only (not potential employers, for example)? How do we keep all the data in one common space so we don\u2019t need to worry about moving them around (which inevitably increases the risk of leakage), and yet can let data be accessed by multiple people securely only if we want them to be? So far, the idea has been promising. But for people who live relatively boring lives such as ourselves, privacy is a relatively minor issue \u2014 at least as far as our own medical records are concerned. As scientists though, we have other reasons to be excited. We approach the problem from the perspective of (socio-)biomedical scientists. Our jobs are to collect and analyze data, to understand how diseases work, in order to figure out ways to treat them. To follow the example of health records, data are precious \u2018goods\u2019 to us. We write proposals to compete for grants to allow ourselves to obtain these goods. In the past couple of years, we have seen many large-scale projects from governments and major research universities tackling mental health problems such as depression in exactly this way. Numerous phone apps have been written to facilitate the collection of such data. Promising as they are, these projects face several obstacles for which decentralized ledger technology may provide solutions. To start, building quality smartphone apps often costs more than academics are prepared for, especially because we don\u2019t necessarily have the connections to shop around wisely. There are open-source platforms (e.g., this Android-based framework ) that are usable, but non-professionally built apps tend to get uninstalled eventually. People get annoyed when these apps drain the batteries of their phones. Lacking an appealing interface also doesn\u2019t help. People get bored and tired of using over time. Overall, getting good data is difficult. People may not want to sacrifice too much of their privacy. But more importantly, it is often the case that providing data is work : Are you willing to report on your mood and thoughts in details by the hour? How frequently are you willing to do a blood test? Traditionally, we pay subjects some small amount of money to compensate for their time. But increasingly, there is a recognition that we need to pay people more substantively for the trouble they take in providing data of quality . And yet, scientific budgets are ever limited. Which is perhaps why scientists are increasingly emphasizing the need and benefits of data sharing. Data are non-rival goods . Once a piece of data is there, your having it doesn\u2019t directly and necessarily diminish the value of my having it . This is unlike a cake, which cannot be eaten twice. For data, it seems that there is every reason to share; it could only make everybody happier. Unfortunately, in reality, this is only partly true. Companies are hoarding data instead of sharing despite the big gains to the society as a whole. The phenomenon is not limited to the industry but also in science as well. After all, science involves competition too. Having taken the trouble to collect the data, researchers, especially the junior ones, understandably want to be the first one to access them, to generate insights and publish papers before others can. While funding agencies and journals often enforce mandatory sharing, in reality, compliance can sometimes be less than prompt and enthusiastic. Blockchain can turn wasteful competition between large-scale science projects into synergy. If you talk to some economists, they may say this is exactly when a firm can step in to help . Imagine a company collecting data on many scientists\u2019 behalf. By pooling together the resources of numerous major projects from different funding agencies and universities, it can build a single best platform for data collection. It can collect a lot more data, to be shared among the different researchers. Of course, in some instances, it does already happen to some limited extent (such as in the use of the Amazon Mechanical Turk system by behavioral psychologists). But some scientists are understandably skeptical of private companies making a profit off of their academic pursuits. Overall, it just doesn\u2019t happen often enough. With decentralized ledger technology, we can ensure the transparency that science needs . Researchers should not be beholden to a company. Instead of having many independent projects all claiming to be doing big data, we can be doing really big data, via platforms that are set up with minimal need for centralized governance. For human health data, we can pay the subjects generously to contractually attract and ensure compliance and quality, as if we are treating data provision as prized labor . The different researchers may want their data in slightly different ways, and some may want to share only after N number of papers are published. With smart contracts , even intricate propositions like \u2014 \u201cwithin the first year, people can only access the data for purpose of replication and review; after that, people can publish on topics not including keywords such as XYZ, and then after 2 years, all restrictions are lifted\u201d \u2014 can be entertained. (Not saying we encourage restricted sharing, but to our minds, restricted sharing is better than no sharing.) Our colleagues at Harmony are working on a new high performance blockchain protocol that can scale to serve the types of data marketplaces we envision. With a scalable protocol that preserves decentralization and security (privacy), we can unleash the next wave of health innovation that seems both so promising, yet out of reach with today\u2019s systems. Kayuet Liu is an Associate Professor at the Department of Sociology, UCLA. Hakwan Lau is a Professor at the Department of Psychology, UCLA. Both are team members of Harmony : open consensus for 10B people.","title":"Data Marketplace for Scientists: A New Hope"},{"location":"learn/tech-zone/use-cases/data-marketplace-for-scientists-a-new-hope/#data-marketplace-for-scientists-a-new-hope","text":"Decentralized ledger technology promises to make data open and immutable. In explaining what \u201cblockchain\u201d is to colleagues outside of the tech industry, we sometimes say it is like putting a ledger up in the sky \u2014 everybody can see the content, and nobody can tamper with it unilaterally. Paradoxically, by putting the data out in the open via this promising new technology, we can also preserve data privacy . This is because we can encrypt the data before we put it up on an open blockchain. By giving the keys only to the people we want, and recording the access history on key usage (on blockchain too, no less), the promise is eventually we will have the best of both worlds \u2014 data that are at once open and transparent, and yet they go only where they are supposed to go. In the past months, numerous projects have come into existence to tackle the issue of health and medical records (such as these and these ). The selling point has mostly been from the perspective of a patient: how does one share one\u2019s medical records, to just the right people (doctors treating one for a particular disease), and the right people only (not potential employers, for example)? How do we keep all the data in one common space so we don\u2019t need to worry about moving them around (which inevitably increases the risk of leakage), and yet can let data be accessed by multiple people securely only if we want them to be? So far, the idea has been promising. But for people who live relatively boring lives such as ourselves, privacy is a relatively minor issue \u2014 at least as far as our own medical records are concerned. As scientists though, we have other reasons to be excited. We approach the problem from the perspective of (socio-)biomedical scientists. Our jobs are to collect and analyze data, to understand how diseases work, in order to figure out ways to treat them. To follow the example of health records, data are precious \u2018goods\u2019 to us. We write proposals to compete for grants to allow ourselves to obtain these goods. In the past couple of years, we have seen many large-scale projects from governments and major research universities tackling mental health problems such as depression in exactly this way. Numerous phone apps have been written to facilitate the collection of such data.","title":"Data Marketplace for Scientists: A New Hope"},{"location":"learn/tech-zone/use-cases/data-marketplace-for-scientists-a-new-hope/#promising-as-they-are-these-projects-face-several-obstacles-for-which-decentralized-ledger-technology-may-provide-solutions","text":"To start, building quality smartphone apps often costs more than academics are prepared for, especially because we don\u2019t necessarily have the connections to shop around wisely. There are open-source platforms (e.g., this Android-based framework ) that are usable, but non-professionally built apps tend to get uninstalled eventually. People get annoyed when these apps drain the batteries of their phones. Lacking an appealing interface also doesn\u2019t help. People get bored and tired of using over time. Overall, getting good data is difficult. People may not want to sacrifice too much of their privacy. But more importantly, it is often the case that providing data is work : Are you willing to report on your mood and thoughts in details by the hour? How frequently are you willing to do a blood test? Traditionally, we pay subjects some small amount of money to compensate for their time. But increasingly, there is a recognition that we need to pay people more substantively for the trouble they take in providing data of quality . And yet, scientific budgets are ever limited. Which is perhaps why scientists are increasingly emphasizing the need and benefits of data sharing.","title":"Promising as they are, these projects face several obstacles for which decentralized ledger technology may provide solutions. "},{"location":"learn/tech-zone/use-cases/data-marketplace-for-scientists-a-new-hope/#data-are-non-rival-goods","text":"Once a piece of data is there, your having it doesn\u2019t directly and necessarily diminish the value of my having it . This is unlike a cake, which cannot be eaten twice. For data, it seems that there is every reason to share; it could only make everybody happier. Unfortunately, in reality, this is only partly true. Companies are hoarding data instead of sharing despite the big gains to the society as a whole. The phenomenon is not limited to the industry but also in science as well. After all, science involves competition too. Having taken the trouble to collect the data, researchers, especially the junior ones, understandably want to be the first one to access them, to generate insights and publish papers before others can. While funding agencies and journals often enforce mandatory sharing, in reality, compliance can sometimes be less than prompt and enthusiastic.","title":"Data are non-rival goods. "},{"location":"learn/tech-zone/use-cases/data-marketplace-for-scientists-a-new-hope/#blockchain-can-turn-wasteful-competition-between-large-scale-science-projects-into-synergy","text":"If you talk to some economists, they may say this is exactly when a firm can step in to help . Imagine a company collecting data on many scientists\u2019 behalf. By pooling together the resources of numerous major projects from different funding agencies and universities, it can build a single best platform for data collection. It can collect a lot more data, to be shared among the different researchers. Of course, in some instances, it does already happen to some limited extent (such as in the use of the Amazon Mechanical Turk system by behavioral psychologists). But some scientists are understandably skeptical of private companies making a profit off of their academic pursuits. Overall, it just doesn\u2019t happen often enough. With decentralized ledger technology, we can ensure the transparency that science needs . Researchers should not be beholden to a company. Instead of having many independent projects all claiming to be doing big data, we can be doing really big data, via platforms that are set up with minimal need for centralized governance. For human health data, we can pay the subjects generously to contractually attract and ensure compliance and quality, as if we are treating data provision as prized labor . The different researchers may want their data in slightly different ways, and some may want to share only after N number of papers are published. With smart contracts , even intricate propositions like \u2014 \u201cwithin the first year, people can only access the data for purpose of replication and review; after that, people can publish on topics not including keywords such as XYZ, and then after 2 years, all restrictions are lifted\u201d \u2014 can be entertained. (Not saying we encourage restricted sharing, but to our minds, restricted sharing is better than no sharing.) Our colleagues at Harmony are working on a new high performance blockchain protocol that can scale to serve the types of data marketplaces we envision. With a scalable protocol that preserves decentralization and security (privacy), we can unleash the next wave of health innovation that seems both so promising, yet out of reach with today\u2019s systems. Kayuet Liu is an Associate Professor at the Department of Sociology, UCLA. Hakwan Lau is a Professor at the Department of Psychology, UCLA. Both are team members of Harmony : open consensus for 10B people.","title":"Blockchain can turn wasteful competition between large-scale science projects into synergy. "},{"location":"resources/breakdown/","text":"Ecosystem Breakdown for Developers Following are the key components and repositories for the Harmony Ecosystem covered in this guide. Harmony Ecosystem Diagram The below diagram can be clicked upon to bring up an interactive image linking to all the component documentation. Protocol Developers Harmony Protocol : Harmony Core Protocol Consensus : Harmony Sharded Proof of Work with BLS key signing, VDR and VDF. LIBP2P Networking : Harmony Networking layer for transaction and block processing. Open Staking : Harmony Open Staking design. Execution EVM : Harmony virutal machine (EVM compatible). Harmony Roadmp Validator Resharding Shard Agnositic Privacy Primitives Zero Knowledge Proofs Network Operations Continuous Deployment Network Deployment experiment-deploy : Repository for conducting benchmark experiments harmony-ops : Harmony Ops Master Repository. Continuous Integration Continuous Deployment (CICD) Pipeline Harmony Test Framework - Harmony TF is a Test Framework for testing various types of test cases and transactions on Harmony's blockchain. Harmony Stress - Stress testing tools for Harmony. Monitoring and Analytics Monitoring Tools watchdog : Monitors Harmony network checking software versions, consensus, block creation and triggers alerts for issues. monitor : Project for https://monitor.hmny.io Analytics harmony-log-analysis : Harmony Log Analysis and Visualization pyhmy : A Python library for interacting and working with the harmony blockchain. Validator Tools harmony-tui : Text based user interface for Harmony node auto-node : Run a harmony node with 1 command! go-sdk : Go-SDK & CLI tool to interact with the Harmony Blockchain Documentation harmony-ops : Harmony Foundational Node Success Guide Explorers and Dashboards staking-dashboard : Harmony Staking Dashboard harmony-dashboard : Harmony Explorer Front End https://explorer.harmony.one TOOLING Development Environment Testnets Hosted API Endpoints Harmony GraphQL Profiling Suite Client Interfaces API backend.go : Harmony API definitions Harmony Open API Specification Generated Clients Protobuf client Postman documentation Client Interfaces SDKS go-sdk : Go-SDK & CLI tool to interact with the Harmony Blockchain go-lib : While go-sdk is an actual program/CLI this library is solely designed to be used/referenced by other tools and applications. sdk : Javascript SDK of Harmony protocol. harmonyj : Harmony Java SDK Web Based Tools Web Based IDE Remix Plugin Chain ide \" Web based IDE developed by White Matrix. TryCrypto DappStarter : DappStarter is a full stack development environment for blockchains. video Local IDE Harmony Deploy Harmony Ganache Harmony Truffle Integration Smart Contract Knowledgebase Smart Contract Standards openzepplin-contract : Harmony leverges open zepplins EVM compatible smart contract standards. Smart Contract Examples HRC : HRC token standards dapp-examples : harmony-sdk examples Smart Contract Protocols Deployed on Harmony DApp Developer Tools docs-developer : Developer Documentation DeFi Primitives Stable Coins busd-contract : Harmony Protocol Deployment of Binance USD (BUSD) Liquidity Pools Wrapped ONE Privacy rings-dapp : This is an Harmony transaction mixer that ultilizes parts of CryptoNote to enable zero-knowledge transactions. Ported from Heiswap from Ethureum. Integration Primitives Oracles KYC fiat on ramps InterChain native-bridge : Native ONE token bridge with BEP2/ERC20 ONE Wallets Cold Wallets *Trust wallet * wallet-core : Trust Wallet Core is a cross-platform library that implements low-level cryptographic wallet functionality for all supported blockchains * blockatlas : Block Atlas by Trust Wallet - Forked for Harmony Use Ledger ledger-app-one : Ledger hardware wallet support for Harmony ONE. ledger-jarmony-js : Web2USB/Javascript driver for Harmony on Ledger Nano S Hot Wallets Harmony Chrome Extension Mathwallet HRC20 Support Developer GAS DApp Developer Tools docs-developer : Developer Documentation DApp Development Tutorial dapp-examples : harmony-sdk examples Applications Exchanges CrossFi Applications MarketPlaces nft-store : NFT store sample dapp with client and server Gaming android-puzzle : Harmony Puzzle Game - Mobile version.","title":"Harmony Technology Suite"},{"location":"resources/breakdown/#ecosystem-breakdown-for-developers","text":"Following are the key components and repositories for the Harmony Ecosystem covered in this guide.","title":"Ecosystem Breakdown for Developers"},{"location":"resources/breakdown/#harmony-ecosystem-diagram","text":"The below diagram can be clicked upon to bring up an interactive image linking to all the component documentation.","title":"Harmony Ecosystem Diagram"},{"location":"resources/breakdown/#protocol-developers","text":"Harmony Protocol : Harmony Core Protocol Consensus : Harmony Sharded Proof of Work with BLS key signing, VDR and VDF. LIBP2P Networking : Harmony Networking layer for transaction and block processing. Open Staking : Harmony Open Staking design. Execution EVM : Harmony virutal machine (EVM compatible). Harmony Roadmp Validator Resharding Shard Agnositic Privacy Primitives Zero Knowledge Proofs","title":"Protocol Developers"},{"location":"resources/breakdown/#network-operations","text":"Continuous Deployment Network Deployment experiment-deploy : Repository for conducting benchmark experiments harmony-ops : Harmony Ops Master Repository. Continuous Integration Continuous Deployment (CICD) Pipeline Harmony Test Framework - Harmony TF is a Test Framework for testing various types of test cases and transactions on Harmony's blockchain. Harmony Stress - Stress testing tools for Harmony. Monitoring and Analytics Monitoring Tools watchdog : Monitors Harmony network checking software versions, consensus, block creation and triggers alerts for issues. monitor : Project for https://monitor.hmny.io Analytics harmony-log-analysis : Harmony Log Analysis and Visualization pyhmy : A Python library for interacting and working with the harmony blockchain. Validator Tools harmony-tui : Text based user interface for Harmony node auto-node : Run a harmony node with 1 command! go-sdk : Go-SDK & CLI tool to interact with the Harmony Blockchain Documentation harmony-ops : Harmony Foundational Node Success Guide Explorers and Dashboards staking-dashboard : Harmony Staking Dashboard harmony-dashboard : Harmony Explorer Front End https://explorer.harmony.one","title":"Network Operations"},{"location":"resources/breakdown/#tooling","text":"Development Environment Testnets Hosted API Endpoints Harmony GraphQL Profiling Suite Client Interfaces API backend.go : Harmony API definitions Harmony Open API Specification Generated Clients Protobuf client Postman documentation Client Interfaces SDKS go-sdk : Go-SDK & CLI tool to interact with the Harmony Blockchain go-lib : While go-sdk is an actual program/CLI this library is solely designed to be used/referenced by other tools and applications. sdk : Javascript SDK of Harmony protocol. harmonyj : Harmony Java SDK Web Based Tools Web Based IDE Remix Plugin Chain ide \" Web based IDE developed by White Matrix. TryCrypto DappStarter : DappStarter is a full stack development environment for blockchains. video Local IDE Harmony Deploy Harmony Ganache Harmony Truffle Integration Smart Contract Knowledgebase Smart Contract Standards openzepplin-contract : Harmony leverges open zepplins EVM compatible smart contract standards. Smart Contract Examples HRC : HRC token standards dapp-examples : harmony-sdk examples Smart Contract Protocols Deployed on Harmony DApp Developer Tools docs-developer : Developer Documentation DeFi Primitives Stable Coins busd-contract : Harmony Protocol Deployment of Binance USD (BUSD) Liquidity Pools Wrapped ONE Privacy rings-dapp : This is an Harmony transaction mixer that ultilizes parts of CryptoNote to enable zero-knowledge transactions. Ported from Heiswap from Ethureum. Integration Primitives Oracles KYC fiat on ramps InterChain native-bridge : Native ONE token bridge with BEP2/ERC20 ONE Wallets Cold Wallets *Trust wallet * wallet-core : Trust Wallet Core is a cross-platform library that implements low-level cryptographic wallet functionality for all supported blockchains * blockatlas : Block Atlas by Trust Wallet - Forked for Harmony Use Ledger ledger-app-one : Ledger hardware wallet support for Harmony ONE. ledger-jarmony-js : Web2USB/Javascript driver for Harmony on Ledger Nano S Hot Wallets Harmony Chrome Extension Mathwallet HRC20 Support Developer GAS DApp Developer Tools docs-developer : Developer Documentation DApp Development Tutorial dapp-examples : harmony-sdk examples","title":"TOOLING"},{"location":"resources/breakdown/#applications","text":"Exchanges CrossFi Applications MarketPlaces nft-store : NFT store sample dapp with client and server Gaming android-puzzle : Harmony Puzzle Game - Mobile version.","title":"Applications"},{"location":"resources/documentation/","text":"docs.johnwhitton.dev Overview Mkdoc build mkdoc - mkdocs.yml mkdocs-material - customization docusarus - a more flexible tool used by NEAR. # Install mkdocs pip3 install --user --upgrade pip pip3 install mkdocs pip3 install mkdocs-material git clone git@github.com:johnwhitton/ethhub.git cd ethhub/ mkdocs build cd site python3 -m http.server 8000 Reference documentation repos Stellar - https://github.com/stellar/docs EOS - git clone git@github.com:EOSIO/welcome.git Polkadot - git clone git@github.com:w3f/polkadot-wiki.git Near - git clone git@github.com:nearprotocol/docs.git nomicon Harmony - https://github.com/harmony-one/docs-home ehthub - https://github.com/ethhub-io/ethhub Findora Celo.org Oasis Coda Protocol","title":"docs.johnwhitton.dev"},{"location":"resources/documentation/#docsjohnwhittondev","text":"","title":"docs.johnwhitton.dev"},{"location":"resources/documentation/#overview","text":"","title":"Overview"},{"location":"resources/documentation/#mkdoc-build","text":"mkdoc - mkdocs.yml mkdocs-material - customization docusarus - a more flexible tool used by NEAR. # Install mkdocs pip3 install --user --upgrade pip pip3 install mkdocs pip3 install mkdocs-material git clone git@github.com:johnwhitton/ethhub.git cd ethhub/ mkdocs build cd site python3 -m http.server 8000 Reference documentation repos Stellar - https://github.com/stellar/docs EOS - git clone git@github.com:EOSIO/welcome.git Polkadot - git clone git@github.com:w3f/polkadot-wiki.git Near - git clone git@github.com:nearprotocol/docs.git nomicon Harmony - https://github.com/harmony-one/docs-home ehthub - https://github.com/ethhub-io/ethhub Findora Celo.org Oasis Coda Protocol","title":"Mkdoc build"},{"location":"resources/infrastructure/","text":"Ecosystem infrastructure tools All layer 1 platforms need a rich ecosystem in order to be succesful. In creating this site a number of layer 1 protocol engagement sites where evaluated, you can review these sites in the resources section . The main sites and tools evaluated are as follows Site Tools Comments https://docs.harmony.one/ gitbook Easy to publish content for non-technical users, pricing per user https://docs.ethhub.io/ mkdocs Open Source and Free, more technical knowledge required to administer https://docs.near.org/ docusarus Open Source and free, most flexible of the tools. better fir for a more technical audience Of the three tools this site was built with mkdocs which I believe is powerful and gives the flexibility required especially if opening up to a larger community (see the contribution guide below. In my humble opinion for ease of use and simplicity gitbooks is the best to get documents up and published. for a more polished and flexible documentation I would prefer to use docusarus, however this would require a semi-dedicated technical resource to maintain and customize the site. For further information please see the links to other blockchain protocol documentataion in the resources section johnwhitton.dev infrastructure overview The following gives a quick breakdown of the tools used to create johnwhitton.dev content was built using the dimension template from html5up.net Served on an AWS t3.small instance nginx used as a frontend let's encrypt used to provide SSL certificates Integrated with a document project built using mkdocs","title":"Ecosystem engagement tools"},{"location":"resources/infrastructure/#ecosystem-infrastructure-tools","text":"All layer 1 platforms need a rich ecosystem in order to be succesful. In creating this site a number of layer 1 protocol engagement sites where evaluated, you can review these sites in the resources section . The main sites and tools evaluated are as follows Site Tools Comments https://docs.harmony.one/ gitbook Easy to publish content for non-technical users, pricing per user https://docs.ethhub.io/ mkdocs Open Source and Free, more technical knowledge required to administer https://docs.near.org/ docusarus Open Source and free, most flexible of the tools. better fir for a more technical audience Of the three tools this site was built with mkdocs which I believe is powerful and gives the flexibility required especially if opening up to a larger community (see the contribution guide below. In my humble opinion for ease of use and simplicity gitbooks is the best to get documents up and published. for a more polished and flexible documentation I would prefer to use docusarus, however this would require a semi-dedicated technical resource to maintain and customize the site. For further information please see the links to other blockchain protocol documentataion in the resources section","title":"Ecosystem infrastructure tools"},{"location":"resources/infrastructure/#johnwhittondev-infrastructure-overview","text":"The following gives a quick breakdown of the tools used to create johnwhitton.dev content was built using the dimension template from html5up.net Served on an AWS t3.small instance nginx used as a frontend let's encrypt used to provide SSL certificates Integrated with a document project built using mkdocs","title":"johnwhitton.dev infrastructure overview"},{"location":"resources/mainnet-validators/","text":"Mainnet Validators Production Migration Leos Gist Setup Overview Model 15 nodes have * 4 slots per nodes = 60 slots @ 110K per slot use johndesktop as control center Create 60 BLS Keys and add them to 15 Node folders (4 per node) Copy existing keys over as well Spin up 1 AWS instance and set up systemd and get it running Add the 4 validators Spin up other 12 instances and do the same Add the bls keys to emasset Transfer 7,000,000 to emasset Stake the 7,000,000 one Spin up a node mkdir -p .hmy/blskeys ./pushkeys.sh ll .hmy/blskeys/* sudo yum update curl -LO https://harmony.one/hmycli && mv hmycli hmy && chmod +x hmy # upgrade node.sh curl -LO https://harmony.one/node.sh chmod +x node.sh # check the node.sh version ./node.sh -v # download the harmony binary to staging/ directory ./node.sh -I -d cp staging/harmony . # check the harmony binary version ./node.sh -V # Push the keys mkdir -p .hmy/blskeys # Rclone setup and synch curl https://rclone.org/install.sh | sudo bash rclone config file cat<<-EOF > ~/.config/rclone/rclone.conf [mainnet] type = s3 provider = AWS env_auth = false region = us-west-1 acl = public-read server_side_encryption = AES256 storage_class = REDUCED_REDUNDANCY EOF rclone config file rclone sync mainnet:pub.harmony.one/mainnet.min/harmony_db_0 harmony_db_0 sudo ./node.sh -S -z -M # https://www.digitalocean.com/community/tutorials/how-to-use-systemctl-to-manage-systemd-services-and-units cd /lib/systemd/system sudo vim harmony.service systemctl status harmony.service sudo systemctl enable harmony.service sudo systemctl start harmony.service sudo systemctl daemon-reload systemctl status harmony.service sudo systemctl start harmony.service systemctl status harmony.service sudo systemctl stop harmony.service systemctl status harmony.service sudo systemctl enable harmony.service systemctl status harmony.service tail -f ~/latest/zerolog-validator-54.244.48.37-9000.log service file [Unit] Description=harmony service After=network.target [Service] Type=simple Restart=always RestartSec=1 User=ec2-user WorkingDirectory=/home/ec2-user/ ExecStart=/home/ec2-user/node.sh -S -z -M StandardError=syslog SyslogIdentifier=harmony StartLimitInterval=0 LimitNOFILE=65536 LimitNPROC=65536 [Install] WantedBy=multi-user.target Register 64 bls keys remove 8 bls keys transfer and delegate emasset1 - Kenny exec ssh -i ~/.ssh/keys/validatorMainnet.pem ec2-user@34.217.58.62 emasset2 - John exec ssh -i ~/.ssh/keys/validatorMainnet.pem ec2-user@34.216.30.197 ./hmy --node=\"https://api.s0.t.hmny.io\" staking create-validator --validator-addr one128c4wclvc3udu09fs2cdrhlxczh42yzuhlcu7u --amount 100000 --bls-pubkeys 10b026f125e10b2e81cdf57b307396c2be60db2d34e0b5795c6085d57318ebcf6339754c6bf64bb8da1c612044482889,2684b9b856e2b3f6ff0916b17137ba61e2495a9636859ff108defcca38f4dc49508c44ff16ad8f74e5182769c6a5a699,943d09421aba03f5edffc3db8e40e40a2a5bb41c1962084fa1b7f7fda653173ec1475cc537f5ca4407d1b7f5af097889,9503d278704d8a30ee52f3e5f3ffc781d702233ca66374282c95841df0ac7323b7c2de5f5ccd6e4830d1c529d474a695 --name \"emasset\" --identity \"emasset\" --details \"emasset 2 nodes 4bls keys per node, 2 t3small machines\" --security-contact \"support@emasset.com\" --website \"www.emasset.com\" --max-change-rate 0.1 --max-rate 1 --rate 1 --max-total-delegation 10000000000 --min-self-delegation 100000 /home/ec2-user/.hmy/blskeys/10b026f125e10b2e81cdf57b307396c2be60db2d34e0b5795c6085d57318ebcf6339754c6bf64bb8da1c612044482889.key /home/ec2-user/.hmy/blskeys/2684b9b856e2b3f6ff0916b17137ba61e2495a9636859ff108defcca38f4dc49508c44ff16ad8f74e5182769c6a5a699.key /home/ec2-user/.hmy/blskeys/943d09421aba03f5edffc3db8e40e40a2a5bb41c1962084fa1b7f7fda653173ec1475cc537f5ca4407d1b7f5af097889.key /home/ec2-user/.hmy/blskeys/9503d278704d8a30ee52f3e5f3ffc781d702233ca66374282c95841df0ac7323b7c2de5f5ccd6e4830d1c529d474a695.key ./hmy --node=\"https://api.s0.t.hmny.io\" staking edit-validator --validator-addr one128c4wclvc3udu09fs2cdrhlxczh42yzuhlcu7u --add-bls-key 30fd467aa370d7f76b3badb695648a0b8be53c4f71871a813413d9d3a5678e586ba234e26777d82fca9fc0668d9c600f ./hmy --node=\"https://api.s0.t.hmny.io\" staking edit-validator --validator-addr one128c4wclvc3udu09fs2cdrhlxczh42yzuhlcu7u --add-bls-key 35a3cb1ef5179fc8773c8d716f33a8edd553cde9cce030f81ee81f8ed6fce310128327133f622b0553efcf0be0308703 ./hmy --node=\"https://api.s0.t.hmny.io\" staking edit-validator --validator-addr one128c4wclvc3udu09fs2cdrhlxczh42yzuhlcu7u --add-bls-key 4a5f16bd127e1487ec37b7bac9e69fc2cc8c0db7fc68dfe064643220a8cea70b6313ad0a7d2d3212fef3b4402cea5397 ./hmy --node=\"https://api.s0.t.hmny.io\" staking edit-validator --validator-addr one128c4wclvc3udu09fs2cdrhlxczh42yzuhlcu7u --add-bls-key 4f48a8cccd6195e729f7626fe50859f04e8d5b2c0597f7da8020b363e4b53cab91cea7a4356fffe1cd44b119b1192d8f /home/ec2-user/.hmy/blskeys/30fd467aa370d7f76b3badb695648a0b8be53c4f71871a813413d9d3a5678e586ba234e26777d82fca9fc0668d9c600f.key /home/ec2-user/.hmy/blskeys/35a3cb1ef5179fc8773c8d716f33a8edd553cde9cce030f81ee81f8ed6fce310128327133f622b0553efcf0be0308703.key /home/ec2-user/.hmy/blskeys/4a5f16bd127e1487ec37b7bac9e69fc2cc8c0db7fc68dfe064643220a8cea70b6313ad0a7d2d3212fef3b4402cea5397.key /home/ec2-user/.hmy/blskeys/4f48a8cccd6195e729f7626fe50859f04e8d5b2c0597f7da8020b363e4b53cab91cea7a4356fffe1cd44b119b1192d8f.key Validator Model (emasset-1 and emasset-3) 2 Validators Each 4 BLS Keys 100% Fees Min 10,000 Max 8,000,000,000","title":"Mainnet Validators"},{"location":"resources/mainnet-validators/#mainnet-validators","text":"","title":"Mainnet Validators"},{"location":"resources/mainnet-validators/#production-migration","text":"Leos Gist","title":"Production Migration"},{"location":"resources/mainnet-validators/#setup-overview","text":"Model 15 nodes have * 4 slots per nodes = 60 slots @ 110K per slot use johndesktop as control center Create 60 BLS Keys and add them to 15 Node folders (4 per node) Copy existing keys over as well Spin up 1 AWS instance and set up systemd and get it running Add the 4 validators Spin up other 12 instances and do the same Add the bls keys to emasset Transfer 7,000,000 to emasset Stake the 7,000,000 one Spin up a node mkdir -p .hmy/blskeys ./pushkeys.sh ll .hmy/blskeys/* sudo yum update curl -LO https://harmony.one/hmycli && mv hmycli hmy && chmod +x hmy # upgrade node.sh curl -LO https://harmony.one/node.sh chmod +x node.sh # check the node.sh version ./node.sh -v # download the harmony binary to staging/ directory ./node.sh -I -d cp staging/harmony . # check the harmony binary version ./node.sh -V # Push the keys mkdir -p .hmy/blskeys # Rclone setup and synch curl https://rclone.org/install.sh | sudo bash rclone config file cat<<-EOF > ~/.config/rclone/rclone.conf [mainnet] type = s3 provider = AWS env_auth = false region = us-west-1 acl = public-read server_side_encryption = AES256 storage_class = REDUCED_REDUNDANCY EOF rclone config file rclone sync mainnet:pub.harmony.one/mainnet.min/harmony_db_0 harmony_db_0 sudo ./node.sh -S -z -M # https://www.digitalocean.com/community/tutorials/how-to-use-systemctl-to-manage-systemd-services-and-units cd /lib/systemd/system sudo vim harmony.service systemctl status harmony.service sudo systemctl enable harmony.service sudo systemctl start harmony.service sudo systemctl daemon-reload systemctl status harmony.service sudo systemctl start harmony.service systemctl status harmony.service sudo systemctl stop harmony.service systemctl status harmony.service sudo systemctl enable harmony.service systemctl status harmony.service tail -f ~/latest/zerolog-validator-54.244.48.37-9000.log service file [Unit] Description=harmony service After=network.target [Service] Type=simple Restart=always RestartSec=1 User=ec2-user WorkingDirectory=/home/ec2-user/ ExecStart=/home/ec2-user/node.sh -S -z -M StandardError=syslog SyslogIdentifier=harmony StartLimitInterval=0 LimitNOFILE=65536 LimitNPROC=65536 [Install] WantedBy=multi-user.target Register 64 bls keys remove 8 bls keys transfer and delegate","title":"Setup Overview"},{"location":"resources/mainnet-validators/#emasset1-kenny","text":"exec ssh -i ~/.ssh/keys/validatorMainnet.pem ec2-user@34.217.58.62 emasset2 - John exec ssh -i ~/.ssh/keys/validatorMainnet.pem ec2-user@34.216.30.197 ./hmy --node=\"https://api.s0.t.hmny.io\" staking create-validator --validator-addr one128c4wclvc3udu09fs2cdrhlxczh42yzuhlcu7u --amount 100000 --bls-pubkeys 10b026f125e10b2e81cdf57b307396c2be60db2d34e0b5795c6085d57318ebcf6339754c6bf64bb8da1c612044482889,2684b9b856e2b3f6ff0916b17137ba61e2495a9636859ff108defcca38f4dc49508c44ff16ad8f74e5182769c6a5a699,943d09421aba03f5edffc3db8e40e40a2a5bb41c1962084fa1b7f7fda653173ec1475cc537f5ca4407d1b7f5af097889,9503d278704d8a30ee52f3e5f3ffc781d702233ca66374282c95841df0ac7323b7c2de5f5ccd6e4830d1c529d474a695 --name \"emasset\" --identity \"emasset\" --details \"emasset 2 nodes 4bls keys per node, 2 t3small machines\" --security-contact \"support@emasset.com\" --website \"www.emasset.com\" --max-change-rate 0.1 --max-rate 1 --rate 1 --max-total-delegation 10000000000 --min-self-delegation 100000 /home/ec2-user/.hmy/blskeys/10b026f125e10b2e81cdf57b307396c2be60db2d34e0b5795c6085d57318ebcf6339754c6bf64bb8da1c612044482889.key /home/ec2-user/.hmy/blskeys/2684b9b856e2b3f6ff0916b17137ba61e2495a9636859ff108defcca38f4dc49508c44ff16ad8f74e5182769c6a5a699.key /home/ec2-user/.hmy/blskeys/943d09421aba03f5edffc3db8e40e40a2a5bb41c1962084fa1b7f7fda653173ec1475cc537f5ca4407d1b7f5af097889.key /home/ec2-user/.hmy/blskeys/9503d278704d8a30ee52f3e5f3ffc781d702233ca66374282c95841df0ac7323b7c2de5f5ccd6e4830d1c529d474a695.key ./hmy --node=\"https://api.s0.t.hmny.io\" staking edit-validator --validator-addr one128c4wclvc3udu09fs2cdrhlxczh42yzuhlcu7u --add-bls-key 30fd467aa370d7f76b3badb695648a0b8be53c4f71871a813413d9d3a5678e586ba234e26777d82fca9fc0668d9c600f ./hmy --node=\"https://api.s0.t.hmny.io\" staking edit-validator --validator-addr one128c4wclvc3udu09fs2cdrhlxczh42yzuhlcu7u --add-bls-key 35a3cb1ef5179fc8773c8d716f33a8edd553cde9cce030f81ee81f8ed6fce310128327133f622b0553efcf0be0308703 ./hmy --node=\"https://api.s0.t.hmny.io\" staking edit-validator --validator-addr one128c4wclvc3udu09fs2cdrhlxczh42yzuhlcu7u --add-bls-key 4a5f16bd127e1487ec37b7bac9e69fc2cc8c0db7fc68dfe064643220a8cea70b6313ad0a7d2d3212fef3b4402cea5397 ./hmy --node=\"https://api.s0.t.hmny.io\" staking edit-validator --validator-addr one128c4wclvc3udu09fs2cdrhlxczh42yzuhlcu7u --add-bls-key 4f48a8cccd6195e729f7626fe50859f04e8d5b2c0597f7da8020b363e4b53cab91cea7a4356fffe1cd44b119b1192d8f /home/ec2-user/.hmy/blskeys/30fd467aa370d7f76b3badb695648a0b8be53c4f71871a813413d9d3a5678e586ba234e26777d82fca9fc0668d9c600f.key /home/ec2-user/.hmy/blskeys/35a3cb1ef5179fc8773c8d716f33a8edd553cde9cce030f81ee81f8ed6fce310128327133f622b0553efcf0be0308703.key /home/ec2-user/.hmy/blskeys/4a5f16bd127e1487ec37b7bac9e69fc2cc8c0db7fc68dfe064643220a8cea70b6313ad0a7d2d3212fef3b4402cea5397.key /home/ec2-user/.hmy/blskeys/4f48a8cccd6195e729f7626fe50859f04e8d5b2c0597f7da8020b363e4b53cab91cea7a4356fffe1cd44b119b1192d8f.key","title":"emasset1 - Kenny"},{"location":"resources/mainnet-validators/#validator-model-emasset-1-and-emasset-3","text":"2 Validators Each 4 BLS Keys 100% Fees Min 10,000 Max 8,000,000,000","title":"Validator Model (emasset-1 and emasset-3)"},{"location":"resources/overview/","text":"Layer 1 Protocol Overview This section is for Blockchain Ecosystem Arthitects and Developers. Here you will find information on Layer 1 protocols and the grants assoicated with them. From here you may also explore the tools built, being built or have grants available to be built, for each protocol.","title":"Overview"},{"location":"resources/overview/#layer-1-protocol-overview","text":"This section is for Blockchain Ecosystem Arthitects and Developers. Here you will find information on Layer 1 protocols and the grants assoicated with them. From here you may also explore the tools built, being built or have grants available to be built, for each protocol.","title":"Layer 1 Protocol  Overview"},{"location":"resources/playground/","text":"Developer Playground Overview To create this site and to develop the profiling suite, Interactive API and mainnet validators John uses AWS instances. Here you will find an overview of how these components are configured and used. There is also an interactive diagram which you can use to go to any of the outward facing endpoints. Developer Overview Iniitally a mapping of all the Harmony Repositories was done and documented here this was then turned into the diagram below. And from there each componenet was documented in the contribute section. Moving forwards for ecosytem grants the following process is suggested Grant proposals are documented as a ticket in the Grant repository Once approved a page is added to the wiki for the grant component This page trackes the grant process Upon complettion the page is updated to include a user guide The information is also added to the ecoystem guide Profiling Suite This can be used in conjunction with stess testing. High level there is An explorer node running with pprof 3 pprof services rendering flamegraphs These are currently run in tmux sessions and can be combined with stress testing to get accurate analytics when under load. Interactive API Please see Open API Specification for information about how to set up an interactive API session. Mainnet Validator Process John runs up to 8 validators each with up to 8 keys giving the ability to run 64 slots. This is controled from a central server prototype.johnwhitton.dev. Each Node has the bls keys stored in a seperate folder. There is a push keys script to push the keys to new nodes. There is a removekeys script to remove the keys from the registered validator. This way new nodes can be spun up or dropped easily to align with the optimal number of nodes for the staking amount available Network Deployment Process can be found here Complete Harmony Suite Ecosystem Breakdown for Developers Following are the key components and repositories for the Harmony Ecosystem covered in this guide. Protocol Developers Harmony Protocol : Harmony Core Protocol Consensus : Harmony Sharded Proof of Work with BLS key signing, VDR and VDF. LIBP2P Networking : Harmony Networking layer for transaction and block processing. Open Staking : Harmony Open Staking design. Execution EVM : Harmony virutal machine (EVM compatible). Harmony Roadmp Validator Resharding Shard Agnositic Privacy Primitives Zero Knowledge Proofs Network Operations Continuous Deployment Network Deployment experiment-deploy : Repository for conducting benchmark experiments harmony-ops : Harmony Ops Master Repository. Continuous Integration Continuous Deployment (CICD) Pipeline Harmony Test Framework - Harmony TF is a Test Framework for testing various types of test cases and transactions on Harmony's blockchain. Harmony Stress - Stress testing tools for Harmony. Monitoring and Analytics Monitoring Tools watchdog : Monitors Harmony network checking software versions, consensus, block creation and triggers alerts for issues. monitor : Project for https://monitor.hmny.io Analytics harmony-log-analysis : Harmony Log Analysis and Visualization pyhmy : A Python library for interacting and working with the harmony blockchain. Validator Tools harmony-tui : Text based user interface for Harmony node auto-node : Run a harmony node with 1 command! go-sdk : Go-SDK & CLI tool to interact with the Harmony Blockchain Documentation harmony-ops : Harmony Foundational Node Success Guide Explorers and Dashboards staking-dashboard : Harmony Staking Dashboard harmony-dashboard : Harmony Explorer Front End https://explorer.harmony.one TOOLING Development Environment Testnets Hosted API Endpoints Harmony GraphQL Profiling Suite Client Interfaces API backend.go : Harmony API definitions Harmony Open API Specification Generated Clients Protobuf client Postman documentation Client Interfaces SDKS go-sdk : Go-SDK & CLI tool to interact with the Harmony Blockchain go-lib : While go-sdk is an actual program/CLI this library is solely designed to be used/referenced by other tools and applications. sdk : Javascript SDK of Harmony protocol. harmonyj : Harmony Java SDK Web Based Tools Web Based IDE Remix Plugin Chain ide \" Web based IDE developed by White Matrix. TryCrypto DappStarter : DappStarter is a full stack development environment for blockchains. video Local IDE Harmony Deploy Harmony Ganache Harmony Truffle Integration Smart Contract Knowledgebase Smart Contract Knowledgebase Smart Contract Standards openzepplin-contract : Harmony leverges open zepplins EVM compatible smart contract standards. Smart Contract Examples HRC : HRC token standards dapp-examples : harmony-sdk examples Smart Contract Protocols Deployed on Harmony DApp Developer Tools docs-developer : Developer Documentation DeFi Primitives Stable Coins busd-contract : Harmony Protocol Deployment of Binance USD (BUSD) Liquidity Pools Wrapped ONE Privacy rings-dapp : This is an Harmony transaction mixer that ultilizes parts of CryptoNote to enable zero-knowledge transactions. Ported from Heiswap from Ethureum. Integration Primitives Oracles KYC fiat on ramps InterChain native-bridge : Native ONE token bridge with BEP2/ERC20 ONE Wallets Cold Wallets *Trust wallet * wallet-core : Trust Wallet Core is a cross-platform library that implements low-level cryptographic wallet functionality for all supported blockchains * blockatlas : Block Atlas by Trust Wallet - Forked for Harmony Use Ledger ledger-app-one : Ledger hardware wallet support for Harmony ONE. ledger-jarmony-js : Web2USB/Javascript driver for Harmony on Ledger Nano S Hot Wallets Harmony Chrome Extension Mathwallet HRC20 Support Developer GAS DApp Developer Tools docs-developer : Developer Documentation DApp Development Tutorial dapp-examples : harmony-sdk examples Applications Exchanges CrossFi Applications MarketPlaces nft-store : NFT store sample dapp with client and server Gaming android-puzzle : Harmony Puzzle Game - Mobile version.","title":"John's Playground"},{"location":"resources/playground/#developer-playground-overview","text":"To create this site and to develop the profiling suite, Interactive API and mainnet validators John uses AWS instances. Here you will find an overview of how these components are configured and used. There is also an interactive diagram which you can use to go to any of the outward facing endpoints.","title":"Developer Playground Overview"},{"location":"resources/playground/#developer-overview","text":"Iniitally a mapping of all the Harmony Repositories was done and documented here this was then turned into the diagram below. And from there each componenet was documented in the contribute section. Moving forwards for ecosytem grants the following process is suggested Grant proposals are documented as a ticket in the Grant repository Once approved a page is added to the wiki for the grant component This page trackes the grant process Upon complettion the page is updated to include a user guide The information is also added to the ecoystem guide","title":"Developer Overview"},{"location":"resources/playground/#profiling-suite","text":"This can be used in conjunction with stess testing. High level there is An explorer node running with pprof 3 pprof services rendering flamegraphs These are currently run in tmux sessions and can be combined with stress testing to get accurate analytics when under load.","title":"Profiling Suite"},{"location":"resources/playground/#interactive-api","text":"Please see Open API Specification for information about how to set up an interactive API session.","title":"Interactive API"},{"location":"resources/playground/#mainnet-validator-process","text":"John runs up to 8 validators each with up to 8 keys giving the ability to run 64 slots. This is controled from a central server prototype.johnwhitton.dev. Each Node has the bls keys stored in a seperate folder. There is a push keys script to push the keys to new nodes. There is a removekeys script to remove the keys from the registered validator. This way new nodes can be spun up or dropped easily to align with the optimal number of nodes for the staking amount available","title":"Mainnet Validator Process"},{"location":"resources/playground/#network-deployment","text":"Process can be found here","title":"Network Deployment"},{"location":"resources/playground/#complete-harmony-suite","text":"","title":"Complete Harmony Suite"},{"location":"resources/playground/#ecosystem-breakdown-for-developers","text":"Following are the key components and repositories for the Harmony Ecosystem covered in this guide.","title":"Ecosystem Breakdown for Developers"},{"location":"resources/playground/#protocol-developers","text":"Harmony Protocol : Harmony Core Protocol Consensus : Harmony Sharded Proof of Work with BLS key signing, VDR and VDF. LIBP2P Networking : Harmony Networking layer for transaction and block processing. Open Staking : Harmony Open Staking design. Execution EVM : Harmony virutal machine (EVM compatible). Harmony Roadmp Validator Resharding Shard Agnositic Privacy Primitives Zero Knowledge Proofs","title":"Protocol Developers"},{"location":"resources/playground/#network-operations","text":"Continuous Deployment Network Deployment experiment-deploy : Repository for conducting benchmark experiments harmony-ops : Harmony Ops Master Repository. Continuous Integration Continuous Deployment (CICD) Pipeline Harmony Test Framework - Harmony TF is a Test Framework for testing various types of test cases and transactions on Harmony's blockchain. Harmony Stress - Stress testing tools for Harmony. Monitoring and Analytics Monitoring Tools watchdog : Monitors Harmony network checking software versions, consensus, block creation and triggers alerts for issues. monitor : Project for https://monitor.hmny.io Analytics harmony-log-analysis : Harmony Log Analysis and Visualization pyhmy : A Python library for interacting and working with the harmony blockchain. Validator Tools harmony-tui : Text based user interface for Harmony node auto-node : Run a harmony node with 1 command! go-sdk : Go-SDK & CLI tool to interact with the Harmony Blockchain Documentation harmony-ops : Harmony Foundational Node Success Guide Explorers and Dashboards staking-dashboard : Harmony Staking Dashboard harmony-dashboard : Harmony Explorer Front End https://explorer.harmony.one","title":"Network Operations"},{"location":"resources/playground/#tooling","text":"Development Environment Testnets Hosted API Endpoints Harmony GraphQL Profiling Suite Client Interfaces API backend.go : Harmony API definitions Harmony Open API Specification Generated Clients Protobuf client Postman documentation Client Interfaces SDKS go-sdk : Go-SDK & CLI tool to interact with the Harmony Blockchain go-lib : While go-sdk is an actual program/CLI this library is solely designed to be used/referenced by other tools and applications. sdk : Javascript SDK of Harmony protocol. harmonyj : Harmony Java SDK Web Based Tools Web Based IDE Remix Plugin Chain ide \" Web based IDE developed by White Matrix. TryCrypto DappStarter : DappStarter is a full stack development environment for blockchains. video Local IDE Harmony Deploy Harmony Ganache Harmony Truffle Integration Smart Contract Knowledgebase Smart Contract Knowledgebase Smart Contract Standards openzepplin-contract : Harmony leverges open zepplins EVM compatible smart contract standards. Smart Contract Examples HRC : HRC token standards dapp-examples : harmony-sdk examples Smart Contract Protocols Deployed on Harmony DApp Developer Tools docs-developer : Developer Documentation DeFi Primitives Stable Coins busd-contract : Harmony Protocol Deployment of Binance USD (BUSD) Liquidity Pools Wrapped ONE Privacy rings-dapp : This is an Harmony transaction mixer that ultilizes parts of CryptoNote to enable zero-knowledge transactions. Ported from Heiswap from Ethureum. Integration Primitives Oracles KYC fiat on ramps InterChain native-bridge : Native ONE token bridge with BEP2/ERC20 ONE Wallets Cold Wallets *Trust wallet * wallet-core : Trust Wallet Core is a cross-platform library that implements low-level cryptographic wallet functionality for all supported blockchains * blockatlas : Block Atlas by Trust Wallet - Forked for Harmony Use Ledger ledger-app-one : Ledger hardware wallet support for Harmony ONE. ledger-jarmony-js : Web2USB/Javascript driver for Harmony on Ledger Nano S Hot Wallets Harmony Chrome Extension Mathwallet HRC20 Support Developer GAS DApp Developer Tools docs-developer : Developer Documentation DApp Development Tutorial dapp-examples : harmony-sdk examples","title":"TOOLING"},{"location":"resources/playground/#applications","text":"Exchanges CrossFi Applications MarketPlaces nft-store : NFT store sample dapp with client and server Gaming android-puzzle : Harmony Puzzle Game - Mobile version.","title":"Applications"},{"location":"resources/profiling/","text":"Developer Profiling and Testing Overview This is an overview of how all the network validation components can be used in conjunction for running stress tests and capturing profiling information. It goes through configuration currently using johns developer desktop as well as a number of hosted aws instances. {% hint style=\"warning\" %} This document is a work in progress and moving forward many of the manual steps can be automated and the current nodes can be replaced with spot instances and scripted moving forward. {% endhint %} Component Overview Endpoints Explorer Profiling Information shows the pprof info on the explorer node Interactive Allocation (alloc) - from explorer Node Interactive Heap (heap) - from explorer node Interactive GoRoutine (goroutine) - from explorer node Hosting Component Hosted Description Explorer Node STN 0 52.42.43.150 Full explorer node with pprof enabled (t3.small) Validator Node STN 0 52.11.85.154 Validator Node with pprof enabled (t3.small) Validator Node STN 1 54.202.197.141 Validator node with pprof enabled (t3.small) Profiler 54.188.46.48 Web server which produces profiling info from the above nodes (t3.small) Regression Tests 54.67.5.59 Runs the complete regression tests (t3.large - johns dev desktop) Stress Tests 54.67.5.59 Runs stress tests (t3.large - johns dev desktop) Grafana monitor.harmony.one Shows cpu usage and memory utilization Analytics analytics.hmny.io Used to pull analytics data Running Tests Comprehensive instructions on how to run stress tests documented in the harmony-stress repository . Whilst the stress tests are running you can then capture the profiling information using the Capture Profiling Information section below. Below is the command used to run stress tests pointed to the Validator with profiling capabilities. ./stress txs --from one1y5n7p8a845v96xyx2gh75wn5eyhtw5002 # with your own custom node ./stress txs --from one1y5n7p8a845v96xyx2gh75wn5eyhtw5002lah27 --network stress --node=http://52.42.43.150:9500 --count 100 --concurrency 10 Component Setup Explorer Node The explorer node is needed to test rpc calls. It also has pprof setup and needs port 6060 exposed. You can then view the profiling information from the explorer at http://52.42.43.150:6060/debug/pprof/ devops.sh cdp pos ./node_ssh tmux attach -t explorer ./node.sh -S -c -z -I -P -T explorer -i 0 -r 0.0.0.0:6060 -N stress -k 463298d9357ddb336038a122b84549b0589597214e28f12b7816f09b554fd4c935437f25eb1720bae923fcb070b3e596.key Profiler The profiler connects to nodes via port 6060. It then enables viewing of these profiling info via a web interface. Setup #### Profiling Machine setup ### devops.sh cdp pstn ./node_ssh.sh 54.188.46.48 sudo yum install -y golang sudo yum install git sudo yum install tmux go get -u github.com/google/pprof sudo yum install graphviz mkdir pprof cd pprof tmux new-session -s pprof bash <(curl -sSL https://raw.githubusercontent.com/SebastianJ/harmony-tools/master/pprof/report.sh) --address localhost:6060 --interval 5m http://52.42.43.150:6060/debug/pprof/profile?seconds=60 curl http://52.42.43.150:6060/debug/pprof/allocs > allocs sudo go tool pprof -http=0.0.0.0:80 pprof.harmony.samples.cpu.086.pb.gz Capturing Profiling Information The following commands should be run to capture profiling information from the explorer whilst running stress tests. After capturing the information the servers need to be restarted. curl http://54.201.207.240:6060/debug/pprof/allocs?seconds=60 > allocs curl http://54.201.207.240:6060/debug/pprof/heap?seconds=60 > heap curl http://54.201.207.240:6060/debug/pprof/goroutine?seconds=60 > goroutine Displaying Various profiles tmux attach -t allocs sudo go tool pprof -http=0.0.0.0:80 allocs allocs tmux attach -t heap sudo go tool pprof -http=0.0.0.0:8080 heap tmux attach -t goroutine sudo go tool pprof -http=0.0.0.0:8081 goroutine","title":"Profiling Suite"},{"location":"resources/profiling/#developer-profiling-and-testing","text":"","title":"Developer Profiling and Testing"},{"location":"resources/profiling/#overview","text":"This is an overview of how all the network validation components can be used in conjunction for running stress tests and capturing profiling information. It goes through configuration currently using johns developer desktop as well as a number of hosted aws instances. {% hint style=\"warning\" %} This document is a work in progress and moving forward many of the manual steps can be automated and the current nodes can be replaced with spot instances and scripted moving forward. {% endhint %}","title":"Overview"},{"location":"resources/profiling/#component-overview","text":"","title":"Component Overview"},{"location":"resources/profiling/#endpoints","text":"Explorer Profiling Information shows the pprof info on the explorer node Interactive Allocation (alloc) - from explorer Node Interactive Heap (heap) - from explorer node Interactive GoRoutine (goroutine) - from explorer node","title":"Endpoints"},{"location":"resources/profiling/#hosting","text":"Component Hosted Description Explorer Node STN 0 52.42.43.150 Full explorer node with pprof enabled (t3.small) Validator Node STN 0 52.11.85.154 Validator Node with pprof enabled (t3.small) Validator Node STN 1 54.202.197.141 Validator node with pprof enabled (t3.small) Profiler 54.188.46.48 Web server which produces profiling info from the above nodes (t3.small) Regression Tests 54.67.5.59 Runs the complete regression tests (t3.large - johns dev desktop) Stress Tests 54.67.5.59 Runs stress tests (t3.large - johns dev desktop) Grafana monitor.harmony.one Shows cpu usage and memory utilization Analytics analytics.hmny.io Used to pull analytics data","title":"Hosting"},{"location":"resources/profiling/#running-tests","text":"Comprehensive instructions on how to run stress tests documented in the harmony-stress repository . Whilst the stress tests are running you can then capture the profiling information using the Capture Profiling Information section below. Below is the command used to run stress tests pointed to the Validator with profiling capabilities. ./stress txs --from one1y5n7p8a845v96xyx2gh75wn5eyhtw5002 # with your own custom node ./stress txs --from one1y5n7p8a845v96xyx2gh75wn5eyhtw5002lah27 --network stress --node=http://52.42.43.150:9500 --count 100 --concurrency 10","title":"Running Tests"},{"location":"resources/profiling/#component-setup","text":"","title":"Component Setup"},{"location":"resources/profiling/#explorer-node","text":"The explorer node is needed to test rpc calls. It also has pprof setup and needs port 6060 exposed. You can then view the profiling information from the explorer at http://52.42.43.150:6060/debug/pprof/ devops.sh cdp pos ./node_ssh tmux attach -t explorer ./node.sh -S -c -z -I -P -T explorer -i 0 -r 0.0.0.0:6060 -N stress -k 463298d9357ddb336038a122b84549b0589597214e28f12b7816f09b554fd4c935437f25eb1720bae923fcb070b3e596.key","title":"Explorer Node"},{"location":"resources/profiling/#profiler","text":"The profiler connects to nodes via port 6060. It then enables viewing of these profiling info via a web interface.","title":"Profiler"},{"location":"resources/profiling/#setup","text":"#### Profiling Machine setup ### devops.sh cdp pstn ./node_ssh.sh 54.188.46.48 sudo yum install -y golang sudo yum install git sudo yum install tmux go get -u github.com/google/pprof sudo yum install graphviz mkdir pprof cd pprof tmux new-session -s pprof bash <(curl -sSL https://raw.githubusercontent.com/SebastianJ/harmony-tools/master/pprof/report.sh) --address localhost:6060 --interval 5m http://52.42.43.150:6060/debug/pprof/profile?seconds=60 curl http://52.42.43.150:6060/debug/pprof/allocs > allocs sudo go tool pprof -http=0.0.0.0:80 pprof.harmony.samples.cpu.086.pb.gz Capturing Profiling Information The following commands should be run to capture profiling information from the explorer whilst running stress tests. After capturing the information the servers need to be restarted. curl http://54.201.207.240:6060/debug/pprof/allocs?seconds=60 > allocs curl http://54.201.207.240:6060/debug/pprof/heap?seconds=60 > heap curl http://54.201.207.240:6060/debug/pprof/goroutine?seconds=60 > goroutine","title":"Setup"},{"location":"resources/profiling/#displaying-various-profiles","text":"tmux attach -t allocs sudo go tool pprof -http=0.0.0.0:80 allocs allocs tmux attach -t heap sudo go tool pprof -http=0.0.0.0:8080 heap tmux attach -t goroutine sudo go tool pprof -http=0.0.0.0:8081 goroutine","title":"Displaying Various profiles"},{"location":"resources/prototype.johnwhitton.dev/","text":"prototype.johnwhitton.dev Nginx # Setup nginx sudo amazon-linux-extras list | grep nginx sudo amazon-linux-extras enable nginx1 sudo yum -y install metadata sudo yum -y install nginx nginx -v sudo yum install -y httpd-tools # Start nginx sudo nginx -h sudo nginx sudo nginx -s stop vim /etc/nginx/nginx.conf # Setup the four endpoints # 8180/swaggerui/index.html - / # 8082/docs - /redux/ # 6060/debug/pprof/ - /pprof/ # 8100 - /allocs/ # 8101 - /goroutine/ # 8102 - /heap/ # Serve the website sudo nginx -s stop sudo cp /etc/nginx/nginx.conf /etc/nginx/nginx.conf.bk sudo cp -R web /usr/share/nginx/. sudo vim /etc/nginx/nginx.conf # Modify root directory to root /usr/share/nginx/web; sudo nginx -s stop sudo nginx -t sudo nginx # Create ssl cert - Note this was not clean - all commands below may not be needed # https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/SSL-on-amazon-linux-2.html#letsencrypt # https://certbot.eff.org/lets-encrypt/centosrhel6-nginx sudo wget -r --no-parent -A 'epel-release-*.rpm' http://dl.fedoraproject.org/pub/epel/7/x86_64/Packages/e/ sudo rpm -Uvh dl.fedoraproject.org/pub/epel/7/x86_64/Packages/e/epel-release-*.rpm sudo yum-config-manager --enable epel* sudo yum repolist all sudo yum -y install python3 sudo yum -y install certbot sudo yum -y install python-certbot-nginx sudo certbot --nginx Local swagger Profiler Heap mem allocs","title":"Prototyping"},{"location":"resources/prototype.johnwhitton.dev/#prototypejohnwhittondev","text":"","title":"prototype.johnwhitton.dev"},{"location":"resources/prototype.johnwhitton.dev/#nginx","text":"# Setup nginx sudo amazon-linux-extras list | grep nginx sudo amazon-linux-extras enable nginx1 sudo yum -y install metadata sudo yum -y install nginx nginx -v sudo yum install -y httpd-tools # Start nginx sudo nginx -h sudo nginx sudo nginx -s stop vim /etc/nginx/nginx.conf # Setup the four endpoints # 8180/swaggerui/index.html - / # 8082/docs - /redux/ # 6060/debug/pprof/ - /pprof/ # 8100 - /allocs/ # 8101 - /goroutine/ # 8102 - /heap/ # Serve the website sudo nginx -s stop sudo cp /etc/nginx/nginx.conf /etc/nginx/nginx.conf.bk sudo cp -R web /usr/share/nginx/. sudo vim /etc/nginx/nginx.conf # Modify root directory to root /usr/share/nginx/web; sudo nginx -s stop sudo nginx -t sudo nginx # Create ssl cert - Note this was not clean - all commands below may not be needed # https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/SSL-on-amazon-linux-2.html#letsencrypt # https://certbot.eff.org/lets-encrypt/centosrhel6-nginx sudo wget -r --no-parent -A 'epel-release-*.rpm' http://dl.fedoraproject.org/pub/epel/7/x86_64/Packages/e/ sudo rpm -Uvh dl.fedoraproject.org/pub/epel/7/x86_64/Packages/e/epel-release-*.rpm sudo yum-config-manager --enable epel* sudo yum repolist all sudo yum -y install python3 sudo yum -y install certbot sudo yum -y install python-certbot-nginx sudo certbot --nginx Local swagger Profiler Heap mem allocs","title":"Nginx"},{"location":"resources/stress/","text":"Stress Tests Stress Testing When launching a network with a new version of the software it is important to run stress tests. Today this is typically done on stressnet and harmony stress repository is used. Notes from Seb And if you're wondering why there seems to be such a massive discrepancy between how fast the stress tool appear to send txs and how few txs actually end up on the explorer - that usually comes down to either a) your ip address getting rate limited by the endpoint rules (AWS network setting I presume), or b) your sender address being marked for spam by the receiving node(s) To fully max out tx stress testing you need to run a modified binary that disables some of the tx pool validation checks and route your requests via that node. So when I try to maximize the tx load I typically do this: Download the custom node binary: bash <(curl -sSL https://raw.githubusercontent.com/SebastianJ/harmony-tools/master/install/install.sh) --node --disable-tx-validation Generate a bls key for a given shard (e.g. shard 0): bash <(curl -sSL https://raw.githubusercontent.com/SebastianJ/harmony-tools/master/keys/generate.sh) --shard 0 --count 1 Start the node: ./node.sh -k *.key -N stress -S -I -z -D -P Run the spammer using the node: ./stress txs --network stress --infinite --concurrency 100 --from YOUR_ADDRESS --node http://localhost:9500 If the node's not on the same machine as the spammer, check the external ip, e.g. curl ifconfig.me and use --node http://EXTERNAL_IP:9500 Caveat with that setup is that my custom branch of harmony-one/harmony has to stay updated with master and that I have to cut a new release whenever that happens - so it's not ideal for e.g. automated stress-testing. It's not a requirement to stress test tho - it's just a way to try to maximize the throughput using a hacked/modified binary","title":"Stress testing"},{"location":"resources/stress/#stress-tests","text":"","title":"Stress Tests"},{"location":"resources/stress/#stress-testing","text":"When launching a network with a new version of the software it is important to run stress tests. Today this is typically done on stressnet and harmony stress repository is used. Notes from Seb And if you're wondering why there seems to be such a massive discrepancy between how fast the stress tool appear to send txs and how few txs actually end up on the explorer - that usually comes down to either a) your ip address getting rate limited by the endpoint rules (AWS network setting I presume), or b) your sender address being marked for spam by the receiving node(s) To fully max out tx stress testing you need to run a modified binary that disables some of the tx pool validation checks and route your requests via that node. So when I try to maximize the tx load I typically do this: Download the custom node binary: bash <(curl -sSL https://raw.githubusercontent.com/SebastianJ/harmony-tools/master/install/install.sh) --node --disable-tx-validation Generate a bls key for a given shard (e.g. shard 0): bash <(curl -sSL https://raw.githubusercontent.com/SebastianJ/harmony-tools/master/keys/generate.sh) --shard 0 --count 1 Start the node: ./node.sh -k *.key -N stress -S -I -z -D -P Run the spammer using the node: ./stress txs --network stress --infinite --concurrency 100 --from YOUR_ADDRESS --node http://localhost:9500 If the node's not on the same machine as the spammer, check the external ip, e.g. curl ifconfig.me and use --node http://EXTERNAL_IP:9500 Caveat with that setup is that my custom branch of harmony-one/harmony has to stay updated with master and that I have to cut a new release whenever that happens - so it's not ideal for e.g. automated stress-testing. It's not a requirement to stress test tho - it's just a way to try to maximize the throughput using a hacked/modified binary","title":"Stress Testing"},{"location":"resources/www.johnwhitton.dev/","text":"www.johnwhitton.dev Overview This gives an overview of how to install a website on an AWS instance. The instance can be setup using the setup guide . Nginx setup # Setup nginx sudo amazon-linux-extras list | grep nginx sudo amazon-linux-extras enable nginx1 sudo yum -y install nginx nginx -v sudo yum install -y httpd-tools # Start nginx sudo nginx -h sudo nginx sudo nginx -s stop vim /etc/nginx/nginx.conf # Create the website cd ~ mkdir web cd web wget https://html5up.net/dimension/download --no-check-certificate unzip download rm download # Serve the website sudo nginx -s stop sudo cp /etc/nginx/nginx.conf /etc/nginx/nginx.conf.bk sudo cp -R web /usr/share/nginx/. sudo vim /etc/nginx/nginx.conf # Modify root directory to root /usr/share/nginx/web; sudo nginx -s stop sudo nginx -t sudo nginx # Password protect the website # https://docs.nginx.com/nginx/admin-guide/security-controls/configuring-http-basic-authentication/ sudo htpasswd -c /etc/nginx/.htpasswd admin JohnWhitton JohnWhitton # Create ssl cert - Note this was not clean - all commands below may not be needed # https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/SSL-on-amazon-linux-2.html#letsencrypt # https://certbot.eff.org/lets-encrypt/centosrhel6-nginx sudo wget -r --no-parent -A 'epel-release-*.rpm' http://dl.fedoraproject.org/pub/epel/7/x86_64/Packages/e/ sudo rpm -Uvh dl.fedoraproject.org/pub/epel/7/x86_64/Packages/e/epel-release-*.rpm sudo yum-config-manager --enable epel* sudo yum repolist all sudo yum -y install python3 sudo yum -y install certbot sudo yum -y install python-certbot-nginx sudo certbot --nginx # Wildcard cert - https://medium.com/@utkarsh_verma/how-to-obtain-a-wildcard-ssl-certificate-from-lets-encrypt-and-setup-nginx-to-use-wildcard-cfb050c8b33f # https://www.digitalocean.com/community/tutorials/how-to-use-certbot-standalone-mode-to-retrieve-let-s-encrypt-ssl-certificates-on-centos-7 sudo certbot --server https://acme-v02.api.letsencrypt.org/directory -d *.johnwhitton.dev -d johnwhitton.dev --manual --preferred-challenges dns-01 certonly # Add the TXT record on google domains and wait a couple of minutes # https://domains.google.com/m/registrar/johnwhitton.dev/dns # - Congratulations! Your certificate and chain have been saved at: # /etc/letsencrypt/live/johnwhitton.dev/fullchain.pem # Modify the config file sudo nginx -s stop Sample /etc/nginx/nginx.conf file # For more information on configuration, see: # * Official English Documentation: http://nginx.org/en/docs/ # * Official Russian Documentation: http://nginx.org/ru/docs/ user nginx; worker_processes auto; error_log /var/log/nginx/error.log; pid /run/nginx.pid; # Load dynamic modules. See /usr/share/doc/nginx/README.dynamic. include /usr/share/nginx/modules/*.conf; events { worker_connections 1024; } http { log_format main '$remote_addr - $remote_user [$time_local] \"$request\" ' '$status $body_bytes_sent \"$http_referer\" ' '\"$http_user_agent\" \"$http_x_forwarded_for\"'; access_log /var/log/nginx/access.log main; sendfile on; tcp_nopush on; tcp_nodelay on; keepalive_timeout 65; types_hash_max_size 2048; include /etc/nginx/mime.types; default_type application/octet-stream; # Load modular configuration files from the /etc/nginx/conf.d directory. # See http://nginx.org/en/docs/ngx_core_module.html#include # for more information. include /etc/nginx/conf.d/*.conf; server { listen 80 default_server; listen [::]:80 default_server; server_name _; root /usr/share/nginx/web; # Load configuration files for the default server block. include /etc/nginx/default.d/*.conf; location / { auth_basic \"Admin's Area\"; auth_basic_user_file /etc/nginx/.htpasswd; } error_page 403 404 /40x.html; location = /40x.html { } error_page 500 502 503 504 /50x.html; location = /50x.html { } } server { server_name *.johnwhitton.dev; # managed by Certbot root /usr/share/nginx/web; # Load configuration files for the default server block. include /etc/nginx/default.d/*.conf; location / { auth_basic \"Admin's Area\"; auth_basic_user_file /etc/nginx/.htpasswd; } error_page 403 404 /40x.html; location = /40x.html { } error_page 500 502 503 504 /50x.html; location = /50x.html { } listen [::]:443 ssl ipv6only=on; # managed by Certbot listen 443 ssl; # managed by Certbot ssl_certificate /etc/letsencrypt/live/johnwhitton.dev/fullchain.pem; # managed by Certbot ssl_certificate_key /etc/letsencrypt/live/johnwhitton.dev/privkey.pem; # managed by Certbot include /etc/letsencrypt/options-ssl-nginx.conf; # managed by Certbot ssl_dhparam /etc/letsencrypt/ssl-dhparams.pem; # managed by Certbot } server { if ($host = johnwhitton.dev) { return 301 https://$host$request_uri; } # managed by Certbot listen 80 ; listen [::]:80 ; server_name *.johnwhitton.dev; return 404; # managed by Certbot }} Clone the website Create the ssl key Direct the domain to it","title":"Website"},{"location":"resources/www.johnwhitton.dev/#wwwjohnwhittondev","text":"","title":"www.johnwhitton.dev"},{"location":"resources/www.johnwhitton.dev/#overview","text":"This gives an overview of how to install a website on an AWS instance. The instance can be setup using the setup guide .","title":"Overview"},{"location":"resources/www.johnwhitton.dev/#nginx-setup","text":"# Setup nginx sudo amazon-linux-extras list | grep nginx sudo amazon-linux-extras enable nginx1 sudo yum -y install nginx nginx -v sudo yum install -y httpd-tools # Start nginx sudo nginx -h sudo nginx sudo nginx -s stop vim /etc/nginx/nginx.conf # Create the website cd ~ mkdir web cd web wget https://html5up.net/dimension/download --no-check-certificate unzip download rm download # Serve the website sudo nginx -s stop sudo cp /etc/nginx/nginx.conf /etc/nginx/nginx.conf.bk sudo cp -R web /usr/share/nginx/. sudo vim /etc/nginx/nginx.conf # Modify root directory to root /usr/share/nginx/web; sudo nginx -s stop sudo nginx -t sudo nginx # Password protect the website # https://docs.nginx.com/nginx/admin-guide/security-controls/configuring-http-basic-authentication/ sudo htpasswd -c /etc/nginx/.htpasswd admin JohnWhitton JohnWhitton # Create ssl cert - Note this was not clean - all commands below may not be needed # https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/SSL-on-amazon-linux-2.html#letsencrypt # https://certbot.eff.org/lets-encrypt/centosrhel6-nginx sudo wget -r --no-parent -A 'epel-release-*.rpm' http://dl.fedoraproject.org/pub/epel/7/x86_64/Packages/e/ sudo rpm -Uvh dl.fedoraproject.org/pub/epel/7/x86_64/Packages/e/epel-release-*.rpm sudo yum-config-manager --enable epel* sudo yum repolist all sudo yum -y install python3 sudo yum -y install certbot sudo yum -y install python-certbot-nginx sudo certbot --nginx # Wildcard cert - https://medium.com/@utkarsh_verma/how-to-obtain-a-wildcard-ssl-certificate-from-lets-encrypt-and-setup-nginx-to-use-wildcard-cfb050c8b33f # https://www.digitalocean.com/community/tutorials/how-to-use-certbot-standalone-mode-to-retrieve-let-s-encrypt-ssl-certificates-on-centos-7 sudo certbot --server https://acme-v02.api.letsencrypt.org/directory -d *.johnwhitton.dev -d johnwhitton.dev --manual --preferred-challenges dns-01 certonly # Add the TXT record on google domains and wait a couple of minutes # https://domains.google.com/m/registrar/johnwhitton.dev/dns # - Congratulations! Your certificate and chain have been saved at: # /etc/letsencrypt/live/johnwhitton.dev/fullchain.pem # Modify the config file sudo nginx -s stop Sample /etc/nginx/nginx.conf file # For more information on configuration, see: # * Official English Documentation: http://nginx.org/en/docs/ # * Official Russian Documentation: http://nginx.org/ru/docs/ user nginx; worker_processes auto; error_log /var/log/nginx/error.log; pid /run/nginx.pid; # Load dynamic modules. See /usr/share/doc/nginx/README.dynamic. include /usr/share/nginx/modules/*.conf; events { worker_connections 1024; } http { log_format main '$remote_addr - $remote_user [$time_local] \"$request\" ' '$status $body_bytes_sent \"$http_referer\" ' '\"$http_user_agent\" \"$http_x_forwarded_for\"'; access_log /var/log/nginx/access.log main; sendfile on; tcp_nopush on; tcp_nodelay on; keepalive_timeout 65; types_hash_max_size 2048; include /etc/nginx/mime.types; default_type application/octet-stream; # Load modular configuration files from the /etc/nginx/conf.d directory. # See http://nginx.org/en/docs/ngx_core_module.html#include # for more information. include /etc/nginx/conf.d/*.conf; server { listen 80 default_server; listen [::]:80 default_server; server_name _; root /usr/share/nginx/web; # Load configuration files for the default server block. include /etc/nginx/default.d/*.conf; location / { auth_basic \"Admin's Area\"; auth_basic_user_file /etc/nginx/.htpasswd; } error_page 403 404 /40x.html; location = /40x.html { } error_page 500 502 503 504 /50x.html; location = /50x.html { } } server { server_name *.johnwhitton.dev; # managed by Certbot root /usr/share/nginx/web; # Load configuration files for the default server block. include /etc/nginx/default.d/*.conf; location / { auth_basic \"Admin's Area\"; auth_basic_user_file /etc/nginx/.htpasswd; } error_page 403 404 /40x.html; location = /40x.html { } error_page 500 502 503 504 /50x.html; location = /50x.html { } listen [::]:443 ssl ipv6only=on; # managed by Certbot listen 443 ssl; # managed by Certbot ssl_certificate /etc/letsencrypt/live/johnwhitton.dev/fullchain.pem; # managed by Certbot ssl_certificate_key /etc/letsencrypt/live/johnwhitton.dev/privkey.pem; # managed by Certbot include /etc/letsencrypt/options-ssl-nginx.conf; # managed by Certbot ssl_dhparam /etc/letsencrypt/ssl-dhparams.pem; # managed by Certbot } server { if ($host = johnwhitton.dev) { return 301 https://$host$request_uri; } # managed by Certbot listen 80 ; listen [::]:80 ; server_name *.johnwhitton.dev; return 404; # managed by Certbot }} Clone the website Create the ssl key Direct the domain to it","title":"Nginx setup"},{"location":"setup/analytics/","text":"Analytics and Python Overview Harmony has a number of python scripts used to capture analytics information. This gives an overview of how to build and run these scripts. The scripts are held in the harmony-log-analysis GitHub repository. Hosted Environment Harmony has http://analytics.hmny.io/ a hosted machine which supports Jupyter notebook running. It has installed all the requirements, so you don't need to worry about the environment setup. The machine requires a password which can be obtained via a teammate. It also supports multiple operation tools. Zerologs (node logs) downloading from s3 bucket # download the latest 2 batches of logs from stress network ops log download stn --count 2 # download a specific file ops log download-from-path s3://harmony-benchmark/logs/2020/03/27/001302 --exclude \"*\" --include \"zerolog-validator-*-2020-03-25T*.gz\" {% hint style=\"info\" %} all the ops commands can be executed in any directory, no need to run under ~/ops folder. (reference: ops tool repo ) {% endhint %} Explorer mini log daily downloading Currently, the explorer mini log downloading and analysis is implemented automatically using cronjob. To check and revise cronjob, execute the following command: crontab -e Reference: tutorial of cron job . Below is the example of explorer mini log ( reference repo ). # downloading new logs at 0:00 (UTC) everyday # m h dom mon dow command 0 0 * * * /home/ubuntu/jupyter/harmony-log-analysis/projects/explorer_mini_log_analysis/daily_log.sh # analyze OSTN logs at 0:02 (UTC), mainnet logs at 0:07 (UTC) everyday 2 0 * * * /home/ubuntu/jupyter/harmony-log-analysis/projects/explorer_mini_log_analysis/daily_analysis_ostn.sh 7 0 * * * /home/ubuntu/jupyter/harmony-log-analysis/projects/explorer_mini_log_analysis/daily_analysis_mainnet.sh # publish the report to GitHub Pages at 0:12 (UTC) 12 0 * * * /home/ubuntu/jupyter/harmony-log-analysis/projects/explorer_mini_log_analysis/daily_github.sh Jupyter notebook protecting and sharing # protect a notebook, only viewable sudo ops notebook protect Test.ipynb # protect a file or directory sudo ops notebook protect-path ~/jupyter/Test.ipynb # share a notebook, make it editable sudo ops notebook share Test.ipynb # share a file or directory sudo ops notebook share-path ~/jupyter/Test.ipynb {% hint style=\"info\" %} for all the commands related to notebooks, you need to use sudo , which requires password, please ask Daniel or Yishuang. {% endhint %} Local Development If you want to run locally, you can git clone the harmony-log-analysis GitHub repo to run the python scripts or notebooks. Or you can follow the README ( example ) in each project under /projects folder to run the specific task only. Requirements Currently all the scripts only support python3 , you need to ensure python3 installed in your local computer. If you don't, run the following command. After installing python3, follow README to install python packages needed for the project. brew install python3 Projects in Progress Projects are stored in harmony-log-analysis folder on the hosted machine and Github repository . Daily Explorer mini log analysis Node log analysis Processing time analysis Error classification analysis Network crash analysis Consensus message analysis Harmony RPC call Economic test Transaction Validator & Delegator info Jenkins API Reference Material Video overview - Gives an overview of how to run the validator & delegator queries Installation gist - Gives instructions on how to run the queries locally Analytics ops tool - Gives instructions to download zerologs and change the attributes of notebooks Explorer mini logs - Gives instructions to download explorer mini logs Cron job tutorial - Gives instructions to set up cron jobs","title":"Analytics"},{"location":"setup/analytics/#analytics-and-python","text":"","title":"Analytics and Python"},{"location":"setup/analytics/#overview","text":"Harmony has a number of python scripts used to capture analytics information. This gives an overview of how to build and run these scripts. The scripts are held in the harmony-log-analysis GitHub repository.","title":"Overview"},{"location":"setup/analytics/#hosted-environment","text":"Harmony has http://analytics.hmny.io/ a hosted machine which supports Jupyter notebook running. It has installed all the requirements, so you don't need to worry about the environment setup. The machine requires a password which can be obtained via a teammate. It also supports multiple operation tools. Zerologs (node logs) downloading from s3 bucket # download the latest 2 batches of logs from stress network ops log download stn --count 2 # download a specific file ops log download-from-path s3://harmony-benchmark/logs/2020/03/27/001302 --exclude \"*\" --include \"zerolog-validator-*-2020-03-25T*.gz\" {% hint style=\"info\" %} all the ops commands can be executed in any directory, no need to run under ~/ops folder. (reference: ops tool repo ) {% endhint %} Explorer mini log daily downloading Currently, the explorer mini log downloading and analysis is implemented automatically using cronjob. To check and revise cronjob, execute the following command: crontab -e Reference: tutorial of cron job . Below is the example of explorer mini log ( reference repo ). # downloading new logs at 0:00 (UTC) everyday # m h dom mon dow command 0 0 * * * /home/ubuntu/jupyter/harmony-log-analysis/projects/explorer_mini_log_analysis/daily_log.sh # analyze OSTN logs at 0:02 (UTC), mainnet logs at 0:07 (UTC) everyday 2 0 * * * /home/ubuntu/jupyter/harmony-log-analysis/projects/explorer_mini_log_analysis/daily_analysis_ostn.sh 7 0 * * * /home/ubuntu/jupyter/harmony-log-analysis/projects/explorer_mini_log_analysis/daily_analysis_mainnet.sh # publish the report to GitHub Pages at 0:12 (UTC) 12 0 * * * /home/ubuntu/jupyter/harmony-log-analysis/projects/explorer_mini_log_analysis/daily_github.sh Jupyter notebook protecting and sharing # protect a notebook, only viewable sudo ops notebook protect Test.ipynb # protect a file or directory sudo ops notebook protect-path ~/jupyter/Test.ipynb # share a notebook, make it editable sudo ops notebook share Test.ipynb # share a file or directory sudo ops notebook share-path ~/jupyter/Test.ipynb {% hint style=\"info\" %} for all the commands related to notebooks, you need to use sudo , which requires password, please ask Daniel or Yishuang. {% endhint %}","title":"Hosted Environment"},{"location":"setup/analytics/#local-development","text":"If you want to run locally, you can git clone the harmony-log-analysis GitHub repo to run the python scripts or notebooks. Or you can follow the README ( example ) in each project under /projects folder to run the specific task only.","title":"Local Development"},{"location":"setup/analytics/#requirements","text":"Currently all the scripts only support python3 , you need to ensure python3 installed in your local computer. If you don't, run the following command. After installing python3, follow README to install python packages needed for the project. brew install python3","title":"Requirements"},{"location":"setup/analytics/#projects-in-progress","text":"Projects are stored in harmony-log-analysis folder on the hosted machine and Github repository . Daily Explorer mini log analysis Node log analysis Processing time analysis Error classification analysis Network crash analysis Consensus message analysis Harmony RPC call Economic test Transaction Validator & Delegator info Jenkins API","title":"Projects in Progress"},{"location":"setup/analytics/#reference-material","text":"Video overview - Gives an overview of how to run the validator & delegator queries Installation gist - Gives instructions on how to run the queries locally Analytics ops tool - Gives instructions to download zerologs and change the attributes of notebooks Explorer mini logs - Gives instructions to download explorer mini logs Cron job tutorial - Gives instructions to set up cron jobs","title":"Reference Material"},{"location":"setup/api/","text":"API and RPC Familiarization Overview Harmony have a robust set of API's which are currently documented using Postman and moving forward will be transitions to swagger . Postman is the easiest way to familiarize yourself with the API's. Quickstart - testing API's The easiest way to test API's is to go to Harmony Postman Team select the documentation and download the mac version and run on your machine. Documentation API Documentation Mainnet ONE OSTN Release Harmony Postman Team - OSTN Postman Publish API Development Roles and Permissions Admin - Admins are responsible for publishing to Postman and managing team members Leo, RJ, Daniel, Ganesha Editor - Editors develop API's and update documentation Janet, Daniel, Minh, Matt, Dennis Viewer Viewers use API's in testing or developers can use the public repository as detailed below Changing and Documenting API's Any changes should begin with a github issue and pull Github Issue Complete the Work Walk through for New API's (example - GetValidatorInformation) Include the definition in backend.go ( v1 and v2 ) Include the definition in blockchain.go ( v1 and v2 ) Include the definitions in hmyapi backend.go and hmyapi README.md Write the API logic in hmy/api_backend.go Create unit test and test locally Update Postman current release to include the API definition and test with localhost Pull Request Create Pull request Note components impacted (block explorer, staking dashboard, wallets, etc) Approve and merge Validation Once deployed to a testnet environment Ensure the API works as expected Add an example to the Postman collection for the testnet environment net_version example rpc.go - starts the http endpoint and receives all requests api_backend.go - holds the api call and return parameters backend.go - holds the function definition (json-rpc) net.go - is where the function logic is held Deploying a new Release We have documented two releases in Postman - each release is managed in it's own collection and published with it's own URL. 1.0 - Mainnet One - Postman Collection - Endpoint - https://apitest.harmony.one/ 2.0 - Open Staking - Postman Collection - Endpoint - https://api.os.hmny.io/ Ongoing we will either continue the process of a new collection and endpoint moving forward or replace or augment this with swagger. Task list Ensure all staking API Parameter and Return values are up to date with latest sample request and response Ensure that v1 and v2 - all have the same API's i.e. duplicate the API's from v1 and include in v2 if there not there Republish Postman to update https://api.os.hmny.io/ Optional - clean out old and redundant collections Update docs.harmony.one to remove all old API documentation and just link to the two postman collections Review all APIs to ensure that Postman is complete and all API's have up to date request and responses Republish https://api.os.hmny.io/","title":"API Development"},{"location":"setup/api/#api-and-rpc-familiarization","text":"","title":"API and RPC Familiarization"},{"location":"setup/api/#overview","text":"Harmony have a robust set of API's which are currently documented using Postman and moving forward will be transitions to swagger . Postman is the easiest way to familiarize yourself with the API's.","title":"Overview"},{"location":"setup/api/#quickstart-testing-apis","text":"The easiest way to test API's is to go to Harmony Postman Team select the documentation and download the mac version and run on your machine.","title":"Quickstart - testing API's"},{"location":"setup/api/#documentation","text":"API Documentation Mainnet ONE OSTN Release Harmony Postman Team - OSTN Postman Publish","title":"Documentation"},{"location":"setup/api/#api-development-roles-and-permissions","text":"Admin - Admins are responsible for publishing to Postman and managing team members Leo, RJ, Daniel, Ganesha Editor - Editors develop API's and update documentation Janet, Daniel, Minh, Matt, Dennis Viewer Viewers use API's in testing or developers can use the public repository as detailed below","title":"API Development Roles and Permissions"},{"location":"setup/api/#changing-and-documenting-apis","text":"Any changes should begin with a github issue and pull Github Issue Complete the Work Walk through for New API's (example - GetValidatorInformation) Include the definition in backend.go ( v1 and v2 ) Include the definition in blockchain.go ( v1 and v2 ) Include the definitions in hmyapi backend.go and hmyapi README.md Write the API logic in hmy/api_backend.go Create unit test and test locally Update Postman current release to include the API definition and test with localhost Pull Request Create Pull request Note components impacted (block explorer, staking dashboard, wallets, etc) Approve and merge Validation Once deployed to a testnet environment Ensure the API works as expected Add an example to the Postman collection for the testnet environment","title":"Changing and Documenting API's"},{"location":"setup/api/#net_version-example","text":"rpc.go - starts the http endpoint and receives all requests api_backend.go - holds the api call and return parameters backend.go - holds the function definition (json-rpc) net.go - is where the function logic is held","title":"net_version example"},{"location":"setup/api/#deploying-a-new-release","text":"We have documented two releases in Postman - each release is managed in it's own collection and published with it's own URL. 1.0 - Mainnet One - Postman Collection - Endpoint - https://apitest.harmony.one/ 2.0 - Open Staking - Postman Collection - Endpoint - https://api.os.hmny.io/ Ongoing we will either continue the process of a new collection and endpoint moving forward or replace or augment this with swagger.","title":"Deploying a new Release"},{"location":"setup/api/#task-list","text":"Ensure all staking API Parameter and Return values are up to date with latest sample request and response Ensure that v1 and v2 - all have the same API's i.e. duplicate the API's from v1 and include in v2 if there not there Republish Postman to update https://api.os.hmny.io/ Optional - clean out old and redundant collections Update docs.harmony.one to remove all old API documentation and just link to the two postman collections Review all APIs to ensure that Postman is complete and all API's have up to date request and responses Republish https://api.os.hmny.io/","title":"Task list"},{"location":"setup/harmony-go-setup/","text":"Setting up the Go Environment Install Go 1.13.6 The Binaries are located at https://golang.org/dl/ : macOS installer: go1.13.6.darwin-amd64.pkg Linux archive: go1.13.6.linux-amd64.tar.gz Windows installer: go1.13.6.windows-amd64.msi Check Bash Version Some scripts require at least bash 4.x You can check your current bash version with $ bash --version Update bash if it's outdated Assuming you're using macOS, install Homebrew first. run $ brew install bash on your terminal run $ which -a bash and keep track of the directory of the newer bash version edit /etc/shells , appending the new directory to the file. (requires admin privileges) i.e. $ sudo vim /etc/shells set the new bash version as the default shell chsh -s <directory of new version> Install gmp, openssl, and jq For Mac: brew install gmp brew install openssl brew install jq For Linux: sudo apt-get install libgmp3-dev libssl-dev jq # or For AWS linux sudo yum install gmp-devel openssl-devel sudo yum install gcc-c++ glibc-static openssl-static crypto-static gmp-static cd ../mcl/ make clean cd ../bls/ make clean cd ../harmony/ make linux_static Setup Global Variables You will have to pick a directory name and remember for future deployments You will have to repeat this step for every new terminal instance export GOPATH=$HOME/<chosen directory> export GO111MODULE=on {% hint style=\"info\" %} We set GOPATH to specify that our path (and it's subdirectories) contain Go source files and binaries. GO111MODULE is set to on to allow us to use Go modules within the GOPATH {% endhint %} Create the Working Directory A new directory needs to be created in the GOPATH; the structure resembles the Github address mkdir -p $GOPATH/src/github.com/harmony-one Clone the Github Repository Before you begin, make sure you have your SSH keys set up to communicate with Github cd $GOPATH/src/github.com/harmony-one git clone git@github.com:harmony-one/mcl.git git clone git@github.com:harmony-one/bls.git git clone git@github.com:harmony-one/harmony.git Update build tools cd harmony ./scripts/install_build_tools.sh You should now be ready to build. Run the Makefile make The binaries should now be built and ready to deploy! Alternative: Build Without the Makefile First set some important environmental variables: export CGO_CFLAGS=\"-I$GOPATH/src/github.com/harmony-one/bls/include -I$GOPATH/src/github.com/harmony-one/mcl/include -I/usr/local/opt/openssl/include\" export CGO_LDFLAGS=\"-L$GOPATH/src/github.com/harmony-one/bls/lib -L/usr/local/opt/openssl/lib\" export LD_LIBRARY_PATH=$GOPATH/src/github.com/harmony-one/bls/lib:$GOPATH/src/github.com/harmony-one/mcl/lib:/usr/local/opt/openssl/lib export LIBRARY_PATH=$LD_LIBRARY_PATH export DYLD_FALLBACK_LIBRARY_PATH=$LD_LIBRARY_PATH export GO111MODULE=on Then, from the harmony directory, run the following script: ./scripts/go_executable_build.sh","title":"Harmony golang setup"},{"location":"setup/harmony-go-setup/#setting-up-the-go-environment","text":"","title":"Setting up the Go Environment"},{"location":"setup/harmony-go-setup/#install-go-1136","text":"The Binaries are located at https://golang.org/dl/ : macOS installer: go1.13.6.darwin-amd64.pkg Linux archive: go1.13.6.linux-amd64.tar.gz Windows installer: go1.13.6.windows-amd64.msi","title":"Install Go 1.13.6"},{"location":"setup/harmony-go-setup/#check-bash-version","text":"Some scripts require at least bash 4.x You can check your current bash version with $ bash --version","title":"Check Bash Version"},{"location":"setup/harmony-go-setup/#update-bash-if-its-outdated","text":"Assuming you're using macOS, install Homebrew first. run $ brew install bash on your terminal run $ which -a bash and keep track of the directory of the newer bash version edit /etc/shells , appending the new directory to the file. (requires admin privileges) i.e. $ sudo vim /etc/shells set the new bash version as the default shell chsh -s <directory of new version>","title":"Update bash if it's outdated"},{"location":"setup/harmony-go-setup/#install-gmp-openssl-and-jq","text":"For Mac: brew install gmp brew install openssl brew install jq For Linux: sudo apt-get install libgmp3-dev libssl-dev jq # or For AWS linux sudo yum install gmp-devel openssl-devel sudo yum install gcc-c++ glibc-static openssl-static crypto-static gmp-static cd ../mcl/ make clean cd ../bls/ make clean cd ../harmony/ make linux_static","title":"Install gmp, openssl, and jq"},{"location":"setup/harmony-go-setup/#setup-global-variables","text":"You will have to pick a directory name and remember for future deployments You will have to repeat this step for every new terminal instance export GOPATH=$HOME/<chosen directory> export GO111MODULE=on {% hint style=\"info\" %} We set GOPATH to specify that our path (and it's subdirectories) contain Go source files and binaries. GO111MODULE is set to on to allow us to use Go modules within the GOPATH {% endhint %}","title":"Setup Global Variables"},{"location":"setup/harmony-go-setup/#create-the-working-directory","text":"A new directory needs to be created in the GOPATH; the structure resembles the Github address mkdir -p $GOPATH/src/github.com/harmony-one","title":"Create the Working Directory"},{"location":"setup/harmony-go-setup/#clone-the-github-repository","text":"","title":"Clone the Github Repository"},{"location":"setup/harmony-go-setup/#before-you-begin-make-sure-you-have-your-ssh-keys-set-up-to-communicate-with-github","text":"cd $GOPATH/src/github.com/harmony-one git clone git@github.com:harmony-one/mcl.git git clone git@github.com:harmony-one/bls.git git clone git@github.com:harmony-one/harmony.git","title":"Before you begin, make sure you have your SSH keys set up to communicate with Github"},{"location":"setup/harmony-go-setup/#update-build-tools","text":"cd harmony ./scripts/install_build_tools.sh You should now be ready to build.","title":"Update build tools"},{"location":"setup/harmony-go-setup/#run-the-makefile","text":"make The binaries should now be built and ready to deploy!","title":"Run the Makefile"},{"location":"setup/harmony-go-setup/#alternative-build-without-the-makefile","text":"First set some important environmental variables: export CGO_CFLAGS=\"-I$GOPATH/src/github.com/harmony-one/bls/include -I$GOPATH/src/github.com/harmony-one/mcl/include -I/usr/local/opt/openssl/include\" export CGO_LDFLAGS=\"-L$GOPATH/src/github.com/harmony-one/bls/lib -L/usr/local/opt/openssl/lib\" export LD_LIBRARY_PATH=$GOPATH/src/github.com/harmony-one/bls/lib:$GOPATH/src/github.com/harmony-one/mcl/lib:/usr/local/opt/openssl/lib export LIBRARY_PATH=$LD_LIBRARY_PATH export DYLD_FALLBACK_LIBRARY_PATH=$LD_LIBRARY_PATH export GO111MODULE=on Then, from the harmony directory, run the following script: ./scripts/go_executable_build.sh","title":"Alternative: Build Without the Makefile"},{"location":"setup/local/","text":"Deploy Harmony Locally Set up Environmental Variables Make sure your GOPATH is still set from Setting up the Go Environment $ cd $GOPATH/src/github.com/harmony-one/harmony $ . ./scripts/setup_bls_build_flags.sh The . command executes the command(s) in the setup_bls_build_flags.sh file. Running a Local Blockchain This script starts a local instance of the Harmony blockchain devnet with 2 shards and 7 nodes $ ./test/debug.sh Configuring the Local Blockchain This section requires use of the Harmony CLI, so you might want to come back to this section later. You can add/remove nodes by modifying the test/configs/local_resharding.txt file. Add a new line in the following format: <ip> <port> <mode> <account> <bls public key> As an example, this is the entry for one of the validators: 127.0.0.1 9006 validator one1spshr72utf6rwxseaz339j09ed8p6f8ke370zj 2d61379e44a772e5757e27ee2b3874254f56073e6bd226eb8b160371cc3c18b8c4977bd3dcb71fd57dc62bf0e143fd08 Test the Local Blockchain We will test the local blockchain we just spun up using ./test/kill_nodes.sh . Start up another terminal instance, set up the environmental variables again , then input: $ ./bin/wallet list $ ./bin/wallet -p local balances This local blockchain will be used to test many of the different tools we'll cover later on in this guide.","title":"Local Development"},{"location":"setup/local/#deploy-harmony-locally","text":"","title":"Deploy Harmony Locally"},{"location":"setup/local/#set-up-environmental-variables","text":"Make sure your GOPATH is still set from Setting up the Go Environment $ cd $GOPATH/src/github.com/harmony-one/harmony $ . ./scripts/setup_bls_build_flags.sh The . command executes the command(s) in the setup_bls_build_flags.sh file.","title":"Set up Environmental Variables"},{"location":"setup/local/#running-a-local-blockchain","text":"This script starts a local instance of the Harmony blockchain devnet with 2 shards and 7 nodes $ ./test/debug.sh","title":"Running a Local Blockchain"},{"location":"setup/local/#configuring-the-local-blockchain","text":"This section requires use of the Harmony CLI, so you might want to come back to this section later. You can add/remove nodes by modifying the test/configs/local_resharding.txt file. Add a new line in the following format: <ip> <port> <mode> <account> <bls public key> As an example, this is the entry for one of the validators: 127.0.0.1 9006 validator one1spshr72utf6rwxseaz339j09ed8p6f8ke370zj 2d61379e44a772e5757e27ee2b3874254f56073e6bd226eb8b160371cc3c18b8c4977bd3dcb71fd57dc62bf0e143fd08","title":"Configuring the Local Blockchain"},{"location":"setup/local/#test-the-local-blockchain","text":"We will test the local blockchain we just spun up using ./test/kill_nodes.sh . Start up another terminal instance, set up the environmental variables again , then input: $ ./bin/wallet list $ ./bin/wallet -p local balances This local blockchain will be used to test many of the different tools we'll cover later on in this guide.","title":"Test the Local Blockchain"},{"location":"setup/python/","text":"Setting up the Python Environment Set up environment 1) Check Python version The first thing you need to do is to check whether you have Python3 installed on your computer. python3 {% hint style=\"info\" %} If you enter into the python environment, and your python version is 3, then you are all set. Just to exit the environment. {% endhint %} exit() {% hint style=\"info\" %} Otherwise you need to use Anaconda or brew to install python3. And then check that. {% endhint %} brew install python # or https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/eb-cli3-install-linux.html sudo yum install python3 curl -O https://bootstrap.pypa.io/get-pip.py python3 get-pip.py --user 2) Install Package pyhmy Next step is to install the updated package. Check the latest pyhmy version , e.g. the current version is 20.1.23 at the time of writing the document. python3 -m pip install pyhmy==20.1.23 python3 -m pip install pyhmy --upgrade You will require the latest version of pyhmy (which may not install if you already have it). To get latest version, just do python3 -m pip install pyhmy --upgrade 3) Import cli module and set up the CLI binary python3 from pyhmy import cli env = cli.download() cli.environment.update(env) import os path = os.getcwd() + \"/bin/hmy\" cli.set_binary(path) 4) Set up the CLI binary used by the module cli env = cli.download() cli.environment.update(env) import os path = os.getcwd() + \"/bin/hmy\" cli.set_binary(path) {% hint style=\"info\" %} Next step is to tell this module where the cli binary locates (the path returned by the terminal after downloading the cli). {% endhint %} {% hint style=\"info\" %} If there is no error, then you have set up the environment. You can just use single_call/ expect_call to add keys, transfer money, check address. {% endhint %} Commands Basically, you can use all the commands in the readme file of go-sdk . 1) Check all the accounts you have $ cli.single_call(\"hmy keys list\") If it doesn't look nice for you, you can try print it. It will be more formatted. $ print(cli.single_call(\"hmy keys list\")) 2) Add Account $ cli.single_call(\"hmy keys add EXAMPLE\") 3) Check balance $ cli.single_call(\"hmy --node=https://api.s0.pga.hmny.io balances one12mul56rvk2qjz48pu8ydvnl855dez59krr02mu\") 4) Transfer money $ cli.single_call(\"hmy --node=https://api.s0.pga.hmny.io/ transfer --from one12mul56rvk2qjz48pu8ydvnl855dez59krr02mu --to one17mm27eutyem43s04l6pjmw9makcmzlg9eghlqz --from-shard 0 --to-shard 0 --amount 200 --chain-id devnet\") if you need to enter passphrase or any other interactive actions, you need to use the expect call. To get more information, refer the code here . $ cli.expect_call(\"hmy --node=https://api.s0.pga.hmny.io/ transfer --from one12mul56rvk2qjz48pu8ydvnl855dez59krr02mu --to one17mm27eutyem43s04l6pjmw9makcmzlg9eghlqz --from-shard 0 --to-shard 0 --amount 200 --chain-id devnet --passphrase\"","title":"Setup"},{"location":"setup/python/#setting-up-the-python-environment","text":"","title":"Setting up the Python Environment"},{"location":"setup/python/#set-up-environment","text":"","title":"Set up environment"},{"location":"setup/python/#1-check-python-version","text":"The first thing you need to do is to check whether you have Python3 installed on your computer. python3 {% hint style=\"info\" %} If you enter into the python environment, and your python version is 3, then you are all set. Just to exit the environment. {% endhint %} exit() {% hint style=\"info\" %} Otherwise you need to use Anaconda or brew to install python3. And then check that. {% endhint %} brew install python # or https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/eb-cli3-install-linux.html sudo yum install python3 curl -O https://bootstrap.pypa.io/get-pip.py python3 get-pip.py --user","title":"1) Check Python version"},{"location":"setup/python/#2-install-package-pyhmy","text":"Next step is to install the updated package. Check the latest pyhmy version , e.g. the current version is 20.1.23 at the time of writing the document. python3 -m pip install pyhmy==20.1.23 python3 -m pip install pyhmy --upgrade You will require the latest version of pyhmy (which may not install if you already have it). To get latest version, just do python3 -m pip install pyhmy --upgrade","title":"2) Install Package pyhmy"},{"location":"setup/python/#3-import-cli-module-and-set-up-the-cli-binary","text":"python3 from pyhmy import cli env = cli.download() cli.environment.update(env) import os path = os.getcwd() + \"/bin/hmy\" cli.set_binary(path)","title":"3) Import cli module and set up the CLI binary"},{"location":"setup/python/#4-set-up-the-cli-binary-used-by-the-module-cli","text":"env = cli.download() cli.environment.update(env) import os path = os.getcwd() + \"/bin/hmy\" cli.set_binary(path) {% hint style=\"info\" %} Next step is to tell this module where the cli binary locates (the path returned by the terminal after downloading the cli). {% endhint %} {% hint style=\"info\" %} If there is no error, then you have set up the environment. You can just use single_call/ expect_call to add keys, transfer money, check address. {% endhint %}","title":"4) Set up the CLI binary used by the module cli"},{"location":"setup/python/#commands","text":"Basically, you can use all the commands in the readme file of go-sdk .","title":"Commands"},{"location":"setup/python/#1-check-all-the-accounts-you-have","text":"$ cli.single_call(\"hmy keys list\") If it doesn't look nice for you, you can try print it. It will be more formatted. $ print(cli.single_call(\"hmy keys list\"))","title":"1) Check all the accounts you have"},{"location":"setup/python/#2-add-account","text":"$ cli.single_call(\"hmy keys add EXAMPLE\")","title":"2) Add Account"},{"location":"setup/python/#3-check-balance","text":"$ cli.single_call(\"hmy --node=https://api.s0.pga.hmny.io balances one12mul56rvk2qjz48pu8ydvnl855dez59krr02mu\")","title":"3) Check balance"},{"location":"setup/python/#4-transfer-money","text":"$ cli.single_call(\"hmy --node=https://api.s0.pga.hmny.io/ transfer --from one12mul56rvk2qjz48pu8ydvnl855dez59krr02mu --to one17mm27eutyem43s04l6pjmw9makcmzlg9eghlqz --from-shard 0 --to-shard 0 --amount 200 --chain-id devnet\") if you need to enter passphrase or any other interactive actions, you need to use the expect call. To get more information, refer the code here . $ cli.expect_call(\"hmy --node=https://api.s0.pga.hmny.io/ transfer --from one12mul56rvk2qjz48pu8ydvnl855dez59krr02mu --to one17mm27eutyem43s04l6pjmw9makcmzlg9eghlqz --from-shard 0 --to-shard 0 --amount 200 --chain-id devnet --passphrase\"","title":"4) Transfer money"},{"location":"setup/testnet/","text":"Developing on testnet","title":"Developing on Testnet"},{"location":"setup/testnet/#developing-on-testnet","text":"","title":"Developing on testnet"},{"location":"validate/autonode-1/","text":"AutoNode {% hint style=\"info\" %} Our team is currently working on optimizing AutoNode. If you face any issues, please ask our 24/7 support group for assistance at https://harmony.one/volunteers . {% endhint %} Step 1: Spin up your instance on AWS or other providers . It is recommended to go with Ubuntu or Amazon Linux as your operating system. Step 2: SSH into the machine. Step 3: Install dependencies: (python3-pip and jq). {% tabs %} {% tab title=\"Ubuntu LTS\" %} sudo apt update && sudo apt install python3-pip jq -y {% endtab %} {% tab title=\"Amazon Linux\" %} sudo yum update && sudo yum install python3-pip jq -y {% endtab %} {% endtabs %} Step 4: Install AutoNode. bash <(curl -s -S -L https://raw.githubusercontent.com/harmony-one/auto-node/migrate_off_docker/scripts/install.sh) Step 5: Add or import a validator key. {% tabs %} {% tab title=\"New Key\" %} ./hmy keys add validator {% endtab %} {% tab title=\"Import Key\" %} ./hmy keys import-private-key <private-key-string> {% endtab %} {% endtabs %} Step 5: Edit the validator_config.json file. {% tabs %} {% tab title=\"Edit Command\" %} nano validator_config.json {% endtab %} {% tab title=\"Example\" %} { \"validator-addr\": \"YOUR ONE1 ADDRESS\", \"name\": \"harmony_autonode\", \"website\": \"harmony.one\", \"security-contact\": \"Daniel-VDM\", \"identity\": \"auto-node\", \"amount\": 10100, \"min-self-delegation\": 10000, \"rate\": 0.1, \"max-rate\": 0.75, \"max-change-rate\": 0.05, \"max-total-delegation\": 100000000.0, \"details\": \"None\" } {% endtab %} {% endtabs %} {% hint style=\"warning\" %} Note that the ONE address has to be in quotes {% endhint %} Step 6: Save and exit config by pressing Ctrl + X then Y , then hit enter . Step 7: Fund your one1 account. For OSTN, the faucet is here . Step 8: Run your validator. ./auto_node.sh run --auto-active --auto-reset --clean Answer the prompts with Y or N (this process may take a minute) Once you see a loop of the node's header information (labeled something like This node's latest header at 2020-04-11 05:35:06.065816: { ... ), feel free to exit with Ctrl+Z And that's it, you're done! Feel free to exit the SSH session. Step 9: Monitor your node. ./auto_node.sh status Feel free to exit with Ctrl + Z .","title":"AutoNode"},{"location":"validate/autonode-1/#autonode","text":"{% hint style=\"info\" %} Our team is currently working on optimizing AutoNode. If you face any issues, please ask our 24/7 support group for assistance at https://harmony.one/volunteers . {% endhint %} Step 1: Spin up your instance on AWS or other providers . It is recommended to go with Ubuntu or Amazon Linux as your operating system. Step 2: SSH into the machine. Step 3: Install dependencies: (python3-pip and jq). {% tabs %} {% tab title=\"Ubuntu LTS\" %} sudo apt update && sudo apt install python3-pip jq -y {% endtab %} {% tab title=\"Amazon Linux\" %} sudo yum update && sudo yum install python3-pip jq -y {% endtab %} {% endtabs %} Step 4: Install AutoNode. bash <(curl -s -S -L https://raw.githubusercontent.com/harmony-one/auto-node/migrate_off_docker/scripts/install.sh) Step 5: Add or import a validator key. {% tabs %} {% tab title=\"New Key\" %} ./hmy keys add validator {% endtab %} {% tab title=\"Import Key\" %} ./hmy keys import-private-key <private-key-string> {% endtab %} {% endtabs %} Step 5: Edit the validator_config.json file. {% tabs %} {% tab title=\"Edit Command\" %} nano validator_config.json {% endtab %} {% tab title=\"Example\" %} { \"validator-addr\": \"YOUR ONE1 ADDRESS\", \"name\": \"harmony_autonode\", \"website\": \"harmony.one\", \"security-contact\": \"Daniel-VDM\", \"identity\": \"auto-node\", \"amount\": 10100, \"min-self-delegation\": 10000, \"rate\": 0.1, \"max-rate\": 0.75, \"max-change-rate\": 0.05, \"max-total-delegation\": 100000000.0, \"details\": \"None\" } {% endtab %} {% endtabs %} {% hint style=\"warning\" %} Note that the ONE address has to be in quotes {% endhint %} Step 6: Save and exit config by pressing Ctrl + X then Y , then hit enter . Step 7: Fund your one1 account. For OSTN, the faucet is here . Step 8: Run your validator. ./auto_node.sh run --auto-active --auto-reset --clean Answer the prompts with Y or N (this process may take a minute) Once you see a loop of the node's header information (labeled something like This node's latest header at 2020-04-11 05:35:06.065816: { ... ), feel free to exit with Ctrl+Z And that's it, you're done! Feel free to exit the SSH session. Step 9: Monitor your node. ./auto_node.sh status Feel free to exit with Ctrl + Z .","title":"AutoNode"},{"location":"validate/autonode-with-docker/","text":"AutoNode with Docker 1. Install Docker Step 1: Spin up your instance on AWS or other providers . It is recommended to go with Ubuntu or Amazon Linux as your operating system. Step 2: SSH into the machine. {% hint style=\"warning\" %} AutoNode DOES NOT run with root , thus you need to login with a user that is not root. If you don't haver a user that is not root, follow the procedures bellow to create one, otherwise you can just skip this part and go to Step 3 . {% endhint %} {% tabs %} {% tab title=\"Ubuntu LTS\" %} You can choose any username you want , it will ask for a password and a password confirmation. (please keep track of this password for future use!) Then we need to add this user to the sudoers group (to give them superuser privilege). sudo useradd -m <your username> sudo passwd <your username> sudo usermod -aG sudo <your username> Now logout of the root session (type exit ), you should see a login as prompt, use here the username you just created. login as: <your username> After giving the password you can pick up the process of setting up auto_node. {% endtab %} {% tab title=\"Amazon Linux\" %} For Amazon Linux you can skip this part. Default ec2-user is not the root user. {% endtab %} {% endtabs %} Step 3: Firewall Setup {% hint style=\"warning\" %} Make sure you have opened ports 6000 and 9000 on your instance in case you have a firewall. The firewall configuration varies from cloud to cloud provider. As an example, you can check how it is done on Digital Ocean or Vultr or in any other of our Cloud Guides . {% endhint %} Step 4: Setup the machine (Docker) {% tabs %} {% tab title=\"Ubuntu LTS\" %} sudo apt-get update -y && sudo apt install docker.io -y \\ && sudo usermod -aG docker $USER && sudo systemctl start docker \\ && sudo systemctl enable docker && exit {% endtab %} {% tab title=\"Amazon Linux\" %} sudo yum update -y && sudo yum install -y docker \\ && sudo usermod -aG docker $USER && sudo service docker start \\ && exit {% endtab %} {% endtabs %} For more details on how to setup docker, reference this . {% hint style=\"info\" %} The above command will exit out your SSH session (needed for docker install). SSH back into the machine. {% endhint %} 2. Configure Validator Step 1: Download the Harmony CLI: curl -LO https://harmony.one/hmycli && mv hmycli hmy && chmod +x hmy Step 2: Create a new key or import an existing key: {% tabs %} {% tab title=\"New Key\" %} ./hmy keys add validator {% endtab %} {% tab title=\"Import Key\" %} ./hmy keys import-private-key <private-key> {% endtab %} {% endtabs %} Step 3: Install/Update AutoNode with: bash <(curl -s -S -L https://raw.githubusercontent.com/harmony-one/auto-node/master/scripts/install.sh) Step 4: Edit the validator_config.json file: {% tabs %} {% tab title=\"Edit Command\" %} nano validator_config.json {% endtab %} {% tab title=\"Example File\" %} { \"validator-addr\": \"YOUR ONE1 ADDRESS\", \"name\": \"harmony_autonode\", \"website\": \"harmony.one\", \"security-contact\": \"Daniel-VDM\", \"identity\": \"auto-node\", \"amount\": 10100, \"min-self-delegation\": 10000, \"rate\": 0.1, \"max-rate\": 0.75, \"max-change-rate\": 0.05, \"max-total-delegation\": 100000000.0, \"details\": \"None\" } {% endtab %} {% endtabs %} {% hint style=\"warning\" %} Note that the ONE address has to be in quotes {% endhint %} Step 5: Save and exit config by pressing Ctrl + O then hit enter, then press Ctrl + X : Step 6: Fund your one1 account. For OSTN, the faucet is here . 3. Run AutoNode {% hint style=\"success\" %} Make sure you have the latest AutoNode version installed before running it. To download the latest version proceed to Section 2 and execute Step 3. {% endhint %} Step 1: Run autonode with the following command: ./auto_node.sh run --auto-active --auto-reset --clean Step 2: Answer the prompts with Y or N (this process may take a minute) Step 3: After you see a loop of the node's header information (labeled something like This node's latest header at 2020-04-11 05:35:06.065816: { ... ), detach from the AutoNode session by pressing Ctrl + b , then d And that's it, you're done! Feel free to exit the SSH session. {% hint style=\"info\" %} Optional: once detached, export the node information with ./auto_node.sh export and save it. {% endhint %} 4. Maintenance {% hint style=\"success\" %} Make sure you are SSH -ed into your node's machine. Make sure you are not attached to your AutoNode's session. If you are attached, detach by pressing Ctrl + b , then d. {% endhint %} Viewing Node progress If detached for AutoNode, attach with: ./auto_node.sh attach Manually creating a Validator Once detached, create a validator with: ./auto_node.sh create-validator This might have to be done if the associated validator address had insufficient funds when AutoNode attempted to create a validator. Saving the BLS keys for reuse Once detached, export the BLS key files with: ./auto_node.sh export-bls . && mkdir -p harmony_bls_keys \\ && cp -R bls_keys/. harmony_bls_keys/ This ensures that the BLS key will be reused should you have to relaunch your node. Deactivating the Node for Maintenance This requires that you DO NOT run AutoNode with --auto-active option. Once detached, deactivate your node with: ./auto_node.sh deactivate Then once you are ready to validate again, activate your node with: ./auto_node.sh activate Killing your Node Once detached, you can kill your node using: ./auto_node.sh kill {% hint style=\"info\" %} More details about AutoNode can be found here . Feel free to contribute! {% endhint %}","title":"AutoNode with Docker"},{"location":"validate/autonode-with-docker/#autonode-with-docker","text":"","title":"AutoNode with Docker"},{"location":"validate/autonode-with-docker/#1-install-docker","text":"Step 1: Spin up your instance on AWS or other providers . It is recommended to go with Ubuntu or Amazon Linux as your operating system. Step 2: SSH into the machine. {% hint style=\"warning\" %} AutoNode DOES NOT run with root , thus you need to login with a user that is not root. If you don't haver a user that is not root, follow the procedures bellow to create one, otherwise you can just skip this part and go to Step 3 . {% endhint %} {% tabs %} {% tab title=\"Ubuntu LTS\" %} You can choose any username you want , it will ask for a password and a password confirmation. (please keep track of this password for future use!) Then we need to add this user to the sudoers group (to give them superuser privilege). sudo useradd -m <your username> sudo passwd <your username> sudo usermod -aG sudo <your username> Now logout of the root session (type exit ), you should see a login as prompt, use here the username you just created. login as: <your username> After giving the password you can pick up the process of setting up auto_node. {% endtab %} {% tab title=\"Amazon Linux\" %} For Amazon Linux you can skip this part. Default ec2-user is not the root user. {% endtab %} {% endtabs %} Step 3: Firewall Setup {% hint style=\"warning\" %} Make sure you have opened ports 6000 and 9000 on your instance in case you have a firewall. The firewall configuration varies from cloud to cloud provider. As an example, you can check how it is done on Digital Ocean or Vultr or in any other of our Cloud Guides . {% endhint %} Step 4: Setup the machine (Docker) {% tabs %} {% tab title=\"Ubuntu LTS\" %} sudo apt-get update -y && sudo apt install docker.io -y \\ && sudo usermod -aG docker $USER && sudo systemctl start docker \\ && sudo systemctl enable docker && exit {% endtab %} {% tab title=\"Amazon Linux\" %} sudo yum update -y && sudo yum install -y docker \\ && sudo usermod -aG docker $USER && sudo service docker start \\ && exit {% endtab %} {% endtabs %} For more details on how to setup docker, reference this . {% hint style=\"info\" %} The above command will exit out your SSH session (needed for docker install). SSH back into the machine. {% endhint %}","title":"1. Install Docker"},{"location":"validate/autonode-with-docker/#2-configure-validator","text":"Step 1: Download the Harmony CLI: curl -LO https://harmony.one/hmycli && mv hmycli hmy && chmod +x hmy Step 2: Create a new key or import an existing key: {% tabs %} {% tab title=\"New Key\" %} ./hmy keys add validator {% endtab %} {% tab title=\"Import Key\" %} ./hmy keys import-private-key <private-key> {% endtab %} {% endtabs %} Step 3: Install/Update AutoNode with: bash <(curl -s -S -L https://raw.githubusercontent.com/harmony-one/auto-node/master/scripts/install.sh) Step 4: Edit the validator_config.json file: {% tabs %} {% tab title=\"Edit Command\" %} nano validator_config.json {% endtab %} {% tab title=\"Example File\" %} { \"validator-addr\": \"YOUR ONE1 ADDRESS\", \"name\": \"harmony_autonode\", \"website\": \"harmony.one\", \"security-contact\": \"Daniel-VDM\", \"identity\": \"auto-node\", \"amount\": 10100, \"min-self-delegation\": 10000, \"rate\": 0.1, \"max-rate\": 0.75, \"max-change-rate\": 0.05, \"max-total-delegation\": 100000000.0, \"details\": \"None\" } {% endtab %} {% endtabs %} {% hint style=\"warning\" %} Note that the ONE address has to be in quotes {% endhint %} Step 5: Save and exit config by pressing Ctrl + O then hit enter, then press Ctrl + X : Step 6: Fund your one1 account. For OSTN, the faucet is here .","title":"2. Configure Validator"},{"location":"validate/autonode-with-docker/#3-run-autonode","text":"{% hint style=\"success\" %} Make sure you have the latest AutoNode version installed before running it. To download the latest version proceed to Section 2 and execute Step 3. {% endhint %} Step 1: Run autonode with the following command: ./auto_node.sh run --auto-active --auto-reset --clean Step 2: Answer the prompts with Y or N (this process may take a minute) Step 3: After you see a loop of the node's header information (labeled something like This node's latest header at 2020-04-11 05:35:06.065816: { ... ), detach from the AutoNode session by pressing Ctrl + b , then d And that's it, you're done! Feel free to exit the SSH session. {% hint style=\"info\" %} Optional: once detached, export the node information with ./auto_node.sh export and save it. {% endhint %}","title":"3. Run AutoNode"},{"location":"validate/autonode-with-docker/#4-maintenance","text":"{% hint style=\"success\" %} Make sure you are SSH -ed into your node's machine. Make sure you are not attached to your AutoNode's session. If you are attached, detach by pressing Ctrl + b , then d. {% endhint %}","title":"4. Maintenance"},{"location":"validate/autonode-with-docker/#viewing-node-progress","text":"If detached for AutoNode, attach with: ./auto_node.sh attach","title":"Viewing Node progress"},{"location":"validate/autonode-with-docker/#manually-creating-a-validator","text":"Once detached, create a validator with: ./auto_node.sh create-validator This might have to be done if the associated validator address had insufficient funds when AutoNode attempted to create a validator.","title":"Manually creating a Validator"},{"location":"validate/autonode-with-docker/#saving-the-bls-keys-for-reuse","text":"Once detached, export the BLS key files with: ./auto_node.sh export-bls . && mkdir -p harmony_bls_keys \\ && cp -R bls_keys/. harmony_bls_keys/ This ensures that the BLS key will be reused should you have to relaunch your node.","title":"Saving the BLS keys for reuse"},{"location":"validate/autonode-with-docker/#deactivating-the-node-for-maintenance","text":"This requires that you DO NOT run AutoNode with --auto-active option. Once detached, deactivate your node with: ./auto_node.sh deactivate Then once you are ready to validate again, activate your node with: ./auto_node.sh activate","title":"Deactivating the Node for Maintenance"},{"location":"validate/autonode-with-docker/#killing-your-node","text":"Once detached, you can kill your node using: ./auto_node.sh kill {% hint style=\"info\" %} More details about AutoNode can be found here . Feel free to contribute! {% endhint %}","title":"Killing your Node"},{"location":"validate/autonode-with-docker/#_1","text":"","title":""},{"location":"validate/autonode-without-docker/","text":"AutoNode without Docker Note: our team is currently working on optimizing AutoNode. If you face any issues, please ask our 24/7 support group for assistance at https://harmony.one/volunteers . Step 1: Spin up your instance on AWS or other providers . It is recommended to go with Ubuntu or Amazon Linux as your operating system. Step 2: SSH into the machine. Step 3: Install dependencies: (python3-pip and jq). {% tabs %} {% tab title=\"Ubuntu LTS\" %} sudo apt update && sudo apt install python3-pip jq -y {% endtab %} {% tab title=\"Amazon Linux\" %} sudo yum update && sudo yum install python3-pip jq -y {% endtab %} {% endtabs %} Step 4: Install AutoNode. bash <(curl -s -S -L https://raw.githubusercontent.com/harmony-one/auto-node/migrate_off_docker/scripts/install.sh) Step 5: Add or import a validator key. {% tabs %} {% tab title=\"New Key\" %} ./hmy keys add validator {% endtab %} {% tab title=\"Import Key\" %} ./hmy keys import-private-key <private-key-string> {% endtab %} {% endtabs %} Step 5: Edit the validator_config.json file. {% tabs %} {% tab title=\"Edit Command\" %} nano validator_config.json {% endtab %} {% tab title=\"Example\" %} { \"validator-addr\": \"YOUR ONE1 ADDRESS\", \"name\": \"harmony_autonode\", \"website\": \"harmony.one\", \"security-contact\": \"Daniel-VDM\", \"identity\": \"auto-node\", \"amount\": 10100, \"min-self-delegation\": 10000, \"rate\": 0.1, \"max-rate\": 0.75, \"max-change-rate\": 0.05, \"max-total-delegation\": 100000000.0, \"details\": \"None\" } {% endtab %} {% endtabs %} {% hint style=\"warning\" %} Note that the ONE address has to be in quotes {% endhint %} Step 6: Save and exit config by pressing Ctrl + X then Y , then hit enter . Step 7: Fund your one1 account. For OSTN, the faucet is here . Step 8: Run your validator. ./auto_node.sh run --auto-active --auto-reset --clean Answer the prompts with Y or N (this process may take a minute) Once you see a loop of the node's header information (labeled something like This node's latest header at 2020-04-11 05:35:06.065816: { ... ), feel free to exit with Ctrl+Z And that's it, you're done! Feel free to exit the SSH session. Step 9: Monitor your node. ./auto_node.sh status Feel free to exit with Ctrl + Z .","title":"AutoNode without Docker"},{"location":"validate/autonode-without-docker/#autonode-without-docker","text":"Note: our team is currently working on optimizing AutoNode. If you face any issues, please ask our 24/7 support group for assistance at https://harmony.one/volunteers . Step 1: Spin up your instance on AWS or other providers . It is recommended to go with Ubuntu or Amazon Linux as your operating system. Step 2: SSH into the machine. Step 3: Install dependencies: (python3-pip and jq). {% tabs %} {% tab title=\"Ubuntu LTS\" %} sudo apt update && sudo apt install python3-pip jq -y {% endtab %} {% tab title=\"Amazon Linux\" %} sudo yum update && sudo yum install python3-pip jq -y {% endtab %} {% endtabs %} Step 4: Install AutoNode. bash <(curl -s -S -L https://raw.githubusercontent.com/harmony-one/auto-node/migrate_off_docker/scripts/install.sh) Step 5: Add or import a validator key. {% tabs %} {% tab title=\"New Key\" %} ./hmy keys add validator {% endtab %} {% tab title=\"Import Key\" %} ./hmy keys import-private-key <private-key-string> {% endtab %} {% endtabs %} Step 5: Edit the validator_config.json file. {% tabs %} {% tab title=\"Edit Command\" %} nano validator_config.json {% endtab %} {% tab title=\"Example\" %} { \"validator-addr\": \"YOUR ONE1 ADDRESS\", \"name\": \"harmony_autonode\", \"website\": \"harmony.one\", \"security-contact\": \"Daniel-VDM\", \"identity\": \"auto-node\", \"amount\": 10100, \"min-self-delegation\": 10000, \"rate\": 0.1, \"max-rate\": 0.75, \"max-change-rate\": 0.05, \"max-total-delegation\": 100000000.0, \"details\": \"None\" } {% endtab %} {% endtabs %} {% hint style=\"warning\" %} Note that the ONE address has to be in quotes {% endhint %} Step 6: Save and exit config by pressing Ctrl + X then Y , then hit enter . Step 7: Fund your one1 account. For OSTN, the faucet is here . Step 8: Run your validator. ./auto_node.sh run --auto-active --auto-reset --clean Answer the prompts with Y or N (this process may take a minute) Once you see a loop of the node's header information (labeled something like This node's latest header at 2020-04-11 05:35:06.065816: { ... ), feel free to exit with Ctrl+Z And that's it, you're done! Feel free to exit the SSH session. Step 9: Monitor your node. ./auto_node.sh status Feel free to exit with Ctrl + Z .","title":"AutoNode without Docker"},{"location":"validate/autonode/","text":"AutoNode {% hint style=\"danger\" %} AutoNode is not optimized for mainnet yet. This notification will be removed when AutoNode is mainnet compatible. Use \" First Time Setup \" to spin up your validator node! {% endhint %} Installing AutoNode Step 1: Spin up your instance on AWS or other providers . It is recommended to go with Ubuntu or Amazon Linux as your operating system. Step 2: SSH into the machine. {% hint style=\"warning\" %} AutoNode DOES NOT run with root, thus you need to login with a user that is not root. Most cloud providers (like AWS) give you such an account as the default login. However, if you don't have a user that is not root, follow the procedures below to create one, otherwise you can just skip this part and go to Step 3. {% endhint %} You can choose any username you want. It will ask for a password and a password confirmation. We will also add this user to the sudo group. Please keep track of this password for future use! sudo useradd -m <your username> sudo passwd <your username> sudo adduser <your username> sudo Now login with the new username you just created. su - <your username> {% hint style=\"warning\" %} If you wish to automatically reset your node during hard resets (the --auto-reset option in step 7) your user ( <your username> ) must have sudo access without a passphrase. Follow instructions here to set that up. If you don't want to do that, you can still run AutoNode! Only thing is that on hard resets, you have to do is step 6 and 7 to restart your node. {% endhint %} Step 3: Install AutoNode. curl -O https://raw.githubusercontent.com/harmony-one/auto-node/master/scripts/install.sh && chmod +x ./install.sh && ./install.sh && rm ./install.sh {% hint style=\"info\" %} If you are upgrading your AutoNode from a previous version the installer might ask you some questions. Answer with Y for the upgrading process to go on. {% endhint %} Step 4: Add or import a validator key. {% tabs %} {% tab title=\"New Key\" %} ./hmy keys add validator {% endtab %} {% tab title=\"Import Keystore File\" %} ./hmy keys import-ks <path-to-keystore-file> {% endtab %} {% tab title=\"Import Private Key (not recommended)\" %} ./hmy keys import-private-key <private-key-string> {% endtab %} {% endtabs %} Step 5: Edit the configuration file and change the validator-addr to the ONE address created on Step 4. ./auto_node.sh edit-config Note that identity must be unique or else your validator won't get created. Save and exit the configuration by pressing Ctrl + X then Y , then by hitting enter . {% hint style=\"warning\" %} Note that the ONE address has to be in quotes {% endhint %} Step 6: Fund your ONE address. Step 7 : Run your validator. ./auto_node.sh run --auto-active --auto-reset --clean Answer the prompts with Y or N (this process may take a minute). Feel free to exit with Ctrl+Z after your node syncs! {% hint style=\"info\" %} You can view all the commands for AutoNode with ~/auto_node.sh -h {% endhint %} Monitoring {% hint style=\"success\" %} If any of the commands activates a monitoring screen, you can always exit using Ctrl + Z . {% endhint %} 1) View the log of your Harmony Monitor: ./auto_node.sh monitor log 2) Using TUI ./auto_node.sh tui run 3) View the status of your Harmony Monitor daemon: ./auto_node.sh monitor status 4) Restart your Harmony Monitor daemon: ./auto_node.sh monitor restart Upgrade AutoNode 1) Deactivate your validator during the upgrade process ./auto_node.sh deactivate 2) Safely kill AutoNode & its monitor (if alive) ./auto_node.sh kill 3) Update AutoNode by running the install step again: curl -O https://raw.githubusercontent.com/harmony-one/auto-node/master/scripts/install.sh && chmod +x ./install.sh && ./install.sh && rm ./install.sh 4) Start up your node again but this time without the --clean option. ./auto_node.sh run --auto-active --auto-reset Once your node is done syncing, AutoNode will automatically activate your validator to be elected in the next epoch! 5) (Optional) If needed, you might have to activate your validator manually, do so with: ./auto_node.sh activate Cleaning Keys 1) You can cleanse your BLS (based on performance of a key) with: ./auto_node.sh cleanse-bls 2) Remove all keys except for keys running on your current autonode with: ./auto_node.sh cleanse-bls --hard More detailed documentation can be found here . Feel free to contribute or open issues!","title":"AutoNode"},{"location":"validate/autonode/#autonode","text":"{% hint style=\"danger\" %} AutoNode is not optimized for mainnet yet. This notification will be removed when AutoNode is mainnet compatible. Use \" First Time Setup \" to spin up your validator node! {% endhint %}","title":"AutoNode"},{"location":"validate/autonode/#installing-autonode","text":"","title":"Installing AutoNode"},{"location":"validate/autonode/#step-1-spin-up-your-instance-on-aws-or-other-providers","text":"It is recommended to go with Ubuntu or Amazon Linux as your operating system.","title":"Step 1: Spin up your instance on AWS or other providers."},{"location":"validate/autonode/#step-2-ssh-into-the-machine","text":"{% hint style=\"warning\" %} AutoNode DOES NOT run with root, thus you need to login with a user that is not root. Most cloud providers (like AWS) give you such an account as the default login. However, if you don't have a user that is not root, follow the procedures below to create one, otherwise you can just skip this part and go to Step 3. {% endhint %} You can choose any username you want. It will ask for a password and a password confirmation. We will also add this user to the sudo group. Please keep track of this password for future use! sudo useradd -m <your username> sudo passwd <your username> sudo adduser <your username> sudo Now login with the new username you just created. su - <your username> {% hint style=\"warning\" %} If you wish to automatically reset your node during hard resets (the --auto-reset option in step 7) your user ( <your username> ) must have sudo access without a passphrase. Follow instructions here to set that up. If you don't want to do that, you can still run AutoNode! Only thing is that on hard resets, you have to do is step 6 and 7 to restart your node. {% endhint %}","title":"Step 2: SSH into the machine."},{"location":"validate/autonode/#step-3-install-autonode","text":"curl -O https://raw.githubusercontent.com/harmony-one/auto-node/master/scripts/install.sh && chmod +x ./install.sh && ./install.sh && rm ./install.sh {% hint style=\"info\" %} If you are upgrading your AutoNode from a previous version the installer might ask you some questions. Answer with Y for the upgrading process to go on. {% endhint %}","title":"Step 3: Install AutoNode."},{"location":"validate/autonode/#step-4-add-or-import-a-validator-key","text":"{% tabs %} {% tab title=\"New Key\" %} ./hmy keys add validator {% endtab %} {% tab title=\"Import Keystore File\" %} ./hmy keys import-ks <path-to-keystore-file> {% endtab %} {% tab title=\"Import Private Key (not recommended)\" %} ./hmy keys import-private-key <private-key-string> {% endtab %} {% endtabs %}","title":"Step 4: Add or import a validator key."},{"location":"validate/autonode/#step-5-edit-the-configuration-file-and-change-the-validator-addrto-the-one-address-created-on-step-4","text":"./auto_node.sh edit-config Note that identity must be unique or else your validator won't get created. Save and exit the configuration by pressing Ctrl + X then Y , then by hitting enter . {% hint style=\"warning\" %} Note that the ONE address has to be in quotes {% endhint %}","title":"Step 5: Edit the configuration file and change the validator-addrto the ONE address created on Step 4."},{"location":"validate/autonode/#step-6-fund-your-one-address","text":"","title":"Step 6: Fund your ONE address."},{"location":"validate/autonode/#step-7-run-your-validator","text":"./auto_node.sh run --auto-active --auto-reset --clean Answer the prompts with Y or N (this process may take a minute). Feel free to exit with Ctrl+Z after your node syncs! {% hint style=\"info\" %} You can view all the commands for AutoNode with ~/auto_node.sh -h {% endhint %}","title":"Step 7 : Run your validator."},{"location":"validate/autonode/#monitoring","text":"{% hint style=\"success\" %} If any of the commands activates a monitoring screen, you can always exit using Ctrl + Z . {% endhint %}","title":"Monitoring"},{"location":"validate/autonode/#1-view-the-log-of-your-harmony-monitor","text":"./auto_node.sh monitor log","title":"1) View the log of your Harmony Monitor:"},{"location":"validate/autonode/#2-using-tui","text":"./auto_node.sh tui run","title":"2) Using TUI"},{"location":"validate/autonode/#3-view-the-status-of-your-harmony-monitor-daemon","text":"./auto_node.sh monitor status","title":"3) View the status of your Harmony Monitor daemon:"},{"location":"validate/autonode/#4-restart-your-harmony-monitor-daemon","text":"./auto_node.sh monitor restart","title":"4) Restart your Harmony Monitor daemon:"},{"location":"validate/autonode/#upgrade-autonode","text":"","title":"Upgrade AutoNode"},{"location":"validate/autonode/#1-deactivate-your-validator-during-the-upgrade-process","text":"./auto_node.sh deactivate","title":"1) Deactivate your validator during the upgrade process"},{"location":"validate/autonode/#2-safely-kill-autonode-its-monitor-if-alive","text":"./auto_node.sh kill","title":"2) Safely kill AutoNode &amp; its monitor (if alive)"},{"location":"validate/autonode/#3-update-autonode-by-running-the-install-step-again","text":"curl -O https://raw.githubusercontent.com/harmony-one/auto-node/master/scripts/install.sh && chmod +x ./install.sh && ./install.sh && rm ./install.sh","title":"3) Update AutoNode by running the install step again:"},{"location":"validate/autonode/#4-start-up-your-node-again-but-this-time-without-the-clean-option","text":"./auto_node.sh run --auto-active --auto-reset Once your node is done syncing, AutoNode will automatically activate your validator to be elected in the next epoch!","title":"4) Start up your node again but this time without the --clean option."},{"location":"validate/autonode/#5-optional-if-needed-you-might-have-to-activate-your-validator-manually-do-so-with","text":"./auto_node.sh activate","title":"5) (Optional) If needed, you might have to activate your validator manually, do so with:"},{"location":"validate/autonode/#cleaning-keys","text":"","title":"Cleaning Keys"},{"location":"validate/autonode/#1-you-can-cleanse-your-bls-based-on-performance-of-a-key-with","text":"./auto_node.sh cleanse-bls","title":"1) You can cleanse your BLS (based on performance of a key) with:"},{"location":"validate/autonode/#2-remove-all-keys-except-for-keys-running-on-your-current-autonode-with","text":"./auto_node.sh cleanse-bls --hard","title":"2) Remove all keys except for keys running on your current autonode with:"},{"location":"validate/autonode/#more-detailed-documentation-can-be-found-here","text":"Feel free to contribute or open issues!","title":"More detailed documentation can be found here."},{"location":"validate/overview/","text":"Validators Harmony is one of the first production mainnets to feature a fully sharded PoS architecture. Across the 4 shards in Harmony mainnet, blocks are produced every 8 seconds and cross-shard transactions are finalized in 2 block times. Currently there are 320 open validator slots, 80 on each shard, to validate new blocks and vote to reach consensus using our FBFT algorithm where a 2/3 quorum of votes is needed for consensus.To be able to vote, validators need to have voting shares bonded to them. One bonded voting share grants one vote for a validator to cast in the FBFT consensus. As detailed in our whitepaper , Harmony blockchain runs in epochs and one epoch lasts for every 16,384 blocks, which is roughly 1.5 days in current block time. Within an epoch, the validators in each shard stay the same and run consensus repeatedly. Harmony\u2019s Effective Proof-of-Stake (EPoS) is the first staking mechanism in a sharded blockchain that achieves both security and decentralization. EPoS allows staking from hundreds of validators and the unique effective stake mechanism reduces the tendency of stake centralization. Meanwhile, stake delegation, reward compounding, double-sign slashing, and unavailability checking are also supported.","title":"Orientation"},{"location":"validate/overview/#validators","text":"Harmony is one of the first production mainnets to feature a fully sharded PoS architecture. Across the 4 shards in Harmony mainnet, blocks are produced every 8 seconds and cross-shard transactions are finalized in 2 block times. Currently there are 320 open validator slots, 80 on each shard, to validate new blocks and vote to reach consensus using our FBFT algorithm where a 2/3 quorum of votes is needed for consensus.To be able to vote, validators need to have voting shares bonded to them. One bonded voting share grants one vote for a validator to cast in the FBFT consensus. As detailed in our whitepaper , Harmony blockchain runs in epochs and one epoch lasts for every 16,384 blocks, which is roughly 1.5 days in current block time. Within an epoch, the validators in each shard stay the same and run consensus repeatedly. Harmony\u2019s Effective Proof-of-Stake (EPoS) is the first staking mechanism in a sharded blockchain that achieves both security and decentralization. EPoS allows staking from hundreds of validators and the unique effective stake mechanism reduces the tendency of stake centralization. Meanwhile, stake delegation, reward compounding, double-sign slashing, and unavailability checking are also supported.","title":"Validators"},{"location":"validate/smartphone-node-setup/","text":"Smartphone Node Setup Download and Install the Termux app in the Playstore . Run the app and install the SSH for the program by typing: pkg install openssh Setup your instance in the different cloud providers . Connect your instance by using the Termux app and use the following command: ssh root@<INSTANCEIPADDRESS> Click \"yes\" for authentication and retype again the command to access your instance. After that, type the unique password associated with your instance that comes from your cloud provider and change it after successful logging in to protect your instance. Before doing anything, update your system by using the command: sudo apt update && apt upgrade Install the following packages that will be needed to run the Harmony: sudo apt update && apt upgrade Download Harmony CLI to interact with your node: {% tabs %} {% tab title=\"Linux Download\" %} curl -LO https://harmony.one/hmycli && mv hmycli hmy && chmod +x hmy {% endtab %} {% endtabs %} Run ./hmy cookbook to see some commonly commands that will help you: ./hmy --node=https://api.s0.t.hmny.io cookbook Create a new BLS key in order to run your validating node. When generating a BLS key, the CLI will ask you to provide a passphrase to encrypt the BLS key file.\u200c To generate the BLS key file type the following command: ./hmy keys generate-bls-key --passphrase {% hint style=\"info\" %} Remember your passphrase. You will need it to decrypt the BLS key file in order to create a validator & start a node with that key. Create a backup of your BLS key file or save the BLS private key (optional). {% endhint %} Check which shard your key will validate by using the command: ./hmy --node=\"https://api.s0.t.hmny.io\" utility shard-for-bls [BLS PUBLIC KEY] {% hint style=\"info\" %} The BLS public key is the same as the name of the file, without the \".key\". {% endhint %} Download the node.sh by running the command: curl -LO https://raw.githubusercontent.com/harmony-one/harmony/master/scripts/node.sh && chmod a+x node.sh Install tmux sudo yum install tmux Create a new tmux session called \"node\" by using the command: tmux new-session -s node Run the node.sh script with the following command. Once you do, it will ask for a passphrase for your BLS key file. Type your passphrase on the screen that follows and your node should be up and running. ./node.sh -S -c -z -I -N staking -k [BLS KEY FILE].key Detach your \"node\" tmux session by press [Ctrl]+b, releasing and and then press d. Create a new wallet and provide your local account name by using the command: ./hmy keys add mylocalaccountname --passphrase {% hint style=\"info\" %} Remember your passphrase. You will need it to decrypt the account keystore in order to send transactions & perform other actions. Also save your seed phrase (mnemonic) somewhere as well, in case you lose your keystore. {% endhint %} You can check the account balance: ./hmy balances [ONE ADDRESS] Fund your ONE address. Creating a validator by replacing everything in [ ] with your own data. ./hmy --node=https://api.s0.t.hmny.io staking create-validator \\ --validator-addr [ONE ADDRESS] --amount 10000 \\ --bls-pubkeys [BLS PUBLIC KEY1],[BLS PUBLIC KEY2] \\ --name \"[NAME]\" --identity \"[IDENTITY]\" --details \"DETAILS\" \\ --security-contact \"CONTACT\" --website \"YOUR-WEBSITE.COM\" \\ --max-change-rate 0.1 --max-rate 0.1 --rate 0.1 \\ --max-total-delegation 100000000 --min-self-delegation 100000 --passphrase Check your validator information by using the command below: ./hmy --node=\"https://api.s0.t.hmny.io\" blockchain validator information [ONE ADDRESS]","title":"Smartphone Node Setup"},{"location":"validate/smartphone-node-setup/#smartphone-node-setup","text":"Download and Install the Termux app in the Playstore . Run the app and install the SSH for the program by typing: pkg install openssh Setup your instance in the different cloud providers . Connect your instance by using the Termux app and use the following command: ssh root@<INSTANCEIPADDRESS> Click \"yes\" for authentication and retype again the command to access your instance. After that, type the unique password associated with your instance that comes from your cloud provider and change it after successful logging in to protect your instance. Before doing anything, update your system by using the command: sudo apt update && apt upgrade Install the following packages that will be needed to run the Harmony: sudo apt update && apt upgrade Download Harmony CLI to interact with your node: {% tabs %} {% tab title=\"Linux Download\" %} curl -LO https://harmony.one/hmycli && mv hmycli hmy && chmod +x hmy {% endtab %} {% endtabs %} Run ./hmy cookbook to see some commonly commands that will help you: ./hmy --node=https://api.s0.t.hmny.io cookbook Create a new BLS key in order to run your validating node. When generating a BLS key, the CLI will ask you to provide a passphrase to encrypt the BLS key file.\u200c To generate the BLS key file type the following command: ./hmy keys generate-bls-key --passphrase {% hint style=\"info\" %} Remember your passphrase. You will need it to decrypt the BLS key file in order to create a validator & start a node with that key. Create a backup of your BLS key file or save the BLS private key (optional). {% endhint %} Check which shard your key will validate by using the command: ./hmy --node=\"https://api.s0.t.hmny.io\" utility shard-for-bls [BLS PUBLIC KEY] {% hint style=\"info\" %} The BLS public key is the same as the name of the file, without the \".key\". {% endhint %} Download the node.sh by running the command: curl -LO https://raw.githubusercontent.com/harmony-one/harmony/master/scripts/node.sh && chmod a+x node.sh Install tmux sudo yum install tmux Create a new tmux session called \"node\" by using the command: tmux new-session -s node Run the node.sh script with the following command. Once you do, it will ask for a passphrase for your BLS key file. Type your passphrase on the screen that follows and your node should be up and running. ./node.sh -S -c -z -I -N staking -k [BLS KEY FILE].key Detach your \"node\" tmux session by press [Ctrl]+b, releasing and and then press d. Create a new wallet and provide your local account name by using the command: ./hmy keys add mylocalaccountname --passphrase {% hint style=\"info\" %} Remember your passphrase. You will need it to decrypt the account keystore in order to send transactions & perform other actions. Also save your seed phrase (mnemonic) somewhere as well, in case you lose your keystore. {% endhint %} You can check the account balance: ./hmy balances [ONE ADDRESS] Fund your ONE address. Creating a validator by replacing everything in [ ] with your own data. ./hmy --node=https://api.s0.t.hmny.io staking create-validator \\ --validator-addr [ONE ADDRESS] --amount 10000 \\ --bls-pubkeys [BLS PUBLIC KEY1],[BLS PUBLIC KEY2] \\ --name \"[NAME]\" --identity \"[IDENTITY]\" --details \"DETAILS\" \\ --security-contact \"CONTACT\" --website \"YOUR-WEBSITE.COM\" \\ --max-change-rate 0.1 --max-rate 0.1 --rate 0.1 \\ --max-total-delegation 100000000 --min-self-delegation 100000 --passphrase Check your validator information by using the command below: ./hmy --node=\"https://api.s0.t.hmny.io\" blockchain validator information [ONE ADDRESS]","title":"Smartphone Node Setup"},{"location":"validate/staking-dashboard/","text":"Staking Dashboard Here is the Staking Explorer link: https://staking.harmony.one/welcome Using the Staking Explorer is an easy way to stake, delegate, send funds and control all information associated with the validators. First you need to login into an account , you can create new address or using an existing address, for example your validator account that you created using CLI After you login, there are several option available, for example you can check all available validators that you can delegate For each transation/delegation you will need to confirm it, for that you can use several ways, using Harmony Browser Extension or ledger nano S. Harmony Browser Extension : https://docs.harmony.one/home/basics/overview/installation Wallets: https://docs.harmony.one/home/basics/overview","title":"Staking Dashboard"},{"location":"validate/staking-dashboard/#staking-dashboard","text":"Here is the Staking Explorer link: https://staking.harmony.one/welcome Using the Staking Explorer is an easy way to stake, delegate, send funds and control all information associated with the validators. First you need to login into an account , you can create new address or using an existing address, for example your validator account that you created using CLI After you login, there are several option available, for example you can check all available validators that you can delegate For each transation/delegation you will need to confirm it, for that you can use several ways, using Harmony Browser Extension or ledger nano S. Harmony Browser Extension : https://docs.harmony.one/home/basics/overview/installation Wallets: https://docs.harmony.one/home/basics/overview","title":"Staking Dashboard"},{"location":"validate/validator-cheat-sheet/","text":"Setup Cheatsheet If you are new to setting up Validators, start here . Access your cloud instance. ssh -i [KEY].pem [SSH ADDRESS] Install tmux , if your Linux distribution does not come with it. sudo yum install tmux Download the Harmony CLI. curl -LO https://harmony.one/hmycli && mv hmycli hmy && chmod +x hmy Create a BLS Key. ./hmy keys generate-bls-key --passphrase Download node.sh . curl -LO https://raw.githubusercontent.com/harmony-one/harmony/master/scripts/node.sh \\ && chmod a+x node.sh Start a new tmux session called node . tmux new-session -s node Run the node. {% tabs %} {% tab title=\"Open Staking Network\" %} ./node.sh -S -c -z -I -N staking -k [BLS KEY FILE].key {% endtab %} {% endtabs %} Detach from the tmux session by pressing CTRL and B at the same time, then press D. Check that your node is syncing (block height > 0). ./hmy blockchain latest-header Create a new wallet. ./hmy keys add [ACCOUNT NAME] --passphrase Get tokens for your validator {% tabs %} {% tab title=\"Open Staking Testnet\" %} curl -X GET https://faucet.os.hmny.io/fund?address=[ONE ADDRESS] {% endtab %} {% endtabs %} Create your Validator {% tabs %} {% tab title=\"Open Staking Testnet\" %} ./hmy --node=\"https://api.s0.os.hmny.io\" staking create-validator \\ --validator-addr [ONE ADDRESS] --amount 100000 \\ --bls-pubkeys [BLS PUBLIC KEY1],[BLS PUBLIC KEY2] \\ --name JohnWhitton --identity JohnIdentity --details \"John The Validator\" \\ --security-contact John --website john@harmony.one \\ --max-change-rate 0.1 --max-rate 0.1 --rate 0.1 \\ --max-total-delegation 100000000 --min-self-delegation 100000 --passphrase {% endtab %} {% endtabs %} Check that your ONE address exists as a validator {% tabs %} {% tab title=\"Open Staking Testnet\" %} ./hmy --node=\"https://api.s0.os.hmny.io\" blockchain validator all | grep [ONE ADDRESS] {% endtab %} {% endtabs %} Collect rewards. {% tabs %} {% tab title=\"Open Staking Testnet\" %} ./hmy --node=\"https://api.s0.os.hmny.io\" staking collect-rewards --delegator-addr [ONE ADDRESS] --passphrase {% endtab %} {% endtabs %} Check validator information for active flag / availability (block signed) / etc ... {% tabs %} {% tab title=\"Open Staking Testnet\" %} ./hmy --node=\"https://api.s0.os.hmny.io\" blockchain validator information [VALIDATOR ONE ADDRESS] {% endtab %} {% endtabs %}","title":"Setup Cheatsheet"},{"location":"validate/validator-cheat-sheet/#setup-cheatsheet","text":"If you are new to setting up Validators, start here . Access your cloud instance. ssh -i [KEY].pem [SSH ADDRESS] Install tmux , if your Linux distribution does not come with it. sudo yum install tmux Download the Harmony CLI. curl -LO https://harmony.one/hmycli && mv hmycli hmy && chmod +x hmy Create a BLS Key. ./hmy keys generate-bls-key --passphrase Download node.sh . curl -LO https://raw.githubusercontent.com/harmony-one/harmony/master/scripts/node.sh \\ && chmod a+x node.sh Start a new tmux session called node . tmux new-session -s node Run the node. {% tabs %} {% tab title=\"Open Staking Network\" %} ./node.sh -S -c -z -I -N staking -k [BLS KEY FILE].key {% endtab %} {% endtabs %} Detach from the tmux session by pressing CTRL and B at the same time, then press D. Check that your node is syncing (block height > 0). ./hmy blockchain latest-header Create a new wallet. ./hmy keys add [ACCOUNT NAME] --passphrase Get tokens for your validator {% tabs %} {% tab title=\"Open Staking Testnet\" %} curl -X GET https://faucet.os.hmny.io/fund?address=[ONE ADDRESS] {% endtab %} {% endtabs %} Create your Validator {% tabs %} {% tab title=\"Open Staking Testnet\" %} ./hmy --node=\"https://api.s0.os.hmny.io\" staking create-validator \\ --validator-addr [ONE ADDRESS] --amount 100000 \\ --bls-pubkeys [BLS PUBLIC KEY1],[BLS PUBLIC KEY2] \\ --name JohnWhitton --identity JohnIdentity --details \"John The Validator\" \\ --security-contact John --website john@harmony.one \\ --max-change-rate 0.1 --max-rate 0.1 --rate 0.1 \\ --max-total-delegation 100000000 --min-self-delegation 100000 --passphrase {% endtab %} {% endtabs %} Check that your ONE address exists as a validator {% tabs %} {% tab title=\"Open Staking Testnet\" %} ./hmy --node=\"https://api.s0.os.hmny.io\" blockchain validator all | grep [ONE ADDRESS] {% endtab %} {% endtabs %} Collect rewards. {% tabs %} {% tab title=\"Open Staking Testnet\" %} ./hmy --node=\"https://api.s0.os.hmny.io\" staking collect-rewards --delegator-addr [ONE ADDRESS] --passphrase {% endtab %} {% endtabs %} Check validator information for active flag / availability (block signed) / etc ... {% tabs %} {% tab title=\"Open Staking Testnet\" %} ./hmy --node=\"https://api.s0.os.hmny.io\" blockchain validator information [VALIDATOR ONE ADDRESS] {% endtab %} {% endtabs %}","title":"Setup Cheatsheet"},{"location":"validate/cloud-guides/","text":"Cloud Guides CPU we recommend 2 core, 2G ram for running single BLS key; 2 core, 4G ram for running up to 4 BLS keys. You may want to refer to the Choosing A Cloud Provider section to decide which VPS provider you want to choose. {% page-ref page=\"aws.md\" %} {% page-ref page=\"google-cloud.md\" %} {% page-ref page=\"vultr.md\" %} {% page-ref page=\"digital-ocean.md\" %} {% page-ref page=\"ankr.md\" %}","title":"Cloud Guides"},{"location":"validate/cloud-guides/#cloud-guides","text":"CPU we recommend 2 core, 2G ram for running single BLS key; 2 core, 4G ram for running up to 4 BLS keys. You may want to refer to the Choosing A Cloud Provider section to decide which VPS provider you want to choose. {% page-ref page=\"aws.md\" %} {% page-ref page=\"google-cloud.md\" %} {% page-ref page=\"vultr.md\" %} {% page-ref page=\"digital-ocean.md\" %} {% page-ref page=\"ankr.md\" %}","title":"Cloud Guides"},{"location":"validate/cloud-guides/ankr/","text":"Ankr Deploying a Harmony Node on Ankr Head to app.ankr.com to deploy and select Deploy A Node Scroll down to find the Harmony card, hover over it and press Deploy The hardware configuration is already set at the optimal system requirements. The platform also recommends a cluster, which is usually the one that has the most freely available resources. In this particular case, the recommended cluster is UK cluster, but another cluster may be recommended depending on your location. In order to deploy the Node, Ankr will generate a BLS Key and a Harmony Wallet for you. For security reasons, these two keys will be encoded with a password that must be set in the Encryption Password field. Please make sure to write this password somewhere safe in order to regain access to your keys. Next, you need to insert a node name in order to identify and get realtime stats of the node on the Harmony Validator Explorer , once your node is elected as a Validator. If you are using the application for the first time, you need to generate a deposit address by clicking Create Unique Address. When the address is generated, click Deploy Node to finish the Harmony Open Staking node deployment. Node Status and Staking Your Harmony node is deploying. Click on the Node to check the details. In order to be eligible for a Validator seat, you need to have ONE tokens in your wallet. You can transfer ONE tokens from any wallet to the generated ONE wallet address from the Information tab. Once the ONE tokens are visible in your token wallet, you can Apply for a Validator spot. You can check your Validator Information on the Harmony Validator Explorer by clicking the View Button.","title":"Ankr"},{"location":"validate/cloud-guides/ankr/#ankr","text":"","title":"Ankr"},{"location":"validate/cloud-guides/ankr/#deploying-a-harmony-node-on-ankr","text":"Head to app.ankr.com to deploy and select Deploy A Node Scroll down to find the Harmony card, hover over it and press Deploy The hardware configuration is already set at the optimal system requirements. The platform also recommends a cluster, which is usually the one that has the most freely available resources. In this particular case, the recommended cluster is UK cluster, but another cluster may be recommended depending on your location. In order to deploy the Node, Ankr will generate a BLS Key and a Harmony Wallet for you. For security reasons, these two keys will be encoded with a password that must be set in the Encryption Password field. Please make sure to write this password somewhere safe in order to regain access to your keys. Next, you need to insert a node name in order to identify and get realtime stats of the node on the Harmony Validator Explorer , once your node is elected as a Validator. If you are using the application for the first time, you need to generate a deposit address by clicking Create Unique Address. When the address is generated, click Deploy Node to finish the Harmony Open Staking node deployment.","title":"Deploying a Harmony Node on Ankr"},{"location":"validate/cloud-guides/ankr/#node-status-and-staking","text":"Your Harmony node is deploying. Click on the Node to check the details. In order to be eligible for a Validator seat, you need to have ONE tokens in your wallet. You can transfer ONE tokens from any wallet to the generated ONE wallet address from the Information tab. Once the ONE tokens are visible in your token wallet, you can Apply for a Validator spot. You can check your Validator Information on the Harmony Validator Explorer by clicking the View Button.","title":"Node Status and Staking"},{"location":"validate/cloud-guides/aws/","text":"AWS Step 1: Launching your AWS Node 1. If you don\u2019t already have an AWS account, register one at https://aws.amazon.com . 2. Once you have set up and logged into your AWS account, click on the top left bar \u201cServices -> Compute -> EC2\". 3. Click on the blue button \u201cLaunch Instance\". 4. Select \u201cAmazon Linux 2 AMI (HVM), SSD Volume Type\u201d. 5. Choose instance type \u201ct3.small\u201d. 6. Click \u201cNext: Configure Instance Details\u201d at the bottom right corner of the page. 7. Don't change anything. Click \u201cNext: Add Storage\u201d at the bottom right corner of the page. 8. Change the \u201cSize (GiB)\u201d category to 30. 9. Click \u201cNext: Add Tags\". 10. Click \"Add Tag.\" Then, in the \u201cKey\u201d input box put \u201cName\u201d in \u201cValue\u201d put \u201cPangaea-key\u201d. 11. Click \u201cNext: Configure Security Group\u201d. 12. On the default SSH with port 22, change the \u201cSource\u201d option to \u201cAnywhere\u201d. 13. Click \"Add Rule\". Under \"Type\" select \"Custom TCP Rule\", under \"Port Range\" put \"6000\" and under \"Source\" select \"Anywhere\". 14. Click \"Add Rule\" again. This time, under \"Type\" select \"Custom TCP Rule\", under \"Port Range\" put \"9000\" and under \"Source\" select \"Anywhere\". 15. Click \u201cReview and Launch\u201d and then click \"Launch\". (Note: Ignore warnings such as \u201cyour security group is open to the world\u201d or \u201cyour instance configuration is not eligible for free tier\u201d) 16. In the pop-up window you will need to create a new key pair. Select \u201cCreate a new key pair\u201d and then enter a name that you like, for example \u201cPangaea-key\u201d. 17. Click \u201cDownload Key Pair\u201d and save the key file somewhere you'll remember. 18. Click \u201cLaunch Instances\u201d. 19. Click \u201cView Instances\u201d at the bottom right. Your new instance should be initializing. Wait a few moments for it to get started. 21. Congratulations your instance is up and running! Now it's time to connect to your instance. Step 2: Connecting to your AWS Instance 1. Open a Terminal window on your computer. For Mac: If you can\u2019t find Terminal, use spotlight to search for it. Or go to your \"Applications' folder, and it should be inside of \u201cUtilities\u201d. For Windows: Download PuTTY to allow your computer to SSH into the AWS instance. For instructions on connecting to an EC2 instance using Putty follow these instructions from Amazon. 2. Once Terminal is open, use the cd command to change your directory to where the key pair file (Pangaea-key.pem) that you generated is. Hint it may be in your \u201cDownloads\u201d folder. 3. Enter the command chmod 400 Pangaea-key.pem . This command makes your key not publicly viewable. Note: On Mac, your pem file may have been changed to a .txt file so the correct command on Mac would be: chmod 400 Pangaea-key.pem.txt 4. Go back to your AWS window where you are viewing your instances. Select your new \"Pangaea-key\" instance and click \u201cConnect\u201d on the top bar. 5. In the pop-up window, under the \u201cExample:\u201d header, copy the sample command to connect to your ec2 instance. The command will look something like: ssh -i \"pangaea-key.pem\" ec2-user@ec2-13-250-30-215.ap-southeast-1.compute.amazonaws.com Now connect to your instance by running the sample command you copied from the \u201cConnect\u201d page in your terminal window. It may ask you whether or not you want to continue connecting. Type in \u201cyes\u201d and hit enter. Congratulations! You should be logged into your new AWS instance! Step 3: Installing Required Packages ****Run the following command to make sure your instance is properly updated: sudo yum update When prompted whether or not you want to download packages, enter \"y\" for yes. Now install the following packages that will be needed to run Harmony by typing: sudo yum install tmux You will be asked to confirm if you would like to download and install these packages. Just press Y to confirm.","title":"AWS"},{"location":"validate/cloud-guides/aws/#aws","text":"","title":"AWS"},{"location":"validate/cloud-guides/aws/#step-1-launching-your-aws-node","text":"1. If you don\u2019t already have an AWS account, register one at https://aws.amazon.com . 2. Once you have set up and logged into your AWS account, click on the top left bar \u201cServices -> Compute -> EC2\". 3. Click on the blue button \u201cLaunch Instance\". 4. Select \u201cAmazon Linux 2 AMI (HVM), SSD Volume Type\u201d. 5. Choose instance type \u201ct3.small\u201d. 6. Click \u201cNext: Configure Instance Details\u201d at the bottom right corner of the page. 7. Don't change anything. Click \u201cNext: Add Storage\u201d at the bottom right corner of the page. 8. Change the \u201cSize (GiB)\u201d category to 30. 9. Click \u201cNext: Add Tags\". 10. Click \"Add Tag.\" Then, in the \u201cKey\u201d input box put \u201cName\u201d in \u201cValue\u201d put \u201cPangaea-key\u201d. 11. Click \u201cNext: Configure Security Group\u201d. 12. On the default SSH with port 22, change the \u201cSource\u201d option to \u201cAnywhere\u201d. 13. Click \"Add Rule\". Under \"Type\" select \"Custom TCP Rule\", under \"Port Range\" put \"6000\" and under \"Source\" select \"Anywhere\". 14. Click \"Add Rule\" again. This time, under \"Type\" select \"Custom TCP Rule\", under \"Port Range\" put \"9000\" and under \"Source\" select \"Anywhere\". 15. Click \u201cReview and Launch\u201d and then click \"Launch\". (Note: Ignore warnings such as \u201cyour security group is open to the world\u201d or \u201cyour instance configuration is not eligible for free tier\u201d) 16. In the pop-up window you will need to create a new key pair. Select \u201cCreate a new key pair\u201d and then enter a name that you like, for example \u201cPangaea-key\u201d. 17. Click \u201cDownload Key Pair\u201d and save the key file somewhere you'll remember. 18. Click \u201cLaunch Instances\u201d. 19. Click \u201cView Instances\u201d at the bottom right. Your new instance should be initializing. Wait a few moments for it to get started. 21. Congratulations your instance is up and running! Now it's time to connect to your instance.","title":"Step 1: Launching your AWS Node "},{"location":"validate/cloud-guides/aws/#step-2-connecting-to-your-aws-instance","text":"1. Open a Terminal window on your computer. For Mac: If you can\u2019t find Terminal, use spotlight to search for it. Or go to your \"Applications' folder, and it should be inside of \u201cUtilities\u201d. For Windows: Download PuTTY to allow your computer to SSH into the AWS instance. For instructions on connecting to an EC2 instance using Putty follow these instructions from Amazon. 2. Once Terminal is open, use the cd command to change your directory to where the key pair file (Pangaea-key.pem) that you generated is. Hint it may be in your \u201cDownloads\u201d folder. 3. Enter the command chmod 400 Pangaea-key.pem . This command makes your key not publicly viewable. Note: On Mac, your pem file may have been changed to a .txt file so the correct command on Mac would be: chmod 400 Pangaea-key.pem.txt 4. Go back to your AWS window where you are viewing your instances. Select your new \"Pangaea-key\" instance and click \u201cConnect\u201d on the top bar. 5. In the pop-up window, under the \u201cExample:\u201d header, copy the sample command to connect to your ec2 instance. The command will look something like: ssh -i \"pangaea-key.pem\" ec2-user@ec2-13-250-30-215.ap-southeast-1.compute.amazonaws.com Now connect to your instance by running the sample command you copied from the \u201cConnect\u201d page in your terminal window. It may ask you whether or not you want to continue connecting. Type in \u201cyes\u201d and hit enter. Congratulations! You should be logged into your new AWS instance!","title":"Step 2: Connecting to your AWS Instance "},{"location":"validate/cloud-guides/aws/#step-3-installing-required-packages","text":"****Run the following command to make sure your instance is properly updated: sudo yum update When prompted whether or not you want to download packages, enter \"y\" for yes. Now install the following packages that will be needed to run Harmony by typing: sudo yum install tmux You will be asked to confirm if you would like to download and install these packages. Just press Y to confirm.","title":"Step 3: Installing Required Packages"},{"location":"validate/cloud-guides/digital-ocean/","text":"Digital Ocean {% hint style=\"success\" %} For new users, you can get $100 dollars free credits to run Digital Ocean services for 2 months using the link bellow {% endhint %} Step 1: Launching your Digital Ocean Node Logging into Digital Ocean \u200b Click here to register a new Digital Ocean account or login if you have an existing one. Create a new P roject Once you have set up and logged into your Digital Ocean account, click on the top left bar \u201cProjects -> New Project\". Enter the desired project name and click on \"Create Project\" as shown by the image below: Create a new Droplet On the top right corner click on \"Create\"->\"Droplets\". Choose now your desired Linux image. We recommend either the latest LTS version of Ubuntu (18.04 as of date of now) or the latest version of Debian . Use the left and right arrows to navigate between the different plans available. Choose the \"Standard\" plan and then select a virtual machine with at least 2 CPUs, 4GB of RAM and 80GB SSD. You can select the datacenter region of your choice here. We chose \"Frankurt\" in our example. We recommend using the \"SSH Keys\" as your authentication method (more secure) instead of the \"One-time password\" method. A button with the name \"New SSH key\" will appear on screen, just click on it. To create your SSH key click here for instructions. When you generated your public SSH key, give it a name and click on button \"Add SSH key\" as shown by the image below. In case you don't have a public SSH key yet, just follow the instructions to create it. Choose a custom hostname if you want and then click on \"Create Droplet\". Firewall Setup Wait a few seconds till your droplet is created and then click on \"Networking\" on the left bar. Click on \"Firewall\" and then on \"Create Firewall\". In the Inbound Rules section, click on \"New rule\" and select \"Custom\". Leave the protocol as TCP and fill the port range field with 6000 . Repeat the same procedure for port 9000 . You will be left with 2 inbound rules as shown by the image below. In the Outbound Rules section leave it as it is. Type the name of the droplet you want to apply your firewall rules (the droplet name is the same as your hostname you chose previously).Click now on \"Create Firewall\". Step 2: Connecting via SSH to your Instance To connect via SSH to your Digital Ocean instance, please follow the instructions here . Step 3: Installing Required Packages Before anything, it is recommended to update your system: sudo apt update && apt upgrade Now install the following packages that will be needed to run Harmony by typing: sudo apt install dnsutils && sudo apt install tmux You will be asked to confirm if you would like to download and install these packages. Just press Y to confirm.","title":"Digital Ocean"},{"location":"validate/cloud-guides/digital-ocean/#digital-ocean","text":"{% hint style=\"success\" %} For new users, you can get $100 dollars free credits to run Digital Ocean services for 2 months using the link bellow {% endhint %}","title":"Digital Ocean"},{"location":"validate/cloud-guides/digital-ocean/#step-1-launching-your-digital-ocean-node","text":"","title":"Step 1: Launching your Digital Ocean Node "},{"location":"validate/cloud-guides/digital-ocean/#logging-into-digital-ocean","text":"\u200b Click here to register a new Digital Ocean account or login if you have an existing one.","title":"Logging into Digital Ocean "},{"location":"validate/cloud-guides/digital-ocean/#create-a-new-project","text":"Once you have set up and logged into your Digital Ocean account, click on the top left bar \u201cProjects -> New Project\". Enter the desired project name and click on \"Create Project\" as shown by the image below:","title":"Create a new Project "},{"location":"validate/cloud-guides/digital-ocean/#create-a-new-droplet","text":"On the top right corner click on \"Create\"->\"Droplets\". Choose now your desired Linux image. We recommend either the latest LTS version of Ubuntu (18.04 as of date of now) or the latest version of Debian . Use the left and right arrows to navigate between the different plans available. Choose the \"Standard\" plan and then select a virtual machine with at least 2 CPUs, 4GB of RAM and 80GB SSD. You can select the datacenter region of your choice here. We chose \"Frankurt\" in our example. We recommend using the \"SSH Keys\" as your authentication method (more secure) instead of the \"One-time password\" method. A button with the name \"New SSH key\" will appear on screen, just click on it. To create your SSH key click here for instructions. When you generated your public SSH key, give it a name and click on button \"Add SSH key\" as shown by the image below. In case you don't have a public SSH key yet, just follow the instructions to create it. Choose a custom hostname if you want and then click on \"Create Droplet\".","title":"Create a new Droplet "},{"location":"validate/cloud-guides/digital-ocean/#firewall-setup","text":"Wait a few seconds till your droplet is created and then click on \"Networking\" on the left bar. Click on \"Firewall\" and then on \"Create Firewall\". In the Inbound Rules section, click on \"New rule\" and select \"Custom\". Leave the protocol as TCP and fill the port range field with 6000 . Repeat the same procedure for port 9000 . You will be left with 2 inbound rules as shown by the image below. In the Outbound Rules section leave it as it is. Type the name of the droplet you want to apply your firewall rules (the droplet name is the same as your hostname you chose previously).Click now on \"Create Firewall\".","title":"Firewall Setup "},{"location":"validate/cloud-guides/digital-ocean/#step-2-connecting-via-ssh-to-your-instance","text":"To connect via SSH to your Digital Ocean instance, please follow the instructions here .","title":"Step 2: Connecting via SSH to your Instance "},{"location":"validate/cloud-guides/digital-ocean/#step-3-installing-required-packages","text":"Before anything, it is recommended to update your system: sudo apt update && apt upgrade Now install the following packages that will be needed to run Harmony by typing: sudo apt install dnsutils && sudo apt install tmux You will be asked to confirm if you would like to download and install these packages. Just press Y to confirm.","title":"Step 3: Installing Required Packages"},{"location":"validate/cloud-guides/google-cloud/","text":"Google Cloud {% hint style=\"success\" %} Google Cloud has a free tier for new users. You get $300 to spend on Google Cloud Platform products during your first 12 months {% endhint %} Step 1: Launching your Google Cloud Instance Go to https://cloud.google.com/free and click on \u201cGet Started for Free\u201d. Login using an existing account or create a new one. After you login and validate your credit card, you will be shown a page pretty much like this one. Click on \u201cCompute Engine\u201d and then in \u201cVM Instances\u201d. Click on the Create button to make a new instance We recommend to name it something like \"pangaea\u201d (the instance name cannot be changed). Select the Machine type as \u201cCustom\u201d and set up 2 vCPU\u2019s and 4GB of Memory. Keep everything default after you have configured the cores and memory. For storage, 80GB is perfectly fine for now. For the Boot Disk, we recommend either the latest LTS version of Ubuntu (18.04 as of date of now) or the latest version of Debian . Click Create. Please wait a few minutes for your instance Once the instance is created. We will open 4 ingoing ports. To do this click on \"nic0\" as shown below. In the next page click on \u201cFirewall rules\u201d and after that on \u201cCREATE FIREWALL RULE\u201d. TCP 6000 TCP 9000 Step 2: Connecting via SSH to your Instance Go back to the VM instances page and click on SSH. This will open a new window and connect via SSH to your instance: Step 3: Installing Required Packages Before anything, it is recommended to update your system: sudo apt update && apt upgrade Now install the following packages that will be needed to run Harmony by typing: sudo apt install dnsutils && sudo apt install tmux You will be asked to confirm if you would like to download and install these packages. Just press Y to confirm.","title":"Google Cloud"},{"location":"validate/cloud-guides/google-cloud/#google-cloud","text":"{% hint style=\"success\" %} Google Cloud has a free tier for new users. You get $300 to spend on Google Cloud Platform products during your first 12 months {% endhint %}","title":"Google Cloud"},{"location":"validate/cloud-guides/google-cloud/#step-1-launching-your-google-cloud-instance","text":"Go to https://cloud.google.com/free and click on \u201cGet Started for Free\u201d. Login using an existing account or create a new one. After you login and validate your credit card, you will be shown a page pretty much like this one. Click on \u201cCompute Engine\u201d and then in \u201cVM Instances\u201d. Click on the Create button to make a new instance We recommend to name it something like \"pangaea\u201d (the instance name cannot be changed). Select the Machine type as \u201cCustom\u201d and set up 2 vCPU\u2019s and 4GB of Memory. Keep everything default after you have configured the cores and memory. For storage, 80GB is perfectly fine for now. For the Boot Disk, we recommend either the latest LTS version of Ubuntu (18.04 as of date of now) or the latest version of Debian . Click Create. Please wait a few minutes for your instance Once the instance is created. We will open 4 ingoing ports. To do this click on \"nic0\" as shown below. In the next page click on \u201cFirewall rules\u201d and after that on \u201cCREATE FIREWALL RULE\u201d. TCP 6000 TCP 9000","title":"Step 1: Launching your Google Cloud Instance "},{"location":"validate/cloud-guides/google-cloud/#step-2-connecting-via-ssh-to-your-instance","text":"Go back to the VM instances page and click on SSH. This will open a new window and connect via SSH to your instance:","title":"Step 2: Connecting via SSH to your Instance "},{"location":"validate/cloud-guides/google-cloud/#step-3-installing-required-packages","text":"Before anything, it is recommended to update your system: sudo apt update && apt upgrade Now install the following packages that will be needed to run Harmony by typing: sudo apt install dnsutils && sudo apt install tmux You will be asked to confirm if you would like to download and install these packages. Just press Y to confirm.","title":"Step 3: Installing Required Packages"},{"location":"validate/cloud-guides/vultr/","text":"Vultr {% hint style=\"success\" %} For new users, check if you can get a promo link to register on Vultr. Usually Vultr offers free credits for the first month. {% endhint %} Step 1: Launching Your Vultr Instance Logging into Vultr \u200bFirst, go to the Vultr Main Page . If you don\u2019t already have an Vultr account, register one by clicking on \"Sign up\". Otherwise, log into your Vultr Account by clicking on \"Sign in\". Create a new instance Once logged in, you'll want to add a new instance. Depending on whether your account is new or not, you may or may not have a Products page. If you already have an instance, click the \"+\" button to deploy a new server. You can also use this link to go to the deploy page. Otherwise, your Products page will be already link you to the Deploy page. Choose Instance Type For Pangaea requirements, two instance types would fit: Cloud Compute and High Frequency. Cloud Compute is recommended for Pangaea. Cloud Compute instances also work properly with 2 CPUs, 4 GB RAM with 80 GB SSDs. High Frequency Instances were recently introduced by Vultr and offer latest generation high performance 3GHz+ CPUs and NVMe SSDs. Select Server Location and Server Type Choose now your desired server type. We recommend either the latest LTS version of Ubuntu (18.04 as of date of now) or the latest version of Debian . Choose Server Size Harmony recommends one of the two following: Cloud Compute 2 CPU, 4 GB RAM, 80 GB SSD High Frequency 2 CPU, 4 GB RAM, 128 GB NVMe SSD For \"Additional Features\", none of the selections are necessary. Setting Server Name You can now set the name of your server, e.g. PangaeaNode Then you should click \"Deploy Now\". At this point you should be back on the Products page and your server should be installing. However, the setup isn't completely done, as you need to still create a firewall. Firewall Setup As we want to allow other nodes to connect to yours, we have to open the correct ports. Once you are on the Firewall page , click Add Firewall Group. Enter a name for the firewall group, e.g. FoundationNode. Open the following 3 ports to the public (\"Anywhere\" on inbound). TCP 22 (SSH) TCP 6000 TCP 9000 Make sure to check that 3 Group Rules have been set. Then link the instance to the firewall group. The steps are as follows: Click Linked Instances. Make sure your new server is selected. Click the + button. Click Add Linked Instance. Your instance should now be added to the firewall group and the number of linked instances should increment by 1. You can now go back to the Products page and your server is now successfully set up! Step 2: Connecting via SSH to your Instance Follow the instructions below accordingly to the operating system you are connecting from: Windows Linux Step 3: Installing Required Packages Before anything, it is recommended to update your system: sudo apt update && apt upgrade Now install the following packages that will be needed to run Harmony by typing: sudo apt install dnsutils && sudo apt install tmux You will be asked to confirm if you would like to download and install these packages. Just press Y to confirm.","title":"Vultr"},{"location":"validate/cloud-guides/vultr/#vultr","text":"{% hint style=\"success\" %} For new users, check if you can get a promo link to register on Vultr. Usually Vultr offers free credits for the first month. {% endhint %}","title":"Vultr"},{"location":"validate/cloud-guides/vultr/#step-1-launching-your-vultr-instance","text":"","title":"Step 1: Launching Your Vultr Instance "},{"location":"validate/cloud-guides/vultr/#logging-into-vultr","text":"\u200bFirst, go to the Vultr Main Page . If you don\u2019t already have an Vultr account, register one by clicking on \"Sign up\". Otherwise, log into your Vultr Account by clicking on \"Sign in\".","title":"Logging into Vultr "},{"location":"validate/cloud-guides/vultr/#create-a-new-instance","text":"Once logged in, you'll want to add a new instance. Depending on whether your account is new or not, you may or may not have a Products page. If you already have an instance, click the \"+\" button to deploy a new server. You can also use this link to go to the deploy page. Otherwise, your Products page will be already link you to the Deploy page.","title":"Create a new instance "},{"location":"validate/cloud-guides/vultr/#choose-instance-type","text":"For Pangaea requirements, two instance types would fit: Cloud Compute and High Frequency. Cloud Compute is recommended for Pangaea. Cloud Compute instances also work properly with 2 CPUs, 4 GB RAM with 80 GB SSDs. High Frequency Instances were recently introduced by Vultr and offer latest generation high performance 3GHz+ CPUs and NVMe SSDs.","title":"Choose Instance Type "},{"location":"validate/cloud-guides/vultr/#select-server-location-and-server-type","text":"Choose now your desired server type. We recommend either the latest LTS version of Ubuntu (18.04 as of date of now) or the latest version of Debian .","title":"Select Server Location and Server Type "},{"location":"validate/cloud-guides/vultr/#choose-server-size","text":"Harmony recommends one of the two following: Cloud Compute 2 CPU, 4 GB RAM, 80 GB SSD High Frequency 2 CPU, 4 GB RAM, 128 GB NVMe SSD For \"Additional Features\", none of the selections are necessary.","title":"Choose Server Size "},{"location":"validate/cloud-guides/vultr/#setting-server-name","text":"You can now set the name of your server, e.g. PangaeaNode Then you should click \"Deploy Now\". At this point you should be back on the Products page and your server should be installing. However, the setup isn't completely done, as you need to still create a firewall.","title":"Setting Server Name "},{"location":"validate/cloud-guides/vultr/#firewall-setup","text":"As we want to allow other nodes to connect to yours, we have to open the correct ports. Once you are on the Firewall page , click Add Firewall Group. Enter a name for the firewall group, e.g. FoundationNode.","title":"Firewall Setup "},{"location":"validate/cloud-guides/vultr/#open-the-following-3-ports-to-the-public-anywhere-on-inbound","text":"TCP 22 (SSH) TCP 6000 TCP 9000 Make sure to check that 3 Group Rules have been set.","title":"Open the following 3 ports to the public (\"Anywhere\" on inbound). "},{"location":"validate/cloud-guides/vultr/#then-link-the-instance-to-the-firewall-group-the-steps-are-as-follows","text":"Click Linked Instances. Make sure your new server is selected. Click the + button. Click Add Linked Instance. Your instance should now be added to the firewall group and the number of linked instances should increment by 1. You can now go back to the Products page and your server is now successfully set up!","title":"Then link the instance to the firewall group. The steps are as follows: "},{"location":"validate/cloud-guides/vultr/#step-2-connecting-via-ssh-to-your-instance","text":"Follow the instructions below accordingly to the operating system you are connecting from: Windows Linux","title":"Step 2: Connecting via SSH to your Instance "},{"location":"validate/cloud-guides/vultr/#step-3-installing-required-packages","text":"Before anything, it is recommended to update your system: sudo apt update && apt upgrade Now install the following packages that will be needed to run Harmony by typing: sudo apt install dnsutils && sudo apt install tmux You will be asked to confirm if you would like to download and install these packages. Just press Y to confirm.","title":"Step 3: Installing Required Packages"},{"location":"validate/definitions/","text":"Terms & Concepts For those validators or delegators who would like to join Harmony Open Staking , this section will help you get started and learn about how everything works. The following links can also help you better understand Harmony's staking mechanism and token economics. Intro to Effective-Proof-of-Stake Harmony Token Economics The Definitive Guide to Harmony Open Staking {% page-ref page=\"validator-keys-and-bids/\" %} {% page-ref page=\"effective-proof-of-stake-bidding-process.md\" %} {% page-ref page=\"epoch-transition.md\" %} {% page-ref page=\"block-reward.md\" %} {% page-ref page=\"others.md\" %}","title":"Terms & Concepts"},{"location":"validate/definitions/#terms-concepts","text":"For those validators or delegators who would like to join Harmony Open Staking , this section will help you get started and learn about how everything works. The following links can also help you better understand Harmony's staking mechanism and token economics. Intro to Effective-Proof-of-Stake Harmony Token Economics The Definitive Guide to Harmony Open Staking {% page-ref page=\"validator-keys-and-bids/\" %} {% page-ref page=\"effective-proof-of-stake-bidding-process.md\" %} {% page-ref page=\"epoch-transition.md\" %} {% page-ref page=\"block-reward.md\" %} {% page-ref page=\"others.md\" %}","title":"Terms &amp; Concepts"},{"location":"validate/definitions/block-reward/","text":"Block Reward For each of the blocks produced and confirmed within a shard, it should contain signatures from the keys with more than 2/3 of the total voting power of the shard committee. Each confirmed block will produce 28 ONE as block reward for the validators behind the committee. The 28 ONE is initially allocated to all the validators whose BLS key(s) signed on the block, proportionally to the voting power of the key(s) that signed. The allocated block reward for a validator will be further distributed to delegators proportionally to their stake after the commission fee is charged. For example, a validator with a commission rate of 25% got allocated 4 ONE for a block it signed. The validator staked 1000 ONE itself and it has 2 delegations each with 1000 ONE. The block reward distribution for this validator works as follows: The commission fee of 1 ONE (4 ONE * 25%) is cut from the original reward and credited to the validator. The rest of the reward of 3 ONE is then distributed to all the stakers (including both the validator and its delegators) proportionally based on their stake. Since the stakers (the validator and the two delegators) each staked/delegated 1000 ONE, they each receive 1 ONE in the reward distribution. For more information about block reward, please read our token economics model .","title":"Block Reward"},{"location":"validate/definitions/block-reward/#block-reward","text":"For each of the blocks produced and confirmed within a shard, it should contain signatures from the keys with more than 2/3 of the total voting power of the shard committee. Each confirmed block will produce 28 ONE as block reward for the validators behind the committee. The 28 ONE is initially allocated to all the validators whose BLS key(s) signed on the block, proportionally to the voting power of the key(s) that signed. The allocated block reward for a validator will be further distributed to delegators proportionally to their stake after the commission fee is charged. For example, a validator with a commission rate of 25% got allocated 4 ONE for a block it signed. The validator staked 1000 ONE itself and it has 2 delegations each with 1000 ONE. The block reward distribution for this validator works as follows: The commission fee of 1 ONE (4 ONE * 25%) is cut from the original reward and credited to the validator. The rest of the reward of 3 ONE is then distributed to all the stakers (including both the validator and its delegators) proportionally based on their stake. Since the stakers (the validator and the two delegators) each staked/delegated 1000 ONE, they each receive 1 ONE in the reward distribution. For more information about block reward, please read our token economics model .","title":"Block Reward"},{"location":"validate/definitions/effective-proof-of-stake-bidding-process/","text":"Effective Proof-of-Stake Effective stake is a new measure introduced in EPoS in order to prevent stake centralization and still provide capitalistic fairness. For exactly how it achieves that, here is the design rationale behind it. Let\u2019s call the bid price of the elected BLS keys the raw stake . The effective stake of an elected BLS key is a bounded value on its raw stake with a threshold around the median bidder\u2019s raw stake (denoted as median_stake in the picture below). The upper threshold is 115% of the median_stake and the lower threshold is 85% of the median_stake. For a key with raw stake that\u2019s out of bound of the threshold, its effective stake will be bounded by the corresponding threshold, otherwise, the effective stake is the same as the raw stake. The effective stake of each BLS key is determined at the last block of an epoch during the election process and will stay the same throughout the next epoch.","title":"Effective Proof-of-Stake"},{"location":"validate/definitions/effective-proof-of-stake-bidding-process/#effective-proof-of-stake","text":"Effective stake is a new measure introduced in EPoS in order to prevent stake centralization and still provide capitalistic fairness. For exactly how it achieves that, here is the design rationale behind it. Let\u2019s call the bid price of the elected BLS keys the raw stake . The effective stake of an elected BLS key is a bounded value on its raw stake with a threshold around the median bidder\u2019s raw stake (denoted as median_stake in the picture below). The upper threshold is 115% of the median_stake and the lower threshold is 85% of the median_stake. For a key with raw stake that\u2019s out of bound of the threshold, its effective stake will be bounded by the corresponding threshold, otherwise, the effective stake is the same as the raw stake. The effective stake of each BLS key is determined at the last block of an epoch during the election process and will stay the same throughout the next epoch.","title":"Effective Proof-of-Stake"},{"location":"validate/definitions/epoch-transition/","text":"Epoch Transition In Harmony mainnet, there are 4 shards each producing new blocks separately and in parallel. The block heights between shards are not synchronized so you will see different shards have different block heights. An epoch is a period of time when the beacon shard (i.e. shard 0, the coordinator for other shards) produces a fixed number of blocks. In Harmony mainnet, an epoch is 2\u00b9\u2074 = 16384 blocks (~1.5 days) in the beacon shard. Once an epoch is completed in the beacon shard, that change is also passed onto the other shards, thus all shards are synchronized by epoch. At the end of each epoch, the committee election process will take place to elect the committees for the next epoch. The election process takes into account all the staking transactions confirmed before the election happens. The election result will take effect immediately, so we encourage all candidate validators to spin up their nodes even before the election happens.","title":"Epoch Transition"},{"location":"validate/definitions/epoch-transition/#epoch-transition","text":"In Harmony mainnet, there are 4 shards each producing new blocks separately and in parallel. The block heights between shards are not synchronized so you will see different shards have different block heights. An epoch is a period of time when the beacon shard (i.e. shard 0, the coordinator for other shards) produces a fixed number of blocks. In Harmony mainnet, an epoch is 2\u00b9\u2074 = 16384 blocks (~1.5 days) in the beacon shard. Once an epoch is completed in the beacon shard, that change is also passed onto the other shards, thus all shards are synchronized by epoch. At the end of each epoch, the committee election process will take place to elect the committees for the next epoch. The election process takes into account all the staking transactions confirmed before the election happens. The election result will take effect immediately, so we encourage all candidate validators to spin up their nodes even before the election happens.","title":"Epoch Transition"},{"location":"validate/definitions/optimizations/","text":"Optimizations State Pruning State pruning is a feature we implemented in harmony nodes to prune redundant state nodes from the state DB before it was written to the DB. State pruning will reduce the blockchain size from current 80+G (as of Feb/25/2020) to <2G. Validators can reduce the disk size significantly to save the cloud cost. You can refer to ethereum\u2019s State Tree Pruning .","title":"Optimizations"},{"location":"validate/definitions/optimizations/#optimizations","text":"","title":"Optimizations"},{"location":"validate/definitions/optimizations/#state-pruning","text":"State pruning is a feature we implemented in harmony nodes to prune redundant state nodes from the state DB before it was written to the DB. State pruning will reduce the blockchain size from current 80+G (as of Feb/25/2020) to <2G. Validators can reduce the disk size significantly to save the cloud cost. You can refer to ethereum\u2019s State Tree Pruning .","title":"State Pruning"},{"location":"validate/definitions/others/","text":"Slashing Slashing is an integral component of EPoS which serves as the deterring factor to prevent any non-conforming behaviors from validators such as double signing and being offline. If validators breach the protocol in the two ways: Unavailability \u2014 a validator temporarily loses his slot if he misses more than 66% of the blocks in an epoch; this unresponsiveness is due to nodes being offline, largely not malicious behavior. Double signing -- a validator loses at least 2% of the stake depending on how many slots are corrupted; this behavior is considered a malicious behavior. A fraction of the staked tokens is slashed as penalties.Slashing penalties are imposed on both validators and delegators. Uptime and Unavailability Penalty The elected validators are obligated to validate blocks with their elected BLS keys. In every epoch, an elected validator should sign more than 2/3 of the signatures that its BLS keys are asked to sign. The signing performance is represented by a percentage value called uptime . A validator\u2019s uptime is the ratio of the number of signatures its elected BLS keys signed over the total number of signatures the keys should sign. For example, a validator has 2 elected BLS keys and each of the keys is presented 100 blocks to sign. In the final tally, the first key signed 70 blocks and the second key signed 80 blocks. Overall, the validator\u2019s uptime is (70+80) / (100*2) = 75%. At the end of each epoch, the validators with uptime of no more than 2/3 (66.66%) will have their status set to \u201cInactive\u201d and be ruled out from the new election. For these inactive validators, they are required to manually set their status to \u201cActive\u201d by sending an EditValidator transaction in order to participate in future elections. We encourage validators to be proactive in maintaining a high uptime to ensure they remain elected and earn the most block reward possible. Double Sign Slashing If any BLS key(s) are detected signing conflicting blocks (i.e. blocks with the same height and view ID but with different block hashes), the validator will be slashed and forever banned from the network. When a validator is slashed, a certain percentage (i.e. slashing rate) of staked tokens from the validator and its delegators will be forfeited, of which half will be burnt and another half will be credited to the reporter of the double sign event. The slashing rate is calculated by simply summing all the voting power of the double signing keys with a minimum of 2%. For example, if 3 BLS keys with voting power of 3%, 3% and 4% double signed at the same time, 10% of all staked tokens will be slashed on the validators who hold the 3 BLS keys.","title":"Slashing"},{"location":"validate/definitions/others/#slashing","text":"Slashing is an integral component of EPoS which serves as the deterring factor to prevent any non-conforming behaviors from validators such as double signing and being offline. If validators breach the protocol in the two ways: Unavailability \u2014 a validator temporarily loses his slot if he misses more than 66% of the blocks in an epoch; this unresponsiveness is due to nodes being offline, largely not malicious behavior. Double signing -- a validator loses at least 2% of the stake depending on how many slots are corrupted; this behavior is considered a malicious behavior. A fraction of the staked tokens is slashed as penalties.Slashing penalties are imposed on both validators and delegators.","title":"Slashing"},{"location":"validate/definitions/others/#uptime-and-unavailability-penalty","text":"The elected validators are obligated to validate blocks with their elected BLS keys. In every epoch, an elected validator should sign more than 2/3 of the signatures that its BLS keys are asked to sign. The signing performance is represented by a percentage value called uptime . A validator\u2019s uptime is the ratio of the number of signatures its elected BLS keys signed over the total number of signatures the keys should sign. For example, a validator has 2 elected BLS keys and each of the keys is presented 100 blocks to sign. In the final tally, the first key signed 70 blocks and the second key signed 80 blocks. Overall, the validator\u2019s uptime is (70+80) / (100*2) = 75%. At the end of each epoch, the validators with uptime of no more than 2/3 (66.66%) will have their status set to \u201cInactive\u201d and be ruled out from the new election. For these inactive validators, they are required to manually set their status to \u201cActive\u201d by sending an EditValidator transaction in order to participate in future elections. We encourage validators to be proactive in maintaining a high uptime to ensure they remain elected and earn the most block reward possible.","title":"Uptime and Unavailability Penalty "},{"location":"validate/definitions/others/#double-sign-slashing","text":"If any BLS key(s) are detected signing conflicting blocks (i.e. blocks with the same height and view ID but with different block hashes), the validator will be slashed and forever banned from the network. When a validator is slashed, a certain percentage (i.e. slashing rate) of staked tokens from the validator and its delegators will be forfeited, of which half will be burnt and another half will be credited to the reporter of the double sign event. The slashing rate is calculated by simply summing all the voting power of the double signing keys with a minimum of 2%. For example, if 3 BLS keys with voting power of 3%, 3% and 4% double signed at the same time, 10% of all staked tokens will be slashed on the validators who hold the 3 BLS keys.","title":"Double Sign Slashing "},{"location":"validate/definitions/slots-bidding-and-election/","text":"Slots Bidding and Election In Open Staking of mainnet, there will be 320 slots available for bidding. A slot represents membership in the network which gives the validator the right to use a specific BLS key to sign on blocks and the signature will be acknowledged by other validators. After you create the validator record, the tokens you stake, along with any delegated tokens to your validator, will be automatically used to bid for the slots. Each of the added BLS keys will create a unique bid for a slot in the network. The bid price equals the total stake on your validator divided by the total number of BLS keys attached to your validator. Simply put, all tokens staked to the validator will be equally divided into each BLS key and each key bids separately. For example, a validator with a total stake of 300 ONE and 3 associated BLS keys will have 3 bids each with a bid price of 100 ONE. The election for the slots works as follows. Before the start of an epoch, all validator bids are ranked by bid price in descending order. The highest 320 bids will be awarded the slots in the upcoming epoch. The BLS key that successfully bids for a slot is deemed elected . Elected BLS keys will eventually form the committees of the shards. A validator in possession of at least one elected BLS key is also deemed elected. Above is a simple example of bidding and election process with 10 slots and 5 validators.","title":"Slots Bidding and Election"},{"location":"validate/definitions/slots-bidding-and-election/#slots-bidding-and-election","text":"In Open Staking of mainnet, there will be 320 slots available for bidding. A slot represents membership in the network which gives the validator the right to use a specific BLS key to sign on blocks and the signature will be acknowledged by other validators. After you create the validator record, the tokens you stake, along with any delegated tokens to your validator, will be automatically used to bid for the slots. Each of the added BLS keys will create a unique bid for a slot in the network. The bid price equals the total stake on your validator divided by the total number of BLS keys attached to your validator. Simply put, all tokens staked to the validator will be equally divided into each BLS key and each key bids separately. For example, a validator with a total stake of 300 ONE and 3 associated BLS keys will have 3 bids each with a bid price of 100 ONE. The election for the slots works as follows. Before the start of an epoch, all validator bids are ranked by bid price in descending order. The highest 320 bids will be awarded the slots in the upcoming epoch. The BLS key that successfully bids for a slot is deemed elected . Elected BLS keys will eventually form the committees of the shards. A validator in possession of at least one elected BLS key is also deemed elected. Above is a simple example of bidding and election process with 10 slots and 5 validators.","title":"Slots Bidding and Election"},{"location":"validate/definitions/undelegation/","text":"Undelegation If a delegator decides to stop delegating to a validator (including self-undelegation), he or she can choose to undelegate their tokens from the validator. After undelegation is initiated from a currently elected validator, the tokens will be locked for 7 epochs before being credited to the delegator\u2019s account balance. Note that the unlocking of the undelegated tokens only happens at the end of every epoch. Locked tokens are still slashable if the validator double signs. For undelegating from a non-elected validator, the token will be unlocked 7 epochs after the validator was last elected. For example, if you are undelegating from a validator who was last elected 3 epochs ago, your token will be locked for 4 epochs after the undelegation starts. This leads to a convenient result that if you undelegate from a validator who is never elected before, you can have your token returned in the current epoch.","title":"Undelegation"},{"location":"validate/definitions/undelegation/#undelegation","text":"If a delegator decides to stop delegating to a validator (including self-undelegation), he or she can choose to undelegate their tokens from the validator. After undelegation is initiated from a currently elected validator, the tokens will be locked for 7 epochs before being credited to the delegator\u2019s account balance. Note that the unlocking of the undelegated tokens only happens at the end of every epoch. Locked tokens are still slashable if the validator double signs. For undelegating from a non-elected validator, the token will be unlocked 7 epochs after the validator was last elected. For example, if you are undelegating from a validator who was last elected 3 epochs ago, your token will be locked for 4 epochs after the undelegation starts. This leads to a convenient result that if you undelegate from a validator who is never elected before, you can have your token returned in the current epoch.","title":"Undelegation"},{"location":"validate/definitions/validator-keys-and-bids/","text":"Validator, BLS key, Instance Validator Setup and Configuration A validator in Harmony blockchain is a single person or entity who stakes tokens and runs nodes (validator client software) to validate blocks. A validator can specify one or multiple validating keys (a.k.a. BLS keys) which will be used to sign on validated blocks. To become a validator in Harmony, you will need to do the following: Setup a validator node(s) and let it fully synchronized with the latest blockchain. Create an on-chain validator record by sending a CreateValidator _****_transaction. Start validating using the node(s) with the BLS key(s) you added in your validator record There are many fields to configure for your validator. It\u2019s worth clarifying some of the important fields in more detail: amount: The amount of ONE tokens the validator will stake initially. rate: The commission fee (%) the validator charges from the block reward. bls-pubkeys: One or multiple BLS public keys the validator will sign with. Each BLS key will be used separately to bid for a slot and if successful, the key is obligated to validate blocks. BLS key(s) {% hint style=\"info\" %} BLS stands for Boneh\u2013Lynn\u2013Shacham . It is a digital signature method used for verifying the authenticity of digital messages or documents. {% endhint %} A BLS key represents what the validator signs the blocks with, and is a way of authenticating the validator. A validator can have multiple keys to sign with, this means that a validator is signing blocks in parallel. BLS keys are attached to validator via: Creating a new validator (put commas between multiple BLS keys) Adding new keys to an existing validator (edit-validator --add-bls-key), only one key can be added at a time Instance(s) & Multi-BLS keys An instance is a virtual private server or dedicated hardware with a unique IP address on which a validator runs the node software. Within each instance, there could be up to 4 BLS keys signing transactions. If you have more than a single BLS key in your instance, it means that you're using the multiBLS feature . If you have a single BLS key in the instance, we will call that single-key instance. Here are some rules to follow: In order to use multiBLS feature (multiple BLS keys in same instance), all keys are required to be on the same shard Total number of BLS keys allowed per validator is 1/3 of total external seats (network level) Note that validators sometimes choose to run duplicate instances (2 instances, each running with same BLS key) as a backup mechanism. Below are some differences to using multiBLS vs. single-key instance: Machine cost will be lower in a multiBLS instance (compare 'validator 2' vs. 'validator 1') Single-key instances could run nodes for a validator in different shards, whereas a multiBLS instance requires all BLS keys to be in the same shard MultiBLS and single-key instance have different staking commands In order to make changes to the keys in a multiBLS instance, the node needs to be stopped and restarted; whereas a single-key instance can be directly added to a validator (since the node is running on a different instance) Too many BLS keys signing using a single node creates a single point of failure (validator\u2019s risk) Visualization","title":"Validator, BLS key, Instance"},{"location":"validate/definitions/validator-keys-and-bids/#validator-bls-key-instance","text":"","title":"Validator, BLS key, Instance"},{"location":"validate/definitions/validator-keys-and-bids/#validator-setup-and-configuration","text":"A validator in Harmony blockchain is a single person or entity who stakes tokens and runs nodes (validator client software) to validate blocks. A validator can specify one or multiple validating keys (a.k.a. BLS keys) which will be used to sign on validated blocks. To become a validator in Harmony, you will need to do the following: Setup a validator node(s) and let it fully synchronized with the latest blockchain. Create an on-chain validator record by sending a CreateValidator _****_transaction. Start validating using the node(s) with the BLS key(s) you added in your validator record There are many fields to configure for your validator. It\u2019s worth clarifying some of the important fields in more detail: amount: The amount of ONE tokens the validator will stake initially. rate: The commission fee (%) the validator charges from the block reward. bls-pubkeys: One or multiple BLS public keys the validator will sign with. Each BLS key will be used separately to bid for a slot and if successful, the key is obligated to validate blocks.","title":"Validator Setup and Configuration"},{"location":"validate/definitions/validator-keys-and-bids/#bls-keys","text":"{% hint style=\"info\" %} BLS stands for Boneh\u2013Lynn\u2013Shacham . It is a digital signature method used for verifying the authenticity of digital messages or documents. {% endhint %} A BLS key represents what the validator signs the blocks with, and is a way of authenticating the validator. A validator can have multiple keys to sign with, this means that a validator is signing blocks in parallel. BLS keys are attached to validator via: Creating a new validator (put commas between multiple BLS keys) Adding new keys to an existing validator (edit-validator --add-bls-key), only one key can be added at a time","title":"BLS key(s)"},{"location":"validate/definitions/validator-keys-and-bids/#instances-multi-bls-keys","text":"An instance is a virtual private server or dedicated hardware with a unique IP address on which a validator runs the node software. Within each instance, there could be up to 4 BLS keys signing transactions. If you have more than a single BLS key in your instance, it means that you're using the multiBLS feature . If you have a single BLS key in the instance, we will call that single-key instance. Here are some rules to follow: In order to use multiBLS feature (multiple BLS keys in same instance), all keys are required to be on the same shard Total number of BLS keys allowed per validator is 1/3 of total external seats (network level) Note that validators sometimes choose to run duplicate instances (2 instances, each running with same BLS key) as a backup mechanism. Below are some differences to using multiBLS vs. single-key instance: Machine cost will be lower in a multiBLS instance (compare 'validator 2' vs. 'validator 1') Single-key instances could run nodes for a validator in different shards, whereas a multiBLS instance requires all BLS keys to be in the same shard MultiBLS and single-key instance have different staking commands In order to make changes to the keys in a multiBLS instance, the node needs to be stopped and restarted; whereas a single-key instance can be directly added to a validator (since the node is running on a different instance) Too many BLS keys signing using a single node creates a single point of failure (validator\u2019s risk)","title":"Instance(s) &amp; Multi-BLS keys"},{"location":"validate/definitions/validator-keys-and-bids/#visualization","text":"","title":"Visualization"},{"location":"validate/definitions/validator-keys-and-bids/#_1","text":"","title":""},{"location":"validate/definitions/validator-keys-and-bids/#_2","text":"","title":""},{"location":"validate/definitions/validator-keys-and-bids/shard-assignment/","text":"Shard Assignment After a validator is elected, each of its elected BLS keys will be semi-randomly assigned to a shard in the network (fully random shard assignment will come in the final phase of mainnet). In the current stage of mainnet, the rule of assignment is simply based on the modulus of the BLS public key\u2019s underlying bytes. For example, with 4 shards, a BLS public key like \u201cxxxxxx8ad5\u201d will be assigned to shard 1 because 5 % 4 = 1. Note that, for each of the elected BLS keys, the validator is obligated to spin up a validator node and validate blocks in the assigned shard.","title":"Shard Assignment"},{"location":"validate/definitions/validator-keys-and-bids/shard-assignment/#shard-assignment","text":"After a validator is elected, each of its elected BLS keys will be semi-randomly assigned to a shard in the network (fully random shard assignment will come in the final phase of mainnet). In the current stage of mainnet, the rule of assignment is simply based on the modulus of the BLS public key\u2019s underlying bytes. For example, with 4 shards, a BLS public key like \u201cxxxxxx8ad5\u201d will be assigned to shard 1 because 5 % 4 = 1. Note that, for each of the elected BLS keys, the validator is obligated to spin up a validator node and validate blocks in the assigned shard.","title":"Shard Assignment"},{"location":"validate/extras/","text":"Monitoring & Security","title":"Monitoring & Security"},{"location":"validate/extras/#monitoring-security","text":"","title":"Monitoring &amp; Security"},{"location":"validate/extras/choosing-a-cloud-provider/","text":"Choosing A Cloud Provider Which cloud provider to choose for your Harmony node? Since we are about to see EPoS go live on Harmony network, I decided to put together a list of possible cloud providers and some examples of their instances that can be used. TLDR CPU we recommend 2 core, 2G ram for running single BLS key; 2 core, 4G ram for running up to 4 BLS keys. Bandwidth better be 100M or better for downlink, uplink 10M or better. Although you can probably run away with a lower instance, it is not recommended, as the performance might be impacted and so are the rewards(slashing risk due to unavailability). In case of computer crash or power outage, you need backup or UPS. Currently the blockchain size is around 30GB. Based on the different cloud service you choose, machine cost can vary from a few dollars (digital ocean) to 29 dollar fixed price per month (Ankr). All prices displayed are based on a monthly basis. AWS (Amazon Web Services) Amazon offers powerful networking options and a large array of hardware specs. They offer speeds from 1 Gigabit and up to 100 Gigabit. Their T instances are burst instances, which means they are capable of high performance for a while only. After that, if the instance is still stretched you might get charged extra. They offer 3 kinds of instance purchases: On-demand instance: this one is self-explanatory, you pick an instance you wish to run, set it up and launch it. This is the default option. Spot instance: A Spot Instance is an unused EC2 instance that is available for less than the On-Demand price. Because Spot Instances enable you to request unused EC2 instances at steep discounts, you can lower your Amazon EC2 costs significantly. The hourly price for a Spot Instance is called a Spot price. Note that although you save some money compared to on-demand instances, there is a high chance the EC2 service will take them back when they need the extra capacity, or you might even have to pay more. Reserved instance (RI): this type allows you to reserve an instance type for a period in advance, for which you receive a significant discount. However, no matter if you still need it or not, you have to pay for it as long as the reserved period lasts (usually 1 year). Here is the link for an explanation of the burst instances: https://www.cloudhealthtech.com/blog/amazon-burstable-instances-explained IMPORTANT NOTE: Bandwidth is charged on a pay-as-you-go basis, and it is calculated on the actual bandwidth usage (GB) in your last month multiplied by AWS bandwidth charges ($0.12/GB). For example, if your server consumed 100GB bandwidth in a month, you will be charged for $12 (100GB x $0.12). Only the first 1GB is free, everything else is payable on top of the instance cost. Currently, the data charges for a Harmony mainnet node are around 20 USD extra per month. For cost estimation also refer to AWS Pricing Calculator . Relevant offers: t3a.small: EBS storage, 2 vCPU, 2GB RAM \u2013 recommended for 1-2 bls keys t3a.medium: EBS storage, 2 vCPU, 4GB RAM \u2013 recommended for 4 bls keys There are also AMD CPU versions of all of the above instances which are also good and a little bit cheaper. They are named like this: T3a.medium, M5a.large. NOTE: if you purchase a RI version of the above instances, then you get a discount of up to 50% on your instance. It also heavily depends on the region you want to launch it. For reference, you can check this website which has a table of the information and a lot of filters: https://www.ec2instances.info/?min_memory=4&min_vcpus=2&region=us-west-2&cost_duration=monthly Payment options: Credit card \u2013 they prefer business accounts, you will have a lot less problems and less questions about what you are using them for. Setup: instantly Digital Ocean Digital Ocean is another seasoned provider with a good reputation and stability. They do not disclose their network speed performance, however, based on user experience from node runners, it is satisfactory. Digital Ocean does not charge any fee on data transfer thus is highly recommended. Relevant offers: 2 GB, 2 vCPUs, 3 TB, 60 GB - $15/month 4 GB, 2 vCPUs, 4 TB, 80 GB - $20/month Payment options: credit card, Paypal Setup: instantly Ankr Ankr has developed a one-click node deployment application for Harmony Open Staking Validator nodes,which takes a lot less manual work to set up and maintain the node. 2 core, 4GB Memory, 60GB Storage, 29.00 USD per month Ankr is now providing a 2 month free period for 200 external validators on our testnet: Ankr provides 2 months of free hosting for Harmony Open Staking Validators . Payment options: credit card, PayPal Vultr Vultr is another very popular option amongst Harmony node runners. It has good pricing and setting it up within your Vultr account is quite simple. They also do not charge anything extra per month, except for the instance price. They do not show their network speed performance, but based on user experience it is more than enough, and probably is around 1 Gigabit. Relevant offers: High frequency compute instances: 128 GB SSD, 2 vCPU, 4GB RAM and 3TB monthly bandwidth \u2013 PRICE: 24 USD Compute instances: 80 GB SSD, 2vCPU, 4GB RAM and 3TB monthly bandwidth \u2013 PRICE: 20 USD By comparison, performance and benchmark testing, the high frequency compute instances are of course better and this recommended. More info here: https://www.vpsbenchmarks.com/posts/vultr_high_frequency_compute_instances Relevant links: https://www.vultr.com/products/cloud-compute/ https://www.vultr.com/news/Get-Paid-by-Referring-Customers/ (Vultr has a referral program if you bring them new customers) promo code GOVULTR that gives you 10 USD of free credit for the first month Payment options: credit card, Bitcoin, Paypal, Alipay, Wechat pay Setup: instantly Hetzner Hetzner is one of the latest popular options amongst node runners. Their prices are great and their service is stable. They also do not show the network speed performance, but based on user experience they are fast enough, and most probably up to 1 Gigabit. Relevant offers: CX41: 160 GB SSD, 4 vCPU, 16GB RAM and 20TB monthly bandwidth \u2013 PRICE 19,4 EUR CX51: 250 GB SSD, 8 vCPU, 32GB RAM and 20TB monthly bandwidth \u2013 PRICE 36,48 EUR Relevant links: https://www.hetzner.com/cloud Payment options: credit card, Paypal, wire transfer Setup: instantly Microsoft Azure Azure offers a similar service like Amazon, with RI instances which are up to 70% cheaper than on-demand instance. However their pricing tiers are even more expensive than Amazon, so I will not go into details about this provider. Google Cloud Platform Google has also similar offers to Amazon and Azure, but it seems to be even more expensive. They charge a lot for data transfer as far as I heard from the node runners. The only bonus they have is the 300 USD free credits for new signups, which can be used within 1 year. Google Cloud Platform Pricing Calculator: https://cloud.google.com/products/calculator Contabo Contabo is one of the newest possibilities amongst node runners, although the service provider itself is quite established already. The pricing is great, albeit not much tested yet within the node runners. Their web interface is a bit more simplified and doesn\u2019t provide all the extra tools that some others do, but for these prices I think its worth it. Their network speed performance varies based on the instance type you choose. Relevant offers: VPS S SSD: 200 GB SSD, 4 vCPU, 8GB RAM and unlimited bandwidth, speed: 200 Mbit \u2013 PRICE 4,99 EUR VPS M SSD: 400 GB SSD, 6 vCPU, 16GB RAM and unlimited bandwidth, speed: 400 Mbit \u2013 PRICE 8,99 EUR VPS L SSD: 800 GB SSD, 8 vCPU, 30GB RAM and unlimited bandwidth, speed: 600 Mbit \u2013 PRICE 14,99 EUR Important note: Contabo is charging a low one-time setup fee for each of your instances, you can find more info about exact prices in the link below. Relevant links: https://contabo.com/?show=vps Payment options: Paypal and wire transfer Setup: after the first payment is received Linode Linode is an established provider with competitive pricing and very good stability. They do show network speeds based on the instance type you choose, but they are all satisfactory. Relevant offers: 160 GB SSD, 2 vCPU, 4GB RAM and 4TB monthly bandwidth, network speed: in 40 Gbps, out 4000 Mbps \u2013 PRICE 20 USD Payment options: credit card, Paypal Setup: instantly Scaleaway Scaleaway is a newer provider to me, but it does offer its services for quite some time already. They offer various options within your account and their network speed performances are good. Relevant offers: DEV1-S: 120 GB SSD, 2 vCPU, 20GB RAM and 200 Mbit/s bandwidth \u2013 PRICE 2.99 EUR Payment options: credit card, SEPA direct debit Setup: instantly Final Notes There are a few clear front runners in these cloud providers, however, I would advise diversity here, as it will make the network stronger and more secure. If you run more than one node, I would also recommend different cloud providers for them. For example, I currently use Vultr and Hetzner. Once EPoS is live I might try some other providers too. As a side note, most of these cloud providers also offer additional block storage, with which you can extend the disk space on your instance in order to keep pace with the blockchain size. However, except for the Amazon service, I would not recommend extending disk space as it usually brings your performance down and lowers your overall IOPS ( https://en.wikipedia.org/wiki/IOPS ).","title":"Choosing A Cloud Provider"},{"location":"validate/extras/choosing-a-cloud-provider/#choosing-a-cloud-provider","text":"Which cloud provider to choose for your Harmony node? Since we are about to see EPoS go live on Harmony network, I decided to put together a list of possible cloud providers and some examples of their instances that can be used. TLDR CPU we recommend 2 core, 2G ram for running single BLS key; 2 core, 4G ram for running up to 4 BLS keys. Bandwidth better be 100M or better for downlink, uplink 10M or better. Although you can probably run away with a lower instance, it is not recommended, as the performance might be impacted and so are the rewards(slashing risk due to unavailability). In case of computer crash or power outage, you need backup or UPS. Currently the blockchain size is around 30GB. Based on the different cloud service you choose, machine cost can vary from a few dollars (digital ocean) to 29 dollar fixed price per month (Ankr). All prices displayed are based on a monthly basis. AWS (Amazon Web Services) Amazon offers powerful networking options and a large array of hardware specs. They offer speeds from 1 Gigabit and up to 100 Gigabit. Their T instances are burst instances, which means they are capable of high performance for a while only. After that, if the instance is still stretched you might get charged extra. They offer 3 kinds of instance purchases: On-demand instance: this one is self-explanatory, you pick an instance you wish to run, set it up and launch it. This is the default option. Spot instance: A Spot Instance is an unused EC2 instance that is available for less than the On-Demand price. Because Spot Instances enable you to request unused EC2 instances at steep discounts, you can lower your Amazon EC2 costs significantly. The hourly price for a Spot Instance is called a Spot price. Note that although you save some money compared to on-demand instances, there is a high chance the EC2 service will take them back when they need the extra capacity, or you might even have to pay more. Reserved instance (RI): this type allows you to reserve an instance type for a period in advance, for which you receive a significant discount. However, no matter if you still need it or not, you have to pay for it as long as the reserved period lasts (usually 1 year). Here is the link for an explanation of the burst instances: https://www.cloudhealthtech.com/blog/amazon-burstable-instances-explained IMPORTANT NOTE: Bandwidth is charged on a pay-as-you-go basis, and it is calculated on the actual bandwidth usage (GB) in your last month multiplied by AWS bandwidth charges ($0.12/GB). For example, if your server consumed 100GB bandwidth in a month, you will be charged for $12 (100GB x $0.12). Only the first 1GB is free, everything else is payable on top of the instance cost. Currently, the data charges for a Harmony mainnet node are around 20 USD extra per month. For cost estimation also refer to AWS Pricing Calculator . Relevant offers: t3a.small: EBS storage, 2 vCPU, 2GB RAM \u2013 recommended for 1-2 bls keys t3a.medium: EBS storage, 2 vCPU, 4GB RAM \u2013 recommended for 4 bls keys There are also AMD CPU versions of all of the above instances which are also good and a little bit cheaper. They are named like this: T3a.medium, M5a.large. NOTE: if you purchase a RI version of the above instances, then you get a discount of up to 50% on your instance. It also heavily depends on the region you want to launch it. For reference, you can check this website which has a table of the information and a lot of filters: https://www.ec2instances.info/?min_memory=4&min_vcpus=2&region=us-west-2&cost_duration=monthly Payment options: Credit card \u2013 they prefer business accounts, you will have a lot less problems and less questions about what you are using them for. Setup: instantly Digital Ocean Digital Ocean is another seasoned provider with a good reputation and stability. They do not disclose their network speed performance, however, based on user experience from node runners, it is satisfactory. Digital Ocean does not charge any fee on data transfer thus is highly recommended. Relevant offers: 2 GB, 2 vCPUs, 3 TB, 60 GB - $15/month 4 GB, 2 vCPUs, 4 TB, 80 GB - $20/month Payment options: credit card, Paypal Setup: instantly Ankr Ankr has developed a one-click node deployment application for Harmony Open Staking Validator nodes,which takes a lot less manual work to set up and maintain the node. 2 core, 4GB Memory, 60GB Storage, 29.00 USD per month Ankr is now providing a 2 month free period for 200 external validators on our testnet: Ankr provides 2 months of free hosting for Harmony Open Staking Validators . Payment options: credit card, PayPal Vultr Vultr is another very popular option amongst Harmony node runners. It has good pricing and setting it up within your Vultr account is quite simple. They also do not charge anything extra per month, except for the instance price. They do not show their network speed performance, but based on user experience it is more than enough, and probably is around 1 Gigabit. Relevant offers: High frequency compute instances: 128 GB SSD, 2 vCPU, 4GB RAM and 3TB monthly bandwidth \u2013 PRICE: 24 USD Compute instances: 80 GB SSD, 2vCPU, 4GB RAM and 3TB monthly bandwidth \u2013 PRICE: 20 USD By comparison, performance and benchmark testing, the high frequency compute instances are of course better and this recommended. More info here: https://www.vpsbenchmarks.com/posts/vultr_high_frequency_compute_instances Relevant links: https://www.vultr.com/products/cloud-compute/ https://www.vultr.com/news/Get-Paid-by-Referring-Customers/ (Vultr has a referral program if you bring them new customers) promo code GOVULTR that gives you 10 USD of free credit for the first month Payment options: credit card, Bitcoin, Paypal, Alipay, Wechat pay Setup: instantly Hetzner Hetzner is one of the latest popular options amongst node runners. Their prices are great and their service is stable. They also do not show the network speed performance, but based on user experience they are fast enough, and most probably up to 1 Gigabit. Relevant offers: CX41: 160 GB SSD, 4 vCPU, 16GB RAM and 20TB monthly bandwidth \u2013 PRICE 19,4 EUR CX51: 250 GB SSD, 8 vCPU, 32GB RAM and 20TB monthly bandwidth \u2013 PRICE 36,48 EUR Relevant links: https://www.hetzner.com/cloud Payment options: credit card, Paypal, wire transfer Setup: instantly Microsoft Azure Azure offers a similar service like Amazon, with RI instances which are up to 70% cheaper than on-demand instance. However their pricing tiers are even more expensive than Amazon, so I will not go into details about this provider. Google Cloud Platform Google has also similar offers to Amazon and Azure, but it seems to be even more expensive. They charge a lot for data transfer as far as I heard from the node runners. The only bonus they have is the 300 USD free credits for new signups, which can be used within 1 year. Google Cloud Platform Pricing Calculator: https://cloud.google.com/products/calculator Contabo Contabo is one of the newest possibilities amongst node runners, although the service provider itself is quite established already. The pricing is great, albeit not much tested yet within the node runners. Their web interface is a bit more simplified and doesn\u2019t provide all the extra tools that some others do, but for these prices I think its worth it. Their network speed performance varies based on the instance type you choose. Relevant offers: VPS S SSD: 200 GB SSD, 4 vCPU, 8GB RAM and unlimited bandwidth, speed: 200 Mbit \u2013 PRICE 4,99 EUR VPS M SSD: 400 GB SSD, 6 vCPU, 16GB RAM and unlimited bandwidth, speed: 400 Mbit \u2013 PRICE 8,99 EUR VPS L SSD: 800 GB SSD, 8 vCPU, 30GB RAM and unlimited bandwidth, speed: 600 Mbit \u2013 PRICE 14,99 EUR Important note: Contabo is charging a low one-time setup fee for each of your instances, you can find more info about exact prices in the link below. Relevant links: https://contabo.com/?show=vps Payment options: Paypal and wire transfer Setup: after the first payment is received Linode Linode is an established provider with competitive pricing and very good stability. They do show network speeds based on the instance type you choose, but they are all satisfactory. Relevant offers: 160 GB SSD, 2 vCPU, 4GB RAM and 4TB monthly bandwidth, network speed: in 40 Gbps, out 4000 Mbps \u2013 PRICE 20 USD Payment options: credit card, Paypal Setup: instantly Scaleaway Scaleaway is a newer provider to me, but it does offer its services for quite some time already. They offer various options within your account and their network speed performances are good. Relevant offers: DEV1-S: 120 GB SSD, 2 vCPU, 20GB RAM and 200 Mbit/s bandwidth \u2013 PRICE 2.99 EUR Payment options: credit card, SEPA direct debit Setup: instantly Final Notes There are a few clear front runners in these cloud providers, however, I would advise diversity here, as it will make the network stronger and more secure. If you run more than one node, I would also recommend different cloud providers for them. For example, I currently use Vultr and Hetzner. Once EPoS is live I might try some other providers too. As a side note, most of these cloud providers also offer additional block storage, with which you can extend the disk space on your instance in order to keep pace with the blockchain size. However, except for the Amazon service, I would not recommend extending disk space as it usually brings your performance down and lowers your overall IOPS ( https://en.wikipedia.org/wiki/IOPS ).","title":"Choosing A Cloud Provider"},{"location":"validate/extras/monitoring-and-reporting-tools/","text":"Monitoring and Reporting Tools Mainnet Block Explorer Harmony Explorer Status Overview (Internal Nodes) Harmony Status Rewards Overview (External Nodes) External Nodes Reward Rate - 1 hour","title":"Monitoring and Reporting Tools"},{"location":"validate/extras/monitoring-and-reporting-tools/#monitoring-and-reporting-tools","text":"Mainnet Block Explorer Harmony Explorer Status Overview (Internal Nodes) Harmony Status Rewards Overview (External Nodes) External Nodes Reward Rate - 1 hour","title":"Monitoring and Reporting Tools"},{"location":"validate/extras/text-based-user-interface-tui/","text":"Text Based User Interface (TUI) Harmony TUI Text based user interface for Harmony node. Below information is currently displayed on Harmony-TUI Section - Harmony Blockchain - _**_Connected peers - Leader's one address - Current epoch number - Recent timestamps of various stages Section - Harmony Node - _**_Harmony node binary version - ShardId of local node - Balance of user's one account Section - Current Block - _**_Current block number - Size of current block in bytes - Hash of current block - StateRoot - BlockEpoch - Number of signers who signed last block Section - System Stats - CPU usage in percentage - Memory/RAM usage of system - Used disk space Section - Validator Logs This section shows validator log file Dependencies harmony node running on localhost:9000 shared libraries required for running harmony node Harmony TUI binary should be in same directory as harmony node binary Build and run harmony-tui binary Build from source code Clone repository - git clone git@github.com:harmony-one/harmony-tui.git cd harmony-tui Invoke make to build harmony-tui binary for local platform or make build-linux for linux binary will get generated in ./bin directory Copy harmony-tui binary from ./bin to the same directory as harmony node binary Invoke binary - path_to_binary/harmony-tui --address=YOUR_ONE_ADDRESS Download binary and run . Download binary directly from here . Place downloaded binary in same directory as harmony node binary Invoke binary - path_to_binary/harmony-tui --address=YOUR_ONE_ADDRESS Usage Invoke binary - path_to_binary/harmony-tui --address=YOUR_ONE_ADDRESS Help information - path_to_binary/harmony-tui--help Command line arguments supported by harmony-tui binary -address string text `address of your one account (default \"Not Provided\")` -env string text `environment of system binary is running on option 1- \"local\" option 2- \"ec2\" (default \"ec2\")` -version text `version of the binary` Examples Run binary - path_to_binary/harmony-tui --address=YOUR_ONE_ADDRESS --env=local Check version - path_to_binary/harmony-tui --version Sample screenshot\u200b \u200b","title":"Text Based User Interface \\(TUI\\)"},{"location":"validate/extras/text-based-user-interface-tui/#text-based-user-interface-tui","text":"","title":"Text Based User Interface (TUI)"},{"location":"validate/extras/text-based-user-interface-tui/#harmony-tui","text":"Text based user interface for Harmony node. Below information is currently displayed on Harmony-TUI Section - Harmony Blockchain - _**_Connected peers - Leader's one address - Current epoch number - Recent timestamps of various stages Section - Harmony Node - _**_Harmony node binary version - ShardId of local node - Balance of user's one account Section - Current Block - _**_Current block number - Size of current block in bytes - Hash of current block - StateRoot - BlockEpoch - Number of signers who signed last block Section - System Stats - CPU usage in percentage - Memory/RAM usage of system - Used disk space Section - Validator Logs This section shows validator log file","title":"Harmony TUI"},{"location":"validate/extras/text-based-user-interface-tui/#dependencies","text":"harmony node running on localhost:9000 shared libraries required for running harmony node Harmony TUI binary should be in same directory as harmony node binary","title":"Dependencies"},{"location":"validate/extras/text-based-user-interface-tui/#build-and-run-harmony-tui-binary","text":"Build from source code Clone repository - git clone git@github.com:harmony-one/harmony-tui.git cd harmony-tui Invoke make to build harmony-tui binary for local platform or make build-linux for linux binary will get generated in ./bin directory Copy harmony-tui binary from ./bin to the same directory as harmony node binary Invoke binary - path_to_binary/harmony-tui --address=YOUR_ONE_ADDRESS Download binary and run . Download binary directly from here . Place downloaded binary in same directory as harmony node binary Invoke binary - path_to_binary/harmony-tui --address=YOUR_ONE_ADDRESS","title":"Build and run harmony-tui binary"},{"location":"validate/extras/text-based-user-interface-tui/#usage","text":"Invoke binary - path_to_binary/harmony-tui --address=YOUR_ONE_ADDRESS Help information - path_to_binary/harmony-tui--help Command line arguments supported by harmony-tui binary -address string text `address of your one account (default \"Not Provided\")` -env string text `environment of system binary is running on option 1- \"local\" option 2- \"ec2\" (default \"ec2\")` -version text `version of the binary` Examples Run binary - path_to_binary/harmony-tui --address=YOUR_ONE_ADDRESS --env=local Check version - path_to_binary/harmony-tui --version","title":"Usage"},{"location":"validate/extras/text-based-user-interface-tui/#sample-screenshot","text":"","title":"Sample screenshot\u200b\u200b "},{"location":"validate/extras/validator-security/","text":"Validator Security This section will teach you about improving the security of your validator. As a validator you play a crucial role in securing and decentralizing the Harmony network. The security of the network is compounded as a sum of all validator's security. Therefore is very important that every single piece in the chain is as secure as possible. Depending on your configuration, if you have the BLS key on your validator server and maybe also the password to decrypt it, for example in order to restart your node automatically, it is strongly recommended that you secure the access to your validator as much as possible. Using 2FA and other security measures can substantially improve the overall security of your validator. The state of the art for 2FA is to use a HSM module like YubiKey. Very important: it is highly recommended to have two YubiKeys associated to ensure one is not locked out in case a YubiKey is lost, stolen, or breaks. In case you find YubiKey an expensive solution, other methods for 2FA can be used, like your phone or authenticator apps for example. Very important: Be aware that SMS based 2FA authentication methods are not secure and not recommended as one could hijack your smartphone\u2019s SIM. Doing this hackers can redirect any two-factor notifications to their own devices. What are and why use HSM modules? Hardware Security Modules (HSMs) generate, manage and store the secure cryptographic keys that are required for authenticating an user or device in a broader network. Malware attacks and remote extraction of private keys are much more difficult when a HSM module is configured properly. When you have your private key on your validator that is secured only by a password, an attacker can simply copy your private key and sign malicious transactions or generate double signs which can result for example in stake slashing or other unwanted operations on your node. By using Two-Factor Authenticator (2FA) and HSM module, you are strengthening the authentication on your Virtual Private Server (VPS). There are many options for 2FA but is recommended that you actually use a HSM module like YubiKey for this. Even better would be to use certificate in combination with a HSM module in order to authenticate and disable password login. How can I secure the access to my VPS better? 1. Add Two-factor Authenticator to your VPS provider if it is allowed. Serious VPS providers allow this already and also to use a HSM module like YubiKey. This guide focuses on Vultr but the documentation for YubiKey activation can be found in the documentation of different VPS providers, e.g. Hetzner: https://wiki.hetzner.de/index.php/KonsoleH:Zwei-Faktor-Authentifizierung/en Activate 2FA with YubiYey for Vultr In order to use YubiKey Authentication, you need any of Yubico\u2019s Yubikey USB devices. Next, you would need to login to your Vultr Account: Click Account -> Authentication -> Manage Two Factor Auth: https://my.vultr.com/settings/twofactor/ Under Add new authentication method, select YubiKey, enter a description of your choice in the next field, then click Add. In the next page, you will need to make sure your YubiKey device is plugged into one of your USB Ports on your computer. You will be presented with a text field in which you need to click, then press the button(s) on your YubiKey Device, or touch the edge of the device if you\u2019re using a YubiKey Nano, then click Update. In the next page, you will need to repeat the previous step to re-enter a secondary token, then click Update. When you are finished, log out of your Vultr account. Then attempt to log back in. You will be asked to enter an authentication code. Insert the YubiKey device in one of your computer\u2019s USB ports, and either press the button(s) or touch the edge of the device. 2. Create a SSH Public-Private Key pair for your VPS and assign the Public Key to the VPS when creating it. On Windows you can use for example PuttyGen to generate your SSH Public-Private Key pair. Setting a passphrase is advisable as it offers another layer of security if your ssh keys will be compromised. Popular algorithms for creating SSH Keys: RSA: It depends on key size. It is recommend to have 3072 or even better 4096-bit length. The 1024-bit length is considered unsafe. Ed25519: It\u2019s the most recommended public-key algorithm available today but you have to check with the cloud provider, e.g. Vultr, Hetzner, AWS if is supporting this. To generate the SSH keys on macOS use the Terminal and the command below. ssh-keygen -t rsa 3. Use SSH Private Key and not password to authenticate on your VPS 4. If you received any root password after creating your VPS, change it passwd Make sure to back-up this password and also be aware where you place it so that it won\u2019t get stolen. Very important: For holding passwords, keywords, etc. an encrypted hardware device and paper wallets are recommended. It is not recommended to hold passwords or keywords on a hot storage like your personal computer or notebook. 5. Once logged in, update your OS For Debian based systems like Ubuntu or Debian use the command below: sudo apt-get update && sudo apt-get upgrade For Amazon Linux use the command below: sudo yum update 6. Create a separate user than root for your application It is not recommended to use directly the root user on your VPS. Therefore create a new user: adduser <your-username> Add the newly created <your-username> user to the sudo group: adduser <your-username> sudo You can switch to the new user with the following command: sudo -u <your-username> -i 7. Create the necessary setup so that the new created user can login using certificate sudo mkdir -p \"/home/<your-username>/.ssh\" sudo chmod 0700 \"/home/<your-username>/.ssh\" sudo chown \"<your-username>:<your-username>\" \"/home/<your-username>/.ssh\" Add the public key to your new created user sudo nano \"/home/<your-username>/.ssh/authorized_keys\" sudo ls \"/home/<your-username>/.ssh\" -l sudo chown \"<your-username>:<your-username>\" \"/home/<your-username>/.ssh/authorized_keys\" sudo chmod 0600 \"/home/<your-username>/.ssh/authorized_keys\" 8. Setup Yubikey 2FA on Debian based systems like Ubuntu and strengthen the general authentication First add the PPA and install the library. sudo add-apt-repository ppa:yubico/stable sudo apt-get update sudo apt-get install libpam-yubico Let\u2019s add pam settings for SSH. sudo nano /etc/pam.d/sshd Add the following line at the top to enable the module: auth sufficient pam_yubico.so id=[Your API Client ID] key=[Your API Client Key] authfile=/etc/yubikey_mappings You can use the following link in order to get the API Client ID and the API Client Key: https://upgrade.yubico.com/getapikey/ To improve the security you should comment the following line out: @include common-auth This way the YubiKey is required to authenticate without a possibility to fall back to providing the password. Result: Save the file and exit -> press Ctrl+X and then press \u201cy\u201d Next step is to create a mapping file where you define which YubiKey device is assigned to which user of your VPS. The mapping file contains users and YubiKey identifiers. The YubiKey identifiers are always the first 12 characters of the generated YubiKey token. In order to generate the YubiKey token you just tap your YubiKey. Then you select its first 12 characters. In case you have multiple YubiKeys you can also add multiple. sudo nano /etc/yubikey_mappings Add the mappings for each user: <user1:<first 12 characters of yubikey1>:<first 12 characters of yubikey2> <user2>:<first 12 characters of yubikey1> Save the file and exit -> press Ctrl+X and then press \u201cy\u201d Next step is to update sshd_config file to authenticate via public key and pam. sudo nano /etc/ssh/sshd_config Following changes need to be made: Enable challenge response authentication by changing it to \u201cyes\u201d **** ChallengeResponseAuthentication yes Add a new line that sets the Authentication Methods to require first the public key to be valid and then the YubiKey token for each user. AuthenticationMethods publickey,keyboard-interactive:pam UsePAM yes Disable the password authentication by removing \u201c#\u201d in front of this line: PasswordAuthentication and set the value from yes to no Disable root authentication - if you have created a separate user for your application, deployments, etc. you can also disable the SSH root user access, which will add an extra layer of security to your VPS. ****Find the line PermitRootLogin , remove the comment sign \u201c#\u201d from the beginning of it and set the value to no Change your SSH port from 22 to another one, for example 2225. **** Don\u2019t use any of the ports in this list: https://en.wikipedia.org/wiki/List_of_TCP_and_UDP_port_numbers , as they are already being used. **** Example sshd_config file - take it only as reference to see the security changes and don't copy it! # $OpenBSD: sshd_config,v 1.101 2017/03/14 07:19:07 djm Exp $ # This is the sshd server system-wide configuration file. See # sshd_config(5) for more information. # This sshd was compiled with PATH=/usr/bin:/bin:/usr/sbin:/sbin # The strategy used for options in the default sshd_config shipped with # OpenSSH is to specify options with their default value where # possible, but leave them commented. Uncommented options override the # default value. Port 2225 #AddressFamily any #ListenAddress 0.0.0.0 #ListenAddress :: #HostKey /etc/ssh/ssh_host_rsa_key #HostKey /etc/ssh/ssh_host_ecdsa_key #HostKey /etc/ssh/ssh_host_ed25519_key # Ciphers and keying #RekeyLimit default none # Logging #SyslogFacility AUTH #LogLevel INFO # Authentication: AuthenticationMethods publickey,keyboard-interactive:pam #LoginGraceTime 2m PermitRootLogin no #StrictModes yes #MaxAuthTries 6 #MaxSessions 10 #PubkeyAuthentication yes # Expect .ssh/authorized_keys2 to be disregarded by default in future. #AuthorizedKeysFile .ssh/authorized_keys .ssh/authorized_keys2 #AuthorizedPrincipalsFile none #AuthorizedKeysCommand none #AuthorizedKeysCommandUser nobody # For this to work you will also need host keys in /etc/ssh/ssh_known_hosts #HostbasedAuthentication no # Change to yes if you don't trust ~/.ssh/known_hosts for # HostbasedAuthentication #IgnoreUserKnownHosts no # Don't read the user's ~/.rhosts and ~/.shosts files #IgnoreRhosts yes # To disable tunneled clear text passwords, change to no here! PasswordAuthentication no #PermitEmptyPasswords no # Change to yes to enable challenge-response passwords (beware issues with # some PAM modules and threads) ChallengeResponseAuthentication yes # Kerberos options #KerberosAuthentication no #KerberosOrLocalPasswd yes #KerberosTicketCleanup yes #KerberosGetAFSToken no # GSSAPI options #GSSAPIAuthentication no #GSSAPICleanupCredentials yes #GSSAPIStrictAcceptorCheck yes #GSSAPIKeyExchange no # Set this to 'yes' to enable PAM authentication, account processing, # and session processing. If this is enabled, PAM authentication will # be allowed through the ChallengeResponseAuthentication and # PasswordAuthentication. Depending on your PAM configuration, # PAM authentication via ChallengeResponseAuthentication may bypass # the setting of \"PermitRootLogin without-password\". # If you just want the PAM account and session checks to run without # PAM authentication, then enable this but set PasswordAuthentication # and ChallengeResponseAuthentication to 'no'. UsePAM yes #AllowAgentForwarding yes #AllowTcpForwarding yes #GatewayPorts no X11Forwarding yes #X11DisplayOffset 10 #X11UseLocalhost yes #PermitTTY yes PrintMotd no #PrintLastLog yes #TCPKeepAlive yes #UseLogin no #PermitUserEnvironment no #Compression delayed #ClientAliveInterval 0 #ClientAliveCountMax 3 #UseDNS no #PidFile /var/run/sshd.pid #MaxStartups 10:30:100 #PermitTunnel no #ChrootDirectory none #VersionAddendum none # no default banner path #Banner none # Allow client to pass locale environment variables AcceptEnv LANG LC_* # override default of no subsystems Subsystem sftp /usr/lib/openssh/sftp-server # Example of overriding settings on a per-user basis #Match User anoncvs # X11Forwarding no # AllowTcpForwarding no # PermitTTY no # ForceCommand cvs server Save the file and exit -> press Ctrl+X and then press \u201cy\u201d Finally restart the sshd service to update the settings. service sshd restart Test the configuration It is recommended to keep the current session active. In case something went wrong, you will still have access to your VPS and be able to make changes. Create a new ssh connection and check if the SSH login with certificate and YubiKey works. First the certificate will be used and then you will be prompted for YubiKey. Once this is the case just tap your YubiKey to enter your token and login. Example: 9. Install fail2ban to reduce brute force attacks sudo apt-get install -y fail2ban Start and enable the service sudo systemctl start fail2ban sudo systemctl enable fail2ban It is recommended to use a separate jail.local file to actually read your own configuration. For that first you have to copy the basic configuration jail.conf to the local one jail.local. The new file jail.local will override the original settings in jail.conf. sudo cp /etc/fail2ban/jail.conf /etc/fail2ban/jail.local Edit the file jail.local sudo nano /etc/fail2ban/jail.local Enter your desired configuration, for example: [sshd] enabled = true port = 22 filter = sshd logpath = /var/log/auth.log maxretry = 5 This configuration will block an IP address that is being used to log into your VPS via SSH, port 22 and fails for 5 times. Save and close the file -> press Ctrl+X and then press \u201cy\u201d Restart fail2ban to activate the settings sudo systemctl restart fail2ban 10. Configure system firewall with IPtables More about it can be found here: https://www.tecmint.com/linux-iptables-firewall-rules-examples-commands/ 11. Monitor and manage your system and process by using htop ****Install htop sudo apt-get install htop Run htop htop","title":"Validator Security"},{"location":"validate/extras/validator-security/#validator-security","text":"This section will teach you about improving the security of your validator. As a validator you play a crucial role in securing and decentralizing the Harmony network. The security of the network is compounded as a sum of all validator's security. Therefore is very important that every single piece in the chain is as secure as possible. Depending on your configuration, if you have the BLS key on your validator server and maybe also the password to decrypt it, for example in order to restart your node automatically, it is strongly recommended that you secure the access to your validator as much as possible. Using 2FA and other security measures can substantially improve the overall security of your validator. The state of the art for 2FA is to use a HSM module like YubiKey. Very important: it is highly recommended to have two YubiKeys associated to ensure one is not locked out in case a YubiKey is lost, stolen, or breaks. In case you find YubiKey an expensive solution, other methods for 2FA can be used, like your phone or authenticator apps for example. Very important: Be aware that SMS based 2FA authentication methods are not secure and not recommended as one could hijack your smartphone\u2019s SIM. Doing this hackers can redirect any two-factor notifications to their own devices.","title":"Validator Security"},{"location":"validate/extras/validator-security/#what-are-and-why-use-hsm-modules","text":"Hardware Security Modules (HSMs) generate, manage and store the secure cryptographic keys that are required for authenticating an user or device in a broader network. Malware attacks and remote extraction of private keys are much more difficult when a HSM module is configured properly. When you have your private key on your validator that is secured only by a password, an attacker can simply copy your private key and sign malicious transactions or generate double signs which can result for example in stake slashing or other unwanted operations on your node. By using Two-Factor Authenticator (2FA) and HSM module, you are strengthening the authentication on your Virtual Private Server (VPS). There are many options for 2FA but is recommended that you actually use a HSM module like YubiKey for this. Even better would be to use certificate in combination with a HSM module in order to authenticate and disable password login.","title":"What are and why use HSM modules?"},{"location":"validate/extras/validator-security/#how-can-i-secure-the-access-to-my-vps-better","text":"","title":"How can I secure the access to my VPS better?"},{"location":"validate/extras/validator-security/#1-add-two-factor-authenticator-to-your-vps-provider-if-it-is-allowed","text":"Serious VPS providers allow this already and also to use a HSM module like YubiKey. This guide focuses on Vultr but the documentation for YubiKey activation can be found in the documentation of different VPS providers, e.g. Hetzner: https://wiki.hetzner.de/index.php/KonsoleH:Zwei-Faktor-Authentifizierung/en Activate 2FA with YubiYey for Vultr In order to use YubiKey Authentication, you need any of Yubico\u2019s Yubikey USB devices. Next, you would need to login to your Vultr Account: Click Account -> Authentication -> Manage Two Factor Auth: https://my.vultr.com/settings/twofactor/ Under Add new authentication method, select YubiKey, enter a description of your choice in the next field, then click Add. In the next page, you will need to make sure your YubiKey device is plugged into one of your USB Ports on your computer. You will be presented with a text field in which you need to click, then press the button(s) on your YubiKey Device, or touch the edge of the device if you\u2019re using a YubiKey Nano, then click Update. In the next page, you will need to repeat the previous step to re-enter a secondary token, then click Update. When you are finished, log out of your Vultr account. Then attempt to log back in. You will be asked to enter an authentication code. Insert the YubiKey device in one of your computer\u2019s USB ports, and either press the button(s) or touch the edge of the device.","title":"1. Add Two-factor Authenticator to your VPS provider if it is allowed."},{"location":"validate/extras/validator-security/#2-create-a-ssh-public-private-key-pair-for-your-vps-and-assign-the-public-key-to-the-vps-when-creating-it","text":"On Windows you can use for example PuttyGen to generate your SSH Public-Private Key pair. Setting a passphrase is advisable as it offers another layer of security if your ssh keys will be compromised. Popular algorithms for creating SSH Keys: RSA: It depends on key size. It is recommend to have 3072 or even better 4096-bit length. The 1024-bit length is considered unsafe. Ed25519: It\u2019s the most recommended public-key algorithm available today but you have to check with the cloud provider, e.g. Vultr, Hetzner, AWS if is supporting this. To generate the SSH keys on macOS use the Terminal and the command below. ssh-keygen -t rsa","title":"2. Create a SSH Public-Private Key pair for your VPS and assign the Public Key to the VPS when creating it."},{"location":"validate/extras/validator-security/#3-use-ssh-private-key-and-not-password-to-authenticate-on-your-vps","text":"","title":"3. Use SSH Private Key and not password to authenticate on your VPS"},{"location":"validate/extras/validator-security/#4-if-you-received-any-root-password-after-creating-your-vps-change-it","text":"passwd Make sure to back-up this password and also be aware where you place it so that it won\u2019t get stolen. Very important: For holding passwords, keywords, etc. an encrypted hardware device and paper wallets are recommended. It is not recommended to hold passwords or keywords on a hot storage like your personal computer or notebook.","title":"4. If you received any root password after creating your VPS, change it"},{"location":"validate/extras/validator-security/#5-once-logged-in-update-your-os","text":"For Debian based systems like Ubuntu or Debian use the command below: sudo apt-get update && sudo apt-get upgrade For Amazon Linux use the command below: sudo yum update","title":"5. Once logged in, update your OS"},{"location":"validate/extras/validator-security/#6-create-a-separate-user-than-root-for-your-application","text":"It is not recommended to use directly the root user on your VPS. Therefore create a new user: adduser <your-username> Add the newly created <your-username> user to the sudo group: adduser <your-username> sudo You can switch to the new user with the following command: sudo -u <your-username> -i","title":"6. Create a separate user than root for your application"},{"location":"validate/extras/validator-security/#7-create-the-necessary-setup-so-that-the-new-created-user-can-login-using-certificate","text":"sudo mkdir -p \"/home/<your-username>/.ssh\" sudo chmod 0700 \"/home/<your-username>/.ssh\" sudo chown \"<your-username>:<your-username>\" \"/home/<your-username>/.ssh\" Add the public key to your new created user sudo nano \"/home/<your-username>/.ssh/authorized_keys\" sudo ls \"/home/<your-username>/.ssh\" -l sudo chown \"<your-username>:<your-username>\" \"/home/<your-username>/.ssh/authorized_keys\" sudo chmod 0600 \"/home/<your-username>/.ssh/authorized_keys\"","title":"7. Create the necessary setup so that the new created user can login using certificate"},{"location":"validate/extras/validator-security/#8-setup-yubikey-2fa-on-debian-based-systems-like-ubuntu-and-strengthen-the-general-authentication","text":"First add the PPA and install the library. sudo add-apt-repository ppa:yubico/stable sudo apt-get update sudo apt-get install libpam-yubico Let\u2019s add pam settings for SSH. sudo nano /etc/pam.d/sshd Add the following line at the top to enable the module: auth sufficient pam_yubico.so id=[Your API Client ID] key=[Your API Client Key] authfile=/etc/yubikey_mappings You can use the following link in order to get the API Client ID and the API Client Key: https://upgrade.yubico.com/getapikey/ To improve the security you should comment the following line out: @include common-auth This way the YubiKey is required to authenticate without a possibility to fall back to providing the password. Result: Save the file and exit -> press Ctrl+X and then press \u201cy\u201d Next step is to create a mapping file where you define which YubiKey device is assigned to which user of your VPS. The mapping file contains users and YubiKey identifiers. The YubiKey identifiers are always the first 12 characters of the generated YubiKey token. In order to generate the YubiKey token you just tap your YubiKey. Then you select its first 12 characters. In case you have multiple YubiKeys you can also add multiple. sudo nano /etc/yubikey_mappings Add the mappings for each user: <user1:<first 12 characters of yubikey1>:<first 12 characters of yubikey2> <user2>:<first 12 characters of yubikey1> Save the file and exit -> press Ctrl+X and then press \u201cy\u201d Next step is to update sshd_config file to authenticate via public key and pam. sudo nano /etc/ssh/sshd_config Following changes need to be made: Enable challenge response authentication by changing it to \u201cyes\u201d **** ChallengeResponseAuthentication yes Add a new line that sets the Authentication Methods to require first the public key to be valid and then the YubiKey token for each user. AuthenticationMethods publickey,keyboard-interactive:pam UsePAM yes Disable the password authentication by removing \u201c#\u201d in front of this line: PasswordAuthentication and set the value from yes to no Disable root authentication - if you have created a separate user for your application, deployments, etc. you can also disable the SSH root user access, which will add an extra layer of security to your VPS. ****Find the line PermitRootLogin , remove the comment sign \u201c#\u201d from the beginning of it and set the value to no Change your SSH port from 22 to another one, for example 2225. **** Don\u2019t use any of the ports in this list: https://en.wikipedia.org/wiki/List_of_TCP_and_UDP_port_numbers , as they are already being used. **** Example sshd_config file - take it only as reference to see the security changes and don't copy it! # $OpenBSD: sshd_config,v 1.101 2017/03/14 07:19:07 djm Exp $ # This is the sshd server system-wide configuration file. See # sshd_config(5) for more information. # This sshd was compiled with PATH=/usr/bin:/bin:/usr/sbin:/sbin # The strategy used for options in the default sshd_config shipped with # OpenSSH is to specify options with their default value where # possible, but leave them commented. Uncommented options override the # default value. Port 2225 #AddressFamily any #ListenAddress 0.0.0.0 #ListenAddress :: #HostKey /etc/ssh/ssh_host_rsa_key #HostKey /etc/ssh/ssh_host_ecdsa_key #HostKey /etc/ssh/ssh_host_ed25519_key # Ciphers and keying #RekeyLimit default none # Logging #SyslogFacility AUTH #LogLevel INFO # Authentication: AuthenticationMethods publickey,keyboard-interactive:pam #LoginGraceTime 2m PermitRootLogin no #StrictModes yes #MaxAuthTries 6 #MaxSessions 10 #PubkeyAuthentication yes # Expect .ssh/authorized_keys2 to be disregarded by default in future. #AuthorizedKeysFile .ssh/authorized_keys .ssh/authorized_keys2 #AuthorizedPrincipalsFile none #AuthorizedKeysCommand none #AuthorizedKeysCommandUser nobody # For this to work you will also need host keys in /etc/ssh/ssh_known_hosts #HostbasedAuthentication no # Change to yes if you don't trust ~/.ssh/known_hosts for # HostbasedAuthentication #IgnoreUserKnownHosts no # Don't read the user's ~/.rhosts and ~/.shosts files #IgnoreRhosts yes # To disable tunneled clear text passwords, change to no here! PasswordAuthentication no #PermitEmptyPasswords no # Change to yes to enable challenge-response passwords (beware issues with # some PAM modules and threads) ChallengeResponseAuthentication yes # Kerberos options #KerberosAuthentication no #KerberosOrLocalPasswd yes #KerberosTicketCleanup yes #KerberosGetAFSToken no # GSSAPI options #GSSAPIAuthentication no #GSSAPICleanupCredentials yes #GSSAPIStrictAcceptorCheck yes #GSSAPIKeyExchange no # Set this to 'yes' to enable PAM authentication, account processing, # and session processing. If this is enabled, PAM authentication will # be allowed through the ChallengeResponseAuthentication and # PasswordAuthentication. Depending on your PAM configuration, # PAM authentication via ChallengeResponseAuthentication may bypass # the setting of \"PermitRootLogin without-password\". # If you just want the PAM account and session checks to run without # PAM authentication, then enable this but set PasswordAuthentication # and ChallengeResponseAuthentication to 'no'. UsePAM yes #AllowAgentForwarding yes #AllowTcpForwarding yes #GatewayPorts no X11Forwarding yes #X11DisplayOffset 10 #X11UseLocalhost yes #PermitTTY yes PrintMotd no #PrintLastLog yes #TCPKeepAlive yes #UseLogin no #PermitUserEnvironment no #Compression delayed #ClientAliveInterval 0 #ClientAliveCountMax 3 #UseDNS no #PidFile /var/run/sshd.pid #MaxStartups 10:30:100 #PermitTunnel no #ChrootDirectory none #VersionAddendum none # no default banner path #Banner none # Allow client to pass locale environment variables AcceptEnv LANG LC_* # override default of no subsystems Subsystem sftp /usr/lib/openssh/sftp-server # Example of overriding settings on a per-user basis #Match User anoncvs # X11Forwarding no # AllowTcpForwarding no # PermitTTY no # ForceCommand cvs server Save the file and exit -> press Ctrl+X and then press \u201cy\u201d Finally restart the sshd service to update the settings. service sshd restart Test the configuration It is recommended to keep the current session active. In case something went wrong, you will still have access to your VPS and be able to make changes. Create a new ssh connection and check if the SSH login with certificate and YubiKey works. First the certificate will be used and then you will be prompted for YubiKey. Once this is the case just tap your YubiKey to enter your token and login. Example: 9. Install fail2ban to reduce brute force attacks sudo apt-get install -y fail2ban Start and enable the service sudo systemctl start fail2ban sudo systemctl enable fail2ban It is recommended to use a separate jail.local file to actually read your own configuration. For that first you have to copy the basic configuration jail.conf to the local one jail.local. The new file jail.local will override the original settings in jail.conf. sudo cp /etc/fail2ban/jail.conf /etc/fail2ban/jail.local Edit the file jail.local sudo nano /etc/fail2ban/jail.local Enter your desired configuration, for example: [sshd] enabled = true port = 22 filter = sshd logpath = /var/log/auth.log maxretry = 5 This configuration will block an IP address that is being used to log into your VPS via SSH, port 22 and fails for 5 times. Save and close the file -> press Ctrl+X and then press \u201cy\u201d Restart fail2ban to activate the settings sudo systemctl restart fail2ban 10. Configure system firewall with IPtables More about it can be found here: https://www.tecmint.com/linux-iptables-firewall-rules-examples-commands/ 11. Monitor and manage your system and process by using htop ****Install htop sudo apt-get install htop Run htop htop","title":"8. Setup Yubikey 2FA on Debian based systems like Ubuntu and strengthen the general authentication"},{"location":"validate/extras/status/","text":"Network Status {% hint style=\"success\" %} See https://harmony.one/status for the current network status and endpoints. {% endhint %} Network Overview Harmony runs not only a production mainnet but also several other testnets. Network Audience Usage Mainnet All Harmony Production Mainnet Long Running Testnet Developers Smart Contract and DApp Development Open Staking Testnet Validators Open Staking Testing and StakeHeist Partner Testnet Partners Staking Partners building for Open Staking Outages Information about outages and postmortems on those outages can be found here .","title":"Network Status"},{"location":"validate/extras/status/#network-status","text":"{% hint style=\"success\" %} See https://harmony.one/status for the current network status and endpoints. {% endhint %}","title":"Network Status"},{"location":"validate/extras/status/#network-overview","text":"Harmony runs not only a production mainnet but also several other testnets. Network Audience Usage Mainnet All Harmony Production Mainnet Long Running Testnet Developers Smart Contract and DApp Development Open Staking Testnet Validators Open Staking Testing and StakeHeist Partner Testnet Partners Staking Partners building for Open Staking","title":"Network Overview"},{"location":"validate/extras/status/#outages","text":"Information about outages and postmortems on those outages can be found here .","title":"Outages"},{"location":"validate/extras/status/outages/","text":"Outages","title":"Outages"},{"location":"validate/extras/status/outages/#outages","text":"","title":"Outages"},{"location":"validate/extras/status/outages/post-mortem-ostn-rolling-upgrade-failure-mar-21-2020/","text":"Post-Mortem: OSTN Rolling Upgrade failure Mar 21, 2020 Summary \u200cOn March 21, 2020 a Open Staking Testnet (OSTN) rolling upgrade commenced around 11:40 a.m. During the upgrade consensus was lost on Shard 0 due to a pre-existing nil pointer issue which was triggered by a view change. This caused (or was compounded by) an inability of nodes to synch to the highest block (17080) due to the fact that 4 out of the 5 nodes which for DNS entry api.s0.os.hmny.io were at a lower height (17061). An attempt was made to bring all the DNS nodes to the same height, however the lower (17061) block height was chosen rather than the highest height 17080. This left shard 0 unable to recover and a hard refresh was required. RJ, quickly investigated and resolved the cause of the underlying view chain. Leo then applied this change as well as all other changes in master to the t3 branch and a rolling upgrade began at around 15:00 which completed at approximately 16:00 p.m. Customer Impact \u200cAll OSTN validators (primarily the p-ops team and harmony) were unable to use OSTN for approximately 3 hours. Also a rolling upgrade became a hard refresh which requires all validators to reset their nodes. At this point in the OSTN lifecycle hard refreshes are a common occurrence and so the validators are prepared for this. People Involved John (john@harmony.one) Daniel (daniel@harmony.one) Leo (leo@harmony.one) RJ (rongjian@harmony.one) Timeline \u200c This outage happened on 2020-03-22 times are in PDT. 11:09 - John confirmed build on team-devops and created pull request 2575 **** 11:40 - John merged commit, informed p-ops and staking and began rolling upgrade 12:31 - Daniel identified issues with Shard 0 seen on watchdog 12:31 - 14:20 Following remediation steps took place Daniel rolled back to last commit i.e. yesterday's version Daniel restarted all shards 1,2 and 3 synched - shard 0 did not Daniel noticed the leader and five others were on block 17080 everyone else on 17061, also one of the Nodes that supported api.os.hmny.io was at 17080 Daniel changed the IPS for the DNS entry removing the node with 17080 and replacing it with another 17061 node Daniel deleted 5 nodes dbs which were at 17080 allowing all to synch to 17061 ~ 1:00 pm (take 80 mins to synch) Leo cloned the db to the nodes (to speed up synching) RJ investigated the nil pointer issue and proposed Merge Signing Fixes to T3 Leo, Daniel - After Cloning the DB\u2019s consensus still could not be gained and blocks could not be produced on Shard 0 14:23 - Leo, RJ, Daniel, John made decision to do a hard refresh 14:23 - John notified p-ops that a hard refresh was needed 14:25 - Leo merged the latest code from Master into t3 see below 14:58 - John began deploying the hard refresh 15:08 - Protocol Upgrade Complete, Consensus Reached and Watchdog Updated 15:08 - 15:46 John, Daniel, Cem - Block Explorer Built, Faucet and Funding Launched, Validator build complete, Sentries Launched and Earning 15:46 - John - Announced Upgrade was complete 16:05 - John Confirmed all 4 Sentries were registered and Earning Root Cause Analysis The view change failed due to a nil pointer issue which was caused by logging on consensus which did not have the required context. See here for the fix. 2. Why did this cause a synching issue? Synching all goes of the DNS entry for the shard, in this case api.s0.os.hmny.io This DNS entry is supported by 5 nodes. In this case four of the nodes were at block height 17061 and one was at block height 17080. This meant that no nodes could sync to the latest block (17080). 3. Why were only five nodes at the latest block height (17080)? Note only 5 of the 20 nodes were at 17080 the other 15 were at 17061. All nodes were at 17080, with the last 19 blocks in memory the nil pointer issue caused crashes and those nodes reverted 17061 due to state pruning that lost the last 20 blocks in memory when the program crashed. Thus triggering the synch issues. 4. Why did the remediation steps fail to solve the problem? Reverting to a lower block height (17061) rather than the latest (17080) left us unable to reach consensus and move forward. Lower block has no required cross-link data to advance the consensus as other shards not impacted had assumed the cross-link to be working. 5. Why did we not immediately do a hard refresh when reverting? Release processes are evolving as our evaluation of our impact to our customers. It may be worthwhile moving straight to a hard refresh when reverting the code base, as we are currently still doing this with other releases. The other option is for more detailed reversion procedures to be developed including tooling for snapshotting all the db\u2019s before beginning each upgrade as well as tooling for reverting to this state. Questions to ask \u200c 1. How was the problem reported? How long did it take to respond to the issue? How could we cut that time in half? \u200c The problem was reported as part of the teams monitoring of the rollout, within 3 minutes of it occurring we were working on a resolution and within 30 minutes we had begun a rollback to the last stable version released. 2. How long did it take to mitigate the issue? How could we cut that time in half? \u200c It took us 3.5 hours to bring OSTN back up. Performing a hard refresh as part of reverting would have dramatically sped up the process. Also in the remediation stages two mistakes were made the first of which was choosing the lower block height db\u2019s as this would ultimately prevent the ability to gain consensus. The second of which was not backing up those db\u2019s in case of reversion. Finally a db-synch tool would have been useful. 3. Are there any pending items that can help prevent this issue? If so, why wasn't it prioritized? \u200c Testing of rolling upgrades in STN could have helped prevent the issue in OSTN. Also clearer understanding of remediation practices for the DNS synching issue would have helped. Also an overall review of voting power and consensus and DNS and synching could prevent this moving forward. 4. Can this issue be detected in a test environment? If not, why? \u200c The issue itself could have been highlighted on STN however it had not gone through an upgrade process and therefore had not triggered a view change. As OSTN is still a testnet for us, we had taken the risk of not imposing too many testing processes before we do a rolling upgrade on OSTN, moving forward we shall test in STN prior to an OSTN release. 5 Whys? a. Why did this cause a synching issue? Synching all goes of the DNS entry for the shard, in this case api.s0.os.hmny.io This DNS entry is supported by 5 nodes. In this case four of the nodes were at block height 17061 and one was at block height 17080. This meant that no nodes could sync to the latest block (17080). b. Why were only five nodes at the latest block height (17080)? Note only 5 of the 20 nodes were at 17080 the other 15 were at 17061. All nodes were at 17080, with the last 19 blocks in memory the nil pointer issue caused crashes and those nodes reverted 17061 due to state pruning that lost the last 20 blocks in memory when the program crashed. Thus triggering the synch issues. c. Why did the remediation steps fail to solve the problem? Reverting to a lower block height (17061) rather than the latest (17080) left us unable to reach consensus and move forward. Lower block has no required cross-link data to advance the consensus as other shards not impacted had assumed the cross-link to be working. d. Why did we not immediately do a hard refresh when reverting? Release processes are evolving as our evaluation of our impact to our customers. It may be worthwhile moving straight to a hard refresh when reverting the code base, as we are currently still doing this with other releases. The other option is for more detailed reversion procedures to be developed including tooling for snapshotting all the db\u2019s before beginning each upgrade as well as tooling for reverting to this state. \u200c Action Items Category Description Owner Tracker Corrective \u200bFix View Change Issue \u200brongjian@harmony.one \u200b Complete Preventive \u200bEnsure PTN goes through upgrade process before OSTN moving forward \u200bjohn@harmony.one \u200bIn Progress Preventive Document Reversion Practice, DB backup john@harmony.one In Progress Preventive Review voting power needed for consensus and it\u2019s impact to synching when nodes supporting DNS are of different values john@harmony.one Complete Preventive Monitoring - Trigger an alert when nodes become out of synch john@harmony.one Complete","title":"Post-Mortem: OSTN Rolling Upgrade failure Mar 21, 2020"},{"location":"validate/extras/status/outages/post-mortem-ostn-rolling-upgrade-failure-mar-21-2020/#post-mortem-ostn-rolling-upgrade-failure-mar-21-2020","text":"","title":"Post-Mortem: OSTN Rolling Upgrade failure Mar 21, 2020"},{"location":"validate/extras/status/outages/post-mortem-ostn-rolling-upgrade-failure-mar-21-2020/#summary","text":"\u200cOn March 21, 2020 a Open Staking Testnet (OSTN) rolling upgrade commenced around 11:40 a.m. During the upgrade consensus was lost on Shard 0 due to a pre-existing nil pointer issue which was triggered by a view change. This caused (or was compounded by) an inability of nodes to synch to the highest block (17080) due to the fact that 4 out of the 5 nodes which for DNS entry api.s0.os.hmny.io were at a lower height (17061). An attempt was made to bring all the DNS nodes to the same height, however the lower (17061) block height was chosen rather than the highest height 17080. This left shard 0 unable to recover and a hard refresh was required. RJ, quickly investigated and resolved the cause of the underlying view chain. Leo then applied this change as well as all other changes in master to the t3 branch and a rolling upgrade began at around 15:00 which completed at approximately 16:00 p.m.","title":"Summary "},{"location":"validate/extras/status/outages/post-mortem-ostn-rolling-upgrade-failure-mar-21-2020/#customer-impact","text":"\u200cAll OSTN validators (primarily the p-ops team and harmony) were unable to use OSTN for approximately 3 hours. Also a rolling upgrade became a hard refresh which requires all validators to reset their nodes. At this point in the OSTN lifecycle hard refreshes are a common occurrence and so the validators are prepared for this.","title":"Customer Impact "},{"location":"validate/extras/status/outages/post-mortem-ostn-rolling-upgrade-failure-mar-21-2020/#people-involved","text":"John (john@harmony.one) Daniel (daniel@harmony.one) Leo (leo@harmony.one) RJ (rongjian@harmony.one)","title":"People Involved "},{"location":"validate/extras/status/outages/post-mortem-ostn-rolling-upgrade-failure-mar-21-2020/#timeline","text":"\u200c This outage happened on 2020-03-22 times are in PDT. 11:09 - John confirmed build on team-devops and created pull request 2575 **** 11:40 - John merged commit, informed p-ops and staking and began rolling upgrade 12:31 - Daniel identified issues with Shard 0 seen on watchdog 12:31 - 14:20 Following remediation steps took place Daniel rolled back to last commit i.e. yesterday's version Daniel restarted all shards 1,2 and 3 synched - shard 0 did not Daniel noticed the leader and five others were on block 17080 everyone else on 17061, also one of the Nodes that supported api.os.hmny.io was at 17080 Daniel changed the IPS for the DNS entry removing the node with 17080 and replacing it with another 17061 node Daniel deleted 5 nodes dbs which were at 17080 allowing all to synch to 17061 ~ 1:00 pm (take 80 mins to synch) Leo cloned the db to the nodes (to speed up synching) RJ investigated the nil pointer issue and proposed Merge Signing Fixes to T3 Leo, Daniel - After Cloning the DB\u2019s consensus still could not be gained and blocks could not be produced on Shard 0 14:23 - Leo, RJ, Daniel, John made decision to do a hard refresh 14:23 - John notified p-ops that a hard refresh was needed 14:25 - Leo merged the latest code from Master into t3 see below 14:58 - John began deploying the hard refresh 15:08 - Protocol Upgrade Complete, Consensus Reached and Watchdog Updated 15:08 - 15:46 John, Daniel, Cem - Block Explorer Built, Faucet and Funding Launched, Validator build complete, Sentries Launched and Earning 15:46 - John - Announced Upgrade was complete 16:05 - John Confirmed all 4 Sentries were registered and Earning","title":"Timeline "},{"location":"validate/extras/status/outages/post-mortem-ostn-rolling-upgrade-failure-mar-21-2020/#root-cause-analysis","text":"The view change failed due to a nil pointer issue which was caused by logging on consensus which did not have the required context. See here for the fix. 2. Why did this cause a synching issue? Synching all goes of the DNS entry for the shard, in this case api.s0.os.hmny.io This DNS entry is supported by 5 nodes. In this case four of the nodes were at block height 17061 and one was at block height 17080. This meant that no nodes could sync to the latest block (17080). 3. Why were only five nodes at the latest block height (17080)? Note only 5 of the 20 nodes were at 17080 the other 15 were at 17061. All nodes were at 17080, with the last 19 blocks in memory the nil pointer issue caused crashes and those nodes reverted 17061 due to state pruning that lost the last 20 blocks in memory when the program crashed. Thus triggering the synch issues. 4. Why did the remediation steps fail to solve the problem? Reverting to a lower block height (17061) rather than the latest (17080) left us unable to reach consensus and move forward. Lower block has no required cross-link data to advance the consensus as other shards not impacted had assumed the cross-link to be working. 5. Why did we not immediately do a hard refresh when reverting? Release processes are evolving as our evaluation of our impact to our customers. It may be worthwhile moving straight to a hard refresh when reverting the code base, as we are currently still doing this with other releases. The other option is for more detailed reversion procedures to be developed including tooling for snapshotting all the db\u2019s before beginning each upgrade as well as tooling for reverting to this state.","title":"Root Cause Analysis "},{"location":"validate/extras/status/outages/post-mortem-ostn-rolling-upgrade-failure-mar-21-2020/#questions-to-ask","text":"\u200c 1. How was the problem reported? How long did it take to respond to the issue? How could we cut that time in half? \u200c The problem was reported as part of the teams monitoring of the rollout, within 3 minutes of it occurring we were working on a resolution and within 30 minutes we had begun a rollback to the last stable version released. 2. How long did it take to mitigate the issue? How could we cut that time in half? \u200c It took us 3.5 hours to bring OSTN back up. Performing a hard refresh as part of reverting would have dramatically sped up the process. Also in the remediation stages two mistakes were made the first of which was choosing the lower block height db\u2019s as this would ultimately prevent the ability to gain consensus. The second of which was not backing up those db\u2019s in case of reversion. Finally a db-synch tool would have been useful. 3. Are there any pending items that can help prevent this issue? If so, why wasn't it prioritized? \u200c Testing of rolling upgrades in STN could have helped prevent the issue in OSTN. Also clearer understanding of remediation practices for the DNS synching issue would have helped. Also an overall review of voting power and consensus and DNS and synching could prevent this moving forward. 4. Can this issue be detected in a test environment? If not, why? \u200c The issue itself could have been highlighted on STN however it had not gone through an upgrade process and therefore had not triggered a view change. As OSTN is still a testnet for us, we had taken the risk of not imposing too many testing processes before we do a rolling upgrade on OSTN, moving forward we shall test in STN prior to an OSTN release.","title":"Questions to ask "},{"location":"validate/extras/status/outages/post-mortem-ostn-rolling-upgrade-failure-mar-21-2020/#5-whys","text":"a. Why did this cause a synching issue? Synching all goes of the DNS entry for the shard, in this case api.s0.os.hmny.io This DNS entry is supported by 5 nodes. In this case four of the nodes were at block height 17061 and one was at block height 17080. This meant that no nodes could sync to the latest block (17080). b. Why were only five nodes at the latest block height (17080)? Note only 5 of the 20 nodes were at 17080 the other 15 were at 17061. All nodes were at 17080, with the last 19 blocks in memory the nil pointer issue caused crashes and those nodes reverted 17061 due to state pruning that lost the last 20 blocks in memory when the program crashed. Thus triggering the synch issues. c. Why did the remediation steps fail to solve the problem? Reverting to a lower block height (17061) rather than the latest (17080) left us unable to reach consensus and move forward. Lower block has no required cross-link data to advance the consensus as other shards not impacted had assumed the cross-link to be working. d. Why did we not immediately do a hard refresh when reverting? Release processes are evolving as our evaluation of our impact to our customers. It may be worthwhile moving straight to a hard refresh when reverting the code base, as we are currently still doing this with other releases. The other option is for more detailed reversion procedures to be developed including tooling for snapshotting all the db\u2019s before beginning each upgrade as well as tooling for reverting to this state. \u200c","title":"5 Whys? "},{"location":"validate/extras/status/outages/post-mortem-ostn-rolling-upgrade-failure-mar-21-2020/#action-items","text":"Category Description Owner Tracker Corrective \u200bFix View Change Issue \u200brongjian@harmony.one \u200b Complete Preventive \u200bEnsure PTN goes through upgrade process before OSTN moving forward \u200bjohn@harmony.one \u200bIn Progress Preventive Document Reversion Practice, DB backup john@harmony.one In Progress Preventive Review voting power needed for consensus and it\u2019s impact to synching when nodes supporting DNS are of different values john@harmony.one Complete Preventive Monitoring - Trigger an alert when nodes become out of synch john@harmony.one Complete","title":"Action Items "},{"location":"validate/first-time-setup/","text":"First Time Setup","title":"First Time Setup"},{"location":"validate/first-time-setup/#first-time-setup","text":"","title":"First Time Setup"},{"location":"validate/first-time-setup/aws/","text":"AWS To launch your AWS instance, we will go through 2 steps. Step 1: Launching your AWS Node Registering AWS and choosing the correct instance. Step 2: Connecting to your AWS Node Connecting to your AWS instance. Step 1: Launching your AWS Node 1. If you don\u2019t already have an AWS account, register one at https://aws.amazon.com . 2. Once you have set up and logged into your AWS account, click on the top left bar \u201cServices -> Compute -> EC2\". 3. Click on the blue button \u201cLaunch Instance\". 4. Select \u201cAmazon Linux 2 AMI (HVM), SSD Volume Type\u201d. 5. Choose instance type \u201ct3.small\u201d. 6. Click \u201cNext: Configure Instance Details\u201d at the bottom right corner of the page. 7. Don't change anything. Click \u201cNext: Add Storage\u201d at the bottom right corner of the page. 8. Change the \u201cSize (GiB)\u201d category to 30. 9. Click \u201cNext: Add Tags\". 10. Click \"Add Tag.\" Then, in the \u201cKey\u201d input box put \u201cName\u201d in \u201cValue\u201d put \u201cPangaea-key\u201d. 11. Click \u201cNext: Configure Security Group\u201d. 12. On the default SSH with port 22, change the \u201cSource\u201d option to \u201cAnywhere\u201d. 13. Click \"Add Rule\". Under \"Type\" select \"Custom TCP Rule\", under \"Port Range\" put \"6000\" and under \"Source\" select \"Anywhere\". 14. Click \"Add Rule\" again. This time, under \"Type\" select \"Custom TCP Rule\", under \"Port Range\" put \"9000\" and under \"Source\" select \"Anywhere\". 15. Click \u201cReview and Launch\u201d and then click \"Launch\". (Note: Ignore warnings such as \u201cyour security group is open to the world\u201d or \u201cyour instance configuration is not eligible for free tier\u201d) 17. In the pop-up window you will need to create a new key pair. Select \u201cCreate a new key pair\u201d and then enter a name that you like, for example \u201cPangaea-key\u201d. 18. Click \u201cDownload Key Pair\u201d and save the key file somewhere you'll remember. 19. Click \u201cLaunch Instances\u201d. 20. Click \u201cView Instances\u201d at the bottom right. Your new instance should be initializing. Wait a few moments for it to get started. 21. Congratulations your instance is up and running! Now it's time to connect to your instance. Step 2: Connecting to your AWS Instance {% embed url=\"https://www.youtube.com/watch?v=SyeZF_3iZME\" %} 1. Open a Terminal window on your computer. For Mac: If you can\u2019t find Terminal, use spotlight to search for it. Or go to your \"Applications' folder, and it should be inside of \u201cUtilities\u201d. For Windows: Download PuTTY to allow your computer to SSH into the AWS instance. For instructions on connecting to an EC2 instance using Putty follow these instructions from Amazon. Skip to Step 6. 2. Once Terminal is open, use the cd command to change your directory to where the key pair file (Pangaea-key.pem) that you generated is. Hint it may be in your \u201cDownloads\u201d folder. 3. Enter the command chmod 400 Pangaea-key.pem . This command makes your key not publicly viewable. Note: On Mac, your pem file may have been changed to a .txt file so the correct command on Mac would be: chmod 400 Pangaea-key.pem.txt 4. Go back to your AWS window where you are viewing your instances. Select your new \"Pangaea-key\" instance and click \u201cConnect\u201d on the top bar. 5. In the pop-up window, under the \u201cExample:\u201d header, copy the sample command to connect to your ec2 instance. The command will look something like: ssh -i \"pangaea-key.pem\" ec2-user@ec2-13-250-30-215.ap-southeast-1.compute.amazonaws.com Now connect to your instance by running the sample command you copied from the \u201cConnect\u201d page in your terminal window. It may ask you whether or not you want to continue connecting. Type in \u201cyes\u201d and hit enter. Congratulations! You should be logged into your new AWS instance! 6. Run the following command to make sure your instance is properly updated: sudo yum update When prompted whether or not you want to download packages, enter \"y\" for yes. 7. Now install the following packages that will be needed to run Harmony by typing: sudo yum install tmux You will be asked to confirm if you would like to download and install these packages. Just press Y to confirm.","title":"AWS"},{"location":"validate/first-time-setup/aws/#aws","text":"To launch your AWS instance, we will go through 2 steps. Step 1: Launching your AWS Node Registering AWS and choosing the correct instance. Step 2: Connecting to your AWS Node Connecting to your AWS instance.","title":"AWS"},{"location":"validate/first-time-setup/aws/#step-1-launching-your-aws-node","text":"1. If you don\u2019t already have an AWS account, register one at https://aws.amazon.com . 2. Once you have set up and logged into your AWS account, click on the top left bar \u201cServices -> Compute -> EC2\". 3. Click on the blue button \u201cLaunch Instance\". 4. Select \u201cAmazon Linux 2 AMI (HVM), SSD Volume Type\u201d. 5. Choose instance type \u201ct3.small\u201d. 6. Click \u201cNext: Configure Instance Details\u201d at the bottom right corner of the page. 7. Don't change anything. Click \u201cNext: Add Storage\u201d at the bottom right corner of the page. 8. Change the \u201cSize (GiB)\u201d category to 30. 9. Click \u201cNext: Add Tags\". 10. Click \"Add Tag.\" Then, in the \u201cKey\u201d input box put \u201cName\u201d in \u201cValue\u201d put \u201cPangaea-key\u201d. 11. Click \u201cNext: Configure Security Group\u201d. 12. On the default SSH with port 22, change the \u201cSource\u201d option to \u201cAnywhere\u201d. 13. Click \"Add Rule\". Under \"Type\" select \"Custom TCP Rule\", under \"Port Range\" put \"6000\" and under \"Source\" select \"Anywhere\". 14. Click \"Add Rule\" again. This time, under \"Type\" select \"Custom TCP Rule\", under \"Port Range\" put \"9000\" and under \"Source\" select \"Anywhere\". 15. Click \u201cReview and Launch\u201d and then click \"Launch\". (Note: Ignore warnings such as \u201cyour security group is open to the world\u201d or \u201cyour instance configuration is not eligible for free tier\u201d) 17. In the pop-up window you will need to create a new key pair. Select \u201cCreate a new key pair\u201d and then enter a name that you like, for example \u201cPangaea-key\u201d. 18. Click \u201cDownload Key Pair\u201d and save the key file somewhere you'll remember. 19. Click \u201cLaunch Instances\u201d. 20. Click \u201cView Instances\u201d at the bottom right. Your new instance should be initializing. Wait a few moments for it to get started. 21. Congratulations your instance is up and running! Now it's time to connect to your instance.","title":"Step 1: Launching your AWS Node"},{"location":"validate/first-time-setup/aws/#step-2-connecting-to-your-aws-instance","text":"{% embed url=\"https://www.youtube.com/watch?v=SyeZF_3iZME\" %} 1. Open a Terminal window on your computer. For Mac: If you can\u2019t find Terminal, use spotlight to search for it. Or go to your \"Applications' folder, and it should be inside of \u201cUtilities\u201d. For Windows: Download PuTTY to allow your computer to SSH into the AWS instance. For instructions on connecting to an EC2 instance using Putty follow these instructions from Amazon. Skip to Step 6. 2. Once Terminal is open, use the cd command to change your directory to where the key pair file (Pangaea-key.pem) that you generated is. Hint it may be in your \u201cDownloads\u201d folder. 3. Enter the command chmod 400 Pangaea-key.pem . This command makes your key not publicly viewable. Note: On Mac, your pem file may have been changed to a .txt file so the correct command on Mac would be: chmod 400 Pangaea-key.pem.txt 4. Go back to your AWS window where you are viewing your instances. Select your new \"Pangaea-key\" instance and click \u201cConnect\u201d on the top bar. 5. In the pop-up window, under the \u201cExample:\u201d header, copy the sample command to connect to your ec2 instance. The command will look something like: ssh -i \"pangaea-key.pem\" ec2-user@ec2-13-250-30-215.ap-southeast-1.compute.amazonaws.com Now connect to your instance by running the sample command you copied from the \u201cConnect\u201d page in your terminal window. It may ask you whether or not you want to continue connecting. Type in \u201cyes\u201d and hit enter. Congratulations! You should be logged into your new AWS instance! 6. Run the following command to make sure your instance is properly updated: sudo yum update When prompted whether or not you want to download packages, enter \"y\" for yes. 7. Now install the following packages that will be needed to run Harmony by typing: sudo yum install tmux You will be asked to confirm if you would like to download and install these packages. Just press Y to confirm.","title":"Step 2: Connecting to your AWS Instance"},{"location":"validate/first-time-setup/cloud-guides/","text":"Cloud Guides We have written a guide for setting up a Harmony node for Amazon Web Services (AWS) , Vultr , Google Cloud Platform (GCP) to make things as simple as possible! If you are curious to know which cloud provider is right for you, read the Choosing a cloud provider section in the Extras section. If you choose to use a cloud provider different from those listed above, you are best off to follow the Vultr guide step by step but be aware that some steps will be different.","title":"Cloud Guides"},{"location":"validate/first-time-setup/cloud-guides/#cloud-guides","text":"We have written a guide for setting up a Harmony node for Amazon Web Services (AWS) , Vultr , Google Cloud Platform (GCP) to make things as simple as possible! If you are curious to know which cloud provider is right for you, read the Choosing a cloud provider section in the Extras section. If you choose to use a cloud provider different from those listed above, you are best off to follow the Vultr guide step by step but be aware that some steps will be different.","title":"Cloud Guides"},{"location":"validate/first-time-setup/creating-a-validator/","text":"Creating A Validator {% hint style=\"info\" %} Wait for your node to sync before creating a validator. Check your current block height with ./hmy blockchain latest-headers Check chain block height with ./hmy blockchain latest-header --node=[endpoint] {% endhint %} Creating a Validator Replace everything in [ ] with your own data: ./hmy --node=\"https://api.s0.t.hmny.io\" staking create-validator \\ --validator-addr [ONE ADDRESS] --amount 10000 \\ --bls-pubkeys [BLS PUBLIC KEY1],[BLS PUBLIC KEY2] \\ --name \"[NAME]\" --identity \"[IDENTITY]\" --details \"DETAILS\" \\ --security-contact \"CONTACT\" --website \"YOUR-WEBSITE.COM\" \\ --max-change-rate 0.1 --max-rate 0.1 --rate 0.1 \\ --max-total-delegation 100000000 --min-self-delegation 10000 --passphrase {% hint style=\"warning\" %} Copy the entire command. Extra white spaces in the command could cause errors. Name, identity, details, security-contact and website need to be put in double quotes if there are more than one word separated by space (example --name \"John the validator\"). {% endhint %} The CLI will prompt you to enter your BLS key file password. --validator-addr is the validator ONE address (string) --amount is the initial amount of ONE you want to stake (float) --bls-pubkeys takes a comma-separated list of BLS public keys (string) --name will be the name displayed on the Staking Explorer (string) --identity is additional information for the validator (string) --details is the description of the validator (string) --security-contact is security contact for the validator (string) --website will be the website displayed on the Staking Explorer (string) --max-change-rate is the maximum rate change the validator can do to their commission rate every epoch (float) --max-rate is the maximum commission rate that the validator can set (float) --rate is the commission rate of the validator (float) --max-total-delegation is the maximum amount of ONE that can be delegated to this validator (float) --min-self-delegation is the minimum amount of ONE the validator must stake to itself (float) {% hint style=\"danger\" %} --max-rate and --max-change-rate cannot be changed later. --min-self-delegation has to be at least 10,000 ONE. {% endhint %} When does the validator participate in election? A new validator will be eligible for the election for next epoch. You can see the time until the next epoch on the Staking Dashboard . Once your validator is elected, the validator will receive rewards and you will be able to see \"BINGO\" in the logs. tail -n 1000 latest/zerolog-validator-*.log | grep -i BINGO Example output: {\"level\":\"info\",\"port\":\"9000\",\"ip\":\"213.136.79.89\",\"blockNum\":3916,\"epochNum\":26,\"ViewId\":3916,\"blockHash\":\"0xca71fc9aa92f694f664aa34d7e3e82cf9b678e3a062d3bbbabebfbc5f0598d84\",\"numTxns\":0,\"numStakingTxns\":0,\"caller\":\"/mnt/jenkins/workspace/harmony-release/harmony/node/node_handler.go:359\",\"time\":\"2019-12-11T14:49:08.983338784+01:00\",\"message\":\"BINGO !!! Reached Consensus\"} {% hint style=\"warning\" %} If you don't want to participate in the election anymore, you can turn your validator inactive using an Edit Validator transaction with --active false. {% endhint %} Checking Validator Information Use the format command ./hmy --node=\"https://api.s0.t.hmny.io\" blockchain validator information [ONE ADDRESS] to check your validator information: ./hmy --node=\"https://api.s0.t.hmny.io\" blockchain validator information one1u6c4wer2dkm767hmjeehnwu6tqqur62gx9vqsd Example output: { \"id\": \"0\", \"jsonrpc\": \"2.0\", \"result\": { \"booted-status\": null, \"current-epoch-performance\": { \"current-epoch-signing-percent\": { \"current-epoch-signed\": 95, \"current-epoch-signing-percentage\": \"1.000000000000000000\", \"current-epoch-to-sign\": 95, \"num-beacon-blocks-until-next-epoch\": 21 } }, \"currently-in-committee\": true, \"epos-status\": \"currently elected\", \"epos-winning-stake\": \"6846745750000000000000000.000000000000000000\", \"lifetime\": { \"apr\": \"6.268807306506151937\", \"blocks\": { \"signed\": 8602, \"to-sign\": 8621 }, \"reward-accumulated\": 7.076705797578808e+21 }, \"metrics\": { \"by-bls-key\": [ { \"earned-reward\": 17373723528937510000, \"key\": { \"bls-public-key\": \"1227f1ef2ba879562c693c2f99af023a9a127b25bfe21fa41c637039bfbd9cc68919d0edce4f2aa57983ffcbc39b1b01\", \"earning-account\": \"one1u6c4wer2dkm767hmjeehnwu6tqqur62gx9vqsd\", \"effective-stake\": \"1369349150000000000000000.000000000000000000\", \"group-percent\": \"0.032657375054393815\", \"overall-percent\": \"0.010450360017406021\", \"shard-id\": 1 } } ] }, \"total-delegation\": 4.184679e+24, \"validator\": { \"address\": \"one1u6c4wer2dkm767hmjeehnwu6tqqur62gx9vqsd\", \"bls-public-keys\": [ \"1227f1ef2ba879562c693c2f99af023a9a127b25bfe21fa41c637039bfbd9cc68919d0edce4f2aa57983ffcbc39b1b01\" ], \"creation-height\": 489, \"delegations\": [ { \"amount\": 1.184679e+24, \"delegator-address\": \"one1u6c4wer2dkm767hmjeehnwu6tqqur62gx9vqsd\", \"reward\": 4.383229639373062e+21, \"undelegations\": [] }, { \"amount\": 3e+24, \"delegator-address\": \"one167gc5t3f4uvupns2h8fsem9xzdgn2egra9w8d3\", \"reward\": 2.1040394698378544e+21, \"undelegations\": [] } ], \"details\": \"Soph #P-OPS Validator node\", \"identity\": \"Soph\", \"last-epoch-in-committee\": 58, \"max-change-rate\": \"0.050000000000000000\", \"max-rate\": \"0.900000000000000000\", \"max-total-delegation\": 1e+27, \"min-self-delegation\": 1e+22, \"name\": \"Soph #P-OPS Validator node\", \"rate\": \"0.100000000000000000\", \"security-contact\": \"Soph\", \"update-height\": 489, \"website\": \"soph.harmony.one\" } } } {% hint style=\"warning\" %} If your validator does not sign more than 2/3 of the blocks in an epoch, the validator will be removed from the pool of eligible validators. In order to be included in the pool again, you will have to use send an Edit Validator transaction with --active true . {% endhint %}","title":"Creating A Validator"},{"location":"validate/first-time-setup/creating-a-validator/#creating-a-validator","text":"{% hint style=\"info\" %} Wait for your node to sync before creating a validator. Check your current block height with ./hmy blockchain latest-headers Check chain block height with ./hmy blockchain latest-header --node=[endpoint] {% endhint %}","title":"Creating A Validator"},{"location":"validate/first-time-setup/creating-a-validator/#creating-a-validator_1","text":"Replace everything in [ ] with your own data: ./hmy --node=\"https://api.s0.t.hmny.io\" staking create-validator \\ --validator-addr [ONE ADDRESS] --amount 10000 \\ --bls-pubkeys [BLS PUBLIC KEY1],[BLS PUBLIC KEY2] \\ --name \"[NAME]\" --identity \"[IDENTITY]\" --details \"DETAILS\" \\ --security-contact \"CONTACT\" --website \"YOUR-WEBSITE.COM\" \\ --max-change-rate 0.1 --max-rate 0.1 --rate 0.1 \\ --max-total-delegation 100000000 --min-self-delegation 10000 --passphrase {% hint style=\"warning\" %} Copy the entire command. Extra white spaces in the command could cause errors. Name, identity, details, security-contact and website need to be put in double quotes if there are more than one word separated by space (example --name \"John the validator\"). {% endhint %} The CLI will prompt you to enter your BLS key file password. --validator-addr is the validator ONE address (string) --amount is the initial amount of ONE you want to stake (float) --bls-pubkeys takes a comma-separated list of BLS public keys (string) --name will be the name displayed on the Staking Explorer (string) --identity is additional information for the validator (string) --details is the description of the validator (string) --security-contact is security contact for the validator (string) --website will be the website displayed on the Staking Explorer (string) --max-change-rate is the maximum rate change the validator can do to their commission rate every epoch (float) --max-rate is the maximum commission rate that the validator can set (float) --rate is the commission rate of the validator (float) --max-total-delegation is the maximum amount of ONE that can be delegated to this validator (float) --min-self-delegation is the minimum amount of ONE the validator must stake to itself (float) {% hint style=\"danger\" %} --max-rate and --max-change-rate cannot be changed later. --min-self-delegation has to be at least 10,000 ONE. {% endhint %}","title":"Creating a Validator "},{"location":"validate/first-time-setup/creating-a-validator/#when-does-the-validator-participate-in-election","text":"A new validator will be eligible for the election for next epoch. You can see the time until the next epoch on the Staking Dashboard . Once your validator is elected, the validator will receive rewards and you will be able to see \"BINGO\" in the logs. tail -n 1000 latest/zerolog-validator-*.log | grep -i BINGO Example output: {\"level\":\"info\",\"port\":\"9000\",\"ip\":\"213.136.79.89\",\"blockNum\":3916,\"epochNum\":26,\"ViewId\":3916,\"blockHash\":\"0xca71fc9aa92f694f664aa34d7e3e82cf9b678e3a062d3bbbabebfbc5f0598d84\",\"numTxns\":0,\"numStakingTxns\":0,\"caller\":\"/mnt/jenkins/workspace/harmony-release/harmony/node/node_handler.go:359\",\"time\":\"2019-12-11T14:49:08.983338784+01:00\",\"message\":\"BINGO !!! Reached Consensus\"} {% hint style=\"warning\" %} If you don't want to participate in the election anymore, you can turn your validator inactive using an Edit Validator transaction with --active false. {% endhint %}","title":"When does the validator participate in election? "},{"location":"validate/first-time-setup/creating-a-validator/#checking-validator-information","text":"Use the format command ./hmy --node=\"https://api.s0.t.hmny.io\" blockchain validator information [ONE ADDRESS] to check your validator information: ./hmy --node=\"https://api.s0.t.hmny.io\" blockchain validator information one1u6c4wer2dkm767hmjeehnwu6tqqur62gx9vqsd Example output: { \"id\": \"0\", \"jsonrpc\": \"2.0\", \"result\": { \"booted-status\": null, \"current-epoch-performance\": { \"current-epoch-signing-percent\": { \"current-epoch-signed\": 95, \"current-epoch-signing-percentage\": \"1.000000000000000000\", \"current-epoch-to-sign\": 95, \"num-beacon-blocks-until-next-epoch\": 21 } }, \"currently-in-committee\": true, \"epos-status\": \"currently elected\", \"epos-winning-stake\": \"6846745750000000000000000.000000000000000000\", \"lifetime\": { \"apr\": \"6.268807306506151937\", \"blocks\": { \"signed\": 8602, \"to-sign\": 8621 }, \"reward-accumulated\": 7.076705797578808e+21 }, \"metrics\": { \"by-bls-key\": [ { \"earned-reward\": 17373723528937510000, \"key\": { \"bls-public-key\": \"1227f1ef2ba879562c693c2f99af023a9a127b25bfe21fa41c637039bfbd9cc68919d0edce4f2aa57983ffcbc39b1b01\", \"earning-account\": \"one1u6c4wer2dkm767hmjeehnwu6tqqur62gx9vqsd\", \"effective-stake\": \"1369349150000000000000000.000000000000000000\", \"group-percent\": \"0.032657375054393815\", \"overall-percent\": \"0.010450360017406021\", \"shard-id\": 1 } } ] }, \"total-delegation\": 4.184679e+24, \"validator\": { \"address\": \"one1u6c4wer2dkm767hmjeehnwu6tqqur62gx9vqsd\", \"bls-public-keys\": [ \"1227f1ef2ba879562c693c2f99af023a9a127b25bfe21fa41c637039bfbd9cc68919d0edce4f2aa57983ffcbc39b1b01\" ], \"creation-height\": 489, \"delegations\": [ { \"amount\": 1.184679e+24, \"delegator-address\": \"one1u6c4wer2dkm767hmjeehnwu6tqqur62gx9vqsd\", \"reward\": 4.383229639373062e+21, \"undelegations\": [] }, { \"amount\": 3e+24, \"delegator-address\": \"one167gc5t3f4uvupns2h8fsem9xzdgn2egra9w8d3\", \"reward\": 2.1040394698378544e+21, \"undelegations\": [] } ], \"details\": \"Soph #P-OPS Validator node\", \"identity\": \"Soph\", \"last-epoch-in-committee\": 58, \"max-change-rate\": \"0.050000000000000000\", \"max-rate\": \"0.900000000000000000\", \"max-total-delegation\": 1e+27, \"min-self-delegation\": 1e+22, \"name\": \"Soph #P-OPS Validator node\", \"rate\": \"0.100000000000000000\", \"security-contact\": \"Soph\", \"update-height\": 489, \"website\": \"soph.harmony.one\" } } } {% hint style=\"warning\" %} If your validator does not sign more than 2/3 of the blocks in an epoch, the validator will be removed from the pool of eligible validators. In order to be included in the pool again, you will have to use send an Edit Validator transaction with --active true . {% endhint %}","title":"Checking Validator Information "},{"location":"validate/first-time-setup/creating-a-wallet/","text":"Creating A Wallet New Wallet (CLI) You need to provide a local account name of your choice and provide a passphrase. _**_When creating an account, the CLI will ask you to provide a passphrase to encrypt the keystore file : ./hmy keys add [LOCAL ACCOUNT NAME] --passphrase example : ./hmy keys add mylocalaccountname --passphrase {% hint style=\"danger\" %} Remember your passphrase. You will need it to decrypt the account keystore in order to send transactions & perform other actions. Also save your seed phrase (mnemonic) somewhere as well, in case you lose your keystore. {% endhint %} Backing Up Your Keystore File (Optional) ./hmy keys location The command above will return the location of your account keystore. You may want to create a backup of this file.\u200c You can check the list of wallets (local accounts) with the following command: ./hmy keys list Example output from above command: #NAME ADDRESS example-account1 one1wh4p0kuc7unxez2z8f82zfnhsg4ty6dupqyjt2 Helpful Information Checking your account balance If you are running a node and your node is synced to the latest block, use the following command to check your balance : ./hmy balances [ONE ADDRESS] ex: ./hmy balances one1u6c4wer2dkm767hmjeehnwu6tqqur62gx9vqsd --node=\"<endpoint-address>\" If you are not running a node or your node is not synced, use the following command to check your balance : ./hmy --node=\"[API_endpoint]\" balances [ONE ADDRESS] ex: ./hmy --node=\"https://api.s0.t.hmny.io\" balances one1u6c4wer2dkm767hmjeehnwu6tqqur62gx9vqsd","title":"Creating A Wallet"},{"location":"validate/first-time-setup/creating-a-wallet/#creating-a-wallet","text":"","title":"Creating A Wallet"},{"location":"validate/first-time-setup/creating-a-wallet/#new-wallet-cli","text":"You need to provide a local account name of your choice and provide a passphrase. _**_When creating an account, the CLI will ask you to provide a passphrase to encrypt the keystore file : ./hmy keys add [LOCAL ACCOUNT NAME] --passphrase example : ./hmy keys add mylocalaccountname --passphrase {% hint style=\"danger\" %} Remember your passphrase. You will need it to decrypt the account keystore in order to send transactions & perform other actions. Also save your seed phrase (mnemonic) somewhere as well, in case you lose your keystore. {% endhint %}","title":"New Wallet (CLI) "},{"location":"validate/first-time-setup/creating-a-wallet/#backing-up-your-keystore-file-optional","text":"./hmy keys location The command above will return the location of your account keystore. You may want to create a backup of this file.\u200c You can check the list of wallets (local accounts) with the following command: ./hmy keys list Example output from above command: #NAME ADDRESS example-account1 one1wh4p0kuc7unxez2z8f82zfnhsg4ty6dupqyjt2","title":"Backing Up Your Keystore File (Optional)"},{"location":"validate/first-time-setup/creating-a-wallet/#helpful-information","text":"","title":"Helpful Information"},{"location":"validate/first-time-setup/creating-a-wallet/#checking-your-account-balance","text":"If you are running a node and your node is synced to the latest block, use the following command to check your balance : ./hmy balances [ONE ADDRESS] ex: ./hmy balances one1u6c4wer2dkm767hmjeehnwu6tqqur62gx9vqsd --node=\"<endpoint-address>\" If you are not running a node or your node is not synced, use the following command to check your balance : ./hmy --node=\"[API_endpoint]\" balances [ONE ADDRESS] ex: ./hmy --node=\"https://api.s0.t.hmny.io\" balances one1u6c4wer2dkm767hmjeehnwu6tqqur62gx9vqsd","title":"Checking your account balance"},{"location":"validate/first-time-setup/generating-a-bls-key/","text":"Generating A BLS Key Creating a new BLS key You will need to generate a BLS key in order to run a validating node. When generating a BLS key, the CLI will ask you to provide a passphrase to encrypt the BLS key file.\u200c ./hmy keys generate-bls-key --passphrase {% hint style=\"danger\" %} Remember your passphrase. You will need it to decrypt the BLS key file in order to create a validator & start a node with that key. Create a backup of your BLS key file or save the BLS private key (optional). {% endhint %} {% hint style=\"info\" %} The BLS public key is the same as the name of the file, without the .key . {% endhint %} Checking which Shard the BLS will validate on You can check which shard your key will validate for using the following command. ./hmy --node=\"https://api.s0.t.hmny.io\" utility shard-for-bls [BLS PUBLIC KEY] Example output: {\"shard-id\":1}","title":"Generating A BLS Key"},{"location":"validate/first-time-setup/generating-a-bls-key/#generating-a-bls-key","text":"","title":"Generating A BLS Key"},{"location":"validate/first-time-setup/generating-a-bls-key/#creating-a-new-bls-key","text":"You will need to generate a BLS key in order to run a validating node. When generating a BLS key, the CLI will ask you to provide a passphrase to encrypt the BLS key file.\u200c ./hmy keys generate-bls-key --passphrase {% hint style=\"danger\" %} Remember your passphrase. You will need it to decrypt the BLS key file in order to create a validator & start a node with that key. Create a backup of your BLS key file or save the BLS private key (optional). {% endhint %} {% hint style=\"info\" %} The BLS public key is the same as the name of the file, without the .key . {% endhint %}","title":"Creating a new BLS key"},{"location":"validate/first-time-setup/generating-a-bls-key/#checking-which-shard-the-bls-will-validate-on","text":"You can check which shard your key will validate for using the following command. ./hmy --node=\"https://api.s0.t.hmny.io\" utility shard-for-bls [BLS PUBLIC KEY] Example output: {\"shard-id\":1}","title":"Checking which Shard the BLS will validate on"},{"location":"validate/first-time-setup/google-cloud/","text":"Google Cloud To launch your Google Cloud instance, we will go through 2 steps. Step 1: Launching your Google Cloud Instance Registering Google Cloud and choosing the correct instance. Step 2: Connecting to your Google Cloud Instance Connecting to your Google Cloud instance Step 1: Launching your Google Cloud Instance Go to https://cloud.google.com and click on \u201cGet Started for Free\u201d if you don\u2019t have an account yet or on \u201cSign in\u201d if you already have a Google Account. If you haven\u2019t used Google Cloud yet, you will get a $300 USD dollars credit for 1 year! After you login and validate your credit card, you will be shown a page pretty much like this one. Click on \u201cCompute Engine\u201d and then in \u201cVM Instances\u201d. Click on the Create button to make a new instance We recommend to name it something like \"pangaea\u201d (the instance name cannot be changed). Select the Machine type as \u201cCustom\u201d and set up 2 vCPU\u2019s and 4GB of Memory. For Pangaea, keep everything default after you have configured the cores and memory. Pangaea with 10GB is perfectly fine for now. Click Create. Please wait a few minutes for your instance Once the instance is created. We will open 4 ingoing ports. To do this click on \"nic0\" as shown below. In the next page click on \u201cFirewall rules\u201d and after that on \u201cCREATE FIREWALL RULE\u201d. TCP 6000 TCP 9000 Now go back to the VM instances page and click on SSH. This will open a new window and connect via SSH to your instance. Step 2: Connecting to your Google Cloud Instance and copying keys {% embed url=\"https://youtu.be/mhy8M5OVezQ\" %} **** You will be thrown to the ssh session with your default user. We will have to first make a password for yourself to change to root user. To do so, enter in sudo passwd Once you have done that, to enter into root mode enter in su This command will then ask you for your password from the step above. When entered correctly it will show you as root user. Before anything is recommended to update your system apt update && apt upgrade Now install the following packages that will be needed to run Harmony by typing: apt-get install dnsutils apt-get install tmux You will be asked to confirm if you would like to download and install these packages. Just press Y to confirm.","title":"Google Cloud"},{"location":"validate/first-time-setup/google-cloud/#google-cloud","text":"To launch your Google Cloud instance, we will go through 2 steps. Step 1: Launching your Google Cloud Instance Registering Google Cloud and choosing the correct instance. Step 2: Connecting to your Google Cloud Instance Connecting to your Google Cloud instance","title":"Google Cloud"},{"location":"validate/first-time-setup/google-cloud/#step-1-launching-your-google-cloud-instance","text":"Go to https://cloud.google.com and click on \u201cGet Started for Free\u201d if you don\u2019t have an account yet or on \u201cSign in\u201d if you already have a Google Account. If you haven\u2019t used Google Cloud yet, you will get a $300 USD dollars credit for 1 year! After you login and validate your credit card, you will be shown a page pretty much like this one. Click on \u201cCompute Engine\u201d and then in \u201cVM Instances\u201d. Click on the Create button to make a new instance We recommend to name it something like \"pangaea\u201d (the instance name cannot be changed). Select the Machine type as \u201cCustom\u201d and set up 2 vCPU\u2019s and 4GB of Memory. For Pangaea, keep everything default after you have configured the cores and memory. Pangaea with 10GB is perfectly fine for now. Click Create. Please wait a few minutes for your instance Once the instance is created. We will open 4 ingoing ports. To do this click on \"nic0\" as shown below. In the next page click on \u201cFirewall rules\u201d and after that on \u201cCREATE FIREWALL RULE\u201d. TCP 6000 TCP 9000 Now go back to the VM instances page and click on SSH. This will open a new window and connect via SSH to your instance.","title":"Step 1: Launching your Google Cloud Instance "},{"location":"validate/first-time-setup/google-cloud/#step-2-connecting-to-your-google-cloud-instance-and-copying-keys","text":"{% embed url=\"https://youtu.be/mhy8M5OVezQ\" %} **** You will be thrown to the ssh session with your default user. We will have to first make a password for yourself to change to root user. To do so, enter in sudo passwd Once you have done that, to enter into root mode enter in su This command will then ask you for your password from the step above. When entered correctly it will show you as root user. Before anything is recommended to update your system apt update && apt upgrade Now install the following packages that will be needed to run Harmony by typing: apt-get install dnsutils apt-get install tmux You will be asked to confirm if you would like to download and install these packages. Just press Y to confirm.","title":"Step 2: Connecting to your Google Cloud Instance and copying keys"},{"location":"validate/first-time-setup/hmy-cli-download-1/","text":"HMY CLI Download To interact with your node, we have developed the HMY CLI. With it, you will be able to do everything in your terminal Download the HMY CLI Linux curl -LO https://harmony.one/hmycli && mv hmycli hmy && chmod +x hmy MacOS curl -O https://raw.githubusercontent.com/harmony-one/go-sdk/master/scripts/hmy.sh chmod u+x hmy.sh ./hmy.sh -d {% hint style=\"danger\" %} For the MacOS version, use ./hmy.sh instead of ./hmy for all commands. {% endhint %} Check the downloaded binary: Run ./hmy cookbook to see some commonly used commands. ./hmy --node=\"https://api.s0.t.hmny.io\" cookbook Example output: #Cookbook of Usage #Note: #1) Every subcommand recognizes a '--help' flag #2) If a passphrase is used by a subcommand, one can enter their own passphrase interactively # with the --passphrase option. Alternatively, one can pass their own passphrase via a file # using the --passphrase-file option. If no passphrase option is selected, the default # passphrase of '' is used. #3) These examples use Shard 0 of Open Staking Network as argument for --node #Examples: #1. Check account balance on given chain ./hmy --node=\"https://api.s0.t.hmny.io\" balances <SOME_ONE_ADDRESS> #2. Check sent transaction ./hmy --node=\"https://api.s0.t.hmny.io\" blockchain transaction-by-hash <SOME_TX_HASH> #3. List local account keys ./hmy keys list #4. Sending a transaction (waits 40 seconds for transaction confirmation) ./hmy --node=\"https://api.s0.t.hmny.io\" transfer \\ --from <SOME_ONE_ADDRESS> --to <SOME_ONE_ADDRESS> \\ --from-shard 0 --to-shard 1 --amount 200 --passphrase #5. Sending a batch of transactions as dictated from a file (the `--dry-run` options still apply) ./hmy --node=\"https://api.s0.t.hmny.io\" transfer --file <PATH_TO_JSON_FILE> #Check README for details on json file format. #6. Check a completed transaction receipt ./hmy --node=\"https://api.s0.t.hmny.io\" blockchain transaction-receipt <SOME_TX_HASH> #7. Import an account using the mnemonic. Prompts the user to give the mnemonic. ./hmy keys recover-from-mnemonic <ACCOUNT_NAME> #8. Import an existing keystore file ./hmy keys import-ks <PATH_TO_KEYSTORE_JSON> #9. Import a keystore file using a secp256k1 private key ./hmy keys import-private-key <secp256k1_PRIVATE_KEY> #10. Export a keystore file's secp256k1 private key ./hmy keys export-private-key <ACCOUNT_ADDRESS> --passphrase #11. Generate a BLS key then encrypt and save the private key to the specified location. ./hmy keys generate-bls-key --bls-file-path <PATH_FOR_BLS_KEY_FILE> #12. Create a new validator with a list of BLS keys ./hmy --node=\"https://api.s0.t.hmny.io\" staking create-validator --amount 10 --validator-addr <SOME_ONE_ADDRESS> \\ --bls-pubkeys <BLS_KEY_1>,<BLS_KEY_2>,<BLS_KEY_3> \\ --identity foo --details bar --name baz --max-change-rate 0.1 --max-rate 0.1 --max-total-delegation 10 \\ --min-self-delegation 10 --rate 0.1 --security-contact Leo --website harmony.one --passphrase #13. Edit an existing validator ./hmy --node=\"https://api.s0.t.hmny.io\" staking edit-validator \\ --validator-addr <SOME_ONE_ADDRESS> --identity foo --details bar \\ --name baz --security-contact EK --website harmony.one \\ --min-self-delegation 0 --max-total-delegation 10 --rate 0.1\\ --add-bls-key <SOME_BLS_KEY> --remove-bls-key <OTHER_BLS_KEY> --passphrase #14. Delegate an amount to a validator ./hmy --node=\"https://api.s0.t.hmny.io\" staking delegate \\ --delegator-addr <SOME_ONE_ADDRESS> --validator-addr <VALIDATOR_ONE_ADDRESS> \\ --amount 10 --passphrase #15. Undelegate to a validator ./hmy --node=\"https://api.s0.t.hmny.io\" staking undelegate \\ --delegator-addr <SOME_ONE_ADDRESS> --validator-addr <VALIDATOR_ONE_ADDRESS> \\ --amount 10 --passphrase #16. Collect block rewards as a delegator ./hmy --node=\"https://api.s0.t.hmny.io\" staking collect-rewards \\ --delegator-addr <SOME_ONE_ADDRESS> --passphrase #17. Check elected validators ./hmy --node=\"https://api.s0.t.hmny.io\" blockchain validator elected #18. Get current staking utility metrics ./hmy --node=\"https://api.s0.t.hmny.io\" blockchain utility-metrics #19. Check in-memory record of failed staking transactions ./hmy --node=\"https://api.s0.t.hmny.io\" failures staking #20. Check which shard your BLS public key would be assigned to as a validator ./hmy --node=\"https://api.s0.t.hmny.io\" utility shard-for-bls 2d61379e44a772e5757e27ee2b3874254f56073e6bd226eb8b160371cc3c18b8c4977bd3dcb71fd57dc62bf0e143fd08 Troubleshooting Frequently encountered errors: ./hmy cookbook -bash: ./hmy: cannot execute binary file: Exec format error \u200b#Make sure you downloaded the right version for your OS.","title":"HMY CLI Download"},{"location":"validate/first-time-setup/hmy-cli-download-1/#hmy-cli-download","text":"To interact with your node, we have developed the HMY CLI. With it, you will be able to do everything in your terminal","title":"HMY CLI Download"},{"location":"validate/first-time-setup/hmy-cli-download-1/#download-the-hmy-cli","text":"","title":"Download the HMY CLI"},{"location":"validate/first-time-setup/hmy-cli-download-1/#linux","text":"curl -LO https://harmony.one/hmycli && mv hmycli hmy && chmod +x hmy","title":"Linux"},{"location":"validate/first-time-setup/hmy-cli-download-1/#macos","text":"curl -O https://raw.githubusercontent.com/harmony-one/go-sdk/master/scripts/hmy.sh chmod u+x hmy.sh ./hmy.sh -d {% hint style=\"danger\" %} For the MacOS version, use ./hmy.sh instead of ./hmy for all commands. {% endhint %}","title":"MacOS"},{"location":"validate/first-time-setup/hmy-cli-download-1/#check-the-downloaded-binary","text":"Run ./hmy cookbook to see some commonly used commands. ./hmy --node=\"https://api.s0.t.hmny.io\" cookbook Example output: #Cookbook of Usage #Note: #1) Every subcommand recognizes a '--help' flag #2) If a passphrase is used by a subcommand, one can enter their own passphrase interactively # with the --passphrase option. Alternatively, one can pass their own passphrase via a file # using the --passphrase-file option. If no passphrase option is selected, the default # passphrase of '' is used. #3) These examples use Shard 0 of Open Staking Network as argument for --node #Examples: #1. Check account balance on given chain ./hmy --node=\"https://api.s0.t.hmny.io\" balances <SOME_ONE_ADDRESS> #2. Check sent transaction ./hmy --node=\"https://api.s0.t.hmny.io\" blockchain transaction-by-hash <SOME_TX_HASH> #3. List local account keys ./hmy keys list #4. Sending a transaction (waits 40 seconds for transaction confirmation) ./hmy --node=\"https://api.s0.t.hmny.io\" transfer \\ --from <SOME_ONE_ADDRESS> --to <SOME_ONE_ADDRESS> \\ --from-shard 0 --to-shard 1 --amount 200 --passphrase #5. Sending a batch of transactions as dictated from a file (the `--dry-run` options still apply) ./hmy --node=\"https://api.s0.t.hmny.io\" transfer --file <PATH_TO_JSON_FILE> #Check README for details on json file format. #6. Check a completed transaction receipt ./hmy --node=\"https://api.s0.t.hmny.io\" blockchain transaction-receipt <SOME_TX_HASH> #7. Import an account using the mnemonic. Prompts the user to give the mnemonic. ./hmy keys recover-from-mnemonic <ACCOUNT_NAME> #8. Import an existing keystore file ./hmy keys import-ks <PATH_TO_KEYSTORE_JSON> #9. Import a keystore file using a secp256k1 private key ./hmy keys import-private-key <secp256k1_PRIVATE_KEY> #10. Export a keystore file's secp256k1 private key ./hmy keys export-private-key <ACCOUNT_ADDRESS> --passphrase #11. Generate a BLS key then encrypt and save the private key to the specified location. ./hmy keys generate-bls-key --bls-file-path <PATH_FOR_BLS_KEY_FILE> #12. Create a new validator with a list of BLS keys ./hmy --node=\"https://api.s0.t.hmny.io\" staking create-validator --amount 10 --validator-addr <SOME_ONE_ADDRESS> \\ --bls-pubkeys <BLS_KEY_1>,<BLS_KEY_2>,<BLS_KEY_3> \\ --identity foo --details bar --name baz --max-change-rate 0.1 --max-rate 0.1 --max-total-delegation 10 \\ --min-self-delegation 10 --rate 0.1 --security-contact Leo --website harmony.one --passphrase #13. Edit an existing validator ./hmy --node=\"https://api.s0.t.hmny.io\" staking edit-validator \\ --validator-addr <SOME_ONE_ADDRESS> --identity foo --details bar \\ --name baz --security-contact EK --website harmony.one \\ --min-self-delegation 0 --max-total-delegation 10 --rate 0.1\\ --add-bls-key <SOME_BLS_KEY> --remove-bls-key <OTHER_BLS_KEY> --passphrase #14. Delegate an amount to a validator ./hmy --node=\"https://api.s0.t.hmny.io\" staking delegate \\ --delegator-addr <SOME_ONE_ADDRESS> --validator-addr <VALIDATOR_ONE_ADDRESS> \\ --amount 10 --passphrase #15. Undelegate to a validator ./hmy --node=\"https://api.s0.t.hmny.io\" staking undelegate \\ --delegator-addr <SOME_ONE_ADDRESS> --validator-addr <VALIDATOR_ONE_ADDRESS> \\ --amount 10 --passphrase #16. Collect block rewards as a delegator ./hmy --node=\"https://api.s0.t.hmny.io\" staking collect-rewards \\ --delegator-addr <SOME_ONE_ADDRESS> --passphrase #17. Check elected validators ./hmy --node=\"https://api.s0.t.hmny.io\" blockchain validator elected #18. Get current staking utility metrics ./hmy --node=\"https://api.s0.t.hmny.io\" blockchain utility-metrics #19. Check in-memory record of failed staking transactions ./hmy --node=\"https://api.s0.t.hmny.io\" failures staking #20. Check which shard your BLS public key would be assigned to as a validator ./hmy --node=\"https://api.s0.t.hmny.io\" utility shard-for-bls 2d61379e44a772e5757e27ee2b3874254f56073e6bd226eb8b160371cc3c18b8c4977bd3dcb71fd57dc62bf0e143fd08","title":"Check the downloaded binary:"},{"location":"validate/first-time-setup/hmy-cli-download-1/#troubleshooting","text":"Frequently encountered errors: ./hmy cookbook -bash: ./hmy: cannot execute binary file: Exec format error \u200b#Make sure you downloaded the right version for your OS.","title":"Troubleshooting "},{"location":"validate/first-time-setup/running-a-node/","text":"Running a Node Download node.sh 1. Run the following command to download the node.sh script: curl -LO https://harmony.one/node.sh && chmod a+x node.sh TMUX Install tmux if your Linux distribution does not already come with it. {% tabs %} {% tab title=\"Ubuntu LTS\" %} sudo apt-get install tmux {% endtab %} {% tab title=\"Amazon Linux\" %} sudo yum install -y tmux {% endtab %} {% endtabs %} Run Node 1. Create a new tmux session called \"node\". tmux new-session -s node {% hint style=\"info\" %} You'll want to use a tmux session in order to leave your node running, while you are not connected to your instance. {% endhint %} {% hint style=\"danger\" %} For any Debian based OS like Ubuntu and others, please install the package below in case you are NOT running statically linked binaries via parameter -I : sudo apt-get install libgmp-dev {% endhint %} 2. Run the node.sh script with the following command. Once you do, it will ask for a passphrase for your BLS key file. Type your passphrase on the screen that follows and your node should be up and running. {% tabs %} {% tab title=\"Mainnet\" %} ./node.sh -S -z -k [BLS KEY FILE].key {% endtab %} {% endtabs %} {% hint style=\"info\" %} Use -S to run node.sh as non root user. (Recommended) Use -c to automatically clear old data for a refreshed network. Use -z to run with staking enabled. (Mandatory to setup validator nodes for open staking) Use -I to run with the statically linked binary (enabled by default already, may ignore). Use -N [NETWORK] to specify which network to connect to (default: mainnet). Use -k [BLS KEY FILE] to specify which BLS key to run the node with. Use -M to run with multiBLS (all keys should be in .hmy/blskeys) For the complete list of parameters use ./node.sh --help {% endhint %} {% hint style=\"danger\" %} Only use -c for our testing networks. Do not use for Mainnet. {% endhint %} 3. Detach your \"node\" tmux session by press [ Ctrl]+b , releasing and and then press d . Detaching from your session will allow you to safely disconnect from your instance, while leaving your node running in the cloud. 4. To check if your node is syncing properly, run the below command and check that the block height is greater than 0. ./hmy blockchain latest-headers {% hint style=\"success\" %} Harmony relies on a beacon shard chain (aka shard 0) to facilitate cross shard transaction. For the node to be fully working both your non shard 0 and shard 0 needs to be fully synced {% endhint %} 5. Confirm that you are fully synced before continuing. Issue the command in the format ./hmy --node= \"[SHARD_RPC_ENDPOINT]\" blockchain latest-headers , where SHARD_RCP_ENDPOINT would be having that format : api.s[Shard #].[NETWORK].hmny.io ex : ./hmy --node=\"https://api.s0.t.hmny.io\" blockchain latest-headers 6. And verity the blocks shown in step 4 and 5 are closed or equals to each other. Multiple BLS Keys (Optional and recommended for advanced users) Optionally, you can run the node using multiple BLS keys if you want. 1. Keys are loaded from .hmy/blskeys folder which has to be created first: mkdir -p .hmy/blskeys 2. Copy all the previously created BLS key(s) to this new folder: cp *.key .hmy/blskeys {% hint style=\"warning\" %} Make sure all your BLS keys belong to the same shard when using multiple BLS keys. You can use the command below to check each one of them. {% endhint %} ./hmy --node=\"https://api.s0.t.hmny.io\" utility shard-for-bls [BLS PUBLIC KEY] 3. For each BLS key file, a corresponding <blskey>.pass file needs to be created inside folder .hmy/blskeys with the passphrase inside it. {% hint style=\"warning\" %} For any .key if no passphrase file is available, it will use the default specified when running the node e.g., ./node.sh -p blspass.txt {% endhint %} 4. You can now run the node using parameter -M for multiple BLS keys. Parameter -k will not be used anymore as we are loading multiple BLS keys here: ./node.sh -S -z -M Helpful Information To re-attach to your tmux session where your node.sh is running, use the following command: tmux attach-session -t node TMUX Cheatsheet","title":"Running a Node"},{"location":"validate/first-time-setup/running-a-node/#running-a-node","text":"","title":"Running a Node"},{"location":"validate/first-time-setup/running-a-node/#download-nodesh","text":"1. Run the following command to download the node.sh script: curl -LO https://harmony.one/node.sh && chmod a+x node.sh","title":"Download node.sh"},{"location":"validate/first-time-setup/running-a-node/#tmux","text":"Install tmux if your Linux distribution does not already come with it. {% tabs %} {% tab title=\"Ubuntu LTS\" %} sudo apt-get install tmux {% endtab %} {% tab title=\"Amazon Linux\" %} sudo yum install -y tmux {% endtab %} {% endtabs %}","title":"TMUX"},{"location":"validate/first-time-setup/running-a-node/#run-node","text":"1. Create a new tmux session called \"node\". tmux new-session -s node {% hint style=\"info\" %} You'll want to use a tmux session in order to leave your node running, while you are not connected to your instance. {% endhint %} {% hint style=\"danger\" %} For any Debian based OS like Ubuntu and others, please install the package below in case you are NOT running statically linked binaries via parameter -I : sudo apt-get install libgmp-dev {% endhint %} 2. Run the node.sh script with the following command. Once you do, it will ask for a passphrase for your BLS key file. Type your passphrase on the screen that follows and your node should be up and running. {% tabs %} {% tab title=\"Mainnet\" %} ./node.sh -S -z -k [BLS KEY FILE].key {% endtab %} {% endtabs %} {% hint style=\"info\" %} Use -S to run node.sh as non root user. (Recommended) Use -c to automatically clear old data for a refreshed network. Use -z to run with staking enabled. (Mandatory to setup validator nodes for open staking) Use -I to run with the statically linked binary (enabled by default already, may ignore). Use -N [NETWORK] to specify which network to connect to (default: mainnet). Use -k [BLS KEY FILE] to specify which BLS key to run the node with. Use -M to run with multiBLS (all keys should be in .hmy/blskeys) For the complete list of parameters use ./node.sh --help {% endhint %} {% hint style=\"danger\" %} Only use -c for our testing networks. Do not use for Mainnet. {% endhint %} 3. Detach your \"node\" tmux session by press [ Ctrl]+b , releasing and and then press d . Detaching from your session will allow you to safely disconnect from your instance, while leaving your node running in the cloud. 4. To check if your node is syncing properly, run the below command and check that the block height is greater than 0. ./hmy blockchain latest-headers {% hint style=\"success\" %} Harmony relies on a beacon shard chain (aka shard 0) to facilitate cross shard transaction. For the node to be fully working both your non shard 0 and shard 0 needs to be fully synced {% endhint %} 5. Confirm that you are fully synced before continuing. Issue the command in the format ./hmy --node= \"[SHARD_RPC_ENDPOINT]\" blockchain latest-headers , where SHARD_RCP_ENDPOINT would be having that format : api.s[Shard #].[NETWORK].hmny.io ex : ./hmy --node=\"https://api.s0.t.hmny.io\" blockchain latest-headers 6. And verity the blocks shown in step 4 and 5 are closed or equals to each other.","title":"Run Node"},{"location":"validate/first-time-setup/running-a-node/#multiple-bls-keys-optional-and-recommended-for-advanced-users","text":"Optionally, you can run the node using multiple BLS keys if you want. 1. Keys are loaded from .hmy/blskeys folder which has to be created first: mkdir -p .hmy/blskeys 2. Copy all the previously created BLS key(s) to this new folder: cp *.key .hmy/blskeys {% hint style=\"warning\" %} Make sure all your BLS keys belong to the same shard when using multiple BLS keys. You can use the command below to check each one of them. {% endhint %} ./hmy --node=\"https://api.s0.t.hmny.io\" utility shard-for-bls [BLS PUBLIC KEY] 3. For each BLS key file, a corresponding <blskey>.pass file needs to be created inside folder .hmy/blskeys with the passphrase inside it. {% hint style=\"warning\" %} For any .key if no passphrase file is available, it will use the default specified when running the node e.g., ./node.sh -p blspass.txt {% endhint %} 4. You can now run the node using parameter -M for multiple BLS keys. Parameter -k will not be used anymore as we are loading multiple BLS keys here: ./node.sh -S -z -M","title":"Multiple BLS Keys (Optional and recommended for advanced users)"},{"location":"validate/first-time-setup/running-a-node/#helpful-information","text":"To re-attach to your tmux session where your node.sh is running, use the following command: tmux attach-session -t node TMUX Cheatsheet","title":"Helpful Information"},{"location":"validate/first-time-setup/using-rclone/","text":"Syncing with Rclone {% hint style=\"warning\" %} This document introduces another centralized fast state syncing method using rclone. Please use it with caution. This guide is mainly used for a newly started node to catch up with the blockchain faster. Otherwise, the blockchain syncing may take weeks from genesis block. {% endhint %} Rclone db snapshot is sync'ed with blockchain frequently. However, there maybe a potential race condition when the rclone may fail due to our nodes were updating the db files at the same time. In this case, just re-run the rclone command to re-sync again. 1. Installing Rclone For installing Rclone, please follow the instructions at https://rclone.org . TL;DR, on a Linux system, you may run the following command. curl https://rclone.org/install.sh | sudo bash 2. Configuring Rclone To check the location of the rclone.conf file run: rclone config file The rclone.conf file is usually located at ~/.config/rclone/rclone.conf . Now run the following command to create the rclone.conf file. cat<<-EOF > ~/.config/rclone/rclone.conf [mainnet] type = s3 provider = AWS env_auth = false region = us-west-1 acl = public-read server_side_encryption = AES256 storage_class = REDUCED_REDUNDANCY EOF 3. Running Rclone Below is the command to sync the shard you want. Replace <ShardID> with the shard number you want to sync. Each of the rclone snapshot is around 1.7 Gb as of 05/14/2020. Shard 0 is around 1.8 Gb as of 5/14/2020. It may take up to 10 minutes for the full sync depending on your network condition. You won't see anything on your Terminal screen after running Rclone but you'll know it's complete if you get the next line of prompt. After the sync, you may use du -h harmony_db_* command to check the size of the downloaded snapshots. rclone sync mainnet:pub.harmony.one/mainnet.min/harmony_db_<ShardID> harmony_db_<ShardID> {% hint style=\"info\" %} Nodes in shard 0 just need to sync harmony_db_0 Nodes in shard 1, 2, 3 need to sync both harmony_db_0 , and harmony_db_<ShardID> {% endhint %} 4. Cheat Sheet shard0: rclone sync mainnet:pub.harmony.one/mainnet.min/harmony_db_0 harmony_db_0 shard1: rclone sync mainnet:pub.harmony.one/mainnet.min/harmony_db_0 harmony_db_0 rclone sync mainnet:pub.harmony.one/mainnet.min/harmony_db_1 harmony_db_1 shard2: rclone sync mainnet:pub.harmony.one/mainnet.min/harmony_db_0 harmony_db_0 rclone sync mainnet:pub.harmony.one/mainnet.min/harmony_db_2 harmony_db_2 shard3: rclone sync mainnet:pub.harmony.one/mainnet.min/harmony_db_0 harmony_db_0 rclone sync mainnet:pub.harmony.one/mainnet.min/harmony_db_3 harmony_db_3 After the sync, you may use du -h harmony_db_* command to check the size of the downloaded snapshots.","title":"Syncing with Rclone"},{"location":"validate/first-time-setup/using-rclone/#syncing-with-rclone","text":"{% hint style=\"warning\" %} This document introduces another centralized fast state syncing method using rclone. Please use it with caution. This guide is mainly used for a newly started node to catch up with the blockchain faster. Otherwise, the blockchain syncing may take weeks from genesis block. {% endhint %} Rclone db snapshot is sync'ed with blockchain frequently. However, there maybe a potential race condition when the rclone may fail due to our nodes were updating the db files at the same time. In this case, just re-run the rclone command to re-sync again.","title":"Syncing with Rclone"},{"location":"validate/first-time-setup/using-rclone/#1-installing-rclone","text":"For installing Rclone, please follow the instructions at https://rclone.org . TL;DR, on a Linux system, you may run the following command. curl https://rclone.org/install.sh | sudo bash","title":"1. Installing Rclone"},{"location":"validate/first-time-setup/using-rclone/#2-configuring-rclone","text":"To check the location of the rclone.conf file run: rclone config file The rclone.conf file is usually located at ~/.config/rclone/rclone.conf . Now run the following command to create the rclone.conf file. cat<<-EOF > ~/.config/rclone/rclone.conf [mainnet] type = s3 provider = AWS env_auth = false region = us-west-1 acl = public-read server_side_encryption = AES256 storage_class = REDUCED_REDUNDANCY EOF","title":"2. Configuring Rclone"},{"location":"validate/first-time-setup/using-rclone/#3-running-rclone","text":"Below is the command to sync the shard you want. Replace <ShardID> with the shard number you want to sync. Each of the rclone snapshot is around 1.7 Gb as of 05/14/2020. Shard 0 is around 1.8 Gb as of 5/14/2020. It may take up to 10 minutes for the full sync depending on your network condition. You won't see anything on your Terminal screen after running Rclone but you'll know it's complete if you get the next line of prompt. After the sync, you may use du -h harmony_db_* command to check the size of the downloaded snapshots. rclone sync mainnet:pub.harmony.one/mainnet.min/harmony_db_<ShardID> harmony_db_<ShardID> {% hint style=\"info\" %} Nodes in shard 0 just need to sync harmony_db_0 Nodes in shard 1, 2, 3 need to sync both harmony_db_0 , and harmony_db_<ShardID> {% endhint %}","title":"3. Running Rclone"},{"location":"validate/first-time-setup/using-rclone/#4-cheat-sheet","text":"","title":"4. Cheat Sheet"},{"location":"validate/first-time-setup/using-rclone/#shard0","text":"rclone sync mainnet:pub.harmony.one/mainnet.min/harmony_db_0 harmony_db_0","title":"shard0:"},{"location":"validate/first-time-setup/using-rclone/#shard1","text":"rclone sync mainnet:pub.harmony.one/mainnet.min/harmony_db_0 harmony_db_0 rclone sync mainnet:pub.harmony.one/mainnet.min/harmony_db_1 harmony_db_1","title":"shard1:"},{"location":"validate/first-time-setup/using-rclone/#shard2","text":"rclone sync mainnet:pub.harmony.one/mainnet.min/harmony_db_0 harmony_db_0 rclone sync mainnet:pub.harmony.one/mainnet.min/harmony_db_2 harmony_db_2","title":"shard2:"},{"location":"validate/first-time-setup/using-rclone/#shard3","text":"rclone sync mainnet:pub.harmony.one/mainnet.min/harmony_db_0 harmony_db_0 rclone sync mainnet:pub.harmony.one/mainnet.min/harmony_db_3 harmony_db_3 After the sync, you may use du -h harmony_db_* command to check the size of the downloaded snapshots.","title":"shard3:"},{"location":"validate/first-time-setup/validator-cheat-sheet/","text":"Setup Cheatsheet If you are new to setting up Validators, start here . Access your cloud instance. ssh -i [KEY].pem [SSH ADDRESS] Install tmux , if your Linux distribution does not come with it. sudo yum install tmux Download the Harmony CLI. curl -LO https://harmony.one/hmycli && mv hmycli hmy && chmod +x hmy Create a BLS Key. ./hmy keys generate-bls-key --passphrase Download node.sh . curl -LO https://raw.githubusercontent.com/harmony-one/harmony/master/scripts/node.sh \\ && chmod a+x node.sh Start a new tmux session called node . tmux new-session -s node Run the node. ./node.sh -S -z -k [BLS KEY FILE].key Detach from the tmux session by pressing CTRL and B at the same time, then press D. Check that your node is syncing (block height > 0). ./hmy blockchain latest-header Create a new wallet. ./hmy keys add [ACCOUNT NAME] --passphrase Fund your ONE address. Create your Validator. ./hmy --node=\"https://api.s0.t.hmny.io\" staking create-validator \\ --validator-addr [ONE ADDRESS] --amount 10000 \\ --bls-pubkeys [BLS PUBLIC KEY1],[BLS PUBLIC KEY2] \\ --name JohnWhitton --identity JohnIdentity --details \"John The Validator\" \\ --security-contact John --website john@harmony.one \\ --max-change-rate 0.1 --max-rate 0.1 --rate 0.1 \\ --max-total-delegation 100000000 --min-self-delegation 10000 --passphrase Check that your ONE address exists as a validator. ./hmy --node=\"https://api.s0.t.hmny.io\" blockchain validator all | grep [ONE ADDRESS] Collect rewards. ./hmy --node=\"https://api.s0.t.hmny.io\" staking collect-rewards --delegator-addr [ONE ADDRESS] --passphrase Check validator information for active flag / availability (block signed) / etc ... ./hmy --node=\"https://api.s0.t.hmny.io\" blockchain validator information [VALIDATOR ONE ADDRESS]","title":"Setup Cheatsheet"},{"location":"validate/first-time-setup/validator-cheat-sheet/#setup-cheatsheet","text":"If you are new to setting up Validators, start here . Access your cloud instance. ssh -i [KEY].pem [SSH ADDRESS] Install tmux , if your Linux distribution does not come with it. sudo yum install tmux Download the Harmony CLI. curl -LO https://harmony.one/hmycli && mv hmycli hmy && chmod +x hmy Create a BLS Key. ./hmy keys generate-bls-key --passphrase Download node.sh . curl -LO https://raw.githubusercontent.com/harmony-one/harmony/master/scripts/node.sh \\ && chmod a+x node.sh Start a new tmux session called node . tmux new-session -s node Run the node. ./node.sh -S -z -k [BLS KEY FILE].key Detach from the tmux session by pressing CTRL and B at the same time, then press D. Check that your node is syncing (block height > 0). ./hmy blockchain latest-header Create a new wallet. ./hmy keys add [ACCOUNT NAME] --passphrase Fund your ONE address. Create your Validator. ./hmy --node=\"https://api.s0.t.hmny.io\" staking create-validator \\ --validator-addr [ONE ADDRESS] --amount 10000 \\ --bls-pubkeys [BLS PUBLIC KEY1],[BLS PUBLIC KEY2] \\ --name JohnWhitton --identity JohnIdentity --details \"John The Validator\" \\ --security-contact John --website john@harmony.one \\ --max-change-rate 0.1 --max-rate 0.1 --rate 0.1 \\ --max-total-delegation 100000000 --min-self-delegation 10000 --passphrase Check that your ONE address exists as a validator. ./hmy --node=\"https://api.s0.t.hmny.io\" blockchain validator all | grep [ONE ADDRESS] Collect rewards. ./hmy --node=\"https://api.s0.t.hmny.io\" staking collect-rewards --delegator-addr [ONE ADDRESS] --passphrase Check validator information for active flag / availability (block signed) / etc ... ./hmy --node=\"https://api.s0.t.hmny.io\" blockchain validator information [VALIDATOR ONE ADDRESS]","title":"Setup Cheatsheet"},{"location":"validate/first-time-setup/vultr/","text":"Vultr To launch your Vultr instance, we will go through 2 steps. Step 1: Launching Your Vultr Node Registering Vultr and choosing the correct instance. Step 2: Connecting to your Vultr Node Connecting to your Vultr instance. Step 1: Launching Your Vultr Instance Logging into Vultr \u200b Vultr Main Page If you don\u2019t already have an Vultr account, register one by clicking on \"Sign up\". Otherwise, log into your Vultr Account by clicking on \"Sign in\". Create a new instance Once logged in, you'll want to add a new instance. Depending on whether your account is new or not, you may or may not have a Products page. If you already have an instance, click the \"+\" button to deploy a new server. You can also use this link to go to the deploy page. Otherwise, your Products page will be already link you to the Deploy page. Choose Instance Type For Pangaea requirements, two instance types would fit: Cloud Compute and High Frequency. Cloud Compute is recommended for Pangaea. Cloud Compute instances also work properly with 2 CPUs, 4 GB RAM with 80 GB SSDs. High Frequency Instances were recently introduced by Vultr and offer latest generation high performance 3GHz+ CPUs and NVMe SSDs. Select Server Location and Server Type You can choose your preferred location as well as server type. Ubuntu 16.04 x64 or Debian 10 x64 have been tested to work very well. Choose Server Size Harmony recommends one of the two following: Cloud Compute 2 CPU, 4 GB RAM, 80 GB SSD High Frequency 2 CPU, 4 GB RAM, 128 GB NVMe SSD For \"Additional Features\", none of the selections are necessary. Setting Server Name You can now set the name of your server, e.g. PangaeaNode Then you should click \"Deploy Now\". At this point you should be back on the Products page and your server should be installing. However, the setup isn't completely done, as you need to still create a firewall. Create Firewall Group As we want to allow other nodes to connect to yours, we have to open the correct ports. Once you are on the Firewall page , click Add Firewall Group. Enter a name for the firewall group, e.g. PangaeaGame. Set Firewall Rules Open the following 3 ports to the public (\"Anywhere\" on inbound). TCP 22 (SSH) TCP 6000 TCP 9000 Make sure to check that 3 Group Rules have been set. Your instance should now be added to the firewall group and the number of linked instances should increment by 1. You can now go back to the Products page and your server is now successfully set up! Step 2: Connecting to your Vultr Node {% embed url=\"https://youtu.be/rtniAY1RUiM\" %} Connect to your Vultr Instance by using Git Bash. If you do not have gitbash installed. Please visit this link to install . Everything can be default selection when you are installing. In your Vultr instance console overview. You will see your instance information. To go into your instance from git bash. We will use the command: ssh root@<INSTANCEIPADDRESS> It will the prompt you for a password. The password is unique to each instance. To find your password. Look at the Vultr Console website. There is a unique password that is associated with your instance. Copy and paste that in. Before anything is recommended to update your system: apt update && apt upgrade Now install the following packages that will be needed to run Harmony by typing: apt-get install dnsutils apt-get install tmux You will be asked to confirm if you would like to download and install these packages. Just press Y to confirm.","title":"Vultr"},{"location":"validate/first-time-setup/vultr/#vultr","text":"To launch your Vultr instance, we will go through 2 steps. Step 1: Launching Your Vultr Node Registering Vultr and choosing the correct instance. Step 2: Connecting to your Vultr Node Connecting to your Vultr instance.","title":"Vultr"},{"location":"validate/first-time-setup/vultr/#step-1-launching-your-vultr-instance","text":"","title":"Step 1: Launching Your Vultr Instance "},{"location":"validate/first-time-setup/vultr/#logging-into-vultr","text":"\u200b Vultr Main Page If you don\u2019t already have an Vultr account, register one by clicking on \"Sign up\". Otherwise, log into your Vultr Account by clicking on \"Sign in\".","title":"Logging into Vultr "},{"location":"validate/first-time-setup/vultr/#create-a-new-instance","text":"Once logged in, you'll want to add a new instance. Depending on whether your account is new or not, you may or may not have a Products page. If you already have an instance, click the \"+\" button to deploy a new server. You can also use this link to go to the deploy page. Otherwise, your Products page will be already link you to the Deploy page.","title":"Create a new instance "},{"location":"validate/first-time-setup/vultr/#choose-instance-type","text":"For Pangaea requirements, two instance types would fit: Cloud Compute and High Frequency. Cloud Compute is recommended for Pangaea. Cloud Compute instances also work properly with 2 CPUs, 4 GB RAM with 80 GB SSDs. High Frequency Instances were recently introduced by Vultr and offer latest generation high performance 3GHz+ CPUs and NVMe SSDs.","title":"Choose Instance Type "},{"location":"validate/first-time-setup/vultr/#select-server-location-and-server-type","text":"You can choose your preferred location as well as server type. Ubuntu 16.04 x64 or Debian 10 x64 have been tested to work very well.","title":"Select Server Location and Server Type "},{"location":"validate/first-time-setup/vultr/#choose-server-size","text":"Harmony recommends one of the two following: Cloud Compute 2 CPU, 4 GB RAM, 80 GB SSD High Frequency 2 CPU, 4 GB RAM, 128 GB NVMe SSD For \"Additional Features\", none of the selections are necessary.","title":"Choose Server Size "},{"location":"validate/first-time-setup/vultr/#setting-server-name","text":"You can now set the name of your server, e.g. PangaeaNode Then you should click \"Deploy Now\". At this point you should be back on the Products page and your server should be installing. However, the setup isn't completely done, as you need to still create a firewall.","title":"Setting Server Name "},{"location":"validate/first-time-setup/vultr/#create-firewall-group","text":"As we want to allow other nodes to connect to yours, we have to open the correct ports. Once you are on the Firewall page , click Add Firewall Group. Enter a name for the firewall group, e.g. PangaeaGame.","title":"Create Firewall Group "},{"location":"validate/first-time-setup/vultr/#set-firewall-rules","text":"","title":"Set Firewall Rules "},{"location":"validate/first-time-setup/vultr/#open-the-following-3-ports-to-the-public-anywhere-on-inbound","text":"TCP 22 (SSH) TCP 6000 TCP 9000 Make sure to check that 3 Group Rules have been set. Your instance should now be added to the firewall group and the number of linked instances should increment by 1. You can now go back to the Products page and your server is now successfully set up!","title":"Open the following 3 ports to the public (\"Anywhere\" on inbound). "},{"location":"validate/first-time-setup/vultr/#step-2-connecting-to-your-vultr-node","text":"{% embed url=\"https://youtu.be/rtniAY1RUiM\" %} Connect to your Vultr Instance by using Git Bash. If you do not have gitbash installed. Please visit this link to install . Everything can be default selection when you are installing. In your Vultr instance console overview. You will see your instance information. To go into your instance from git bash. We will use the command: ssh root@<INSTANCEIPADDRESS> It will the prompt you for a password. The password is unique to each instance. To find your password. Look at the Vultr Console website. There is a unique password that is associated with your instance. Copy and paste that in. Before anything is recommended to update your system: apt update && apt upgrade Now install the following packages that will be needed to run Harmony by typing: apt-get install dnsutils apt-get install tmux You will be asked to confirm if you would like to download and install these packages. Just press Y to confirm.","title":"Step 2: Connecting to your Vultr Node "},{"location":"validate/first-time-setup/cloud-guides/","text":"Cloud Guides {% page-ref page=\"aws.md\" %} {% page-ref page=\"google-cloud.md\" %} {% page-ref page=\"vultr.md\" %} {% page-ref page=\"digital-ocean.md\" %}","title":"Cloud Guides"},{"location":"validate/first-time-setup/cloud-guides/#cloud-guides","text":"{% page-ref page=\"aws.md\" %} {% page-ref page=\"google-cloud.md\" %} {% page-ref page=\"vultr.md\" %} {% page-ref page=\"digital-ocean.md\" %}","title":"Cloud Guides"},{"location":"validate/first-time-setup/cloud-guides/aws/","text":"AWS To launch your AWS instance, we will go through the steps bellow. Step 1: Launching your AWS Node 1. If you don\u2019t already have an AWS account, register one at https://aws.amazon.com . 2. Once you have set up and logged into your AWS account, click on the top left bar \u201cServices -> Compute -> EC2\". 3. Click on the blue button \u201cLaunch Instance\". 4. Select \u201cAmazon Linux 2 AMI (HVM), SSD Volume Type\u201d. 5. Choose instance type \u201ct3.small\u201d. 6. Click \u201cNext: Configure Instance Details\u201d at the bottom right corner of the page. 7. Don't change anything. Click \u201cNext: Add Storage\u201d at the bottom right corner of the page. 8. Change the \u201cSize (GiB)\u201d category to 30. 9. Click \u201cNext: Add Tags\". 10. Click \"Add Tag.\" Then, in the \u201cKey\u201d input box put \u201cName\u201d in \u201cValue\u201d put \u201cPangaea-key\u201d. 11. Click \u201cNext: Configure Security Group\u201d. 12. On the default SSH with port 22, change the \u201cSource\u201d option to \u201cAnywhere\u201d. 13. Click \"Add Rule\". Under \"Type\" select \"Custom TCP Rule\", under \"Port Range\" put \"6000\" and under \"Source\" select \"Anywhere\". 14. Click \"Add Rule\" again. This time, under \"Type\" select \"Custom TCP Rule\", under \"Port Range\" put \"9000\" and under \"Source\" select \"Anywhere\". 15. Click \u201cReview and Launch\u201d and then click \"Launch\". (Note: Ignore warnings such as \u201cyour security group is open to the world\u201d or \u201cyour instance configuration is not eligible for free tier\u201d) 16. In the pop-up window you will need to create a new key pair. Select \u201cCreate a new key pair\u201d and then enter a name that you like, for example \u201cPangaea-key\u201d. 17. Click \u201cDownload Key Pair\u201d and save the key file somewhere you'll remember. 18. Click \u201cLaunch Instances\u201d. 19. Click \u201cView Instances\u201d at the bottom right. Your new instance should be initializing. Wait a few moments for it to get started. 21. Congratulations your instance is up and running! Now it's time to connect to your instance. Step 2: Connecting to your AWS Instance 1. Open a Terminal window on your computer. For Mac: If you can\u2019t find Terminal, use spotlight to search for it. Or go to your \"Applications' folder, and it should be inside of \u201cUtilities\u201d. For Windows: Download PuTTY to allow your computer to SSH into the AWS instance. For instructions on connecting to an EC2 instance using Putty follow these instructions from Amazon. 2. Once Terminal is open, use the cd command to change your directory to where the key pair file (Pangaea-key.pem) that you generated is. Hint it may be in your \u201cDownloads\u201d folder. 3. Enter the command chmod 400 Pangaea-key.pem . This command makes your key not publicly viewable. Note: On Mac, your pem file may have been changed to a .txt file so the correct command on Mac would be: chmod 400 Pangaea-key.pem.txt 4. Go back to your AWS window where you are viewing your instances. Select your new \"Pangaea-key\" instance and click \u201cConnect\u201d on the top bar. 5. In the pop-up window, under the \u201cExample:\u201d header, copy the sample command to connect to your ec2 instance. The command will look something like: ssh -i \"pangaea-key.pem\" ec2-user@ec2-13-250-30-215.ap-southeast-1.compute.amazonaws.com Now connect to your instance by running the sample command you copied from the \u201cConnect\u201d page in your terminal window. It may ask you whether or not you want to continue connecting. Type in \u201cyes\u201d and hit enter. Congratulations! You should be logged into your new AWS instance! Step 3: Installing Required Packages ****Run the following command to make sure your instance is properly updated: sudo yum update When prompted whether or not you want to download packages, enter \"y\" for yes. Now install the following packages that will be needed to run Harmony by typing: sudo yum install tmux You will be asked to confirm if you would like to download and install these packages. Just press Y to confirm.","title":"AWS"},{"location":"validate/first-time-setup/cloud-guides/aws/#aws","text":"To launch your AWS instance, we will go through the steps bellow.","title":"AWS"},{"location":"validate/first-time-setup/cloud-guides/aws/#step-1-launching-your-aws-node","text":"1. If you don\u2019t already have an AWS account, register one at https://aws.amazon.com . 2. Once you have set up and logged into your AWS account, click on the top left bar \u201cServices -> Compute -> EC2\". 3. Click on the blue button \u201cLaunch Instance\". 4. Select \u201cAmazon Linux 2 AMI (HVM), SSD Volume Type\u201d. 5. Choose instance type \u201ct3.small\u201d. 6. Click \u201cNext: Configure Instance Details\u201d at the bottom right corner of the page. 7. Don't change anything. Click \u201cNext: Add Storage\u201d at the bottom right corner of the page. 8. Change the \u201cSize (GiB)\u201d category to 30. 9. Click \u201cNext: Add Tags\". 10. Click \"Add Tag.\" Then, in the \u201cKey\u201d input box put \u201cName\u201d in \u201cValue\u201d put \u201cPangaea-key\u201d. 11. Click \u201cNext: Configure Security Group\u201d. 12. On the default SSH with port 22, change the \u201cSource\u201d option to \u201cAnywhere\u201d. 13. Click \"Add Rule\". Under \"Type\" select \"Custom TCP Rule\", under \"Port Range\" put \"6000\" and under \"Source\" select \"Anywhere\". 14. Click \"Add Rule\" again. This time, under \"Type\" select \"Custom TCP Rule\", under \"Port Range\" put \"9000\" and under \"Source\" select \"Anywhere\". 15. Click \u201cReview and Launch\u201d and then click \"Launch\". (Note: Ignore warnings such as \u201cyour security group is open to the world\u201d or \u201cyour instance configuration is not eligible for free tier\u201d) 16. In the pop-up window you will need to create a new key pair. Select \u201cCreate a new key pair\u201d and then enter a name that you like, for example \u201cPangaea-key\u201d. 17. Click \u201cDownload Key Pair\u201d and save the key file somewhere you'll remember. 18. Click \u201cLaunch Instances\u201d. 19. Click \u201cView Instances\u201d at the bottom right. Your new instance should be initializing. Wait a few moments for it to get started. 21. Congratulations your instance is up and running! Now it's time to connect to your instance.","title":"Step 1: Launching your AWS Node "},{"location":"validate/first-time-setup/cloud-guides/aws/#step-2-connecting-to-your-aws-instance","text":"1. Open a Terminal window on your computer. For Mac: If you can\u2019t find Terminal, use spotlight to search for it. Or go to your \"Applications' folder, and it should be inside of \u201cUtilities\u201d. For Windows: Download PuTTY to allow your computer to SSH into the AWS instance. For instructions on connecting to an EC2 instance using Putty follow these instructions from Amazon. 2. Once Terminal is open, use the cd command to change your directory to where the key pair file (Pangaea-key.pem) that you generated is. Hint it may be in your \u201cDownloads\u201d folder. 3. Enter the command chmod 400 Pangaea-key.pem . This command makes your key not publicly viewable. Note: On Mac, your pem file may have been changed to a .txt file so the correct command on Mac would be: chmod 400 Pangaea-key.pem.txt 4. Go back to your AWS window where you are viewing your instances. Select your new \"Pangaea-key\" instance and click \u201cConnect\u201d on the top bar. 5. In the pop-up window, under the \u201cExample:\u201d header, copy the sample command to connect to your ec2 instance. The command will look something like: ssh -i \"pangaea-key.pem\" ec2-user@ec2-13-250-30-215.ap-southeast-1.compute.amazonaws.com Now connect to your instance by running the sample command you copied from the \u201cConnect\u201d page in your terminal window. It may ask you whether or not you want to continue connecting. Type in \u201cyes\u201d and hit enter. Congratulations! You should be logged into your new AWS instance!","title":"Step 2: Connecting to your AWS Instance "},{"location":"validate/first-time-setup/cloud-guides/aws/#step-3-installing-required-packages","text":"****Run the following command to make sure your instance is properly updated: sudo yum update When prompted whether or not you want to download packages, enter \"y\" for yes. Now install the following packages that will be needed to run Harmony by typing: sudo yum install tmux You will be asked to confirm if you would like to download and install these packages. Just press Y to confirm.","title":"Step 3: Installing Required Packages"},{"location":"validate/first-time-setup/cloud-guides/digital-ocean/","text":"Digital Ocean To launch your Digital Ocean instance, we will go through the steps bellow. {% hint style=\"success\" %} For new users, you can get $100 dollars free credits to run Digital Ocean services for 2 months using the link bellow {% endhint %} Step 1: Launching your Digital Ocean Node Logging into Digital Ocean \u200b Click here to register a new Digital Ocean account or login if you have an existing one. Create a new P roject Once you have set up and logged into your Digital Ocean account, click on the top left bar \u201cProjects -> New Project\". Enter the desired project name and click on \"Create Project\" as shown by the image bellow: Create a new Droplet On the top right corner click on \"Create\"->\"Droplets\". Choose now your desired Linux image. We recommend either the latest LTS version of Ubuntu (18.04 as of date of now) or the latest version of Debian . Use the left and right arrows to navigate between the different plans available. Choose the \"Standard\" plan and then select a virtual machine with at least 2 CPUs, 4GB of RAM and 80GB SSD. You can select the datacenter region of your choice here. We chose \"Frankurt\" in our example. We recommend using the \"SSH Keys\" as your authentication method (more secure) instead of the \"One-time password\" method. A button with the name \"New SSH key\" will appear on screen, just click on it. To create your SSH key click here for instructions. When you generated your public SSH key, give it a name and click on button \"Add SSH key\" as shown by the image bellow. In case you don't have a public SSH key yet, just follow the instructions to create it. Choose a custom hostname if you want and then click on \"Create Droplet\". Firewall Setup Wait a few seconds till your droplet is created and then click on \"Networking\" on the left bar. Click on \"Firewall\" and then on \"Create Firewall\". In the Inbound Rules section, click on \"New rule\" and select \"Custom\". Leave the protocol as TCP and fill the port range field with 6000 . Repeat the same procedure for port 9000 . You will be left with 2 inbound rules as shown by the image bellow. In the Outbound Rules section leave it as it is. Type the name of the droplet you want to apply your firewall rules (the droplet name is the same as your hostname you chose previously).Click now on \"Create Firewall\". Step 2: Connecting via SSH to your Instance To connect via SSH to your Digital Ocean instance, please follow the instructions here . Step 3: Installing Required Packages Before anything, it is recommended to update your system: sudo apt update && apt upgrade Now install the following packages that will be needed to run Harmony by typing: sudo apt install dnsutils && sudo apt install tmux You will be asked to confirm if you would like to download and install these packages. Just press Y to confirm.","title":"Digital Ocean"},{"location":"validate/first-time-setup/cloud-guides/digital-ocean/#digital-ocean","text":"To launch your Digital Ocean instance, we will go through the steps bellow. {% hint style=\"success\" %} For new users, you can get $100 dollars free credits to run Digital Ocean services for 2 months using the link bellow {% endhint %}","title":"Digital Ocean"},{"location":"validate/first-time-setup/cloud-guides/digital-ocean/#step-1-launching-your-digital-ocean-node","text":"","title":"Step 1: Launching your Digital Ocean Node "},{"location":"validate/first-time-setup/cloud-guides/digital-ocean/#logging-into-digital-ocean","text":"\u200b Click here to register a new Digital Ocean account or login if you have an existing one.","title":"Logging into Digital Ocean "},{"location":"validate/first-time-setup/cloud-guides/digital-ocean/#create-a-new-project","text":"Once you have set up and logged into your Digital Ocean account, click on the top left bar \u201cProjects -> New Project\". Enter the desired project name and click on \"Create Project\" as shown by the image bellow:","title":"Create a new Project "},{"location":"validate/first-time-setup/cloud-guides/digital-ocean/#create-a-new-droplet","text":"On the top right corner click on \"Create\"->\"Droplets\". Choose now your desired Linux image. We recommend either the latest LTS version of Ubuntu (18.04 as of date of now) or the latest version of Debian . Use the left and right arrows to navigate between the different plans available. Choose the \"Standard\" plan and then select a virtual machine with at least 2 CPUs, 4GB of RAM and 80GB SSD. You can select the datacenter region of your choice here. We chose \"Frankurt\" in our example. We recommend using the \"SSH Keys\" as your authentication method (more secure) instead of the \"One-time password\" method. A button with the name \"New SSH key\" will appear on screen, just click on it. To create your SSH key click here for instructions. When you generated your public SSH key, give it a name and click on button \"Add SSH key\" as shown by the image bellow. In case you don't have a public SSH key yet, just follow the instructions to create it. Choose a custom hostname if you want and then click on \"Create Droplet\".","title":"Create a new Droplet "},{"location":"validate/first-time-setup/cloud-guides/digital-ocean/#firewall-setup","text":"Wait a few seconds till your droplet is created and then click on \"Networking\" on the left bar. Click on \"Firewall\" and then on \"Create Firewall\". In the Inbound Rules section, click on \"New rule\" and select \"Custom\". Leave the protocol as TCP and fill the port range field with 6000 . Repeat the same procedure for port 9000 . You will be left with 2 inbound rules as shown by the image bellow. In the Outbound Rules section leave it as it is. Type the name of the droplet you want to apply your firewall rules (the droplet name is the same as your hostname you chose previously).Click now on \"Create Firewall\".","title":"Firewall Setup "},{"location":"validate/first-time-setup/cloud-guides/digital-ocean/#step-2-connecting-via-ssh-to-your-instance","text":"To connect via SSH to your Digital Ocean instance, please follow the instructions here .","title":"Step 2: Connecting via SSH to your Instance "},{"location":"validate/first-time-setup/cloud-guides/digital-ocean/#step-3-installing-required-packages","text":"Before anything, it is recommended to update your system: sudo apt update && apt upgrade Now install the following packages that will be needed to run Harmony by typing: sudo apt install dnsutils && sudo apt install tmux You will be asked to confirm if you would like to download and install these packages. Just press Y to confirm.","title":"Step 3: Installing Required Packages"},{"location":"validate/first-time-setup/cloud-guides/google-cloud/","text":"Google Cloud To launch your Google Cloud instance, we will go through the steps bellow. {% hint style=\"success\" %} Google Cloud has a free tier for new users. You get $300 to spend on Google Cloud Platform products during your first 12 months {% endhint %} Step 1: Launching your Google Cloud Instance Go to https://cloud.google.com/free and click on \u201cGet Started for Free\u201d. Login using an existing account or create a new one. After you login and validate your credit card, you will be shown a page pretty much like this one. Click on \u201cCompute Engine\u201d and then in \u201cVM Instances\u201d. Click on the Create button to make a new instance We recommend to name it something like \"pangaea\u201d (the instance name cannot be changed). Select the Machine type as \u201cCustom\u201d and set up 2 vCPU\u2019s and 4GB of Memory. Keep everything default after you have configured the cores and memory. For storage, 80GB is perfectly fine for now. For the Boot Disk, we recommend either the latest LTS version of Ubuntu (18.04 as of date of now) or the latest version of Debian . Click Create. Please wait a few minutes for your instance Once the instance is created. We will open 4 ingoing ports. To do this click on \"nic0\" as shown below. In the next page click on \u201cFirewall rules\u201d and after that on \u201cCREATE FIREWALL RULE\u201d. TCP 6000 TCP 9000 Step 2: Connecting via SSH to your Instance Go back to the VM instances page and click on SSH. This will open a new window and connect via SSH to your instance: Step 3: Installing Required Packages Before anything, it is recommended to update your system: sudo apt update && apt upgrade Now install the following packages that will be needed to run Harmony by typing: sudo apt install dnsutils && sudo apt install tmux You will be asked to confirm if you would like to download and install these packages. Just press Y to confirm.","title":"Google Cloud"},{"location":"validate/first-time-setup/cloud-guides/google-cloud/#google-cloud","text":"To launch your Google Cloud instance, we will go through the steps bellow. {% hint style=\"success\" %} Google Cloud has a free tier for new users. You get $300 to spend on Google Cloud Platform products during your first 12 months {% endhint %}","title":"Google Cloud"},{"location":"validate/first-time-setup/cloud-guides/google-cloud/#step-1-launching-your-google-cloud-instance","text":"Go to https://cloud.google.com/free and click on \u201cGet Started for Free\u201d. Login using an existing account or create a new one. After you login and validate your credit card, you will be shown a page pretty much like this one. Click on \u201cCompute Engine\u201d and then in \u201cVM Instances\u201d. Click on the Create button to make a new instance We recommend to name it something like \"pangaea\u201d (the instance name cannot be changed). Select the Machine type as \u201cCustom\u201d and set up 2 vCPU\u2019s and 4GB of Memory. Keep everything default after you have configured the cores and memory. For storage, 80GB is perfectly fine for now. For the Boot Disk, we recommend either the latest LTS version of Ubuntu (18.04 as of date of now) or the latest version of Debian . Click Create. Please wait a few minutes for your instance Once the instance is created. We will open 4 ingoing ports. To do this click on \"nic0\" as shown below. In the next page click on \u201cFirewall rules\u201d and after that on \u201cCREATE FIREWALL RULE\u201d. TCP 6000 TCP 9000","title":"Step 1: Launching your Google Cloud Instance "},{"location":"validate/first-time-setup/cloud-guides/google-cloud/#step-2-connecting-via-ssh-to-your-instance","text":"Go back to the VM instances page and click on SSH. This will open a new window and connect via SSH to your instance:","title":"Step 2: Connecting via SSH to your Instance "},{"location":"validate/first-time-setup/cloud-guides/google-cloud/#step-3-installing-required-packages","text":"Before anything, it is recommended to update your system: sudo apt update && apt upgrade Now install the following packages that will be needed to run Harmony by typing: sudo apt install dnsutils && sudo apt install tmux You will be asked to confirm if you would like to download and install these packages. Just press Y to confirm.","title":"Step 3: Installing Required Packages"},{"location":"validate/first-time-setup/cloud-guides/vultr/","text":"Vultr To launch your Vultr instance, we will go through the steps bellow. {% hint style=\"success\" %} For new users, check if you can get a promo link to register on Vultr. Usually Vultr offers free credits on the first month {% endhint %} Step 1: Launching Your Vultr Instance Logging into Vultr \u200bFirst, go to the Vultr Main Page . If you don\u2019t already have an Vultr account, register one by clicking on \"Sign up\". Otherwise, log into your Vultr Account by clicking on \"Sign in\". Create a new instance Once logged in, you'll want to add a new instance. Depending on whether your account is new or not, you may or may not have a Products page. If you already have an instance, click the \"+\" button to deploy a new server. You can also use this link to go to the deploy page. Otherwise, your Products page will be already link you to the Deploy page. Choose Instance Type For Pangaea requirements, two instance types would fit: Cloud Compute and High Frequency. Cloud Compute is recommended for Pangaea. Cloud Compute instances also work properly with 2 CPUs, 4 GB RAM with 80 GB SSDs. High Frequency Instances were recently introduced by Vultr and offer latest generation high performance 3GHz+ CPUs and NVMe SSDs. Select Server Location and Server Type Choose now your desired server type. We recommend either the latest LTS version of Ubuntu (18.04 as of date of now) or the latest version of Debian . Choose Server Size Harmony recommends one of the two following: Cloud Compute 2 CPU, 4 GB RAM, 80 GB SSD High Frequency 2 CPU, 4 GB RAM, 128 GB NVMe SSD For \"Additional Features\", none of the selections are necessary. Setting Server Name You can now set the name of your server, e.g. PangaeaNode Then you should click \"Deploy Now\". At this point you should be back on the Products page and your server should be installing. However, the setup isn't completely done, as you need to still create a firewall. Firewall Setup As we want to allow other nodes to connect to yours, we have to open the correct ports. Once you are on the Firewall page , click Add Firewall Group. Enter a name for the firewall group, e.g. FoundationNode. Open the following 3 ports to the public (\"Anywhere\" on inbound). TCP 22 (SSH) TCP 6000 TCP 9000 Make sure to check that 3 Group Rules have been set. Then link the instance to the firewall group. The steps are as follows: Click Linked Instances. Make sure your new server is selected. Click the + button. Click Add Linked Instance. Your instance should now be added to the firewall group and the number of linked instances should increment by 1. You can now go back to the Products page and your server is now successfully set up! Step 2: Connecting via SSH to your Instance Follow the instructions bellow accordingly to the operating system you are connecting from: Windows Linux Step 3: Installing Required Packages Before anything, it is recommended to update your system: sudo apt update && apt upgrade Now install the following packages that will be needed to run Harmony by typing: sudo apt install dnsutils && sudo apt install tmux You will be asked to confirm if you would like to download and install these packages. Just press Y to confirm.","title":"Vultr"},{"location":"validate/first-time-setup/cloud-guides/vultr/#vultr","text":"To launch your Vultr instance, we will go through the steps bellow. {% hint style=\"success\" %} For new users, check if you can get a promo link to register on Vultr. Usually Vultr offers free credits on the first month {% endhint %}","title":"Vultr"},{"location":"validate/first-time-setup/cloud-guides/vultr/#step-1-launching-your-vultr-instance","text":"","title":"Step 1: Launching Your Vultr Instance "},{"location":"validate/first-time-setup/cloud-guides/vultr/#logging-into-vultr","text":"\u200bFirst, go to the Vultr Main Page . If you don\u2019t already have an Vultr account, register one by clicking on \"Sign up\". Otherwise, log into your Vultr Account by clicking on \"Sign in\".","title":"Logging into Vultr "},{"location":"validate/first-time-setup/cloud-guides/vultr/#create-a-new-instance","text":"Once logged in, you'll want to add a new instance. Depending on whether your account is new or not, you may or may not have a Products page. If you already have an instance, click the \"+\" button to deploy a new server. You can also use this link to go to the deploy page. Otherwise, your Products page will be already link you to the Deploy page.","title":"Create a new instance "},{"location":"validate/first-time-setup/cloud-guides/vultr/#choose-instance-type","text":"For Pangaea requirements, two instance types would fit: Cloud Compute and High Frequency. Cloud Compute is recommended for Pangaea. Cloud Compute instances also work properly with 2 CPUs, 4 GB RAM with 80 GB SSDs. High Frequency Instances were recently introduced by Vultr and offer latest generation high performance 3GHz+ CPUs and NVMe SSDs.","title":"Choose Instance Type "},{"location":"validate/first-time-setup/cloud-guides/vultr/#select-server-location-and-server-type","text":"Choose now your desired server type. We recommend either the latest LTS version of Ubuntu (18.04 as of date of now) or the latest version of Debian .","title":"Select Server Location and Server Type "},{"location":"validate/first-time-setup/cloud-guides/vultr/#choose-server-size","text":"Harmony recommends one of the two following: Cloud Compute 2 CPU, 4 GB RAM, 80 GB SSD High Frequency 2 CPU, 4 GB RAM, 128 GB NVMe SSD For \"Additional Features\", none of the selections are necessary.","title":"Choose Server Size "},{"location":"validate/first-time-setup/cloud-guides/vultr/#setting-server-name","text":"You can now set the name of your server, e.g. PangaeaNode Then you should click \"Deploy Now\". At this point you should be back on the Products page and your server should be installing. However, the setup isn't completely done, as you need to still create a firewall.","title":"Setting Server Name "},{"location":"validate/first-time-setup/cloud-guides/vultr/#firewall-setup","text":"As we want to allow other nodes to connect to yours, we have to open the correct ports. Once you are on the Firewall page , click Add Firewall Group. Enter a name for the firewall group, e.g. FoundationNode.","title":"Firewall Setup "},{"location":"validate/first-time-setup/cloud-guides/vultr/#open-the-following-3-ports-to-the-public-anywhere-on-inbound","text":"TCP 22 (SSH) TCP 6000 TCP 9000 Make sure to check that 3 Group Rules have been set.","title":"Open the following 3 ports to the public (\"Anywhere\" on inbound). "},{"location":"validate/first-time-setup/cloud-guides/vultr/#then-link-the-instance-to-the-firewall-group-the-steps-are-as-follows","text":"Click Linked Instances. Make sure your new server is selected. Click the + button. Click Add Linked Instance. Your instance should now be added to the firewall group and the number of linked instances should increment by 1. You can now go back to the Products page and your server is now successfully set up!","title":"Then link the instance to the firewall group. The steps are as follows: "},{"location":"validate/first-time-setup/cloud-guides/vultr/#step-2-connecting-via-ssh-to-your-instance","text":"Follow the instructions bellow accordingly to the operating system you are connecting from: Windows Linux","title":"Step 2: Connecting via SSH to your Instance "},{"location":"validate/first-time-setup/cloud-guides/vultr/#step-3-installing-required-packages","text":"Before anything, it is recommended to update your system: sudo apt update && apt upgrade Now install the following packages that will be needed to run Harmony by typing: sudo apt install dnsutils && sudo apt install tmux You will be asked to confirm if you would like to download and install these packages. Just press Y to confirm.","title":"Step 3: Installing Required Packages"},{"location":"validate/first-time-setup/fast-state-syncing/","text":"Fast State Syncing Harmony supports fast state syncing of its blockchain so you don't need to sync it all from scratch.","title":"Fast State Syncing"},{"location":"validate/first-time-setup/fast-state-syncing/#fast-state-syncing","text":"Harmony supports fast state syncing of its blockchain so you don't need to sync it all from scratch.","title":"Fast State Syncing"},{"location":"validate/first-time-setup/fast-state-syncing/using-rclone/","text":"Using Rclone This document introduces another centralized fast state syncing method using rclone. The document is still working-in-progress. Please use it with caution. This guide is mainly used for a newly started node to catch up with the blockchain faster. Otherwise, the blockchain syncing may take weeks. Rclone db snapshot is sync'ed with blockchain once a day. It is more recent than the db tarball. However, there maybe a potential race condition when the rclone may fail due to our nodes were updating the db files at the same time. In this case, just re-run the rclone command to re-sync again. Rclone If you don't know what is rclone, please visit the rclone website for some more info and usage. Install rclone => https://rclone.org/ Rclone.conf Add the following rclone.conf file to ~/.config/rclone directory [mainnet] type = s3 provider = AWS env_auth = false region = us-west-1 acl = public-read server_side_encryption = AES256 storage_class = REDUCED_REDUNDANCY Rclone DB snapshot For example, rclone DB snapshot for shard 0. Just replace ShardID with the real shard ID 0. rclone sync mainnet:pub.harmony.one/mainnet/harmony_db_<ShardID> harmony_db_<ShardID> For state pruning enabled node, please rclone a different DB snapshot from s3. rclone sync mainnet:pub.harmony.one/mainnet.min/harmony_db_<ShardID> harmony_db_<ShardID> {% hint style=\"info\" %} Nodes in shard 0 just need to sync harmony_db_0 Nodes in shard 1, 2, 3 need to sync both harmony_db_0 , and harmony_db_<shardid> {% endhint %}","title":"Using Rclone"},{"location":"validate/first-time-setup/fast-state-syncing/using-rclone/#using-rclone","text":"This document introduces another centralized fast state syncing method using rclone. The document is still working-in-progress. Please use it with caution. This guide is mainly used for a newly started node to catch up with the blockchain faster. Otherwise, the blockchain syncing may take weeks. Rclone db snapshot is sync'ed with blockchain once a day. It is more recent than the db tarball. However, there maybe a potential race condition when the rclone may fail due to our nodes were updating the db files at the same time. In this case, just re-run the rclone command to re-sync again.","title":"Using Rclone"},{"location":"validate/first-time-setup/fast-state-syncing/using-rclone/#rclone","text":"If you don't know what is rclone, please visit the rclone website for some more info and usage. Install rclone => https://rclone.org/","title":"Rclone"},{"location":"validate/first-time-setup/fast-state-syncing/using-rclone/#rcloneconf","text":"Add the following rclone.conf file to ~/.config/rclone directory [mainnet] type = s3 provider = AWS env_auth = false region = us-west-1 acl = public-read server_side_encryption = AES256 storage_class = REDUCED_REDUNDANCY","title":"Rclone.conf"},{"location":"validate/first-time-setup/fast-state-syncing/using-rclone/#rclone-db-snapshot","text":"For example, rclone DB snapshot for shard 0. Just replace ShardID with the real shard ID 0. rclone sync mainnet:pub.harmony.one/mainnet/harmony_db_<ShardID> harmony_db_<ShardID> For state pruning enabled node, please rclone a different DB snapshot from s3. rclone sync mainnet:pub.harmony.one/mainnet.min/harmony_db_<ShardID> harmony_db_<ShardID> {% hint style=\"info\" %} Nodes in shard 0 just need to sync harmony_db_0 Nodes in shard 1, 2, 3 need to sync both harmony_db_0 , and harmony_db_<shardid> {% endhint %}","title":"Rclone DB snapshot"},{"location":"validate/managing-your-validator/","text":"Managing Your Validator","title":"Managing Your Validator"},{"location":"validate/managing-your-validator/#managing-your-validator","text":"","title":"Managing Your Validator"},{"location":"validate/managing-your-validator/adding-a-validator-logo/","text":"Adding A Validator Logo Uploading A Custom Logo Fork this github repo: https://github.com/harmony-one/validator-logos \u200b Add your logo by creating the logo image name using your Harmony one address as the file name and placing it inside \"validators\" folder. The logo image needs to be a .jpg file with 256x256 pixels or 512x512 pixels. Exemple: validators/one1pdv9lrdwl0rg5vglh4xtyrv3wjk3wsqket7zxy.jpg {% hint style=\"danger\" %} Do not upload the .jpg file name in the root repository. It needs be be inside folder \"validators\". {% endhint %} Create a pull request for your changes. A Harmony team member will review the image & approve it.","title":"Adding A Validator Logo"},{"location":"validate/managing-your-validator/adding-a-validator-logo/#adding-a-validator-logo","text":"","title":"Adding A Validator Logo"},{"location":"validate/managing-your-validator/adding-a-validator-logo/#uploading-a-custom-logo","text":"Fork this github repo: https://github.com/harmony-one/validator-logos \u200b Add your logo by creating the logo image name using your Harmony one address as the file name and placing it inside \"validators\" folder. The logo image needs to be a .jpg file with 256x256 pixels or 512x512 pixels. Exemple: validators/one1pdv9lrdwl0rg5vglh4xtyrv3wjk3wsqket7zxy.jpg {% hint style=\"danger\" %} Do not upload the .jpg file name in the root repository. It needs be be inside folder \"validators\". {% endhint %} Create a pull request for your changes. A Harmony team member will review the image & approve it.","title":"Uploading A Custom Logo "},{"location":"validate/managing-your-validator/changing-validator-information/","text":"Changing Validator Information You can edit your validator\u2019s information using the CLI with the following command. Using the Binary: ./hmy --node=\"https://api.s0.t.hmny.io\" staking edit-validator \\ --validator-addr [ONE ADDRESS] [FIELDS TO EDIT] --passphrase Using the Shell Wrapper: ./hmy.sh -- node=\"https://api.s0.t.hmny.io\" staking edit-validator \\ --validator-addr [ONE ADDRESS] [FIELDS TO EDIT] --passphrase The CLI will prompt you to enter your BLS key file password. Only the --validator-addr field is required; all other fields are optional. --validator-addr is the validator ONE address that you want to edit (string) --active to set validator as eligible or not to be elected (bool) --name to change the name displayed on the Staking Explorer (string) --identity to change the identity field (string) --website to change the website field (string) --details to change the details field (string) --security-contact to change the security contact field (string) --rate to change the current commission rate (float) --min-self-delegation to change the minimum stake by the validator (float) --max-total-delegation to change the maximum stake that the validator can take (float) --remove-bls-key to remove a BLS public key associated with your validator (string) --add-bls-key to add another BLS public key to your validator (string) {% hint style=\"info\" %} --validator-addr is the only field that is required. Sending the command without the arguments will leave those fields of your validator as is. {% endhint %} {% hint style=\"danger\" %} --max-rate and --max-change-rate cannot be changed later. --min-self-delegation has to be at least 10,000 ONE. {% endhint %}","title":"Changing Validator Information"},{"location":"validate/managing-your-validator/changing-validator-information/#changing-validator-information","text":"You can edit your validator\u2019s information using the CLI with the following command.","title":"Changing Validator Information"},{"location":"validate/managing-your-validator/changing-validator-information/#using-the-binary","text":"./hmy --node=\"https://api.s0.t.hmny.io\" staking edit-validator \\ --validator-addr [ONE ADDRESS] [FIELDS TO EDIT] --passphrase","title":"Using the Binary:"},{"location":"validate/managing-your-validator/changing-validator-information/#using-the-shell-wrapper","text":"./hmy.sh -- node=\"https://api.s0.t.hmny.io\" staking edit-validator \\ --validator-addr [ONE ADDRESS] [FIELDS TO EDIT] --passphrase The CLI will prompt you to enter your BLS key file password. Only the --validator-addr field is required; all other fields are optional. --validator-addr is the validator ONE address that you want to edit (string) --active to set validator as eligible or not to be elected (bool) --name to change the name displayed on the Staking Explorer (string) --identity to change the identity field (string) --website to change the website field (string) --details to change the details field (string) --security-contact to change the security contact field (string) --rate to change the current commission rate (float) --min-self-delegation to change the minimum stake by the validator (float) --max-total-delegation to change the maximum stake that the validator can take (float) --remove-bls-key to remove a BLS public key associated with your validator (string) --add-bls-key to add another BLS public key to your validator (string) {% hint style=\"info\" %} --validator-addr is the only field that is required. Sending the command without the arguments will leave those fields of your validator as is. {% endhint %} {% hint style=\"danger\" %} --max-rate and --max-change-rate cannot be changed later. --min-self-delegation has to be at least 10,000 ONE. {% endhint %}","title":"Using the Shell Wrapper:"},{"location":"validate/managing-your-validator/checking-validator-information/","text":"Checking Validator Information Using the Binary: ./hmy blockchain validator information [ONE ADDRESS] --node=\"https://api.s0.t.hmny.io\" Using the Shell Wrapper: ./hmy.sh -- blockchain validator information [ONE ADDRESS] --node=\"https://api.s0.t.hmny.io\" Example: ./hmy blockchain validator information one1925zlp5celp8r8jj3utpcxpjtncuuv2nu2449v --node=\"https://api.s0.t.hmny.io\" Output: { \"id\": \"0\", \"jsonrpc\": \"2.0\", \"result\": { \"current-epoch-performance\": { \"current-epoch-signing-percent\": { \"current-epoch-blocks-left\": 9, \"current-epoch-signed\": 29, \"current-epoch-signing-percentage\": \"1.000000000000000000\", \"current-epoch-to-sign\": 29 } }, \"currently-in-committee\": true, \"epos-status\": \"currently elected and signing enough blocks to be eligible for election next epoch\", \"lifetime\": { \"apr\": \"0.000000000000000000\", \"blocks\": { \"signed\": 5879, \"to-sign\": 5880 }, \"reward-accumulated\": 6.966841018353012e+21 }, \"metrics\": { \"by-shard\": [ { \"bls-public-key\": \"3a26c230170cb295a20931661967ebc3bd817859e11d1eecda5cabb9ad372cd6cbba7843a72a24f24352dc3757aad014\", \"earning-account\": \"one1925zlp5celp8r8jj3utpcxpjtncuuv2nu2449v\", \"effective-stake\": \"250000000000000000000000.000000000000000000\", \"group-percent\": \"0.035843835577157440\", \"overall-percent\": \"0.011470027384690381\", \"shard-id\": 0 } ], \"total-effective-stake\": \"250000000000000000000000.000000000000000000\" }, \"total-delegation\": 2.5e+23, \"validator\": { \"address\": \"one1925zlp5celp8r8jj3utpcxpjtncuuv2nu2449v\", \"bls-public-keys\": [ \"3a26c230170cb295a20931661967ebc3bd817859e11d1eecda5cabb9ad372cd6cbba7843a72a24f24352dc3757aad014\" ], \"creation-height\": 12037, \"delegations\": [ { \"amount\": 1.5e+23, \"delegator-address\": \"one1925zlp5celp8r8jj3utpcxpjtncuuv2nu2449v\", \"reward\": 6.149775864909033e+21, \"undelegations\": [] }, { \"amount\": 1e+23, \"delegator-address\": \"one1jjq5pl4le0fhhu3n2znkkt9tydrzjcyzaljtnl\", \"reward\": 620363080921910600000, \"undelegations\": [] } ], \"details\": \"S0\", \"identity\": \"J\", \"last-epoch-in-committee\": 471, \"max-change-rate\": \"0.100000000000000000\", \"max-rate\": \"0.500000000000000000\", \"max-total-delegation\": 1e+25, \"min-self-delegation\": 1e+22, \"name\": \"[R]\", \"rate\": \"0.100000000000000000\", \"security-contact\": \"J\", \"update-height\": 12037, \"website\": \"harmony.one\" } } } {% hint style=\"warning\" %} If your validator does not sign more than 2/3 of the blocks in an epoch, the validator will be removed from the pool of eligible validators. In order to be included in the pool again, you will have to use send an Edit Validator transaction with --active true. {% endhint %}","title":"Checking Validator Information"},{"location":"validate/managing-your-validator/checking-validator-information/#checking-validator-information","text":"","title":"Checking Validator Information"},{"location":"validate/managing-your-validator/checking-validator-information/#using-the-binary","text":"./hmy blockchain validator information [ONE ADDRESS] --node=\"https://api.s0.t.hmny.io\"","title":"Using the Binary:"},{"location":"validate/managing-your-validator/checking-validator-information/#using-the-shell-wrapper","text":"./hmy.sh -- blockchain validator information [ONE ADDRESS] --node=\"https://api.s0.t.hmny.io\"","title":"Using the Shell Wrapper:"},{"location":"validate/managing-your-validator/checking-validator-information/#example","text":"./hmy blockchain validator information one1925zlp5celp8r8jj3utpcxpjtncuuv2nu2449v --node=\"https://api.s0.t.hmny.io\"","title":"Example:"},{"location":"validate/managing-your-validator/checking-validator-information/#output","text":"{ \"id\": \"0\", \"jsonrpc\": \"2.0\", \"result\": { \"current-epoch-performance\": { \"current-epoch-signing-percent\": { \"current-epoch-blocks-left\": 9, \"current-epoch-signed\": 29, \"current-epoch-signing-percentage\": \"1.000000000000000000\", \"current-epoch-to-sign\": 29 } }, \"currently-in-committee\": true, \"epos-status\": \"currently elected and signing enough blocks to be eligible for election next epoch\", \"lifetime\": { \"apr\": \"0.000000000000000000\", \"blocks\": { \"signed\": 5879, \"to-sign\": 5880 }, \"reward-accumulated\": 6.966841018353012e+21 }, \"metrics\": { \"by-shard\": [ { \"bls-public-key\": \"3a26c230170cb295a20931661967ebc3bd817859e11d1eecda5cabb9ad372cd6cbba7843a72a24f24352dc3757aad014\", \"earning-account\": \"one1925zlp5celp8r8jj3utpcxpjtncuuv2nu2449v\", \"effective-stake\": \"250000000000000000000000.000000000000000000\", \"group-percent\": \"0.035843835577157440\", \"overall-percent\": \"0.011470027384690381\", \"shard-id\": 0 } ], \"total-effective-stake\": \"250000000000000000000000.000000000000000000\" }, \"total-delegation\": 2.5e+23, \"validator\": { \"address\": \"one1925zlp5celp8r8jj3utpcxpjtncuuv2nu2449v\", \"bls-public-keys\": [ \"3a26c230170cb295a20931661967ebc3bd817859e11d1eecda5cabb9ad372cd6cbba7843a72a24f24352dc3757aad014\" ], \"creation-height\": 12037, \"delegations\": [ { \"amount\": 1.5e+23, \"delegator-address\": \"one1925zlp5celp8r8jj3utpcxpjtncuuv2nu2449v\", \"reward\": 6.149775864909033e+21, \"undelegations\": [] }, { \"amount\": 1e+23, \"delegator-address\": \"one1jjq5pl4le0fhhu3n2znkkt9tydrzjcyzaljtnl\", \"reward\": 620363080921910600000, \"undelegations\": [] } ], \"details\": \"S0\", \"identity\": \"J\", \"last-epoch-in-committee\": 471, \"max-change-rate\": \"0.100000000000000000\", \"max-rate\": \"0.500000000000000000\", \"max-total-delegation\": 1e+25, \"min-self-delegation\": 1e+22, \"name\": \"[R]\", \"rate\": \"0.100000000000000000\", \"security-contact\": \"J\", \"update-height\": 12037, \"website\": \"harmony.one\" } } } {% hint style=\"warning\" %} If your validator does not sign more than 2/3 of the blocks in an epoch, the validator will be removed from the pool of eligible validators. In order to be included in the pool again, you will have to use send an Edit Validator transaction with --active true. {% endhint %}","title":"Output:"},{"location":"validate/managing-your-validator/collecting-rewards/","text":"Collecting Rewards You can collect your block rewards with the following command. Using the Binary: ./hmy --node=\"https://api.s0.t.hmny.io\" staking collect-rewards \\ --delegator-addr [ONE ADDRESS] --passphrase Using the Shell Wrapper: ./hmy.sh -- node=\"https://api.s0.t.hmny.io\" staking collect-rewards \\ --delegator-addr [ONE ADDRESS] --passphrase Example: ./hmy --node=\"https://api.s0.t.hmny.io\" staking collect-rewards \\ --delegator-addr one1km7xg8e3xjys7azp9f4xp8hkw79vm2h3f2lade --passphrase The CLI will prompt your for the passphrase of the delegation account. --delegator-addr is the account to collect rewards for {% hint style=\"warning\" %} You can only collect ALL of your block rewards at once, not partially. {% endhint %}","title":"Collecting Rewards"},{"location":"validate/managing-your-validator/collecting-rewards/#collecting-rewards","text":"You can collect your block rewards with the following command.","title":"Collecting Rewards"},{"location":"validate/managing-your-validator/collecting-rewards/#using-the-binary","text":"./hmy --node=\"https://api.s0.t.hmny.io\" staking collect-rewards \\ --delegator-addr [ONE ADDRESS] --passphrase","title":"Using the Binary:"},{"location":"validate/managing-your-validator/collecting-rewards/#using-the-shell-wrapper","text":"./hmy.sh -- node=\"https://api.s0.t.hmny.io\" staking collect-rewards \\ --delegator-addr [ONE ADDRESS] --passphrase","title":"Using the Shell Wrapper:"},{"location":"validate/managing-your-validator/collecting-rewards/#example","text":"./hmy --node=\"https://api.s0.t.hmny.io\" staking collect-rewards \\ --delegator-addr one1km7xg8e3xjys7azp9f4xp8hkw79vm2h3f2lade --passphrase The CLI will prompt your for the passphrase of the delegation account. --delegator-addr is the account to collect rewards for {% hint style=\"warning\" %} You can only collect ALL of your block rewards at once, not partially. {% endhint %}","title":"Example:"},{"location":"validate/managing-your-validator/delegating-to-a-validator/","text":"Delegating To A Validator You can delegate tokens to a validator using the following command. Using the Binary: ./hmy --node=\"https://api.s0.t.hmny.io\" staking delegate \\ --delegator-addr [ONE ADDRESS] --validator-addr [ONE ADDRESS] \\ --amount [AMOUNT] --passphrase Using the Shell Wrapper: ./hmy.sh -- node=\"https://api.s0.t.hmny.io\" staking delegate \\ --delegator-addr [ONE ADDRESS] --validator-addr [ONE ADDRESS] \\ --amount [AMOUNT] --passphrase Example: ./hmy --node=\"https://api.s0.t.hmny.io\" staking delegate \\ --delegator-addr one1km7xg8e3xjys7azp9f4xp8hkw79vm2h3f2lade --validator-addr one1km7xg8e3xjys7azp9f4xp8hkw79vm2h3f2lade \\ --amount 10000 --passphrase The CLI will ask for the passphrase for the delegator-addr keystore file. --delegator-addr is the ONE address of the delegator (string) --validator-addr is the ONE address of the validator (string) --amount is the number of ONE tokens to delegate to the validator (float) {% hint style=\"info\" %} As a validator, if you want to increase your stake, you will have to delegate to yourself. For delegating to your own validator, delegator-addr and validator-addr will be the same. {% endhint %}","title":"Delegating To A Validator"},{"location":"validate/managing-your-validator/delegating-to-a-validator/#delegating-to-a-validator","text":"You can delegate tokens to a validator using the following command.","title":"Delegating To A Validator"},{"location":"validate/managing-your-validator/delegating-to-a-validator/#using-the-binary","text":"./hmy --node=\"https://api.s0.t.hmny.io\" staking delegate \\ --delegator-addr [ONE ADDRESS] --validator-addr [ONE ADDRESS] \\ --amount [AMOUNT] --passphrase","title":"Using the Binary:"},{"location":"validate/managing-your-validator/delegating-to-a-validator/#using-the-shell-wrapper","text":"./hmy.sh -- node=\"https://api.s0.t.hmny.io\" staking delegate \\ --delegator-addr [ONE ADDRESS] --validator-addr [ONE ADDRESS] \\ --amount [AMOUNT] --passphrase","title":"Using the Shell Wrapper:"},{"location":"validate/managing-your-validator/delegating-to-a-validator/#example","text":"./hmy --node=\"https://api.s0.t.hmny.io\" staking delegate \\ --delegator-addr one1km7xg8e3xjys7azp9f4xp8hkw79vm2h3f2lade --validator-addr one1km7xg8e3xjys7azp9f4xp8hkw79vm2h3f2lade \\ --amount 10000 --passphrase The CLI will ask for the passphrase for the delegator-addr keystore file. --delegator-addr is the ONE address of the delegator (string) --validator-addr is the ONE address of the validator (string) --amount is the number of ONE tokens to delegate to the validator (float) {% hint style=\"info\" %} As a validator, if you want to increase your stake, you will have to delegate to yourself. For delegating to your own validator, delegator-addr and validator-addr will be the same. {% endhint %}","title":"Example:"},{"location":"validate/managing-your-validator/seeing-stakers/","text":"Seeing Stakers You can see the number of delegations to your validator with the following command. Using the Binary: ./hmy --node=\"https://api.s0.t.hmny.io\" blockchain delegation by-validator [VALIDATOR ADDRESS] Using the Shell Wrapper: ./hmy.sh -- node=\"https://api.s0.t.hmny.io\" blockchain delegation by-validator [VALIDATOR ADDRESS] Example: ./hmy node=\"https://api.s0.t.hmny.io\" blockchain delegation by-validator one1km7xg8e3xjys7azp9f4xp8hkw79vm2h3f2lade Output: { \"id\": \"0\", \"jsonrpc\": \"2.0\", \"result\": [ { \"Undelegations\": [], \"amount\": 93000000000000000000, \"delegator_address\": \"one1ctr58xue32peagud620tmthc95w5ch94vfhfgp\", \"reward\": 193348691324709180000, \"validator_address\": \"one1ctr58xue32peagud620tmthc95w5ch94vfhfgp\" }, { \"Undelegations\": [], \"amount\": 1.01e+22, \"delegator_address\": \"one1cg5d67v28m3s0xuph46y8w842yu9dzd7094zr5\", \"reward\": 646413329184000700000, \"validator_address\": \"one1ctr58xue32peagud620tmthc95w5ch94vfhfgp\" } ] }","title":"Seeing Stakers"},{"location":"validate/managing-your-validator/seeing-stakers/#seeing-stakers","text":"You can see the number of delegations to your validator with the following command.","title":"Seeing Stakers"},{"location":"validate/managing-your-validator/seeing-stakers/#using-the-binary","text":"./hmy --node=\"https://api.s0.t.hmny.io\" blockchain delegation by-validator [VALIDATOR ADDRESS]","title":"Using the Binary:"},{"location":"validate/managing-your-validator/seeing-stakers/#using-the-shell-wrapper","text":"./hmy.sh -- node=\"https://api.s0.t.hmny.io\" blockchain delegation by-validator [VALIDATOR ADDRESS]","title":"Using the Shell Wrapper:"},{"location":"validate/managing-your-validator/seeing-stakers/#example","text":"./hmy node=\"https://api.s0.t.hmny.io\" blockchain delegation by-validator one1km7xg8e3xjys7azp9f4xp8hkw79vm2h3f2lade","title":"Example:"},{"location":"validate/managing-your-validator/seeing-stakers/#output","text":"{ \"id\": \"0\", \"jsonrpc\": \"2.0\", \"result\": [ { \"Undelegations\": [], \"amount\": 93000000000000000000, \"delegator_address\": \"one1ctr58xue32peagud620tmthc95w5ch94vfhfgp\", \"reward\": 193348691324709180000, \"validator_address\": \"one1ctr58xue32peagud620tmthc95w5ch94vfhfgp\" }, { \"Undelegations\": [], \"amount\": 1.01e+22, \"delegator_address\": \"one1cg5d67v28m3s0xuph46y8w842yu9dzd7094zr5\", \"reward\": 646413329184000700000, \"validator_address\": \"one1ctr58xue32peagud620tmthc95w5ch94vfhfgp\" } ] }","title":"Output:"},{"location":"validate/managing-your-validator/undelegating-to-a-validator/","text":"Undelegating From A Validator You can un-delegate tokens from a validator using the following command: Using the Binary: ./hmy --node=\"https://api.s0.t.hmny.io\" staking undelegate \\ --delegator-addr [ONE ADDRESS] --validator-addr [ONE ADDRESS] \\ --amount [AMOUNT] --passphrase Using the Shell Wrapper: ./hmy.sh -- node=\"https://api.s0.t.hmny.io\" staking undelegate \\ --delegator-addr [ONE ADDRESS] --validator-addr [ONE ADDRESS] \\ --amount [AMOUNT] --passphrase Example: ./hmy.sh -- node=\"https://api.s0.t.hmny.io\" staking undelegate \\ --delegator-addr one1km7xg8e3xjys7azp9f4xp8hkw79vm2h3f2lade --validator-addr one1km7xg8e3xjys7azp9f4xp8hkw79vm2h3f2lade \\ --amount 10000 --passphrase The CLI will ask for the passphrase for the delegator-addr keystore file. --delegator-addr is the ONE address of the delegator (string) --validator-addr is the ONE address of the validator (string) --amount is the number of ONE tokens to un-delegate (float) {% hint style=\"info\" %} As a validator, for un-delegating from your own validator, delegator-addr and validator-addr will be the same. {% endhint %} When will I get my tokens back after un-delegating? When you decide to un-delegate your tokens from a validator, your tokens will be subjected to a cool-down period lasting 7 epochs . You will receive your tokens back in your account balance on the 8th epoch after an un-delegation transaction. This means that you will NOT have access to these tokens and can NOT transfer them after choosing to un-delegate your tokens from a validator. If your validator didn't get elected in the last 7 epoch, there is no cool-down period and you will get the token back at the end of current epoch.","title":"Undelegating From A Validator"},{"location":"validate/managing-your-validator/undelegating-to-a-validator/#undelegating-from-a-validator","text":"You can un-delegate tokens from a validator using the following command:","title":"Undelegating From A Validator"},{"location":"validate/managing-your-validator/undelegating-to-a-validator/#using-the-binary","text":"./hmy --node=\"https://api.s0.t.hmny.io\" staking undelegate \\ --delegator-addr [ONE ADDRESS] --validator-addr [ONE ADDRESS] \\ --amount [AMOUNT] --passphrase","title":"Using the Binary:"},{"location":"validate/managing-your-validator/undelegating-to-a-validator/#using-the-shell-wrapper","text":"./hmy.sh -- node=\"https://api.s0.t.hmny.io\" staking undelegate \\ --delegator-addr [ONE ADDRESS] --validator-addr [ONE ADDRESS] \\ --amount [AMOUNT] --passphrase","title":"Using the Shell Wrapper:"},{"location":"validate/managing-your-validator/undelegating-to-a-validator/#example","text":"./hmy.sh -- node=\"https://api.s0.t.hmny.io\" staking undelegate \\ --delegator-addr one1km7xg8e3xjys7azp9f4xp8hkw79vm2h3f2lade --validator-addr one1km7xg8e3xjys7azp9f4xp8hkw79vm2h3f2lade \\ --amount 10000 --passphrase The CLI will ask for the passphrase for the delegator-addr keystore file. --delegator-addr is the ONE address of the delegator (string) --validator-addr is the ONE address of the validator (string) --amount is the number of ONE tokens to un-delegate (float) {% hint style=\"info\" %} As a validator, for un-delegating from your own validator, delegator-addr and validator-addr will be the same. {% endhint %}","title":"Example:"},{"location":"validate/managing-your-validator/undelegating-to-a-validator/#when-will-i-get-my-tokens-back-after-un-delegating","text":"When you decide to un-delegate your tokens from a validator, your tokens will be subjected to a cool-down period lasting 7 epochs . You will receive your tokens back in your account balance on the 8th epoch after an un-delegation transaction. This means that you will NOT have access to these tokens and can NOT transfer them after choosing to un-delegate your tokens from a validator. If your validator didn't get elected in the last 7 epoch, there is no cool-down period and you will get the token back at the end of current epoch.","title":"When will I get my tokens back after un-delegating?"},{"location":"validate/staking-explorer/","text":"Staking Explorer","title":"Staking Explorer"},{"location":"validate/staking-explorer/#staking-explorer","text":"","title":"Staking Explorer"},{"location":"validate/staking-explorer/installation/","text":"Installation {% hint style=\"danger\" %} Save your private key(s) before updating the extension. {% endhint %} Download the latest version here . Unzip the file. Type chrome://extensions on Google Chrome web browser. Enable \u201cDeveloper mode\u201d located in the top right corner, then click on Load unpacked button. Then specify the unzipped folder \u2192 you may need to clear site application - go to Clear site data below. You should see small H icon as following. Click on the icon, create a new address. Click on the icon, create a new address. (do not forget to remember passphrase). Go to https://staking.harmony.one . Click on Sign in, Use an existing address, Use Lunie Browser Extension (sorry we will modify as Harmony Browser Extension), Use Account. Click on your address to copy the address. Ask the team to fund some money to your address. For transfer, go to Portfolio page, for staking go Validators page (pick a validator for staking/unstaking). Click on transfer Send, or Stake for staking, Unstake for unstaking. Then Next, Next, NexT. You would see H icon with label 1 like below. Click on that and specify password for signing and sending the txn to the network.","title":"Installation"},{"location":"validate/staking-explorer/installation/#installation","text":"{% hint style=\"danger\" %} Save your private key(s) before updating the extension. {% endhint %} Download the latest version here . Unzip the file. Type chrome://extensions on Google Chrome web browser. Enable \u201cDeveloper mode\u201d located in the top right corner, then click on Load unpacked button. Then specify the unzipped folder \u2192 you may need to clear site application - go to Clear site data below. You should see small H icon as following. Click on the icon, create a new address. Click on the icon, create a new address. (do not forget to remember passphrase). Go to https://staking.harmony.one . Click on Sign in, Use an existing address, Use Lunie Browser Extension (sorry we will modify as Harmony Browser Extension), Use Account. Click on your address to copy the address. Ask the team to fund some money to your address. For transfer, go to Portfolio page, for staking go Validators page (pick a validator for staking/unstaking). Click on transfer Send, or Stake for staking, Unstake for unstaking. Then Next, Next, NexT. You would see H icon with label 1 like below. Click on that and specify password for signing and sending the txn to the network.","title":"Installation"},{"location":"validate/validator-troubleshooting/","text":"Troubleshooting","title":"Troubleshooting"},{"location":"validate/validator-troubleshooting/#troubleshooting","text":"","title":"Troubleshooting"},{"location":"validate/validator-troubleshooting/technical-faq/","text":"Technical FAQ Q: A:","title":"Technical FAQ"},{"location":"validate/validator-troubleshooting/technical-faq/#technical-faq","text":"Q: A:","title":"Technical FAQ"},{"location":"validate/validator-troubleshooting/why-am-i-not-elected-in-the-epos-committee/","text":"Why am I not elected in the EPOS Committee EPOS medium document https://harmony.one/epos Now let\u2019s get into action. Non election in the EPOS committee are caused by two main issues : Your validator profile needs to have satisfactory conditions current total stake has to be among the 320 highest stake before the change of next epoch Active flag needs to be true The numbers of block signed per epoch needs to be above 66% Your node needs to be functional Fully synced Signing blocks Validator profile need to satisfy the below Bidding for a place in the EPOS committee Verify the median stake {% tabs %} {% tab title=\"CLI\" %} ./hmy --node=\"https://api.s0.t.hmny.io\" blockchain median-stake | grep median \"epos-median-stake\": \"1550000000000000000000000.000000000000000000\", {% endtab %} {% tab title=\"Staking Explorer\" %} go to : https://staking.harmony.one/validators {% endtab %} {% endtabs %} {% hint style=\"success\" %} the CLI returned a value in wei, it can be converted online converter like https://eth-converter.com/ {% endhint %} Total delegation is above the median stake Visit https://staking.harmony.one/validators/ <youroneaccount> Example : https://staking.harmony.one/validators/one1u6c4wer2dkm767hmjeehnwu6tqqur62gx9vqsd Your current total stake has to be among the 320 highest stake slots before the change of next epoch. For that, one way to make sure of it is to be near / above the median stake. Being just above the last bidder would ensure your a place but it is risky as you might be outbid during the next election. If you are not above the median stake then time to ask for more delegation or delegate yourself more ONE token following this doc on how to delegate more ONE token . {% hint style=\"info\" %} Make sure your max-total-delegation is high enough and above the median stake so your added delegation work {% endhint %} Your validator node epos-eligibility-status flag needs to be active Issue the command ./hmy -n https://api.s0.t.hmny.io blockchain validator information [VALIDATOR-ACCOUNT] | grep epos-status ./hmy --node=\"https://api.s0.t.hmny.io\" blockchain validator information one1u6c4wer2dkm767hmjeehnwu6tqqur62gx9vqsd | grep epos-status \"epos-status\": \"currently elected\", If not eligible , update it to active via the command ./hmy -n https://api.s0.t.hmny.io staking edit-validator --validator-addr <ONE_VALIDATOR_ACCOUNT> --active true --passphrase {% tabs %} {% tab title=\"Mainnet\" %} ./hmy --node=\"https://api.s0.t.hmny.io\" staking edit-validator --validator-addr one1u6c4wer2dkm767hmjeehnwu6tqqur62gx9vqsd --active true --passphrase {% endtab %} {% endtabs %} Finally check your signed blocked using the command ./hmy -n https://api.s0.t.hmny.io blockchain validator information <ONE_VALIDATOR_ACCOUNT> {% tabs %} {% tab title=\"Mainnet\" %} ./hmy --node=\"https://api.s0.t.hmny.io\" blockchain validator information one1u6c4wer2dkm767hmjeehnwu6tqqur62gx9vqsd {% endtab %} {% endtabs %} and search for : \"current-epoch-performance\": { \"current-epoch-signing-percent\": { \"current-epoch-signed\": 50, \"current-epoch-signing-percentage\": \"0.500000000000000000\", \"current-epoch-to-sign\": 100, \"num-beacon-blocks-until-next-epoch\": 28 } }, For your validator to stay elected, you wanna make sure the current-epoch-signing-percentage is above 66% (0.66). To fix the above, we have to make sure the node is working correctly and below are few pointers Your node needs to be functional Fully synced node Compare your block height ./hmy blockchain latest-headers | grep block-number {% hint style=\"danger\" %} If the above doesn\u2019t work and you have an error message similar to this: commit: v304-0e26945, error: dial tcp4 127.0.0.1:9500: connect: connection refused It means the harmony node binary is not running. Please follow this documentation on how to run the node . {% endhint %} and the network block height {% tabs %} {% tab title=\"Mainnet\" %} ./hmy --node=\"https://api.s0.t.hmny.io\" blockchain latest-headers | grep blockNumber {% endtab %} {% endtabs %} Make sure network height and your current height are very close or equal. Also, for non shard 0 node, you need 2 DBs to be synced, your non-shard 0 and the shard 0. {% hint style=\"info\" %} the above command is for network height on shard 0, change s0 to s1, s2, .. to match yours in the api URL {% endhint %} When you are fully synced and your validator profile is satisfactory you should start having BINGOs in your validator log file at epoch change . You can check BINGOs via this command tail -f latest/zero*.log | grep BINGO And you\u2019ll notice in your validator information that you started signing blocks \"current-epoch-performance\": { \"current-epoch-signing-percent\": { \"current-epoch-signed\": 60, \"current-epoch-signing-percentage\": \"1.000000000000000000\", \"current-epoch-to-sign\": 60, \"num-beacon-blocks-until-next-epoch\": 28 } }, If you fail to sign blocks, verify your machine/vps doesn't have CPU/memory/hard disk/internet issues. When you fail to sign more than 66% of the blocks in an epoch, you\u2019ll be kicked out from the committee","title":"Why am I not elected in the EPOS Committee"},{"location":"validate/validator-troubleshooting/why-am-i-not-elected-in-the-epos-committee/#why-am-i-not-elected-in-the-epos-committee","text":"","title":"Why am I not elected in the EPOS Committee"},{"location":"validate/validator-troubleshooting/why-am-i-not-elected-in-the-epos-committee/#epos-medium-document","text":"https://harmony.one/epos","title":"EPOS medium document"},{"location":"validate/validator-troubleshooting/why-am-i-not-elected-in-the-epos-committee/#now-lets-get-into-action","text":"Non election in the EPOS committee are caused by two main issues : Your validator profile needs to have satisfactory conditions current total stake has to be among the 320 highest stake before the change of next epoch Active flag needs to be true The numbers of block signed per epoch needs to be above 66% Your node needs to be functional Fully synced Signing blocks","title":"Now let\u2019s get into action."},{"location":"validate/validator-troubleshooting/why-am-i-not-elected-in-the-epos-committee/#validator-profile-need-to-satisfy-the-below","text":"","title":"Validator profile need to satisfy the below"},{"location":"validate/validator-troubleshooting/why-am-i-not-elected-in-the-epos-committee/#bidding-for-a-place-in-the-epos-committee","text":"","title":"Bidding for a place in the EPOS committee"},{"location":"validate/validator-troubleshooting/why-am-i-not-elected-in-the-epos-committee/#verify-the-median-stake","text":"{% tabs %} {% tab title=\"CLI\" %} ./hmy --node=\"https://api.s0.t.hmny.io\" blockchain median-stake | grep median \"epos-median-stake\": \"1550000000000000000000000.000000000000000000\", {% endtab %} {% tab title=\"Staking Explorer\" %} go to : https://staking.harmony.one/validators {% endtab %} {% endtabs %} {% hint style=\"success\" %} the CLI returned a value in wei, it can be converted online converter like https://eth-converter.com/ {% endhint %}","title":"Verify the median stake"},{"location":"validate/validator-troubleshooting/why-am-i-not-elected-in-the-epos-committee/#total-delegation-is-above-the-median-stake","text":"Visit https://staking.harmony.one/validators/ <youroneaccount> Example : https://staking.harmony.one/validators/one1u6c4wer2dkm767hmjeehnwu6tqqur62gx9vqsd Your current total stake has to be among the 320 highest stake slots before the change of next epoch. For that, one way to make sure of it is to be near / above the median stake. Being just above the last bidder would ensure your a place but it is risky as you might be outbid during the next election. If you are not above the median stake then time to ask for more delegation or delegate yourself more ONE token following this doc on how to delegate more ONE token . {% hint style=\"info\" %} Make sure your max-total-delegation is high enough and above the median stake so your added delegation work {% endhint %}","title":"Total delegation is above the median stake"},{"location":"validate/validator-troubleshooting/why-am-i-not-elected-in-the-epos-committee/#your-validator-node-epos-eligibility-status-flag-needs-to-be-active","text":"Issue the command ./hmy -n https://api.s0.t.hmny.io blockchain validator information [VALIDATOR-ACCOUNT] | grep epos-status ./hmy --node=\"https://api.s0.t.hmny.io\" blockchain validator information one1u6c4wer2dkm767hmjeehnwu6tqqur62gx9vqsd | grep epos-status \"epos-status\": \"currently elected\", If not eligible , update it to active via the command ./hmy -n https://api.s0.t.hmny.io staking edit-validator --validator-addr <ONE_VALIDATOR_ACCOUNT> --active true --passphrase {% tabs %} {% tab title=\"Mainnet\" %} ./hmy --node=\"https://api.s0.t.hmny.io\" staking edit-validator --validator-addr one1u6c4wer2dkm767hmjeehnwu6tqqur62gx9vqsd --active true --passphrase {% endtab %} {% endtabs %} Finally check your signed blocked using the command ./hmy -n https://api.s0.t.hmny.io blockchain validator information <ONE_VALIDATOR_ACCOUNT> {% tabs %} {% tab title=\"Mainnet\" %} ./hmy --node=\"https://api.s0.t.hmny.io\" blockchain validator information one1u6c4wer2dkm767hmjeehnwu6tqqur62gx9vqsd {% endtab %} {% endtabs %} and search for : \"current-epoch-performance\": { \"current-epoch-signing-percent\": { \"current-epoch-signed\": 50, \"current-epoch-signing-percentage\": \"0.500000000000000000\", \"current-epoch-to-sign\": 100, \"num-beacon-blocks-until-next-epoch\": 28 } }, For your validator to stay elected, you wanna make sure the current-epoch-signing-percentage is above 66% (0.66). To fix the above, we have to make sure the node is working correctly and below are few pointers","title":"Your validator node epos-eligibility-status flag needs to be active"},{"location":"validate/validator-troubleshooting/why-am-i-not-elected-in-the-epos-committee/#your-node-needs-to-be-functional","text":"","title":"Your node needs to be functional"},{"location":"validate/validator-troubleshooting/why-am-i-not-elected-in-the-epos-committee/#fully-synced-node","text":"Compare your block height ./hmy blockchain latest-headers | grep block-number {% hint style=\"danger\" %} If the above doesn\u2019t work and you have an error message similar to this: commit: v304-0e26945, error: dial tcp4 127.0.0.1:9500: connect: connection refused It means the harmony node binary is not running. Please follow this documentation on how to run the node . {% endhint %} and the network block height {% tabs %} {% tab title=\"Mainnet\" %} ./hmy --node=\"https://api.s0.t.hmny.io\" blockchain latest-headers | grep blockNumber {% endtab %} {% endtabs %} Make sure network height and your current height are very close or equal. Also, for non shard 0 node, you need 2 DBs to be synced, your non-shard 0 and the shard 0. {% hint style=\"info\" %} the above command is for network height on shard 0, change s0 to s1, s2, .. to match yours in the api URL {% endhint %} When you are fully synced and your validator profile is satisfactory you should start having BINGOs in your validator log file at epoch change . You can check BINGOs via this command tail -f latest/zero*.log | grep BINGO And you\u2019ll notice in your validator information that you started signing blocks \"current-epoch-performance\": { \"current-epoch-signing-percent\": { \"current-epoch-signed\": 60, \"current-epoch-signing-percentage\": \"1.000000000000000000\", \"current-epoch-to-sign\": 60, \"num-beacon-blocks-until-next-epoch\": 28 } }, If you fail to sign blocks, verify your machine/vps doesn't have CPU/memory/hard disk/internet issues. When you fail to sign more than 66% of the blocks in an epoch, you\u2019ll be kicked out from the committee","title":"Fully synced node"}]}